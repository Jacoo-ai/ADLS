{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 12:17:44,114] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.669100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.464600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:20:09,888] Trial 0 finished with value: 0.80772 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.80772.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:22:42,868] Trial 1 finished with value: 0.85248 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:25:06,632] Trial 2 finished with value: 0.84712 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:27:30,320] Trial 3 finished with value: 0.81892 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:29:54,689] Trial 4 finished with value: 0.8486 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:32:08,697] Trial 5 finished with value: 0.80188 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:34:18,755] Trial 6 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:36:37,296] Trial 7 finished with value: 0.84712 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:39:00,638] Trial 8 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:41:21,329] Trial 9 finished with value: 0.8486 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:43:44,921] Trial 10 finished with value: 0.8524 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:45:59,458] Trial 11 finished with value: 0.81892 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:48:21,857] Trial 12 finished with value: 0.85248 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:50:42,281] Trial 13 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:52:59,495] Trial 14 finished with value: 0.84712 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:55:13,973] Trial 15 finished with value: 0.80188 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:57:29,013] Trial 16 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 12:59:49,615] Trial 17 finished with value: 0.8486 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:02:03,844] Trial 18 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:04:18,355] Trial 19 finished with value: 0.80188 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:06:29,786] Trial 20 finished with value: 0.81052 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:08:46,889] Trial 21 finished with value: 0.8486 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:10:56,313] Trial 22 finished with value: 0.801 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:13:10,194] Trial 23 finished with value: 0.80188 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:15:30,739] Trial 24 finished with value: 0.8524 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:17:42,373] Trial 25 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:20:03,610] Trial 26 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:22:25,677] Trial 27 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:24:35,713] Trial 28 finished with value: 0.801 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:26:47,126] Trial 29 finished with value: 0.801 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:28:57,168] Trial 30 finished with value: 0.801 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 1 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:31:16,361] Trial 31 finished with value: 0.84712 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.85248.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import GridSampler, TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4],\n",
    "    \"num_heads\": [2, 4],\n",
    "    \"hidden_size\": [128, 192],\n",
    "    \"intermediate_size\": [512, 768],\n",
    "    \"linear_layer_type\": [\"linear\", \"identity\"],  # 用字符串代替类名\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        # chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # # 将选中的值设置到 config 中\n",
    "        # print(f\"Param is {param}\")\n",
    "        # print(f\"Choose from 0 to {len(search_space[param]) - 1}\")\n",
    "        # print(f\"Idx is {chosen_idx}\")\n",
    "        # setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            # new_layer_cls = trial.suggest_categorical(\n",
    "            #     f\"{name}_type\",\n",
    "            #     search_space[\"linear_layer_choices\"],\n",
    "            # )\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    # 获取当前 trial 结果\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params  # 记录所有超参数\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_trial_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = GridSampler(search_space=search_space)\n",
    "n_trial = np.prod([len(v) for v in search_space.values()])  # 600\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 60 * 24,\n",
    ")\n",
    "\n",
    "# 获取所有 trial 的准确率\n",
    "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# 计算累积最大准确率\n",
    "best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"GridSampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Grid Search Performance on BERT-tiny NAS\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 19:04:10,294] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.530100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:06:37,697] Trial 0 finished with value: 0.81792 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.81792.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:08:59,258] Trial 1 finished with value: 0.801 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.81792.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:11:22,623] Trial 2 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 2 with value: 0.81892.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:13:44,648] Trial 3 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 2 with value: 0.81892.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:16:11,671] Trial 4 finished with value: 0.84712 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 4 with value: 0.84712.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:18:35,490] Trial 5 finished with value: 0.81892 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 4 with value: 0.84712.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:20:55,034] Trial 6 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 4 with value: 0.84712.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:23:22,478] Trial 7 finished with value: 0.84712 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 4 with value: 0.84712.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:25:53,910] Trial 8 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:28:20,618] Trial 9 finished with value: 0.81892 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:30:48,440] Trial 10 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:33:17,456] Trial 11 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:35:42,324] Trial 12 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:38:06,540] Trial 13 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:40:33,737] Trial 14 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:43:02,800] Trial 15 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:45:26,891] Trial 16 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:47:54,019] Trial 17 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:50:16,990] Trial 18 finished with value: 0.8486 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:52:46,037] Trial 19 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:55:12,895] Trial 20 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 19:57:39,969] Trial 21 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:00:08,629] Trial 22 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:02:35,755] Trial 23 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:05:07,683] Trial 24 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:07:37,787] Trial 25 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:10:03,813] Trial 26 finished with value: 0.8486 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:12:34,286] Trial 27 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:15:03,332] Trial 28 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:17:32,972] Trial 29 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:20:04,849] Trial 30 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 20:22:34,514] Trial 31 finished with value: 0.85248 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 8 with value: 0.85248.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import GridSampler, TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4],\n",
    "    \"num_heads\": [2, 4],\n",
    "    \"hidden_size\": [128, 192],\n",
    "    \"intermediate_size\": [512, 768],\n",
    "    \"linear_layer_type\": [\"linear\", \"identity\"],\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        # chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # # 将选中的值设置到 config 中\n",
    "        # print(f\"Param is {param}\")\n",
    "        # print(f\"Choose from 0 to {len(search_space[param]) - 1}\")\n",
    "        # print(f\"Idx is {chosen_idx}\")\n",
    "        # setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            # new_layer_cls = trial.suggest_categorical(\n",
    "            #     f\"{name}_type\",\n",
    "            #     search_space[\"linear_layer_choices\"],\n",
    "            # )\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    # 获取当前 trial 结果\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params  # 记录所有超参数\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_trial_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = TPESampler()\n",
    "n_trial = 32\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 60 * 24,\n",
    ")\n",
    "\n",
    "# 获取所有 trial 的准确率\n",
    "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# 计算累积最大准确率\n",
    "best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"TPESampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"TPESampler Performance on BERT-tiny NAS\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 读取 JSON 数据\n",
    "file_path = \"lab2_trial_results.json\"  # 你的 JSON 文件路径\n",
    "with open(file_path, \"r\") as f:\n",
    "    trials = [json.loads(line) for line in f]\n",
    "\n",
    "# 确保数据正确\n",
    "num_trials_per_sampler = len(trials) // 2  \n",
    "grid_trials = trials[:num_trials_per_sampler]\n",
    "tpe_trials = trials[num_trials_per_sampler:]\n",
    "\n",
    "# 提取 trial 号 和 accuracy\n",
    "grid_trial_numbers = [t[\"trial\"] for t in grid_trials]\n",
    "grid_accuracies = [t[\"accuracy\"] for t in grid_trials]\n",
    "\n",
    "tpe_trial_numbers = [t[\"trial\"] for t in tpe_trials]\n",
    "tpe_accuracies = [t[\"accuracy\"] for t in tpe_trials]\n",
    "\n",
    "# 计算累计最大 accuracy\n",
    "grid_best_so_far = np.maximum.accumulate(grid_accuracies)\n",
    "tpe_best_so_far = np.maximum.accumulate(tpe_accuracies)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(grid_trial_numbers, grid_best_so_far, marker='o', linestyle='-', label=\"GridSampler\")\n",
    "plt.plot(tpe_trial_numbers, tpe_best_so_far, marker='s', linestyle='-', label=\"TPESampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Comparison of GridSampler vs. TPESampler Performance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "[I 2025-02-12 18:54:28,705] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/local/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 08:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.334000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.259600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.263600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-12 19:03:52,118] Trial 0 finished with value: 0.87892 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.87892.\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import GridSampler, TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2],\n",
    "    \"num_heads\": [2],\n",
    "    \"hidden_size\": [128],\n",
    "    \"intermediate_size\": [512],\n",
    "    \"linear_layer_type\": [\"linear\"],\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=4,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    # 获取当前 trial 结果\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params  # 记录所有超参数\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_epoch1_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = TPESampler()\n",
    "n_trial = 1\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 60 * 24,\n",
    ")\n",
    "\n",
    "# # 获取所有 trial 的准确率\n",
    "# trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "# accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# # 计算累积最大准确率\n",
    "# best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# # 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"TPESampler\")\n",
    "\n",
    "# plt.xlabel(\"Number of Trials\")\n",
    "# plt.ylabel(\"Best Accuracy Achieved\")\n",
    "# plt.title(\"TPESampler Performance on BERT-tiny NAS\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# 0.84272\n",
    "# 0.86252\n",
    "# 0.87892\n",
    "# 0.87892\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 数据\n",
    "epochs = [1, 2, 3, 4]\n",
    "accuracy = [0.84272, 0.86252, 0.87892, 0.87892]\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(epochs, accuracy, marker='o', linestyle='-', color='b')\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title(\"Accuracy vs. Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.84, 0.88)  # 适当调整 y 轴范围\n",
    "\n",
    "# 显示数据点\n",
    "for x, y in zip(epochs, accuracy):\n",
    "    plt.text(x, y, f\"{y:.5f}\", ha='right', va='bottom', fontsize=10)\n",
    "\n",
    "# 显示网格\n",
    "plt.grid(True)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 读取 JSON 数据\n",
    "file_path = \"lab2_trial_results.json\"  # 你的 JSON 文件路径\n",
    "with open(file_path, \"r\") as f:\n",
    "    trials = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "records = []\n",
    "for trial in trials:\n",
    "    params = trial[\"params\"]\n",
    "    params[\"accuracy\"] = trial[\"accuracy\"]\n",
    "    records.append(params)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 设置 Seaborn 样式\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 画箱线图\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate([\"num_layers\", \"num_heads\", \"hidden_size\", \"intermediate_size\", \"linear_layer_type\"]):\n",
    "    sns.boxplot(x=df[param], y=df[\"accuracy\"], ax=axes[i])\n",
    "    axes[i].set_title(f\"Accuracy Distribution for {param}\")\n",
    "\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 No compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[I 2025-01-31 00:11:23,769] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:13:55,140] Trial 0 finished with value: 0.8524 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:16:18,960] Trial 1 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:18:45,869] Trial 2 finished with value: 0.81892 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:21:08,704] Trial 3 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:23:31,871] Trial 4 finished with value: 0.80188 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:25:51,057] Trial 5 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:28:09,588] Trial 6 finished with value: 0.81052 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:30:26,238] Trial 7 finished with value: 0.81052 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:32:46,655] Trial 8 finished with value: 0.80188 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:35:10,040] Trial 9 finished with value: 0.81892 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.8524.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "import torch\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4],\n",
    "    \"num_heads\": [2, 4],\n",
    "    \"hidden_size\": [128, 192],\n",
    "    \"intermediate_size\": [512, 768],\n",
    "    \"linear_layer_type\": [\"linear\", \"identity\"],  # 用字符串代替类名\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        # chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # # 将选中的值设置到 config 中\n",
    "        # print(f\"Param is {param}\")\n",
    "        # print(f\"Choose from 0 to {len(search_space[param]) - 1}\")\n",
    "        # print(f\"Idx is {chosen_idx}\")\n",
    "        # setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            # new_layer_cls = trial.suggest_categorical(\n",
    "            #     f\"{name}_type\",\n",
    "            #     search_space[\"linear_layer_choices\"],\n",
    "            # )\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 确定运行设备\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial).to(device)  # 将模型移动到 GPU\n",
    "\n",
    "    # Train a few epoches\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "    \n",
    "    # 获取当前 trial 结果\n",
    "    eval_results = trainer.evaluate()\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params,  # 记录所有超参数\n",
    "        \"compression\": True,\n",
    "        \"post_training\": False  # 这里标记未进行 post-training\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_no_com_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = TPESampler()\n",
    "n_trial = 10\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 60* 24,\n",
    ")\n",
    "\n",
    "# 获取所有 trial 的准确率\n",
    "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# 计算累积最大准确率\n",
    "best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"GridSampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Grid Search Performance on BERT-tiny NAS\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Compression-Aware (No Post-Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:15:35,297] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.549100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.402800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.362300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-0.1017,  0.2667, -0.3961,  ..., -0.4096,  0.1208, -0.3852],\n",
      "         [ 0.1788,  0.2400, -0.4952,  ..., -0.4038,  0.4661,  0.4043],\n",
      "         [-0.4839, -0.1359, -0.3833,  ..., -0.0537,  0.3961, -0.0469],\n",
      "         ...,\n",
      "         [ 0.2637,  0.4258, -0.6065,  ..., -0.6663,  0.3348,  0.4906],\n",
      "         [ 0.2168,  0.2976, -0.1845,  ...,  0.1425, -0.0594,  0.3576],\n",
      "         [-0.0652,  0.7450, -0.8085,  ..., -0.3963,  0.1872, -0.2022]],\n",
      "\n",
      "        [[-0.3621,  0.0776, -0.2548,  ..., -0.2447,  0.0706, -0.1902],\n",
      "         [ 0.1322,  0.1477, -0.6995,  ..., -0.2466,  0.7332,  0.1717],\n",
      "         [-0.4933, -0.2203, -0.4847,  ...,  0.1279,  0.4591,  0.1163],\n",
      "         ...,\n",
      "         [-0.0520,  0.1863, -0.6266,  ..., -0.3710,  0.5309,  0.3433],\n",
      "         [ 0.1541,  0.1433, -0.4919,  ...,  0.2357, -0.0119,  0.1726],\n",
      "         [ 0.1247,  0.5274, -0.8691,  ..., -0.2056,  0.1716, -0.1589]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1017,  0.2667, -0.3961,  ..., -0.4096,  0.1208, -0.3852],\n",
      "         [ 0.1788,  0.2400, -0.4952,  ..., -0.4038,  0.4661,  0.4043],\n",
      "         [-0.4839, -0.1359, -0.3833,  ..., -0.0537,  0.3961, -0.0469],\n",
      "         ...,\n",
      "         [ 0.2637,  0.4258, -0.6065,  ..., -0.6663,  0.3348,  0.4906],\n",
      "         [ 0.2168,  0.2976, -0.1845,  ...,  0.1425, -0.0594,  0.3576],\n",
      "         [-0.0652,  0.7450, -0.8085,  ..., -0.3963,  0.1872, -0.2022]],\n",
      "\n",
      "        [[-0.3621,  0.0776, -0.2548,  ..., -0.2447,  0.0706, -0.1902],\n",
      "         [ 0.1322,  0.1477, -0.6995,  ..., -0.2466,  0.7332,  0.1717],\n",
      "         [-0.4933, -0.2203, -0.4847,  ...,  0.1279,  0.4591,  0.1163],\n",
      "         ...,\n",
      "         [-0.0520,  0.1863, -0.6266,  ..., -0.3710,  0.5309,  0.3433],\n",
      "         [ 0.1541,  0.1433, -0.4919,  ...,  0.2357, -0.0119,  0.1726],\n",
      "         [ 0.1247,  0.5274, -0.8691,  ..., -0.2056,  0.1716, -0.1589]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1017,  0.2667, -0.3961,  ..., -0.1019, -0.3998,  0.4572],\n",
      "          [-0.6733,  0.4051,  0.6246,  ..., -0.4096,  0.1208, -0.3852]],\n",
      "\n",
      "         [[ 0.1788,  0.2400, -0.4952,  ..., -0.2368, -0.3572,  0.0864],\n",
      "          [-0.9101,  0.2780,  0.6456,  ..., -0.4038,  0.4661,  0.4043]],\n",
      "\n",
      "         [[-0.4839, -0.1359, -0.3833,  ..., -0.4073,  0.0606,  0.1806],\n",
      "          [-0.5164, -0.0112,  0.9339,  ..., -0.0537,  0.3961, -0.0469]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2637,  0.4258, -0.6065,  ...,  0.3063, -0.8053,  0.4314],\n",
      "          [-0.7554,  0.5587,  0.9609,  ..., -0.6663,  0.3348,  0.4906]],\n",
      "\n",
      "         [[ 0.2168,  0.2976, -0.1845,  ...,  0.0349, -0.3227,  0.1830],\n",
      "          [-0.1580,  0.0601, -0.5007,  ...,  0.1425, -0.0594,  0.3576]],\n",
      "\n",
      "         [[-0.0652,  0.7450, -0.8085,  ..., -0.1194, -0.5731,  0.6306],\n",
      "          [-0.6910,  0.4579,  0.0222,  ..., -0.3963,  0.1872, -0.2022]]],\n",
      "\n",
      "\n",
      "        [[[-0.3621,  0.0776, -0.2548,  ..., -0.1647, -0.1810,  0.6740],\n",
      "          [-0.3419,  0.5771,  0.6066,  ..., -0.2447,  0.0706, -0.1902]],\n",
      "\n",
      "         [[ 0.1322,  0.1477, -0.6995,  ...,  0.2565, -0.6907,  0.7262],\n",
      "          [-1.1376,  0.3412,  0.7574,  ..., -0.2466,  0.7332,  0.1717]],\n",
      "\n",
      "         [[-0.4933, -0.2203, -0.4847,  ..., -0.0882,  0.1223, -0.1151],\n",
      "          [-0.2050,  0.1208,  0.6461,  ...,  0.1279,  0.4591,  0.1163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0520,  0.1863, -0.6266,  ...,  0.1048, -0.8125,  0.3463],\n",
      "          [-0.3355,  0.4293,  0.4963,  ..., -0.3710,  0.5309,  0.3433]],\n",
      "\n",
      "         [[ 0.1541,  0.1433, -0.4919,  ...,  0.4463, -0.3872,  0.5267],\n",
      "          [-0.4665,  0.3534, -0.0510,  ...,  0.2357, -0.0119,  0.1726]],\n",
      "\n",
      "         [[ 0.1247,  0.5274, -0.8691,  ..., -0.1129, -0.6693,  0.6435],\n",
      "          [-0.8725,  0.2511, -0.0066,  ..., -0.2056,  0.1716, -0.1589]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5068, -0.0829, -0.5578,  ...,  0.0341, -0.3409, -0.5965],\n",
      "         [ 0.5861,  0.1594, -0.4202,  ..., -0.1287,  0.0263,  0.4914],\n",
      "         [-0.0806, -0.0767, -0.4942,  ..., -0.2574,  0.2821,  0.0607],\n",
      "         ...,\n",
      "         [ 0.6053,  0.4607, -0.6631,  ..., -0.2513, -0.1876,  0.2139],\n",
      "         [-0.3257,  0.6876, -0.9594,  ..., -0.2622,  0.1021, -0.1632],\n",
      "         [ 0.3595,  0.1969, -0.6945,  ..., -0.1786, -0.3106,  0.4293]],\n",
      "\n",
      "        [[ 0.5703, -0.1177, -0.6202,  ...,  0.1151, -0.3054, -0.4332],\n",
      "         [ 0.6672, -0.1928, -0.6036,  ...,  0.4608,  0.0577,  0.1190],\n",
      "         [-0.1635,  0.1566, -0.7579,  ..., -0.0845,  0.1494, -0.3241],\n",
      "         ...,\n",
      "         [ 0.4576,  0.2912, -0.0792,  ..., -0.1377, -0.5739,  0.3041],\n",
      "         [ 0.1790, -0.0235, -0.5770,  ..., -0.3583, -0.0292,  0.0561],\n",
      "         [ 0.6218,  0.1341, -0.6303,  ..., -0.1984, -0.3014,  0.2772]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5068, -0.0829, -0.5578,  ...,  0.0341, -0.3409, -0.5965],\n",
      "         [ 0.5861,  0.1594, -0.4202,  ..., -0.1287,  0.0263,  0.4914],\n",
      "         [-0.0806, -0.0767, -0.4942,  ..., -0.2574,  0.2821,  0.0607],\n",
      "         ...,\n",
      "         [ 0.6053,  0.4607, -0.6631,  ..., -0.2513, -0.1876,  0.2139],\n",
      "         [-0.3257,  0.6876, -0.9594,  ..., -0.2622,  0.1021, -0.1632],\n",
      "         [ 0.3595,  0.1969, -0.6945,  ..., -0.1786, -0.3106,  0.4293]],\n",
      "\n",
      "        [[ 0.5703, -0.1177, -0.6202,  ...,  0.1151, -0.3054, -0.4332],\n",
      "         [ 0.6672, -0.1928, -0.6036,  ...,  0.4608,  0.0577,  0.1190],\n",
      "         [-0.1635,  0.1566, -0.7579,  ..., -0.0845,  0.1494, -0.3241],\n",
      "         ...,\n",
      "         [ 0.4576,  0.2912, -0.0792,  ..., -0.1377, -0.5739,  0.3041],\n",
      "         [ 0.1790, -0.0235, -0.5770,  ..., -0.3583, -0.0292,  0.0561],\n",
      "         [ 0.6218,  0.1341, -0.6303,  ..., -0.1984, -0.3014,  0.2772]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5068, -0.0829, -0.5578,  ...,  0.0193, -0.2766, -0.0648],\n",
      "          [-0.2002, -0.3375, -0.2751,  ...,  0.0341, -0.3409, -0.5965]],\n",
      "\n",
      "         [[ 0.5861,  0.1594, -0.4202,  ..., -0.1767,  0.0058, -0.0424],\n",
      "          [ 0.5212, -0.5092, -0.4043,  ..., -0.1287,  0.0263,  0.4914]],\n",
      "\n",
      "         [[-0.0806, -0.0767, -0.4942,  ...,  0.0535,  0.2869, -0.4909],\n",
      "          [-0.2152, -0.5267,  0.1021,  ..., -0.2574,  0.2821,  0.0607]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6053,  0.4607, -0.6631,  ...,  0.3184,  0.5300, -0.3752],\n",
      "          [ 0.1186, -0.8422, -0.2286,  ..., -0.2513, -0.1876,  0.2139]],\n",
      "\n",
      "         [[-0.3257,  0.6876, -0.9594,  ...,  0.3925, -0.0475, -0.2982],\n",
      "          [ 0.1275, -0.4437, -0.2582,  ..., -0.2622,  0.1021, -0.1632]],\n",
      "\n",
      "         [[ 0.3595,  0.1969, -0.6945,  ...,  0.3886,  0.0340, -0.4090],\n",
      "          [ 0.8215, -0.5363, -0.3445,  ..., -0.1786, -0.3106,  0.4293]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5703, -0.1177, -0.6202,  ...,  0.1433, -0.1944,  0.1203],\n",
      "          [-0.4274, -0.4825, -0.4474,  ...,  0.1151, -0.3054, -0.4332]],\n",
      "\n",
      "         [[ 0.6672, -0.1928, -0.6036,  ...,  0.1190, -0.2837,  0.2240],\n",
      "          [ 0.3085, -0.0910, -0.3511,  ...,  0.4608,  0.0577,  0.1190]],\n",
      "\n",
      "         [[-0.1635,  0.1566, -0.7579,  ...,  0.7951,  0.6029, -0.5559],\n",
      "          [ 0.2394, -0.4216,  0.3412,  ..., -0.0845,  0.1494, -0.3241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4576,  0.2912, -0.0792,  ...,  0.4382,  0.0498,  0.2010],\n",
      "          [ 0.4621, -0.0992, -0.4189,  ..., -0.1377, -0.5739,  0.3041]],\n",
      "\n",
      "         [[ 0.1790, -0.0235, -0.5770,  ...,  0.0874, -0.0729, -0.1918],\n",
      "          [ 0.0651, -0.2616, -0.7070,  ..., -0.3583, -0.0292,  0.0561]],\n",
      "\n",
      "         [[ 0.6218,  0.1341, -0.6303,  ...,  0.3999, -0.1363, -0.3605],\n",
      "          [ 0.8099, -0.3457, -0.1647,  ..., -0.1984, -0.3014,  0.2772]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1124, -1.1372,  1.2353,  ...,  1.9863, -0.9297, -0.2599],\n",
      "         [-0.4520, -0.0588,  0.5614,  ...,  0.5484, -0.1822, -0.4611],\n",
      "         [-0.2724,  0.2245,  0.2468,  ...,  0.7252, -0.5589, -0.1467],\n",
      "         ...,\n",
      "         [-0.6961, -0.1450,  0.0253,  ...,  0.5501, -0.1207,  0.1618],\n",
      "         [-0.4338, -0.0749,  0.4322,  ...,  0.4558,  0.2832, -0.0295],\n",
      "         [ 0.0238, -0.2361,  0.3185,  ...,  0.8978,  0.1612, -0.4849]],\n",
      "\n",
      "        [[-1.0954, -1.2023,  1.0354,  ...,  1.7170, -0.8899, -0.1872],\n",
      "         [-0.5407,  0.1023,  0.8757,  ...,  1.0421, -0.0434, -0.6357],\n",
      "         [-0.3490,  0.5992,  0.6237,  ...,  0.6215, -0.3795,  0.0462],\n",
      "         ...,\n",
      "         [-0.8605, -0.4331,  0.1283,  ...,  0.6879, -0.3193,  0.1487],\n",
      "         [-0.6311, -0.4540,  0.9015,  ...,  1.0942, -0.0131, -0.5042],\n",
      "         [-0.1377, -0.1573,  0.2329,  ...,  0.9282, -0.0121, -0.5795]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1124, -1.1372,  1.2353,  ...,  1.9863, -0.9297, -0.2599],\n",
      "         [-0.4520, -0.0588,  0.5614,  ...,  0.5484, -0.1822, -0.4611],\n",
      "         [-0.2724,  0.2245,  0.2468,  ...,  0.7252, -0.5589, -0.1467],\n",
      "         ...,\n",
      "         [-0.6961, -0.1450,  0.0253,  ...,  0.5501, -0.1207,  0.1618],\n",
      "         [-0.4338, -0.0749,  0.4322,  ...,  0.4558,  0.2832, -0.0295],\n",
      "         [ 0.0238, -0.2361,  0.3185,  ...,  0.8978,  0.1612, -0.4849]],\n",
      "\n",
      "        [[-1.0954, -1.2023,  1.0354,  ...,  1.7170, -0.8899, -0.1872],\n",
      "         [-0.5407,  0.1023,  0.8757,  ...,  1.0421, -0.0434, -0.6357],\n",
      "         [-0.3490,  0.5992,  0.6237,  ...,  0.6215, -0.3795,  0.0462],\n",
      "         ...,\n",
      "         [-0.8605, -0.4331,  0.1283,  ...,  0.6879, -0.3193,  0.1487],\n",
      "         [-0.6311, -0.4540,  0.9015,  ...,  1.0942, -0.0131, -0.5042],\n",
      "         [-0.1377, -0.1573,  0.2329,  ...,  0.9282, -0.0121, -0.5795]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1124e+00, -1.1372e+00,  1.2353e+00,  ..., -1.3627e+00,\n",
      "            1.6662e+00, -4.7457e-01],\n",
      "          [ 1.0156e+00, -1.0939e+00, -1.0782e+00,  ...,  1.9863e+00,\n",
      "           -9.2973e-01, -2.5989e-01]],\n",
      "\n",
      "         [[-4.5202e-01, -5.8796e-02,  5.6137e-01,  ..., -6.6385e-01,\n",
      "            8.9823e-01, -4.2515e-01],\n",
      "          [ 5.6434e-01,  6.1256e-01, -4.7142e-01,  ...,  5.4839e-01,\n",
      "           -1.8217e-01, -4.6108e-01]],\n",
      "\n",
      "         [[-2.7244e-01,  2.2452e-01,  2.4684e-01,  ..., -4.5179e-01,\n",
      "            1.1326e+00, -1.6643e-02],\n",
      "          [ 4.2146e-01, -1.0087e-01, -2.4996e-01,  ...,  7.2523e-01,\n",
      "           -5.5894e-01, -1.4669e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9614e-01, -1.4497e-01,  2.5320e-02,  ..., -5.0999e-01,\n",
      "            4.3973e-02, -1.4219e-01],\n",
      "          [-1.5380e-01, -1.4980e-01, -6.3802e-01,  ...,  5.5008e-01,\n",
      "           -1.2071e-01,  1.6179e-01]],\n",
      "\n",
      "         [[-4.3376e-01, -7.4887e-02,  4.3219e-01,  ..., -3.8231e-01,\n",
      "            1.4648e-01,  1.3272e-01],\n",
      "          [-8.0776e-02,  3.2691e-02,  8.2890e-02,  ...,  4.5576e-01,\n",
      "            2.8316e-01, -2.9464e-02]],\n",
      "\n",
      "         [[ 2.3823e-02, -2.3606e-01,  3.1846e-01,  ..., -3.0073e-01,\n",
      "            6.4864e-01, -2.0795e-01],\n",
      "          [ 8.8902e-02, -8.5969e-02, -7.0797e-01,  ...,  8.9779e-01,\n",
      "            1.6116e-01, -4.8495e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0954e+00, -1.2023e+00,  1.0354e+00,  ..., -1.2598e+00,\n",
      "            1.6937e+00, -4.3423e-01],\n",
      "          [ 9.7247e-01, -9.2501e-01, -1.3030e+00,  ...,  1.7170e+00,\n",
      "           -8.8989e-01, -1.8716e-01]],\n",
      "\n",
      "         [[-5.4071e-01,  1.0230e-01,  8.7567e-01,  ..., -1.0515e+00,\n",
      "            7.8591e-01,  1.1774e-01],\n",
      "          [ 6.9575e-01,  8.7862e-02, -6.3014e-01,  ...,  1.0421e+00,\n",
      "           -4.3369e-02, -6.3574e-01]],\n",
      "\n",
      "         [[-3.4903e-01,  5.9921e-01,  6.2368e-01,  ..., -3.6727e-01,\n",
      "            7.9636e-01, -1.3554e-01],\n",
      "          [ 1.0288e-01, -1.6519e-01, -5.2357e-01,  ...,  6.2148e-01,\n",
      "           -3.7955e-01,  4.6155e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6048e-01, -4.3311e-01,  1.2830e-01,  ..., -6.3987e-01,\n",
      "            1.8715e-01, -7.0500e-02],\n",
      "          [ 1.4875e-03,  2.7908e-02, -2.9406e-01,  ...,  6.8790e-01,\n",
      "           -3.1925e-01,  1.4870e-01]],\n",
      "\n",
      "         [[-6.3112e-01, -4.5395e-01,  9.0146e-01,  ..., -8.4900e-01,\n",
      "            4.5060e-01, -4.4464e-01],\n",
      "          [-2.2961e-02,  3.3972e-01, -3.7624e-01,  ...,  1.0942e+00,\n",
      "           -1.3066e-02, -5.0421e-01]],\n",
      "\n",
      "         [[-1.3774e-01, -1.5730e-01,  2.3291e-01,  ..., -5.3512e-01,\n",
      "            6.6072e-01, -2.3537e-01],\n",
      "          [ 1.5077e-01, -1.8023e-01, -7.1785e-01,  ...,  9.2825e-01,\n",
      "           -1.2121e-02, -5.7947e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1017,  0.2667, -0.3961,  ..., -0.1019, -0.3998,  0.4572],\n",
      "          [ 0.1788,  0.2400, -0.4952,  ..., -0.2368, -0.3572,  0.0864],\n",
      "          [-0.4839, -0.1359, -0.3833,  ..., -0.4073,  0.0606,  0.1806],\n",
      "          ...,\n",
      "          [ 0.2637,  0.4258, -0.6065,  ...,  0.3063, -0.8053,  0.4314],\n",
      "          [ 0.2168,  0.2976, -0.1845,  ...,  0.0349, -0.3227,  0.1830],\n",
      "          [-0.0652,  0.7450, -0.8085,  ..., -0.1194, -0.5731,  0.6306]],\n",
      "\n",
      "         [[-0.6733,  0.4051,  0.6246,  ..., -0.4096,  0.1208, -0.3852],\n",
      "          [-0.9101,  0.2780,  0.6456,  ..., -0.4038,  0.4661,  0.4043],\n",
      "          [-0.5164, -0.0112,  0.9339,  ..., -0.0537,  0.3961, -0.0469],\n",
      "          ...,\n",
      "          [-0.7554,  0.5587,  0.9609,  ..., -0.6663,  0.3348,  0.4906],\n",
      "          [-0.1580,  0.0601, -0.5007,  ...,  0.1425, -0.0594,  0.3576],\n",
      "          [-0.6910,  0.4579,  0.0222,  ..., -0.3963,  0.1872, -0.2022]]],\n",
      "\n",
      "\n",
      "        [[[-0.3621,  0.0776, -0.2548,  ..., -0.1647, -0.1810,  0.6740],\n",
      "          [ 0.1322,  0.1477, -0.6995,  ...,  0.2565, -0.6907,  0.7262],\n",
      "          [-0.4933, -0.2203, -0.4847,  ..., -0.0882,  0.1223, -0.1151],\n",
      "          ...,\n",
      "          [-0.0520,  0.1863, -0.6266,  ...,  0.1048, -0.8125,  0.3463],\n",
      "          [ 0.1541,  0.1433, -0.4919,  ...,  0.4463, -0.3872,  0.5267],\n",
      "          [ 0.1247,  0.5274, -0.8691,  ..., -0.1129, -0.6693,  0.6435]],\n",
      "\n",
      "         [[-0.3419,  0.5771,  0.6066,  ..., -0.2447,  0.0706, -0.1902],\n",
      "          [-1.1376,  0.3412,  0.7574,  ..., -0.2466,  0.7332,  0.1717],\n",
      "          [-0.2050,  0.1208,  0.6461,  ...,  0.1279,  0.4591,  0.1163],\n",
      "          ...,\n",
      "          [-0.3355,  0.4293,  0.4963,  ..., -0.3710,  0.5309,  0.3433],\n",
      "          [-0.4665,  0.3534, -0.0510,  ...,  0.2357, -0.0119,  0.1726],\n",
      "          [-0.8725,  0.2511, -0.0066,  ..., -0.2056,  0.1716, -0.1589]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.3379,  0.2630, -0.6495,  ...,  0.3066,  0.5193, -0.2420],\n",
      "          [ 0.3162,  0.2165, -0.6681,  ...,  0.1990,  0.3078, -0.2163],\n",
      "          [ 0.3492,  0.2287, -0.6805,  ...,  0.2184,  0.3195, -0.2017],\n",
      "          ...,\n",
      "          [ 0.3768,  0.2120, -0.6720,  ...,  0.1908,  0.2782, -0.1817],\n",
      "          [ 0.3249,  0.1791, -0.6230,  ...,  0.1829,  0.2322, -0.1675],\n",
      "          [ 0.1630,  0.1043, -0.3514,  ...,  0.0507,  0.0022, -0.0550]],\n",
      "\n",
      "         [[ 0.0612, -0.4473, -0.0426,  ..., -0.0845,  0.0727, -0.0748],\n",
      "          [ 0.0497, -0.4708, -0.1358,  ..., -0.1145, -0.0035, -0.0464],\n",
      "          [ 0.0061, -0.4496, -0.1226,  ..., -0.1003,  0.0207, -0.0608],\n",
      "          ...,\n",
      "          [ 0.0740, -0.4495, -0.1271,  ..., -0.1213,  0.0149,  0.0028],\n",
      "          [-0.0020, -0.4452, -0.1537,  ..., -0.1132, -0.0018, -0.0472],\n",
      "          [ 0.0064, -0.4100, -0.1025,  ..., -0.1024, -0.0033, -0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2717,  0.0346, -0.5000,  ...,  0.1527,  0.2130, -0.0080],\n",
      "          [ 0.4043,  0.0137, -0.5228,  ...,  0.1113,  0.1098,  0.0664],\n",
      "          [ 0.4277,  0.0207, -0.5364,  ...,  0.1149,  0.0846,  0.0785],\n",
      "          ...,\n",
      "          [ 0.2952,  0.0236, -0.3715,  ...,  0.0989,  0.0755,  0.0353],\n",
      "          [ 0.4191,  0.0153, -0.5219,  ...,  0.1040,  0.0986,  0.0802],\n",
      "          [ 0.3907, -0.0018, -0.5108,  ...,  0.0935,  0.1027,  0.0573]],\n",
      "\n",
      "         [[-0.2156,  0.0029, -0.3064,  ..., -0.0338,  0.2381, -0.4321],\n",
      "          [-0.0975, -0.1237, -0.3677,  ..., -0.0641,  0.1453, -0.3234],\n",
      "          [-0.1244, -0.1362, -0.2897,  ..., -0.1019,  0.0999, -0.1943],\n",
      "          ...,\n",
      "          [-0.0716, -0.0889, -0.2729,  ...,  0.0073,  0.1228, -0.3193],\n",
      "          [-0.0316, -0.0968, -0.3664,  ..., -0.0740,  0.1191, -0.2555],\n",
      "          [ 0.0811, -0.1755, -0.2922,  ..., -0.0317,  0.0167, -0.1894]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.3379,  0.2630, -0.6495,  ...,  0.3066,  0.5193, -0.2420],\n",
      "          [ 0.0612, -0.4473, -0.0426,  ..., -0.0845,  0.0727, -0.0748]],\n",
      "\n",
      "         [[ 0.3162,  0.2165, -0.6681,  ...,  0.1990,  0.3078, -0.2163],\n",
      "          [ 0.0497, -0.4708, -0.1358,  ..., -0.1145, -0.0035, -0.0464]],\n",
      "\n",
      "         [[ 0.3492,  0.2287, -0.6805,  ...,  0.2184,  0.3195, -0.2017],\n",
      "          [ 0.0061, -0.4496, -0.1226,  ..., -0.1003,  0.0207, -0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3768,  0.2120, -0.6720,  ...,  0.1908,  0.2782, -0.1817],\n",
      "          [ 0.0740, -0.4495, -0.1271,  ..., -0.1213,  0.0149,  0.0028]],\n",
      "\n",
      "         [[ 0.3249,  0.1791, -0.6230,  ...,  0.1829,  0.2322, -0.1675],\n",
      "          [-0.0020, -0.4452, -0.1537,  ..., -0.1132, -0.0018, -0.0472]],\n",
      "\n",
      "         [[ 0.1630,  0.1043, -0.3514,  ...,  0.0507,  0.0022, -0.0550],\n",
      "          [ 0.0064, -0.4100, -0.1025,  ..., -0.1024, -0.0033, -0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2717,  0.0346, -0.5000,  ...,  0.1527,  0.2130, -0.0080],\n",
      "          [-0.2156,  0.0029, -0.3064,  ..., -0.0338,  0.2381, -0.4321]],\n",
      "\n",
      "         [[ 0.4043,  0.0137, -0.5228,  ...,  0.1113,  0.1098,  0.0664],\n",
      "          [-0.0975, -0.1237, -0.3677,  ..., -0.0641,  0.1453, -0.3234]],\n",
      "\n",
      "         [[ 0.4277,  0.0207, -0.5364,  ...,  0.1149,  0.0846,  0.0785],\n",
      "          [-0.1244, -0.1362, -0.2897,  ..., -0.1019,  0.0999, -0.1943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2952,  0.0236, -0.3715,  ...,  0.0989,  0.0755,  0.0353],\n",
      "          [-0.0716, -0.0889, -0.2729,  ...,  0.0073,  0.1228, -0.3193]],\n",
      "\n",
      "         [[ 0.4191,  0.0153, -0.5219,  ...,  0.1040,  0.0986,  0.0802],\n",
      "          [-0.0316, -0.0968, -0.3664,  ..., -0.0740,  0.1191, -0.2555]],\n",
      "\n",
      "         [[ 0.3907, -0.0018, -0.5108,  ...,  0.0935,  0.1027,  0.0573],\n",
      "          [ 0.0811, -0.1755, -0.2922,  ..., -0.0317,  0.0167, -0.1894]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.3379,  0.2630, -0.6495,  ...,  0.3066,  0.5193, -0.2420],\n",
      "          [ 0.0612, -0.4473, -0.0426,  ..., -0.0845,  0.0727, -0.0748]],\n",
      "\n",
      "         [[ 0.3162,  0.2165, -0.6681,  ...,  0.1990,  0.3078, -0.2163],\n",
      "          [ 0.0497, -0.4708, -0.1358,  ..., -0.1145, -0.0035, -0.0464]],\n",
      "\n",
      "         [[ 0.3492,  0.2287, -0.6805,  ...,  0.2184,  0.3195, -0.2017],\n",
      "          [ 0.0061, -0.4496, -0.1226,  ..., -0.1003,  0.0207, -0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3768,  0.2120, -0.6720,  ...,  0.1908,  0.2782, -0.1817],\n",
      "          [ 0.0740, -0.4495, -0.1271,  ..., -0.1213,  0.0149,  0.0028]],\n",
      "\n",
      "         [[ 0.3249,  0.1791, -0.6230,  ...,  0.1829,  0.2322, -0.1675],\n",
      "          [-0.0020, -0.4452, -0.1537,  ..., -0.1132, -0.0018, -0.0472]],\n",
      "\n",
      "         [[ 0.1630,  0.1043, -0.3514,  ...,  0.0507,  0.0022, -0.0550],\n",
      "          [ 0.0064, -0.4100, -0.1025,  ..., -0.1024, -0.0033, -0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2717,  0.0346, -0.5000,  ...,  0.1527,  0.2130, -0.0080],\n",
      "          [-0.2156,  0.0029, -0.3064,  ..., -0.0338,  0.2381, -0.4321]],\n",
      "\n",
      "         [[ 0.4043,  0.0137, -0.5228,  ...,  0.1113,  0.1098,  0.0664],\n",
      "          [-0.0975, -0.1237, -0.3677,  ..., -0.0641,  0.1453, -0.3234]],\n",
      "\n",
      "         [[ 0.4277,  0.0207, -0.5364,  ...,  0.1149,  0.0846,  0.0785],\n",
      "          [-0.1244, -0.1362, -0.2897,  ..., -0.1019,  0.0999, -0.1943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2952,  0.0236, -0.3715,  ...,  0.0989,  0.0755,  0.0353],\n",
      "          [-0.0716, -0.0889, -0.2729,  ...,  0.0073,  0.1228, -0.3193]],\n",
      "\n",
      "         [[ 0.4191,  0.0153, -0.5219,  ...,  0.1040,  0.0986,  0.0802],\n",
      "          [-0.0316, -0.0968, -0.3664,  ..., -0.0740,  0.1191, -0.2555]],\n",
      "\n",
      "         [[ 0.3907, -0.0018, -0.5108,  ...,  0.0935,  0.1027,  0.0573],\n",
      "          [ 0.0811, -0.1755, -0.2922,  ..., -0.0317,  0.0167, -0.1894]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.3379,  0.2630, -0.6495,  ...,  0.3066,  0.5193, -0.2420],\n",
      "          [ 0.0612, -0.4473, -0.0426,  ..., -0.0845,  0.0727, -0.0748]],\n",
      "\n",
      "         [[ 0.3162,  0.2165, -0.6681,  ...,  0.1990,  0.3078, -0.2163],\n",
      "          [ 0.0497, -0.4708, -0.1358,  ..., -0.1145, -0.0035, -0.0464]],\n",
      "\n",
      "         [[ 0.3492,  0.2287, -0.6805,  ...,  0.2184,  0.3195, -0.2017],\n",
      "          [ 0.0061, -0.4496, -0.1226,  ..., -0.1003,  0.0207, -0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3768,  0.2120, -0.6720,  ...,  0.1908,  0.2782, -0.1817],\n",
      "          [ 0.0740, -0.4495, -0.1271,  ..., -0.1213,  0.0149,  0.0028]],\n",
      "\n",
      "         [[ 0.3249,  0.1791, -0.6230,  ...,  0.1829,  0.2322, -0.1675],\n",
      "          [-0.0020, -0.4452, -0.1537,  ..., -0.1132, -0.0018, -0.0472]],\n",
      "\n",
      "         [[ 0.1630,  0.1043, -0.3514,  ...,  0.0507,  0.0022, -0.0550],\n",
      "          [ 0.0064, -0.4100, -0.1025,  ..., -0.1024, -0.0033, -0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2717,  0.0346, -0.5000,  ...,  0.1527,  0.2130, -0.0080],\n",
      "          [-0.2156,  0.0029, -0.3064,  ..., -0.0338,  0.2381, -0.4321]],\n",
      "\n",
      "         [[ 0.4043,  0.0137, -0.5228,  ...,  0.1113,  0.1098,  0.0664],\n",
      "          [-0.0975, -0.1237, -0.3677,  ..., -0.0641,  0.1453, -0.3234]],\n",
      "\n",
      "         [[ 0.4277,  0.0207, -0.5364,  ...,  0.1149,  0.0846,  0.0785],\n",
      "          [-0.1244, -0.1362, -0.2897,  ..., -0.1019,  0.0999, -0.1943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2952,  0.0236, -0.3715,  ...,  0.0989,  0.0755,  0.0353],\n",
      "          [-0.0716, -0.0889, -0.2729,  ...,  0.0073,  0.1228, -0.3193]],\n",
      "\n",
      "         [[ 0.4191,  0.0153, -0.5219,  ...,  0.1040,  0.0986,  0.0802],\n",
      "          [-0.0316, -0.0968, -0.3664,  ..., -0.0740,  0.1191, -0.2555]],\n",
      "\n",
      "         [[ 0.3907, -0.0018, -0.5108,  ...,  0.0935,  0.1027,  0.0573],\n",
      "          [ 0.0811, -0.1755, -0.2922,  ..., -0.0317,  0.0167, -0.1894]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.0922, -0.0391,  0.2772,  ...,  0.2296, -0.5902, -0.3977],\n",
      "         [-0.2358, -0.2617, -0.1045,  ..., -0.1531, -0.6636, -0.3626],\n",
      "         [-0.1207, -0.2922, -0.2456,  ..., -0.2835, -0.4041, -0.3881],\n",
      "         ...,\n",
      "         [-0.1396, -0.5171, -0.0406,  ...,  0.0203, -0.7748, -0.7959],\n",
      "         [-0.0724, -0.0214,  0.0125,  ..., -0.0383,  0.2979, -0.5503],\n",
      "         [-0.2619, -0.2116, -0.0282,  ..., -0.0529, -0.4398, -1.2283]],\n",
      "\n",
      "        [[ 0.1609, -0.0296,  0.4994,  ...,  0.3180, -0.4883, -0.1186],\n",
      "         [-0.2361, -0.3353,  0.4128,  ...,  0.2465, -0.9065, -0.2838],\n",
      "         [ 0.0660, -0.1284, -0.2656,  ...,  0.0307,  0.0690, -0.4316],\n",
      "         ...,\n",
      "         [ 0.0534, -0.2931,  0.0843,  ...,  0.4345, -1.1608, -0.4422],\n",
      "         [-0.0821, -0.0142, -0.1211,  ...,  0.3067,  0.0713, -0.2070],\n",
      "         [-0.2947, -0.4191, -0.0090,  ..., -0.0144, -0.4875, -1.2673]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0922, -0.0391,  0.2772,  ...,  0.2296, -0.5902, -0.3977],\n",
      "         [-0.2358, -0.2617, -0.1045,  ..., -0.1531, -0.6636, -0.3626],\n",
      "         [-0.1207, -0.2922, -0.2456,  ..., -0.2835, -0.4041, -0.3881],\n",
      "         ...,\n",
      "         [-0.1396, -0.5171, -0.0406,  ...,  0.0203, -0.7748, -0.7959],\n",
      "         [-0.0724, -0.0214,  0.0125,  ..., -0.0383,  0.2979, -0.5503],\n",
      "         [-0.2619, -0.2116, -0.0282,  ..., -0.0529, -0.4398, -1.2283]],\n",
      "\n",
      "        [[ 0.1609, -0.0296,  0.4994,  ...,  0.3180, -0.4883, -0.1186],\n",
      "         [-0.2361, -0.3353,  0.4128,  ...,  0.2465, -0.9065, -0.2838],\n",
      "         [ 0.0660, -0.1284, -0.2656,  ...,  0.0307,  0.0690, -0.4316],\n",
      "         ...,\n",
      "         [ 0.0534, -0.2931,  0.0843,  ...,  0.4345, -1.1608, -0.4422],\n",
      "         [-0.0821, -0.0142, -0.1211,  ...,  0.3067,  0.0713, -0.2070],\n",
      "         [-0.2947, -0.4191, -0.0090,  ..., -0.0144, -0.4875, -1.2673]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0922, -0.0391,  0.2772,  ..., -0.2316,  0.5270, -0.6896],\n",
      "          [ 0.3326, -0.2102,  0.5636,  ...,  0.2296, -0.5902, -0.3977]],\n",
      "\n",
      "         [[-0.2358, -0.2617, -0.1045,  ..., -0.3948,  0.2587, -0.5346],\n",
      "          [ 0.1765, -0.1540,  0.4289,  ..., -0.1531, -0.6636, -0.3626]],\n",
      "\n",
      "         [[-0.1207, -0.2922, -0.2456,  ...,  0.1406,  0.1875, -0.4670],\n",
      "          [ 0.0121, -0.1392,  0.4673,  ..., -0.2835, -0.4041, -0.3881]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1396, -0.5171, -0.0406,  ..., -1.0455,  0.5000, -0.9834],\n",
      "          [ 0.3928,  0.2040,  1.0652,  ...,  0.0203, -0.7748, -0.7959]],\n",
      "\n",
      "         [[-0.0724, -0.0214,  0.0125,  ..., -0.2520,  0.5463, -0.3800],\n",
      "          [-0.3577,  0.3613,  0.6954,  ..., -0.0383,  0.2979, -0.5503]],\n",
      "\n",
      "         [[-0.2619, -0.2116, -0.0282,  ..., -0.5574,  0.4143, -0.4663],\n",
      "          [-0.0124, -0.1943,  0.4534,  ..., -0.0529, -0.4398, -1.2283]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1609, -0.0296,  0.4994,  ..., -0.2091,  0.5696, -0.6172],\n",
      "          [ 0.5187,  0.0543,  0.3725,  ...,  0.3180, -0.4883, -0.1186]],\n",
      "\n",
      "         [[-0.2361, -0.3353,  0.4128,  ..., -0.3395,  0.5865, -0.6554],\n",
      "          [ 0.6984, -0.0701,  0.5762,  ...,  0.2465, -0.9065, -0.2838]],\n",
      "\n",
      "         [[ 0.0660, -0.1284, -0.2656,  ..., -0.0290,  0.1806, -0.4699],\n",
      "          [ 0.1116,  0.2062,  0.2869,  ...,  0.0307,  0.0690, -0.4316]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0534, -0.2931,  0.0843,  ..., -0.8068,  0.7289, -0.9132],\n",
      "          [-0.1082, -0.0849,  0.8656,  ...,  0.4345, -1.1608, -0.4422]],\n",
      "\n",
      "         [[-0.0821, -0.0142, -0.1211,  ..., -0.2576,  0.3305, -0.5815],\n",
      "          [ 0.2581,  0.4590,  0.2480,  ...,  0.3067,  0.0713, -0.2070]],\n",
      "\n",
      "         [[-0.2947, -0.4191, -0.0090,  ..., -0.4604,  0.3516, -0.3455],\n",
      "          [ 0.3157, -0.2914,  0.5392,  ..., -0.0144, -0.4875, -1.2673]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3975,  0.4963,  0.0999,  ..., -0.7690,  0.2714,  0.0211],\n",
      "         [ 0.4890,  0.8156, -0.0956,  ..., -0.6033,  0.5628, -0.4067],\n",
      "         [ 0.9610,  0.7927, -0.7180,  ..., -0.6816,  0.5381, -0.4593],\n",
      "         ...,\n",
      "         [ 0.5781,  0.8530, -0.0592,  ..., -0.6739,  0.2429, -0.5114],\n",
      "         [ 0.4706,  0.9544, -0.3604,  ..., -0.9745,  0.7530, -0.6378],\n",
      "         [ 0.7195,  1.2262, -0.0176,  ..., -0.8247,  0.1889, -0.0023]],\n",
      "\n",
      "        [[-0.0921,  0.0698,  0.5196,  ...,  0.1133, -0.2320,  0.4182],\n",
      "         [ 0.1072, -0.1339,  0.5100,  ...,  0.4345,  0.0598, -0.1606],\n",
      "         [ 0.7610,  0.6778, -0.3796,  ..., -0.6529,  0.4724, -0.4950],\n",
      "         ...,\n",
      "         [-0.5347,  0.1439,  0.1761,  ...,  0.4568, -0.2138, -0.1534],\n",
      "         [-0.2322, -0.2351,  0.0617,  ...,  0.4106,  0.2720,  0.0268],\n",
      "         [ 0.6331,  1.0145, -0.0056,  ..., -0.4062,  0.3821,  0.1417]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3975,  0.4963,  0.0999,  ..., -0.7690,  0.2714,  0.0211],\n",
      "         [ 0.4890,  0.8156, -0.0956,  ..., -0.6033,  0.5628, -0.4067],\n",
      "         [ 0.9610,  0.7927, -0.7180,  ..., -0.6816,  0.5381, -0.4593],\n",
      "         ...,\n",
      "         [ 0.5781,  0.8530, -0.0592,  ..., -0.6739,  0.2429, -0.5114],\n",
      "         [ 0.4706,  0.9544, -0.3604,  ..., -0.9745,  0.7530, -0.6378],\n",
      "         [ 0.7195,  1.2262, -0.0176,  ..., -0.8247,  0.1889, -0.0023]],\n",
      "\n",
      "        [[-0.0921,  0.0698,  0.5196,  ...,  0.1133, -0.2320,  0.4182],\n",
      "         [ 0.1072, -0.1339,  0.5100,  ...,  0.4345,  0.0598, -0.1606],\n",
      "         [ 0.7610,  0.6778, -0.3796,  ..., -0.6529,  0.4724, -0.4950],\n",
      "         ...,\n",
      "         [-0.5347,  0.1439,  0.1761,  ...,  0.4568, -0.2138, -0.1534],\n",
      "         [-0.2322, -0.2351,  0.0617,  ...,  0.4106,  0.2720,  0.0268],\n",
      "         [ 0.6331,  1.0145, -0.0056,  ..., -0.4062,  0.3821,  0.1417]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.9749e-01,  4.9629e-01,  9.9878e-02,  ...,  8.7653e-01,\n",
      "           -5.5652e-01, -7.2744e-01],\n",
      "          [-7.9617e-01, -8.6738e-01,  3.4704e-01,  ..., -7.6901e-01,\n",
      "            2.7137e-01,  2.1061e-02]],\n",
      "\n",
      "         [[ 4.8901e-01,  8.1561e-01, -9.5593e-02,  ...,  8.0021e-01,\n",
      "           -1.0957e+00, -1.0003e+00],\n",
      "          [-1.1446e+00, -7.5057e-01,  3.8336e-01,  ..., -6.0325e-01,\n",
      "            5.6282e-01, -4.0675e-01]],\n",
      "\n",
      "         [[ 9.6100e-01,  7.9271e-01, -7.1804e-01,  ...,  8.7847e-01,\n",
      "           -5.3757e-01, -1.0989e+00],\n",
      "          [-1.0515e+00, -7.3612e-01,  7.3338e-02,  ..., -6.8162e-01,\n",
      "            5.3815e-01, -4.5929e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7810e-01,  8.5300e-01, -5.9152e-02,  ...,  3.1479e-01,\n",
      "           -4.2320e-01, -3.7771e-01],\n",
      "          [-9.3191e-01, -6.5276e-01, -6.7711e-02,  ..., -6.7392e-01,\n",
      "            2.4288e-01, -5.1142e-01]],\n",
      "\n",
      "         [[ 4.7060e-01,  9.5444e-01, -3.6041e-01,  ...,  8.4494e-01,\n",
      "           -2.6252e-01, -7.2861e-01],\n",
      "          [-1.4404e+00, -7.8051e-01,  7.2448e-03,  ..., -9.7451e-01,\n",
      "            7.5299e-01, -6.3782e-01]],\n",
      "\n",
      "         [[ 7.1947e-01,  1.2262e+00, -1.7571e-02,  ...,  1.0454e+00,\n",
      "           -6.6527e-01, -1.1027e+00],\n",
      "          [-9.8866e-01, -9.6741e-01,  1.2997e-01,  ..., -8.2466e-01,\n",
      "            1.8888e-01, -2.3374e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.2125e-02,  6.9762e-02,  5.1961e-01,  ..., -1.1150e-01,\n",
      "           -2.3528e-01,  2.1574e-01],\n",
      "          [ 4.4215e-01,  1.0962e-01, -4.7077e-02,  ...,  1.1334e-01,\n",
      "           -2.3203e-01,  4.1815e-01]],\n",
      "\n",
      "         [[ 1.0723e-01, -1.3395e-01,  5.0998e-01,  ..., -1.2678e-01,\n",
      "           -5.2483e-01,  2.0541e-01],\n",
      "          [-8.0198e-04,  3.4653e-01, -4.8802e-02,  ...,  4.3447e-01,\n",
      "            5.9836e-02, -1.6062e-01]],\n",
      "\n",
      "         [[ 7.6096e-01,  6.7783e-01, -3.7958e-01,  ...,  5.2741e-01,\n",
      "           -5.8888e-01, -7.5982e-01],\n",
      "          [-8.6647e-01, -4.5176e-01, -1.3002e-01,  ..., -6.5285e-01,\n",
      "            4.7237e-01, -4.9504e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3473e-01,  1.4395e-01,  1.7609e-01,  ..., -5.3158e-02,\n",
      "           -4.5056e-01,  1.9260e-01],\n",
      "          [-1.2458e-01, -5.9340e-02, -2.9982e-01,  ...,  4.5677e-01,\n",
      "           -2.1384e-01, -1.5335e-01]],\n",
      "\n",
      "         [[-2.3224e-01, -2.3513e-01,  6.1730e-02,  ...,  9.0982e-02,\n",
      "           -6.2946e-01,  2.5306e-01],\n",
      "          [ 1.9233e-01,  7.1845e-01, -5.1404e-02,  ...,  4.1061e-01,\n",
      "            2.7202e-01,  2.6848e-02]],\n",
      "\n",
      "         [[ 6.3311e-01,  1.0145e+00, -5.6330e-03,  ...,  6.5899e-01,\n",
      "           -7.7254e-01, -6.0800e-01],\n",
      "          [-7.3877e-01, -7.3834e-01, -2.1889e-02,  ..., -4.0616e-01,\n",
      "            3.8211e-01,  1.4173e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2088,  1.3858, -1.4754,  ..., -0.0439,  1.2244,  0.9809],\n",
      "         [ 0.1954,  0.4630, -0.6624,  ...,  0.2578,  0.2335,  0.7610],\n",
      "         [ 0.0961,  0.8297, -1.0578,  ...,  0.6595,  0.3254,  0.5889],\n",
      "         ...,\n",
      "         [ 0.3523,  0.7641, -0.7154,  ...,  0.2905,  0.1106,  0.3010],\n",
      "         [ 0.2479,  0.5887, -0.9007,  ...,  0.3248,  0.2818,  0.4094],\n",
      "         [ 0.6676,  0.3765, -0.7483,  ...,  0.4079,  0.2765,  0.5052]],\n",
      "\n",
      "        [[ 0.1210,  0.9197, -0.9927,  ..., -0.8038,  1.6039,  0.9305],\n",
      "         [ 0.0718,  0.3254, -0.4704,  ..., -0.5422,  0.6817,  0.3429],\n",
      "         [ 0.3075,  0.5038, -0.7040,  ...,  0.4544,  0.2834,  0.1346],\n",
      "         ...,\n",
      "         [-0.1890,  0.3348, -0.2868,  ..., -0.1279,  0.9230,  0.5117],\n",
      "         [ 0.3792,  0.4674, -0.1417,  ..., -0.0570,  0.7808,  0.4723],\n",
      "         [ 0.6983,  0.5555, -0.4947,  ...,  0.2972,  0.1429,  0.3588]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2088,  1.3858, -1.4754,  ..., -0.0439,  1.2244,  0.9809],\n",
      "         [ 0.1954,  0.4630, -0.6624,  ...,  0.2578,  0.2335,  0.7610],\n",
      "         [ 0.0961,  0.8297, -1.0578,  ...,  0.6595,  0.3254,  0.5889],\n",
      "         ...,\n",
      "         [ 0.3523,  0.7641, -0.7154,  ...,  0.2905,  0.1106,  0.3010],\n",
      "         [ 0.2479,  0.5887, -0.9007,  ...,  0.3248,  0.2818,  0.4094],\n",
      "         [ 0.6676,  0.3765, -0.7483,  ...,  0.4079,  0.2765,  0.5052]],\n",
      "\n",
      "        [[ 0.1210,  0.9197, -0.9927,  ..., -0.8038,  1.6039,  0.9305],\n",
      "         [ 0.0718,  0.3254, -0.4704,  ..., -0.5422,  0.6817,  0.3429],\n",
      "         [ 0.3075,  0.5038, -0.7040,  ...,  0.4544,  0.2834,  0.1346],\n",
      "         ...,\n",
      "         [-0.1890,  0.3348, -0.2868,  ..., -0.1279,  0.9230,  0.5117],\n",
      "         [ 0.3792,  0.4674, -0.1417,  ..., -0.0570,  0.7808,  0.4723],\n",
      "         [ 0.6983,  0.5555, -0.4947,  ...,  0.2972,  0.1429,  0.3588]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2088,  1.3858, -1.4754,  ...,  1.1033, -0.9040,  1.5881],\n",
      "          [-0.7946, -0.6661, -1.3841,  ..., -0.0439,  1.2244,  0.9809]],\n",
      "\n",
      "         [[ 0.1954,  0.4630, -0.6624,  ...,  0.2382, -0.6173,  1.5439],\n",
      "          [ 0.0942, -0.2920, -0.6572,  ...,  0.2578,  0.2335,  0.7610]],\n",
      "\n",
      "         [[ 0.0961,  0.8297, -1.0578,  ...,  0.1286, -0.2994,  1.0785],\n",
      "          [-0.1114, -0.1855, -0.3542,  ...,  0.6595,  0.3254,  0.5889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3523,  0.7641, -0.7154,  ...,  0.2026, -0.4953,  0.8693],\n",
      "          [ 0.2175, -0.0149, -0.5927,  ...,  0.2905,  0.1106,  0.3010]],\n",
      "\n",
      "         [[ 0.2479,  0.5887, -0.9007,  ...,  0.2006, -0.1991,  1.0563],\n",
      "          [ 0.3650, -0.5154, -0.5654,  ...,  0.3248,  0.2818,  0.4094]],\n",
      "\n",
      "         [[ 0.6676,  0.3765, -0.7483,  ...,  0.3728, -0.2704,  0.8774],\n",
      "          [ 0.3797, -0.2310, -0.5768,  ...,  0.4079,  0.2765,  0.5052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1210,  0.9197, -0.9927,  ...,  0.7715, -0.9049,  0.8727],\n",
      "          [-0.8598, -0.5561, -1.0755,  ..., -0.8038,  1.6039,  0.9305]],\n",
      "\n",
      "         [[ 0.0718,  0.3254, -0.4704,  ...,  0.5661, -0.8701,  0.7281],\n",
      "          [-0.0723, -0.1195, -0.7876,  ..., -0.5422,  0.6817,  0.3429]],\n",
      "\n",
      "         [[ 0.3075,  0.5038, -0.7040,  ...,  0.1783, -0.5235,  1.0506],\n",
      "          [-0.0277, -0.0027, -0.0738,  ...,  0.4544,  0.2834,  0.1346]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1890,  0.3348, -0.2868,  ...,  0.3616, -0.5875,  0.3999],\n",
      "          [-0.2156, -0.2205, -0.5417,  ..., -0.1279,  0.9230,  0.5117]],\n",
      "\n",
      "         [[ 0.3792,  0.4674, -0.1417,  ...,  0.1808, -0.2204,  0.2270],\n",
      "          [ 0.1398, -0.2228, -0.4978,  ..., -0.0570,  0.7808,  0.4723]],\n",
      "\n",
      "         [[ 0.6983,  0.5555, -0.4947,  ...,  0.4862, -0.3829,  0.4684],\n",
      "          [ 0.2862, -0.1624, -0.6069,  ...,  0.2972,  0.1429,  0.3588]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0922, -0.0391,  0.2772,  ..., -0.2316,  0.5270, -0.6896],\n",
      "          [-0.2358, -0.2617, -0.1045,  ..., -0.3948,  0.2587, -0.5346],\n",
      "          [-0.1207, -0.2922, -0.2456,  ...,  0.1406,  0.1875, -0.4670],\n",
      "          ...,\n",
      "          [-0.1396, -0.5171, -0.0406,  ..., -1.0455,  0.5000, -0.9834],\n",
      "          [-0.0724, -0.0214,  0.0125,  ..., -0.2520,  0.5463, -0.3800],\n",
      "          [-0.2619, -0.2116, -0.0282,  ..., -0.5574,  0.4143, -0.4663]],\n",
      "\n",
      "         [[ 0.3326, -0.2102,  0.5636,  ...,  0.2296, -0.5902, -0.3977],\n",
      "          [ 0.1765, -0.1540,  0.4289,  ..., -0.1531, -0.6636, -0.3626],\n",
      "          [ 0.0121, -0.1392,  0.4673,  ..., -0.2835, -0.4041, -0.3881],\n",
      "          ...,\n",
      "          [ 0.3928,  0.2040,  1.0652,  ...,  0.0203, -0.7748, -0.7959],\n",
      "          [-0.3577,  0.3613,  0.6954,  ..., -0.0383,  0.2979, -0.5503],\n",
      "          [-0.0124, -0.1943,  0.4534,  ..., -0.0529, -0.4398, -1.2283]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1609, -0.0296,  0.4994,  ..., -0.2091,  0.5696, -0.6172],\n",
      "          [-0.2361, -0.3353,  0.4128,  ..., -0.3395,  0.5865, -0.6554],\n",
      "          [ 0.0660, -0.1284, -0.2656,  ..., -0.0290,  0.1806, -0.4699],\n",
      "          ...,\n",
      "          [ 0.0534, -0.2931,  0.0843,  ..., -0.8068,  0.7289, -0.9132],\n",
      "          [-0.0821, -0.0142, -0.1211,  ..., -0.2576,  0.3305, -0.5815],\n",
      "          [-0.2947, -0.4191, -0.0090,  ..., -0.4604,  0.3516, -0.3455]],\n",
      "\n",
      "         [[ 0.5187,  0.0543,  0.3725,  ...,  0.3180, -0.4883, -0.1186],\n",
      "          [ 0.6984, -0.0701,  0.5762,  ...,  0.2465, -0.9065, -0.2838],\n",
      "          [ 0.1116,  0.2062,  0.2869,  ...,  0.0307,  0.0690, -0.4316],\n",
      "          ...,\n",
      "          [-0.1082, -0.0849,  0.8656,  ...,  0.4345, -1.1608, -0.4422],\n",
      "          [ 0.2581,  0.4590,  0.2480,  ...,  0.3067,  0.0713, -0.2070],\n",
      "          [ 0.3157, -0.2914,  0.5392,  ..., -0.0144, -0.4875, -1.2673]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.6255,  0.9179, -0.5389,  ...,  0.8981, -0.5145, -1.1149],\n",
      "          [ 0.6117,  0.9082, -0.4245,  ...,  0.8707, -0.5869, -1.0346],\n",
      "          [ 0.4342,  0.7581, -0.2848,  ...,  0.7069, -0.4916, -0.8228],\n",
      "          ...,\n",
      "          [ 0.4540,  0.6030, -0.3331,  ...,  0.5985, -0.4072, -0.7459],\n",
      "          [ 0.4382,  0.7652, -0.2722,  ...,  0.7057, -0.5132, -0.8117],\n",
      "          [ 0.5591,  0.8412, -0.4071,  ...,  0.7563, -0.5348, -0.9195]],\n",
      "\n",
      "         [[-1.2300, -1.0547,  0.1776,  ..., -0.6874,  0.5437, -0.6042],\n",
      "          [-1.0544, -0.8937,  0.1072,  ..., -0.7456,  0.4389, -0.4969],\n",
      "          [-1.0809, -0.8977,  0.1037,  ..., -0.7507,  0.4580, -0.5152],\n",
      "          ...,\n",
      "          [-1.0771, -0.9093,  0.1104,  ..., -0.7450,  0.4539, -0.5126],\n",
      "          [-1.0515, -0.8760,  0.1045,  ..., -0.7498,  0.4439, -0.4976],\n",
      "          [-1.0208, -0.8399,  0.1070,  ..., -0.6956,  0.4234, -0.4744]]],\n",
      "\n",
      "\n",
      "        [[[-0.1574,  0.0157, -0.0393,  ..., -0.0739, -0.5339, -0.1330],\n",
      "          [-0.0130,  0.1034, -0.0624,  ..., -0.0129, -0.4527, -0.1993],\n",
      "          [-0.1578,  0.0126, -0.0330,  ..., -0.0628, -0.5101, -0.1053],\n",
      "          ...,\n",
      "          [-0.1672, -0.0246,  0.0845,  ..., -0.0773, -0.3396, -0.0159],\n",
      "          [-0.1205, -0.0054,  0.0749,  ..., -0.0780, -0.4121, -0.0064],\n",
      "          [-0.0035,  0.1332, -0.0777,  ...,  0.0669, -0.4881, -0.1520]],\n",
      "\n",
      "         [[ 0.1479,  0.1542, -0.1847,  ...,  0.1754,  0.1606,  0.2021],\n",
      "          [ 0.2273,  0.1670, -0.3042,  ...,  0.1655,  0.1061,  0.1463],\n",
      "          [ 0.2371,  0.1740, -0.2861,  ...,  0.1693,  0.0779,  0.1449],\n",
      "          ...,\n",
      "          [ 0.2118,  0.1675, -0.2856,  ...,  0.1707,  0.1015,  0.1411],\n",
      "          [ 0.1687,  0.0525, -0.2694,  ...,  0.1078,  0.0631,  0.1382],\n",
      "          [ 0.1320,  0.1031, -0.1631,  ...,  0.0307,  0.0960,  0.0963]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.6255,  0.9179, -0.5389,  ...,  0.8981, -0.5145, -1.1149],\n",
      "          [-1.2300, -1.0547,  0.1776,  ..., -0.6874,  0.5437, -0.6042]],\n",
      "\n",
      "         [[ 0.6117,  0.9082, -0.4245,  ...,  0.8707, -0.5869, -1.0346],\n",
      "          [-1.0544, -0.8937,  0.1072,  ..., -0.7456,  0.4389, -0.4969]],\n",
      "\n",
      "         [[ 0.4342,  0.7581, -0.2848,  ...,  0.7069, -0.4916, -0.8228],\n",
      "          [-1.0809, -0.8977,  0.1037,  ..., -0.7507,  0.4580, -0.5152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4540,  0.6030, -0.3331,  ...,  0.5985, -0.4072, -0.7459],\n",
      "          [-1.0771, -0.9093,  0.1104,  ..., -0.7450,  0.4539, -0.5126]],\n",
      "\n",
      "         [[ 0.4382,  0.7652, -0.2722,  ...,  0.7057, -0.5132, -0.8117],\n",
      "          [-1.0515, -0.8760,  0.1045,  ..., -0.7498,  0.4439, -0.4976]],\n",
      "\n",
      "         [[ 0.5591,  0.8412, -0.4071,  ...,  0.7563, -0.5348, -0.9195],\n",
      "          [-1.0208, -0.8399,  0.1070,  ..., -0.6956,  0.4234, -0.4744]]],\n",
      "\n",
      "\n",
      "        [[[-0.1574,  0.0157, -0.0393,  ..., -0.0739, -0.5339, -0.1330],\n",
      "          [ 0.1479,  0.1542, -0.1847,  ...,  0.1754,  0.1606,  0.2021]],\n",
      "\n",
      "         [[-0.0130,  0.1034, -0.0624,  ..., -0.0129, -0.4527, -0.1993],\n",
      "          [ 0.2273,  0.1670, -0.3042,  ...,  0.1655,  0.1061,  0.1463]],\n",
      "\n",
      "         [[-0.1578,  0.0126, -0.0330,  ..., -0.0628, -0.5101, -0.1053],\n",
      "          [ 0.2371,  0.1740, -0.2861,  ...,  0.1693,  0.0779,  0.1449]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1672, -0.0246,  0.0845,  ..., -0.0773, -0.3396, -0.0159],\n",
      "          [ 0.2118,  0.1675, -0.2856,  ...,  0.1707,  0.1015,  0.1411]],\n",
      "\n",
      "         [[-0.1205, -0.0054,  0.0749,  ..., -0.0780, -0.4121, -0.0064],\n",
      "          [ 0.1687,  0.0525, -0.2694,  ...,  0.1078,  0.0631,  0.1382]],\n",
      "\n",
      "         [[-0.0035,  0.1332, -0.0777,  ...,  0.0669, -0.4881, -0.1520],\n",
      "          [ 0.1320,  0.1031, -0.1631,  ...,  0.0307,  0.0960,  0.0963]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.6255,  0.9179, -0.5389,  ...,  0.8981, -0.5145, -1.1149],\n",
      "          [-1.2300, -1.0547,  0.1776,  ..., -0.6874,  0.5437, -0.6042]],\n",
      "\n",
      "         [[ 0.6117,  0.9082, -0.4245,  ...,  0.8707, -0.5869, -1.0346],\n",
      "          [-1.0544, -0.8937,  0.1072,  ..., -0.7456,  0.4389, -0.4969]],\n",
      "\n",
      "         [[ 0.4342,  0.7581, -0.2848,  ...,  0.7069, -0.4916, -0.8228],\n",
      "          [-1.0809, -0.8977,  0.1037,  ..., -0.7507,  0.4580, -0.5152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4540,  0.6030, -0.3331,  ...,  0.5985, -0.4072, -0.7459],\n",
      "          [-1.0771, -0.9093,  0.1104,  ..., -0.7450,  0.4539, -0.5126]],\n",
      "\n",
      "         [[ 0.4382,  0.7652, -0.2722,  ...,  0.7057, -0.5132, -0.8117],\n",
      "          [-1.0515, -0.8760,  0.1045,  ..., -0.7498,  0.4439, -0.4976]],\n",
      "\n",
      "         [[ 0.5591,  0.8412, -0.4071,  ...,  0.7563, -0.5348, -0.9195],\n",
      "          [-1.0208, -0.8399,  0.1070,  ..., -0.6956,  0.4234, -0.4744]]],\n",
      "\n",
      "\n",
      "        [[[-0.1574,  0.0157, -0.0393,  ..., -0.0739, -0.5339, -0.1330],\n",
      "          [ 0.1479,  0.1542, -0.1847,  ...,  0.1754,  0.1606,  0.2021]],\n",
      "\n",
      "         [[-0.0130,  0.1034, -0.0624,  ..., -0.0129, -0.4527, -0.1993],\n",
      "          [ 0.2273,  0.1670, -0.3042,  ...,  0.1655,  0.1061,  0.1463]],\n",
      "\n",
      "         [[-0.1578,  0.0126, -0.0330,  ..., -0.0628, -0.5101, -0.1053],\n",
      "          [ 0.2371,  0.1740, -0.2861,  ...,  0.1693,  0.0779,  0.1449]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1672, -0.0246,  0.0845,  ..., -0.0773, -0.3396, -0.0159],\n",
      "          [ 0.2118,  0.1675, -0.2856,  ...,  0.1707,  0.1015,  0.1411]],\n",
      "\n",
      "         [[-0.1205, -0.0054,  0.0749,  ..., -0.0780, -0.4121, -0.0064],\n",
      "          [ 0.1687,  0.0525, -0.2694,  ...,  0.1078,  0.0631,  0.1382]],\n",
      "\n",
      "         [[-0.0035,  0.1332, -0.0777,  ...,  0.0669, -0.4881, -0.1520],\n",
      "          [ 0.1320,  0.1031, -0.1631,  ...,  0.0307,  0.0960,  0.0963]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.6255,  0.9179, -0.5389,  ...,  0.8981, -0.5145, -1.1149],\n",
      "          [-1.2300, -1.0547,  0.1776,  ..., -0.6874,  0.5437, -0.6042]],\n",
      "\n",
      "         [[ 0.6117,  0.9082, -0.4245,  ...,  0.8707, -0.5869, -1.0346],\n",
      "          [-1.0544, -0.8937,  0.1072,  ..., -0.7456,  0.4389, -0.4969]],\n",
      "\n",
      "         [[ 0.4342,  0.7581, -0.2848,  ...,  0.7069, -0.4916, -0.8228],\n",
      "          [-1.0809, -0.8977,  0.1037,  ..., -0.7507,  0.4580, -0.5152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4540,  0.6030, -0.3331,  ...,  0.5985, -0.4072, -0.7459],\n",
      "          [-1.0771, -0.9093,  0.1104,  ..., -0.7450,  0.4539, -0.5126]],\n",
      "\n",
      "         [[ 0.4382,  0.7652, -0.2722,  ...,  0.7057, -0.5132, -0.8117],\n",
      "          [-1.0515, -0.8760,  0.1045,  ..., -0.7498,  0.4439, -0.4976]],\n",
      "\n",
      "         [[ 0.5591,  0.8412, -0.4071,  ...,  0.7563, -0.5348, -0.9195],\n",
      "          [-1.0208, -0.8399,  0.1070,  ..., -0.6956,  0.4234, -0.4744]]],\n",
      "\n",
      "\n",
      "        [[[-0.1574,  0.0157, -0.0393,  ..., -0.0739, -0.5339, -0.1330],\n",
      "          [ 0.1479,  0.1542, -0.1847,  ...,  0.1754,  0.1606,  0.2021]],\n",
      "\n",
      "         [[-0.0130,  0.1034, -0.0624,  ..., -0.0129, -0.4527, -0.1993],\n",
      "          [ 0.2273,  0.1670, -0.3042,  ...,  0.1655,  0.1061,  0.1463]],\n",
      "\n",
      "         [[-0.1578,  0.0126, -0.0330,  ..., -0.0628, -0.5101, -0.1053],\n",
      "          [ 0.2371,  0.1740, -0.2861,  ...,  0.1693,  0.0779,  0.1449]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1672, -0.0246,  0.0845,  ..., -0.0773, -0.3396, -0.0159],\n",
      "          [ 0.2118,  0.1675, -0.2856,  ...,  0.1707,  0.1015,  0.1411]],\n",
      "\n",
      "         [[-0.1205, -0.0054,  0.0749,  ..., -0.0780, -0.4121, -0.0064],\n",
      "          [ 0.1687,  0.0525, -0.2694,  ...,  0.1078,  0.0631,  0.1382]],\n",
      "\n",
      "         [[-0.0035,  0.1332, -0.0777,  ...,  0.0669, -0.4881, -0.1520],\n",
      "          [ 0.1320,  0.1031, -0.1631,  ...,  0.0307,  0.0960,  0.0963]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.9618,  1.8002],\n",
      "        [ 0.7303, -0.7498]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:18:58,664] Trial 0 finished with value: 0.822 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.463100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8269e-01,  1.9637e-01,  7.0163e-01,  ...,  1.1832e+00,\n",
      "            7.4217e-01, -1.1201e+00],\n",
      "          [-0.0000e+00,  2.6916e-01,  1.2520e+00,  ...,  1.3334e+00,\n",
      "           -1.3975e+00,  1.8971e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -8.7442e-01,  1.4515e-01,  ...,  4.9321e-01,\n",
      "            9.4474e-01,  1.6536e-01],\n",
      "          [-5.9895e-01,  1.1779e+00, -4.1942e-01,  ...,  1.8613e+00,\n",
      "           -2.5637e+00,  1.3678e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.3387e-01,  8.9452e-02,  9.0826e-01,  ..., -3.9520e-01,\n",
      "            2.4478e+00,  3.5793e-02],\n",
      "          [-1.5669e+00, -8.1599e-01, -1.4432e-01,  ...,  0.0000e+00,\n",
      "           -1.6814e+00, -5.3479e-01]],\n",
      "\n",
      "         [[-1.8262e+00,  1.3517e-02,  1.0035e+00,  ..., -1.5107e+00,\n",
      "           -7.0928e-02, -8.7685e-02],\n",
      "          [-1.8619e+00, -7.0286e-01,  3.0895e-01,  ...,  1.2520e+00,\n",
      "            8.6920e-01,  1.7922e+00]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  3.9398e-01,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -1.5329e+00,  1.5304e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  9.5053e-02,  1.9460e+00,  ...,  1.0815e-01,\n",
      "            2.2035e+00, -0.0000e+00],\n",
      "          [-9.7299e-02, -2.9377e-02,  6.6763e-01,  ...,  0.0000e+00,\n",
      "            7.6327e-01,  1.1784e+00]],\n",
      "\n",
      "         [[ 1.1503e+00, -1.8529e+00,  1.2823e+00,  ...,  1.3171e-01,\n",
      "            1.2239e+00, -1.7977e-01],\n",
      "          [-2.9493e-01,  6.3133e-01, -5.6628e-01,  ...,  8.3643e-01,\n",
      "           -2.0318e+00,  1.2150e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7341e-02, -2.6221e-01,  1.2431e+00,  ..., -1.3245e-02,\n",
      "            2.6615e+00, -2.4790e-01],\n",
      "          [-1.2148e-02, -9.6842e-01,  9.7155e-01,  ...,  1.1135e+00,\n",
      "           -2.0636e+00, -7.1358e-02]],\n",
      "\n",
      "         [[ 1.1446e-01,  0.0000e+00,  1.5510e+00,  ..., -5.7851e-01,\n",
      "            3.6857e-01, -7.4315e-01],\n",
      "          [-5.7981e-01, -1.3441e+00,  5.7350e-01,  ...,  1.8663e+00,\n",
      "           -3.5822e-01,  8.8250e-01]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  3.3940e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8269e-01,  1.9637e-01,  7.0163e-01,  ...,  1.1832e+00,\n",
      "            7.4217e-01, -1.1201e+00],\n",
      "          [-0.0000e+00,  2.6916e-01,  1.2520e+00,  ...,  1.3334e+00,\n",
      "           -1.3975e+00,  1.8971e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -8.7442e-01,  1.4515e-01,  ...,  4.9321e-01,\n",
      "            9.4474e-01,  1.6536e-01],\n",
      "          [-5.9895e-01,  1.1779e+00, -4.1942e-01,  ...,  1.8613e+00,\n",
      "           -2.5637e+00,  1.3678e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.3387e-01,  8.9452e-02,  9.0826e-01,  ..., -3.9520e-01,\n",
      "            2.4478e+00,  3.5793e-02],\n",
      "          [-1.5669e+00, -8.1599e-01, -1.4432e-01,  ...,  0.0000e+00,\n",
      "           -1.6814e+00, -5.3479e-01]],\n",
      "\n",
      "         [[-1.8262e+00,  1.3517e-02,  1.0035e+00,  ..., -1.5107e+00,\n",
      "           -7.0928e-02, -8.7685e-02],\n",
      "          [-1.8619e+00, -7.0286e-01,  3.0895e-01,  ...,  1.2520e+00,\n",
      "            8.6920e-01,  1.7922e+00]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  3.9398e-01,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -1.5329e+00,  1.5304e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  9.5053e-02,  1.9460e+00,  ...,  1.0815e-01,\n",
      "            2.2035e+00, -0.0000e+00],\n",
      "          [-9.7299e-02, -2.9377e-02,  6.6763e-01,  ...,  0.0000e+00,\n",
      "            7.6327e-01,  1.1784e+00]],\n",
      "\n",
      "         [[ 1.1503e+00, -1.8529e+00,  1.2823e+00,  ...,  1.3171e-01,\n",
      "            1.2239e+00, -1.7977e-01],\n",
      "          [-2.9493e-01,  6.3133e-01, -5.6628e-01,  ...,  8.3643e-01,\n",
      "           -2.0318e+00,  1.2150e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7341e-02, -2.6221e-01,  1.2431e+00,  ..., -1.3245e-02,\n",
      "            2.6615e+00, -2.4790e-01],\n",
      "          [-1.2148e-02, -9.6842e-01,  9.7155e-01,  ...,  1.1135e+00,\n",
      "           -2.0636e+00, -7.1358e-02]],\n",
      "\n",
      "         [[ 1.1446e-01,  0.0000e+00,  1.5510e+00,  ..., -5.7851e-01,\n",
      "            3.6857e-01, -7.4315e-01],\n",
      "          [-5.7981e-01, -1.3441e+00,  5.7350e-01,  ...,  1.8663e+00,\n",
      "           -3.5822e-01,  8.8250e-01]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  3.3940e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -0.0000,  0.0000],\n",
      "         [-0.1827,  0.1964,  0.7016,  ...,  1.3334, -1.3975,  1.8971],\n",
      "         [ 0.0000, -0.8744,  0.1452,  ...,  1.8613, -2.5637,  1.3678],\n",
      "         ...,\n",
      "         [-0.9339,  0.0895,  0.9083,  ...,  0.0000, -1.6814, -0.5348],\n",
      "         [-1.8262,  0.0135,  1.0035,  ...,  1.2520,  0.8692,  1.7922],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.0000]],\n",
      "\n",
      "        [[ 0.5302, -0.3247,  2.5968,  ...,  1.0343, -1.5329,  1.5304],\n",
      "         [-0.0000,  0.0951,  1.9460,  ...,  0.0000,  0.7633,  1.1784],\n",
      "         [ 1.1503, -1.8529,  1.2823,  ...,  0.8364, -2.0318,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0573, -0.2622,  1.2431,  ...,  1.1135, -2.0636, -0.0714],\n",
      "         [ 0.1145,  0.0000,  1.5510,  ...,  1.8663, -0.3582,  0.8825],\n",
      "         [-0.5079,  0.8962,  0.8585,  ...,  1.7126, -1.2410,  0.3394]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8269e-01,  1.9637e-01,  7.0163e-01,  ...,  1.1832e+00,\n",
      "            7.4217e-01, -1.1201e+00],\n",
      "          [-0.0000e+00,  2.6916e-01,  1.2520e+00,  ...,  1.3334e+00,\n",
      "           -1.3975e+00,  1.8971e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -8.7442e-01,  1.4515e-01,  ...,  4.9321e-01,\n",
      "            9.4474e-01,  1.6536e-01],\n",
      "          [-5.9895e-01,  1.1779e+00, -4.1942e-01,  ...,  1.8613e+00,\n",
      "           -2.5637e+00,  1.3678e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.3387e-01,  8.9452e-02,  9.0826e-01,  ..., -3.9520e-01,\n",
      "            2.4478e+00,  3.5793e-02],\n",
      "          [-1.5669e+00, -8.1599e-01, -1.4432e-01,  ...,  0.0000e+00,\n",
      "           -1.6814e+00, -5.3479e-01]],\n",
      "\n",
      "         [[-1.8262e+00,  1.3517e-02,  1.0035e+00,  ..., -1.5107e+00,\n",
      "           -7.0928e-02, -8.7685e-02],\n",
      "          [-1.8619e+00, -7.0286e-01,  3.0895e-01,  ...,  1.2520e+00,\n",
      "            8.6920e-01,  1.7922e+00]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  3.9398e-01,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -1.5329e+00,  1.5304e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  9.5053e-02,  1.9460e+00,  ...,  1.0815e-01,\n",
      "            2.2035e+00, -0.0000e+00],\n",
      "          [-9.7299e-02, -2.9377e-02,  6.6763e-01,  ...,  0.0000e+00,\n",
      "            7.6327e-01,  1.1784e+00]],\n",
      "\n",
      "         [[ 1.1503e+00, -1.8529e+00,  1.2823e+00,  ...,  1.3171e-01,\n",
      "            1.2239e+00, -1.7977e-01],\n",
      "          [-2.9493e-01,  6.3133e-01, -5.6628e-01,  ...,  8.3643e-01,\n",
      "           -2.0318e+00,  1.2150e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7341e-02, -2.6221e-01,  1.2431e+00,  ..., -1.3245e-02,\n",
      "            2.6615e+00, -2.4790e-01],\n",
      "          [-1.2148e-02, -9.6842e-01,  9.7155e-01,  ...,  1.1135e+00,\n",
      "           -2.0636e+00, -7.1358e-02]],\n",
      "\n",
      "         [[ 1.1446e-01,  0.0000e+00,  1.5510e+00,  ..., -5.7851e-01,\n",
      "            3.6857e-01, -7.4315e-01],\n",
      "          [-5.7981e-01, -1.3441e+00,  5.7350e-01,  ...,  1.8663e+00,\n",
      "           -3.5822e-01,  8.8250e-01]],\n",
      "\n",
      "         [[-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.4322e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  3.3940e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-1.8269e-01,  1.9637e-01,  7.0163e-01,  ...,  1.1832e+00,\n",
      "            7.4217e-01, -1.1201e+00],\n",
      "          [ 0.0000e+00, -8.7442e-01,  1.4515e-01,  ...,  4.9321e-01,\n",
      "            9.4474e-01,  1.6536e-01],\n",
      "          ...,\n",
      "          [-9.3387e-01,  8.9452e-02,  9.0826e-01,  ..., -3.9520e-01,\n",
      "            2.4478e+00,  3.5793e-02],\n",
      "          [-1.8262e+00,  1.3517e-02,  1.0035e+00,  ..., -1.5107e+00,\n",
      "           -7.0928e-02, -8.7685e-02],\n",
      "          [-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  3.9398e-01,\n",
      "            0.0000e+00, -5.4322e-01]],\n",
      "\n",
      "         [[-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -0.0000e+00,  0.0000e+00],\n",
      "          [-0.0000e+00,  2.6916e-01,  1.2520e+00,  ...,  1.3334e+00,\n",
      "           -1.3975e+00,  1.8971e+00],\n",
      "          [-5.9895e-01,  1.1779e+00, -4.1942e-01,  ...,  1.8613e+00,\n",
      "           -2.5637e+00,  1.3678e+00],\n",
      "          ...,\n",
      "          [-1.5669e+00, -8.1599e-01, -1.4432e-01,  ...,  0.0000e+00,\n",
      "           -1.6814e+00, -5.3479e-01],\n",
      "          [-1.8619e+00, -7.0286e-01,  3.0895e-01,  ...,  1.2520e+00,\n",
      "            8.6920e-01,  1.7922e+00],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3023e-01, -3.2475e-01,  2.5968e+00,  ..., -5.3322e-01,\n",
      "            3.0272e-01, -5.8279e-01],\n",
      "          [-0.0000e+00,  9.5053e-02,  1.9460e+00,  ...,  1.0815e-01,\n",
      "            2.2035e+00, -0.0000e+00],\n",
      "          [ 1.1503e+00, -1.8529e+00,  1.2823e+00,  ...,  1.3171e-01,\n",
      "            1.2239e+00, -1.7977e-01],\n",
      "          ...,\n",
      "          [ 5.7341e-02, -2.6221e-01,  1.2431e+00,  ..., -1.3245e-02,\n",
      "            2.6615e+00, -2.4790e-01],\n",
      "          [ 1.1446e-01,  0.0000e+00,  1.5510e+00,  ..., -5.7851e-01,\n",
      "            3.6857e-01, -7.4315e-01],\n",
      "          [-5.0789e-01,  8.9616e-01,  8.5851e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.4322e-01]],\n",
      "\n",
      "         [[-6.9721e-02,  4.3819e-02, -2.7994e-05,  ...,  1.0343e+00,\n",
      "           -1.5329e+00,  1.5304e+00],\n",
      "          [-9.7299e-02, -2.9377e-02,  6.6763e-01,  ...,  0.0000e+00,\n",
      "            7.6327e-01,  1.1784e+00],\n",
      "          [-2.9493e-01,  6.3133e-01, -5.6628e-01,  ...,  8.3643e-01,\n",
      "           -2.0318e+00,  1.2150e+00],\n",
      "          ...,\n",
      "          [-1.2148e-02, -9.6842e-01,  9.7155e-01,  ...,  1.1135e+00,\n",
      "           -2.0636e+00, -7.1358e-02],\n",
      "          [-5.7981e-01, -1.3441e+00,  5.7350e-01,  ...,  1.8663e+00,\n",
      "           -3.5822e-01,  8.8250e-01],\n",
      "          [-1.6371e+00,  9.8866e-01, -7.2853e-01,  ...,  1.7126e+00,\n",
      "           -1.2410e+00,  3.3940e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.4705e-01, -3.4061e-01,  2.8371e+00,  ..., -5.7598e-01,\n",
      "            3.4559e-01, -6.3473e-01],\n",
      "          [-2.4636e-01,  2.2850e-01,  8.8671e-01,  ...,  1.2067e+00,\n",
      "            8.1093e-01, -1.2199e+00],\n",
      "          [-2.2148e-02, -8.0760e-01,  4.3742e-01,  ...,  4.2828e-01,\n",
      "            9.8508e-01,  9.2872e-02],\n",
      "          ...,\n",
      "          [-9.4919e-01,  1.1616e-01,  1.2080e+00,  ..., -4.1396e-01,\n",
      "            2.3466e+00, -5.1326e-02],\n",
      "          [-1.9682e+00,  2.6376e-02,  1.1443e+00,  ..., -1.6258e+00,\n",
      "           -4.6614e-02, -1.0390e-01],\n",
      "          [-5.6288e-01,  9.8870e-01,  9.5953e-01,  ...,  4.3043e-01,\n",
      "            3.6804e-03, -6.0127e-01]],\n",
      "\n",
      "         [[-2.6303e-01,  1.5292e-02,  3.2465e-03,  ...,  1.1090e+00,\n",
      "           -1.4754e-01,  1.5608e-01],\n",
      "          [-5.5769e-03,  2.9887e-01,  1.3795e+00,  ...,  1.4798e+00,\n",
      "           -1.5471e+00,  2.0977e+00],\n",
      "          [-6.6924e-01,  1.2753e+00, -4.5587e-01,  ...,  2.0340e+00,\n",
      "           -2.8096e+00,  1.4904e+00],\n",
      "          ...,\n",
      "          [-1.7379e+00, -9.0232e-01, -1.6034e-01,  ...,  4.1836e-03,\n",
      "           -1.8639e+00, -5.8793e-01],\n",
      "          [-2.0475e+00, -7.7171e-01,  3.3732e-01,  ...,  1.3826e+00,\n",
      "            9.4335e-01,  1.9652e+00],\n",
      "          [-1.6795e+00,  1.0035e+00, -7.3199e-01,  ...,  1.7877e+00,\n",
      "           -1.2715e+00,  7.2507e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1445e-03,  1.7922e-02,  7.6684e-02,  ...,  2.4755e-02,\n",
      "            3.4963e-02, -1.7424e-02],\n",
      "          [ 2.3766e-04,  1.1015e-01,  2.1634e+00,  ...,  1.2179e-01,\n",
      "            2.4350e+00, -5.2561e-03],\n",
      "          [ 9.9193e-01, -1.6093e+00,  1.5919e+00,  ...,  1.9577e-01,\n",
      "            1.2672e+00, -3.0920e-01],\n",
      "          ...,\n",
      "          [ 6.2497e-02, -2.8659e-01,  1.3874e+00,  ..., -1.0180e-02,\n",
      "            2.9363e+00, -2.8035e-01],\n",
      "          [ 8.4322e-02,  1.4722e-02,  1.8952e+00,  ..., -4.6787e-01,\n",
      "            4.8735e-01, -7.7094e-01],\n",
      "          [-5.5054e-01,  9.7092e-01,  1.0065e+00,  ...,  1.4496e-02,\n",
      "            2.5529e-02, -5.9771e-01]],\n",
      "\n",
      "         [[-7.1752e-02,  5.1330e-03,  3.4826e-02,  ...,  1.1101e+00,\n",
      "           -1.5756e+00,  1.5554e+00],\n",
      "          [-1.1071e-01, -3.4717e-02,  7.3233e-01,  ...,  1.5332e-02,\n",
      "            8.2664e-01,  1.3110e+00],\n",
      "          [-3.2658e-01,  6.9483e-01, -6.2464e-01,  ...,  9.3210e-01,\n",
      "           -2.2508e+00,  1.3467e+00],\n",
      "          ...,\n",
      "          [-2.3238e-04,  6.5374e-03, -5.4714e-03,  ...,  3.3627e-02,\n",
      "           -4.1591e-02,  3.8613e-02],\n",
      "          [-6.3666e-01, -1.4768e+00,  6.3073e-01,  ...,  2.0584e+00,\n",
      "           -4.0602e-01,  9.7693e-01],\n",
      "          [-1.6862e+00,  1.0163e+00, -7.5991e-01,  ...,  1.8213e+00,\n",
      "           -1.3366e+00,  4.5401e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 5.4705e-01, -3.4061e-01,  2.8371e+00,  ..., -5.7598e-01,\n",
      "            3.4559e-01, -6.3473e-01],\n",
      "          [-2.6303e-01,  1.5292e-02,  3.2465e-03,  ...,  1.1090e+00,\n",
      "           -1.4754e-01,  1.5608e-01]],\n",
      "\n",
      "         [[-2.4636e-01,  2.2850e-01,  8.8671e-01,  ...,  1.2067e+00,\n",
      "            8.1093e-01, -1.2199e+00],\n",
      "          [-5.5769e-03,  2.9887e-01,  1.3795e+00,  ...,  1.4798e+00,\n",
      "           -1.5471e+00,  2.0977e+00]],\n",
      "\n",
      "         [[-2.2148e-02, -8.0760e-01,  4.3742e-01,  ...,  4.2828e-01,\n",
      "            9.8508e-01,  9.2872e-02],\n",
      "          [-6.6924e-01,  1.2753e+00, -4.5587e-01,  ...,  2.0340e+00,\n",
      "           -2.8096e+00,  1.4904e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.4919e-01,  1.1616e-01,  1.2080e+00,  ..., -4.1396e-01,\n",
      "            2.3466e+00, -5.1326e-02],\n",
      "          [-1.7379e+00, -9.0232e-01, -1.6034e-01,  ...,  4.1836e-03,\n",
      "           -1.8639e+00, -5.8793e-01]],\n",
      "\n",
      "         [[-1.9682e+00,  2.6376e-02,  1.1443e+00,  ..., -1.6258e+00,\n",
      "           -4.6614e-02, -1.0390e-01],\n",
      "          [-2.0475e+00, -7.7171e-01,  3.3732e-01,  ...,  1.3826e+00,\n",
      "            9.4335e-01,  1.9652e+00]],\n",
      "\n",
      "         [[-5.6288e-01,  9.8870e-01,  9.5953e-01,  ...,  4.3043e-01,\n",
      "            3.6804e-03, -6.0127e-01],\n",
      "          [-1.6795e+00,  1.0035e+00, -7.3199e-01,  ...,  1.7877e+00,\n",
      "           -1.2715e+00,  7.2507e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1445e-03,  1.7922e-02,  7.6684e-02,  ...,  2.4755e-02,\n",
      "            3.4963e-02, -1.7424e-02],\n",
      "          [-7.1752e-02,  5.1330e-03,  3.4826e-02,  ...,  1.1101e+00,\n",
      "           -1.5756e+00,  1.5554e+00]],\n",
      "\n",
      "         [[ 2.3766e-04,  1.1015e-01,  2.1634e+00,  ...,  1.2179e-01,\n",
      "            2.4350e+00, -5.2561e-03],\n",
      "          [-1.1071e-01, -3.4717e-02,  7.3233e-01,  ...,  1.5332e-02,\n",
      "            8.2664e-01,  1.3110e+00]],\n",
      "\n",
      "         [[ 9.9193e-01, -1.6093e+00,  1.5919e+00,  ...,  1.9577e-01,\n",
      "            1.2672e+00, -3.0920e-01],\n",
      "          [-3.2658e-01,  6.9483e-01, -6.2464e-01,  ...,  9.3210e-01,\n",
      "           -2.2508e+00,  1.3467e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2497e-02, -2.8659e-01,  1.3874e+00,  ..., -1.0180e-02,\n",
      "            2.9363e+00, -2.8035e-01],\n",
      "          [-2.3238e-04,  6.5374e-03, -5.4714e-03,  ...,  3.3627e-02,\n",
      "           -4.1591e-02,  3.8613e-02]],\n",
      "\n",
      "         [[ 8.4322e-02,  1.4722e-02,  1.8952e+00,  ..., -4.6787e-01,\n",
      "            4.8735e-01, -7.7094e-01],\n",
      "          [-6.3666e-01, -1.4768e+00,  6.3073e-01,  ...,  2.0584e+00,\n",
      "           -4.0602e-01,  9.7693e-01]],\n",
      "\n",
      "         [[-5.5054e-01,  9.7092e-01,  1.0065e+00,  ...,  1.4496e-02,\n",
      "            2.5529e-02, -5.9771e-01],\n",
      "          [-1.6862e+00,  1.0163e+00, -7.5991e-01,  ...,  1.8213e+00,\n",
      "           -1.3366e+00,  4.5401e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.4705e-01, -3.4061e-01,  2.8371e+00,  ..., -5.7598e-01,\n",
      "            3.4559e-01, -6.3473e-01],\n",
      "          [-2.6303e-01,  1.5292e-02,  3.2465e-03,  ...,  1.1090e+00,\n",
      "           -1.4754e-01,  1.5608e-01]],\n",
      "\n",
      "         [[-2.4636e-01,  2.2850e-01,  8.8671e-01,  ...,  1.2067e+00,\n",
      "            8.1093e-01, -1.2199e+00],\n",
      "          [-5.5769e-03,  2.9887e-01,  1.3795e+00,  ...,  1.4798e+00,\n",
      "           -1.5471e+00,  2.0977e+00]],\n",
      "\n",
      "         [[-2.2148e-02, -8.0760e-01,  4.3742e-01,  ...,  4.2828e-01,\n",
      "            9.8508e-01,  9.2872e-02],\n",
      "          [-6.6924e-01,  1.2753e+00, -4.5587e-01,  ...,  2.0340e+00,\n",
      "           -2.8096e+00,  1.4904e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.4919e-01,  1.1616e-01,  1.2080e+00,  ..., -4.1396e-01,\n",
      "            2.3466e+00, -5.1326e-02],\n",
      "          [-1.7379e+00, -9.0232e-01, -1.6034e-01,  ...,  4.1836e-03,\n",
      "           -1.8639e+00, -5.8793e-01]],\n",
      "\n",
      "         [[-1.9682e+00,  2.6376e-02,  1.1443e+00,  ..., -1.6258e+00,\n",
      "           -4.6614e-02, -1.0390e-01],\n",
      "          [-2.0475e+00, -7.7171e-01,  3.3732e-01,  ...,  1.3826e+00,\n",
      "            9.4335e-01,  1.9652e+00]],\n",
      "\n",
      "         [[-5.6288e-01,  9.8870e-01,  9.5953e-01,  ...,  4.3043e-01,\n",
      "            3.6804e-03, -6.0127e-01],\n",
      "          [-1.6795e+00,  1.0035e+00, -7.3199e-01,  ...,  1.7877e+00,\n",
      "           -1.2715e+00,  7.2507e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1445e-03,  1.7922e-02,  7.6684e-02,  ...,  2.4755e-02,\n",
      "            3.4963e-02, -1.7424e-02],\n",
      "          [-7.1752e-02,  5.1330e-03,  3.4826e-02,  ...,  1.1101e+00,\n",
      "           -1.5756e+00,  1.5554e+00]],\n",
      "\n",
      "         [[ 2.3766e-04,  1.1015e-01,  2.1634e+00,  ...,  1.2179e-01,\n",
      "            2.4350e+00, -5.2561e-03],\n",
      "          [-1.1071e-01, -3.4717e-02,  7.3233e-01,  ...,  1.5332e-02,\n",
      "            8.2664e-01,  1.3110e+00]],\n",
      "\n",
      "         [[ 9.9193e-01, -1.6093e+00,  1.5919e+00,  ...,  1.9577e-01,\n",
      "            1.2672e+00, -3.0920e-01],\n",
      "          [-3.2658e-01,  6.9483e-01, -6.2464e-01,  ...,  9.3210e-01,\n",
      "           -2.2508e+00,  1.3467e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2497e-02, -2.8659e-01,  1.3874e+00,  ..., -1.0180e-02,\n",
      "            2.9363e+00, -2.8035e-01],\n",
      "          [-2.3238e-04,  6.5374e-03, -5.4714e-03,  ...,  3.3627e-02,\n",
      "           -4.1591e-02,  3.8613e-02]],\n",
      "\n",
      "         [[ 8.4322e-02,  1.4722e-02,  1.8952e+00,  ..., -4.6787e-01,\n",
      "            4.8735e-01, -7.7094e-01],\n",
      "          [-6.3666e-01, -1.4768e+00,  6.3073e-01,  ...,  2.0584e+00,\n",
      "           -4.0602e-01,  9.7693e-01]],\n",
      "\n",
      "         [[-5.5054e-01,  9.7092e-01,  1.0065e+00,  ...,  1.4496e-02,\n",
      "            2.5529e-02, -5.9771e-01],\n",
      "          [-1.6862e+00,  1.0163e+00, -7.5991e-01,  ...,  1.8213e+00,\n",
      "           -1.3366e+00,  4.5401e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 5.4705e-01, -3.4061e-01,  2.8371e+00,  ..., -5.7598e-01,\n",
      "            3.4559e-01, -6.3473e-01],\n",
      "          [-2.6303e-01,  1.5292e-02,  3.2465e-03,  ...,  1.1090e+00,\n",
      "           -1.4754e-01,  1.5608e-01]],\n",
      "\n",
      "         [[-2.4636e-01,  2.2850e-01,  8.8671e-01,  ...,  1.2067e+00,\n",
      "            8.1093e-01, -1.2199e+00],\n",
      "          [-5.5769e-03,  2.9887e-01,  1.3795e+00,  ...,  1.4798e+00,\n",
      "           -1.5471e+00,  2.0977e+00]],\n",
      "\n",
      "         [[-2.2148e-02, -8.0760e-01,  4.3742e-01,  ...,  4.2828e-01,\n",
      "            9.8508e-01,  9.2872e-02],\n",
      "          [-6.6924e-01,  1.2753e+00, -4.5587e-01,  ...,  2.0340e+00,\n",
      "           -2.8096e+00,  1.4904e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.4919e-01,  1.1616e-01,  1.2080e+00,  ..., -4.1396e-01,\n",
      "            2.3466e+00, -5.1326e-02],\n",
      "          [-1.7379e+00, -9.0232e-01, -1.6034e-01,  ...,  4.1836e-03,\n",
      "           -1.8639e+00, -5.8793e-01]],\n",
      "\n",
      "         [[-1.9682e+00,  2.6376e-02,  1.1443e+00,  ..., -1.6258e+00,\n",
      "           -4.6614e-02, -1.0390e-01],\n",
      "          [-2.0475e+00, -7.7171e-01,  3.3732e-01,  ...,  1.3826e+00,\n",
      "            9.4335e-01,  1.9652e+00]],\n",
      "\n",
      "         [[-5.6288e-01,  9.8870e-01,  9.5953e-01,  ...,  4.3043e-01,\n",
      "            3.6804e-03, -6.0127e-01],\n",
      "          [-1.6795e+00,  1.0035e+00, -7.3199e-01,  ...,  1.7877e+00,\n",
      "           -1.2715e+00,  7.2507e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1445e-03,  1.7922e-02,  7.6684e-02,  ...,  2.4755e-02,\n",
      "            3.4963e-02, -1.7424e-02],\n",
      "          [-7.1752e-02,  5.1330e-03,  3.4826e-02,  ...,  1.1101e+00,\n",
      "           -1.5756e+00,  1.5554e+00]],\n",
      "\n",
      "         [[ 2.3766e-04,  1.1015e-01,  2.1634e+00,  ...,  1.2179e-01,\n",
      "            2.4350e+00, -5.2561e-03],\n",
      "          [-1.1071e-01, -3.4717e-02,  7.3233e-01,  ...,  1.5332e-02,\n",
      "            8.2664e-01,  1.3110e+00]],\n",
      "\n",
      "         [[ 9.9193e-01, -1.6093e+00,  1.5919e+00,  ...,  1.9577e-01,\n",
      "            1.2672e+00, -3.0920e-01],\n",
      "          [-3.2658e-01,  6.9483e-01, -6.2464e-01,  ...,  9.3210e-01,\n",
      "           -2.2508e+00,  1.3467e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2497e-02, -2.8659e-01,  1.3874e+00,  ..., -1.0180e-02,\n",
      "            2.9363e+00, -2.8035e-01],\n",
      "          [-2.3238e-04,  6.5374e-03, -5.4714e-03,  ...,  3.3627e-02,\n",
      "           -4.1591e-02,  3.8613e-02]],\n",
      "\n",
      "         [[ 8.4322e-02,  1.4722e-02,  1.8952e+00,  ..., -4.6787e-01,\n",
      "            4.8735e-01, -7.7094e-01],\n",
      "          [-6.3666e-01, -1.4768e+00,  6.3073e-01,  ...,  2.0584e+00,\n",
      "           -4.0602e-01,  9.7693e-01]],\n",
      "\n",
      "         [[-5.5054e-01,  9.7092e-01,  1.0065e+00,  ...,  1.4496e-02,\n",
      "            2.5529e-02, -5.9771e-01],\n",
      "          [-1.6862e+00,  1.0163e+00, -7.5991e-01,  ...,  1.8213e+00,\n",
      "           -1.3366e+00,  4.5401e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ..., -4.2932e-01,\n",
      "            2.3776e-01, -3.8306e-01],\n",
      "          [-2.9510e-04,  8.4139e-02, -1.3101e-01,  ...,  1.0622e+00,\n",
      "            5.9233e-02,  4.7447e-01]],\n",
      "\n",
      "         [[-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2312e+00,\n",
      "            3.5623e-01, -1.0708e+00],\n",
      "          [ 1.1736e-01,  4.6061e-02,  1.2484e+00,  ...,  1.2586e+00,\n",
      "           -1.2809e+00,  1.8739e+00]],\n",
      "\n",
      "         [[-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  4.0399e-01,\n",
      "            9.4862e-01,  4.1856e-01],\n",
      "          [-6.3925e-01,  1.5122e+00, -1.0792e+00,  ...,  1.7959e+00,\n",
      "           -2.2566e+00,  1.3626e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.7808e-01,\n",
      "            2.2985e+00,  2.7471e-01],\n",
      "          [-1.6058e+00, -7.5509e-02, -5.7110e-01,  ..., -4.5660e-01,\n",
      "           -1.2948e+00, -5.8341e-01]],\n",
      "\n",
      "         [[-1.8966e+00, -4.2556e-01,  9.2253e-01,  ..., -1.4783e+00,\n",
      "           -1.0317e-01,  1.5499e-01],\n",
      "          [-1.7722e+00, -4.4583e-01, -1.7098e-01,  ...,  8.0216e-01,\n",
      "            1.0031e+00,  1.6764e+00]],\n",
      "\n",
      "         [[-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  5.4744e-01,\n",
      "           -1.9918e-01, -3.5232e-01],\n",
      "          [-1.4283e+00,  5.1447e-01, -8.7082e-01,  ...,  1.6534e+00,\n",
      "           -9.7372e-01, -2.1263e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ..., -2.4278e-01,\n",
      "            2.3608e-02, -3.5038e-01],\n",
      "          [ 1.7966e-02,  5.3725e-02, -1.1375e-01,  ...,  1.3163e+00,\n",
      "           -1.9300e+00,  2.4275e+00]],\n",
      "\n",
      "         [[ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ...,  3.3590e-01,\n",
      "            1.8219e+00, -2.7341e-02],\n",
      "          [ 2.1597e-01, -3.0118e-01,  8.5102e-01,  ..., -4.1850e-02,\n",
      "            3.4603e-01,  5.1816e-01]],\n",
      "\n",
      "         [[ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  2.1714e-01,\n",
      "            1.2684e+00,  6.2421e-02],\n",
      "          [-3.4506e-01,  1.1309e+00, -1.1300e+00,  ...,  5.9669e-01,\n",
      "           -1.7256e+00,  1.2792e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ..., -1.5472e-02,\n",
      "            3.0969e+00, -2.2519e-01],\n",
      "          [ 2.3174e-01, -6.3868e-01,  5.6830e-01,  ...,  2.8469e-01,\n",
      "           -9.0352e-01, -1.6159e-02]],\n",
      "\n",
      "         [[-2.3909e-02, -2.7392e-01,  1.5834e+00,  ..., -4.8154e-01,\n",
      "            3.6199e-01, -5.5629e-01],\n",
      "          [-4.6450e-01, -5.2436e-01,  3.2091e-01,  ...,  1.7847e+00,\n",
      "           -1.8865e-01,  1.0437e+00]],\n",
      "\n",
      "         [[-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  4.1485e-02,\n",
      "           -1.7011e-01, -3.0652e-01],\n",
      "          [-1.5166e+00,  1.2491e+00, -1.0485e+00,  ...,  6.6783e-01,\n",
      "           -1.0338e+00,  3.0362e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ..., -4.2932e-01,\n",
      "            2.3776e-01, -3.8306e-01],\n",
      "          [-2.9510e-04,  8.4139e-02, -1.3101e-01,  ...,  1.0622e+00,\n",
      "            5.9233e-02,  4.7447e-01]],\n",
      "\n",
      "         [[-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2312e+00,\n",
      "            3.5623e-01, -1.0708e+00],\n",
      "          [ 1.1736e-01,  4.6061e-02,  1.2484e+00,  ...,  1.2586e+00,\n",
      "           -1.2809e+00,  1.8739e+00]],\n",
      "\n",
      "         [[-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  4.0399e-01,\n",
      "            9.4862e-01,  4.1856e-01],\n",
      "          [-6.3925e-01,  1.5122e+00, -1.0792e+00,  ...,  1.7959e+00,\n",
      "           -2.2566e+00,  1.3626e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.7808e-01,\n",
      "            2.2985e+00,  2.7471e-01],\n",
      "          [-1.6058e+00, -7.5509e-02, -5.7110e-01,  ..., -4.5660e-01,\n",
      "           -1.2948e+00, -5.8341e-01]],\n",
      "\n",
      "         [[-1.8966e+00, -4.2556e-01,  9.2253e-01,  ..., -1.4783e+00,\n",
      "           -1.0317e-01,  1.5499e-01],\n",
      "          [-1.7722e+00, -4.4583e-01, -1.7098e-01,  ...,  8.0216e-01,\n",
      "            1.0031e+00,  1.6764e+00]],\n",
      "\n",
      "         [[-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  5.4744e-01,\n",
      "           -1.9918e-01, -3.5232e-01],\n",
      "          [-1.4283e+00,  5.1447e-01, -8.7082e-01,  ...,  1.6534e+00,\n",
      "           -9.7372e-01, -2.1263e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ..., -2.4278e-01,\n",
      "            2.3608e-02, -3.5038e-01],\n",
      "          [ 1.7966e-02,  5.3725e-02, -1.1375e-01,  ...,  1.3163e+00,\n",
      "           -1.9300e+00,  2.4275e+00]],\n",
      "\n",
      "         [[ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ...,  3.3590e-01,\n",
      "            1.8219e+00, -2.7341e-02],\n",
      "          [ 2.1597e-01, -3.0118e-01,  8.5102e-01,  ..., -4.1850e-02,\n",
      "            3.4603e-01,  5.1816e-01]],\n",
      "\n",
      "         [[ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  2.1714e-01,\n",
      "            1.2684e+00,  6.2421e-02],\n",
      "          [-3.4506e-01,  1.1309e+00, -1.1300e+00,  ...,  5.9669e-01,\n",
      "           -1.7256e+00,  1.2792e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ..., -1.5472e-02,\n",
      "            3.0969e+00, -2.2519e-01],\n",
      "          [ 2.3174e-01, -6.3868e-01,  5.6830e-01,  ...,  2.8469e-01,\n",
      "           -9.0352e-01, -1.6159e-02]],\n",
      "\n",
      "         [[-2.3909e-02, -2.7392e-01,  1.5834e+00,  ..., -4.8154e-01,\n",
      "            3.6199e-01, -5.5629e-01],\n",
      "          [-4.6450e-01, -5.2436e-01,  3.2091e-01,  ...,  1.7847e+00,\n",
      "           -1.8865e-01,  1.0437e+00]],\n",
      "\n",
      "         [[-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  4.1485e-02,\n",
      "           -1.7011e-01, -3.0652e-01],\n",
      "          [-1.5166e+00,  1.2491e+00, -1.0485e+00,  ...,  6.6783e-01,\n",
      "           -1.0338e+00,  3.0362e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ...,  1.0622e+00,\n",
      "           5.9233e-02,  4.7447e-01],\n",
      "         [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2586e+00,\n",
      "          -1.2809e+00,  1.8739e+00],\n",
      "         [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  1.7959e+00,\n",
      "          -2.2566e+00,  1.3626e+00],\n",
      "         ...,\n",
      "         [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.5660e-01,\n",
      "          -1.2948e+00, -5.8341e-01],\n",
      "         [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ...,  8.0216e-01,\n",
      "           1.0031e+00,  1.6764e+00],\n",
      "         [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  1.6534e+00,\n",
      "          -9.7372e-01, -2.1263e-01]],\n",
      "\n",
      "        [[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ...,  1.3163e+00,\n",
      "          -1.9300e+00,  2.4275e+00],\n",
      "         [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ..., -4.1850e-02,\n",
      "           3.4603e-01,  5.1816e-01],\n",
      "         [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  5.9669e-01,\n",
      "          -1.7256e+00,  1.2792e+00],\n",
      "         ...,\n",
      "         [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ...,  2.8469e-01,\n",
      "          -9.0352e-01, -1.6159e-02],\n",
      "         [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ...,  1.7847e+00,\n",
      "          -1.8865e-01,  1.0437e+00],\n",
      "         [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  6.6783e-01,\n",
      "          -1.0338e+00,  3.0362e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ..., -4.2932e-01,\n",
      "            2.3776e-01, -3.8306e-01],\n",
      "          [-2.9510e-04,  8.4139e-02, -1.3101e-01,  ...,  1.0622e+00,\n",
      "            5.9233e-02,  4.7447e-01]],\n",
      "\n",
      "         [[-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2312e+00,\n",
      "            3.5623e-01, -1.0708e+00],\n",
      "          [ 1.1736e-01,  4.6061e-02,  1.2484e+00,  ...,  1.2586e+00,\n",
      "           -1.2809e+00,  1.8739e+00]],\n",
      "\n",
      "         [[-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  4.0399e-01,\n",
      "            9.4862e-01,  4.1856e-01],\n",
      "          [-6.3925e-01,  1.5122e+00, -1.0792e+00,  ...,  1.7959e+00,\n",
      "           -2.2566e+00,  1.3626e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.7808e-01,\n",
      "            2.2985e+00,  2.7471e-01],\n",
      "          [-1.6058e+00, -7.5509e-02, -5.7110e-01,  ..., -4.5660e-01,\n",
      "           -1.2948e+00, -5.8341e-01]],\n",
      "\n",
      "         [[-1.8966e+00, -4.2556e-01,  9.2253e-01,  ..., -1.4783e+00,\n",
      "           -1.0317e-01,  1.5499e-01],\n",
      "          [-1.7722e+00, -4.4583e-01, -1.7098e-01,  ...,  8.0216e-01,\n",
      "            1.0031e+00,  1.6764e+00]],\n",
      "\n",
      "         [[-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  5.4744e-01,\n",
      "           -1.9918e-01, -3.5232e-01],\n",
      "          [-1.4283e+00,  5.1447e-01, -8.7082e-01,  ...,  1.6534e+00,\n",
      "           -9.7372e-01, -2.1263e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ..., -2.4278e-01,\n",
      "            2.3608e-02, -3.5038e-01],\n",
      "          [ 1.7966e-02,  5.3725e-02, -1.1375e-01,  ...,  1.3163e+00,\n",
      "           -1.9300e+00,  2.4275e+00]],\n",
      "\n",
      "         [[ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ...,  3.3590e-01,\n",
      "            1.8219e+00, -2.7341e-02],\n",
      "          [ 2.1597e-01, -3.0118e-01,  8.5102e-01,  ..., -4.1850e-02,\n",
      "            3.4603e-01,  5.1816e-01]],\n",
      "\n",
      "         [[ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  2.1714e-01,\n",
      "            1.2684e+00,  6.2421e-02],\n",
      "          [-3.4506e-01,  1.1309e+00, -1.1300e+00,  ...,  5.9669e-01,\n",
      "           -1.7256e+00,  1.2792e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ..., -1.5472e-02,\n",
      "            3.0969e+00, -2.2519e-01],\n",
      "          [ 2.3174e-01, -6.3868e-01,  5.6830e-01,  ...,  2.8469e-01,\n",
      "           -9.0352e-01, -1.6159e-02]],\n",
      "\n",
      "         [[-2.3909e-02, -2.7392e-01,  1.5834e+00,  ..., -4.8154e-01,\n",
      "            3.6199e-01, -5.5629e-01],\n",
      "          [-4.6450e-01, -5.2436e-01,  3.2091e-01,  ...,  1.7847e+00,\n",
      "           -1.8865e-01,  1.0437e+00]],\n",
      "\n",
      "         [[-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  4.1485e-02,\n",
      "           -1.7011e-01, -3.0652e-01],\n",
      "          [-1.5166e+00,  1.2491e+00, -1.0485e+00,  ...,  6.6783e-01,\n",
      "           -1.0338e+00,  3.0362e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 4.5302e-01, -4.2169e-01,  2.3806e+00,  ..., -4.2932e-01,\n",
      "            2.3776e-01, -3.8306e-01],\n",
      "          [-2.4142e-01,  1.2541e-01,  6.7816e-01,  ...,  1.2312e+00,\n",
      "            3.5623e-01, -1.0708e+00],\n",
      "          [-3.9841e-02, -1.1479e+00, -1.1510e-03,  ...,  4.0399e-01,\n",
      "            9.4862e-01,  4.1856e-01],\n",
      "          ...,\n",
      "          [-1.0230e+00, -9.3019e-02,  6.9950e-01,  ..., -4.7808e-01,\n",
      "            2.2985e+00,  2.7471e-01],\n",
      "          [-1.8966e+00, -4.2556e-01,  9.2253e-01,  ..., -1.4783e+00,\n",
      "           -1.0317e-01,  1.5499e-01],\n",
      "          [-4.0048e-01,  9.7661e-01,  8.8843e-01,  ...,  5.4744e-01,\n",
      "           -1.9918e-01, -3.5232e-01]],\n",
      "\n",
      "         [[-2.9510e-04,  8.4139e-02, -1.3101e-01,  ...,  1.0622e+00,\n",
      "            5.9233e-02,  4.7447e-01],\n",
      "          [ 1.1736e-01,  4.6061e-02,  1.2484e+00,  ...,  1.2586e+00,\n",
      "           -1.2809e+00,  1.8739e+00],\n",
      "          [-6.3925e-01,  1.5122e+00, -1.0792e+00,  ...,  1.7959e+00,\n",
      "           -2.2566e+00,  1.3626e+00],\n",
      "          ...,\n",
      "          [-1.6058e+00, -7.5509e-02, -5.7110e-01,  ..., -4.5660e-01,\n",
      "           -1.2948e+00, -5.8341e-01],\n",
      "          [-1.7722e+00, -4.4583e-01, -1.7098e-01,  ...,  8.0216e-01,\n",
      "            1.0031e+00,  1.6764e+00],\n",
      "          [-1.4283e+00,  5.1447e-01, -8.7082e-01,  ...,  1.6534e+00,\n",
      "           -9.7372e-01, -2.1263e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0962e-01, -3.4025e-01,  1.4510e+00,  ..., -2.4278e-01,\n",
      "            2.3608e-02, -3.5038e-01],\n",
      "          [ 4.7663e-02,  2.5341e-01,  1.8644e+00,  ...,  3.3590e-01,\n",
      "            1.8219e+00, -2.7341e-02],\n",
      "          [ 1.0901e+00, -1.9505e+00,  1.2374e+00,  ...,  2.1714e-01,\n",
      "            1.2684e+00,  6.2421e-02],\n",
      "          ...,\n",
      "          [ 8.4880e-02, -1.6726e-01,  1.4236e+00,  ..., -1.5472e-02,\n",
      "            3.0969e+00, -2.2519e-01],\n",
      "          [-2.3909e-02, -2.7392e-01,  1.5834e+00,  ..., -4.8154e-01,\n",
      "            3.6199e-01, -5.5629e-01],\n",
      "          [-5.0128e-01,  8.3669e-01,  9.9120e-01,  ...,  4.1485e-02,\n",
      "           -1.7011e-01, -3.0652e-01]],\n",
      "\n",
      "         [[ 1.7966e-02,  5.3725e-02, -1.1375e-01,  ...,  1.3163e+00,\n",
      "           -1.9300e+00,  2.4275e+00],\n",
      "          [ 2.1597e-01, -3.0118e-01,  8.5102e-01,  ..., -4.1850e-02,\n",
      "            3.4603e-01,  5.1816e-01],\n",
      "          [-3.4506e-01,  1.1309e+00, -1.1300e+00,  ...,  5.9669e-01,\n",
      "           -1.7256e+00,  1.2792e+00],\n",
      "          ...,\n",
      "          [ 2.3174e-01, -6.3868e-01,  5.6830e-01,  ...,  2.8469e-01,\n",
      "           -9.0352e-01, -1.6159e-02],\n",
      "          [-4.6450e-01, -5.2436e-01,  3.2091e-01,  ...,  1.7847e+00,\n",
      "           -1.8865e-01,  1.0437e+00],\n",
      "          [-1.5166e+00,  1.2491e+00, -1.0485e+00,  ...,  6.6783e-01,\n",
      "           -1.0338e+00,  3.0362e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 4.4814e-01, -4.4681e-01,  2.6062e+00,  ..., -4.7312e-01,\n",
      "            2.7786e-01, -4.1615e-01],\n",
      "          [-3.0557e-01,  1.5025e-01,  8.5249e-01,  ...,  1.2625e+00,\n",
      "            3.9149e-01, -1.1643e+00],\n",
      "          [-4.5827e-02,  1.0023e-02,  4.3408e-01,  ..., -7.1060e-02,\n",
      "            9.3218e-02, -6.2415e-02],\n",
      "          ...,\n",
      "          [-8.1508e-01, -7.6472e-02,  1.0943e+00,  ..., -4.0038e-01,\n",
      "            1.7100e+00,  6.2276e-02],\n",
      "          [-2.0000e+00, -4.3319e-01,  1.0665e+00,  ..., -1.5548e+00,\n",
      "           -7.9853e-02,  1.4504e-01],\n",
      "          [-4.4676e-01,  1.0772e+00,  9.8975e-01,  ...,  6.0173e-01,\n",
      "           -2.1510e-01, -3.8985e-01]],\n",
      "\n",
      "         [[-1.1388e-01,  1.3932e-01, -2.0549e-01,  ...,  1.1797e+00,\n",
      "            1.2586e-02,  5.9139e-01],\n",
      "          [ 1.2543e-01,  5.4238e-02,  1.3718e+00,  ...,  1.3974e+00,\n",
      "           -1.4144e+00,  2.0707e+00],\n",
      "          [-7.1723e-01,  1.6512e+00, -1.1869e+00,  ...,  1.9697e+00,\n",
      "           -2.4712e+00,  1.4916e+00],\n",
      "          ...,\n",
      "          [-1.7791e+00, -8.0340e-02, -6.3544e-01,  ..., -4.9855e-01,\n",
      "           -1.4334e+00, -6.3843e-01],\n",
      "          [-1.8301e+00, -4.2474e-01, -2.4221e-01,  ...,  9.4459e-01,\n",
      "            1.0093e+00,  1.7184e+00],\n",
      "          [-1.5020e+00,  5.5798e-01, -9.0802e-01,  ...,  1.7471e+00,\n",
      "           -1.0599e+00, -1.3121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8422e-02,  5.8422e-03,  1.9848e+00,  ...,  3.1713e-01,\n",
      "            6.3941e-01, -2.4778e-01],\n",
      "          [ 5.1655e-02,  2.8567e-01,  2.0569e+00,  ...,  3.7512e-01,\n",
      "            2.0002e+00, -3.2895e-02],\n",
      "          [ 1.0072e+00, -1.8463e+00,  1.4009e+00,  ...,  2.6534e-01,\n",
      "            1.2946e+00,  2.3435e-02],\n",
      "          ...,\n",
      "          [ 9.4325e-02, -1.8577e-01,  1.5817e+00,  ..., -1.7133e-02,\n",
      "            3.4407e+00, -2.5021e-01],\n",
      "          [-8.6065e-02, -2.5117e-01,  1.8832e+00,  ..., -3.0905e-01,\n",
      "            4.5676e-01, -5.0071e-01],\n",
      "          [-5.5476e-01,  9.1333e-01,  1.1162e+00,  ...,  5.1947e-02,\n",
      "           -1.7619e-01, -3.3592e-01]],\n",
      "\n",
      "         [[ 1.8720e-02,  5.8681e-02, -1.2573e-01,  ...,  1.4563e+00,\n",
      "           -2.1310e+00,  2.6825e+00],\n",
      "          [ 2.4572e-01, -3.3205e-01,  9.3320e-01,  ..., -2.8385e-02,\n",
      "            3.6203e-01,  5.9261e-01],\n",
      "          [-3.7798e-01,  1.2348e+00, -1.2486e+00,  ...,  6.7966e-01,\n",
      "           -1.8998e+00,  1.4250e+00],\n",
      "          ...,\n",
      "          [ 1.8243e-01, -8.7117e-02, -1.3469e-02,  ...,  1.0168e+00,\n",
      "           -1.0642e+00,  1.2489e+00],\n",
      "          [ 8.3291e-04,  2.8919e-03, -7.0949e-03,  ...,  1.6695e-02,\n",
      "           -2.0404e-02,  2.6644e-02],\n",
      "          [-1.5369e+00,  1.3146e+00, -1.1218e+00,  ...,  7.5407e-01,\n",
      "           -1.1407e+00,  4.1158e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 4.4814e-01, -4.4681e-01,  2.6062e+00,  ..., -4.7312e-01,\n",
      "            2.7786e-01, -4.1615e-01],\n",
      "          [-1.1388e-01,  1.3932e-01, -2.0549e-01,  ...,  1.1797e+00,\n",
      "            1.2586e-02,  5.9139e-01]],\n",
      "\n",
      "         [[-3.0557e-01,  1.5025e-01,  8.5249e-01,  ...,  1.2625e+00,\n",
      "            3.9149e-01, -1.1643e+00],\n",
      "          [ 1.2543e-01,  5.4238e-02,  1.3718e+00,  ...,  1.3974e+00,\n",
      "           -1.4144e+00,  2.0707e+00]],\n",
      "\n",
      "         [[-4.5827e-02,  1.0023e-02,  4.3408e-01,  ..., -7.1060e-02,\n",
      "            9.3218e-02, -6.2415e-02],\n",
      "          [-7.1723e-01,  1.6512e+00, -1.1869e+00,  ...,  1.9697e+00,\n",
      "           -2.4712e+00,  1.4916e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1508e-01, -7.6472e-02,  1.0943e+00,  ..., -4.0038e-01,\n",
      "            1.7100e+00,  6.2276e-02],\n",
      "          [-1.7791e+00, -8.0340e-02, -6.3544e-01,  ..., -4.9855e-01,\n",
      "           -1.4334e+00, -6.3843e-01]],\n",
      "\n",
      "         [[-2.0000e+00, -4.3319e-01,  1.0665e+00,  ..., -1.5548e+00,\n",
      "           -7.9853e-02,  1.4504e-01],\n",
      "          [-1.8301e+00, -4.2474e-01, -2.4221e-01,  ...,  9.4459e-01,\n",
      "            1.0093e+00,  1.7184e+00]],\n",
      "\n",
      "         [[-4.4676e-01,  1.0772e+00,  9.8975e-01,  ...,  6.0173e-01,\n",
      "           -2.1510e-01, -3.8985e-01],\n",
      "          [-1.5020e+00,  5.5798e-01, -9.0802e-01,  ...,  1.7471e+00,\n",
      "           -1.0599e+00, -1.3121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8422e-02,  5.8422e-03,  1.9848e+00,  ...,  3.1713e-01,\n",
      "            6.3941e-01, -2.4778e-01],\n",
      "          [ 1.8720e-02,  5.8681e-02, -1.2573e-01,  ...,  1.4563e+00,\n",
      "           -2.1310e+00,  2.6825e+00]],\n",
      "\n",
      "         [[ 5.1655e-02,  2.8567e-01,  2.0569e+00,  ...,  3.7512e-01,\n",
      "            2.0002e+00, -3.2895e-02],\n",
      "          [ 2.4572e-01, -3.3205e-01,  9.3320e-01,  ..., -2.8385e-02,\n",
      "            3.6203e-01,  5.9261e-01]],\n",
      "\n",
      "         [[ 1.0072e+00, -1.8463e+00,  1.4009e+00,  ...,  2.6534e-01,\n",
      "            1.2946e+00,  2.3435e-02],\n",
      "          [-3.7798e-01,  1.2348e+00, -1.2486e+00,  ...,  6.7966e-01,\n",
      "           -1.8998e+00,  1.4250e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4325e-02, -1.8577e-01,  1.5817e+00,  ..., -1.7133e-02,\n",
      "            3.4407e+00, -2.5021e-01],\n",
      "          [ 1.8243e-01, -8.7117e-02, -1.3469e-02,  ...,  1.0168e+00,\n",
      "           -1.0642e+00,  1.2489e+00]],\n",
      "\n",
      "         [[-8.6065e-02, -2.5117e-01,  1.8832e+00,  ..., -3.0905e-01,\n",
      "            4.5676e-01, -5.0071e-01],\n",
      "          [ 8.3291e-04,  2.8919e-03, -7.0949e-03,  ...,  1.6695e-02,\n",
      "           -2.0404e-02,  2.6644e-02]],\n",
      "\n",
      "         [[-5.5476e-01,  9.1333e-01,  1.1162e+00,  ...,  5.1947e-02,\n",
      "           -1.7619e-01, -3.3592e-01],\n",
      "          [-1.5369e+00,  1.3146e+00, -1.1218e+00,  ...,  7.5407e-01,\n",
      "           -1.1407e+00,  4.1158e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 4.4814e-01, -4.4681e-01,  2.6062e+00,  ..., -4.7312e-01,\n",
      "            2.7786e-01, -4.1615e-01],\n",
      "          [-1.1388e-01,  1.3932e-01, -2.0549e-01,  ...,  1.1797e+00,\n",
      "            1.2586e-02,  5.9139e-01]],\n",
      "\n",
      "         [[-3.0557e-01,  1.5025e-01,  8.5249e-01,  ...,  1.2625e+00,\n",
      "            3.9149e-01, -1.1643e+00],\n",
      "          [ 1.2543e-01,  5.4238e-02,  1.3718e+00,  ...,  1.3974e+00,\n",
      "           -1.4144e+00,  2.0707e+00]],\n",
      "\n",
      "         [[-4.5827e-02,  1.0023e-02,  4.3408e-01,  ..., -7.1060e-02,\n",
      "            9.3218e-02, -6.2415e-02],\n",
      "          [-7.1723e-01,  1.6512e+00, -1.1869e+00,  ...,  1.9697e+00,\n",
      "           -2.4712e+00,  1.4916e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1508e-01, -7.6472e-02,  1.0943e+00,  ..., -4.0038e-01,\n",
      "            1.7100e+00,  6.2276e-02],\n",
      "          [-1.7791e+00, -8.0340e-02, -6.3544e-01,  ..., -4.9855e-01,\n",
      "           -1.4334e+00, -6.3843e-01]],\n",
      "\n",
      "         [[-2.0000e+00, -4.3319e-01,  1.0665e+00,  ..., -1.5548e+00,\n",
      "           -7.9853e-02,  1.4504e-01],\n",
      "          [-1.8301e+00, -4.2474e-01, -2.4221e-01,  ...,  9.4459e-01,\n",
      "            1.0093e+00,  1.7184e+00]],\n",
      "\n",
      "         [[-4.4676e-01,  1.0772e+00,  9.8975e-01,  ...,  6.0173e-01,\n",
      "           -2.1510e-01, -3.8985e-01],\n",
      "          [-1.5020e+00,  5.5798e-01, -9.0802e-01,  ...,  1.7471e+00,\n",
      "           -1.0599e+00, -1.3121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8422e-02,  5.8422e-03,  1.9848e+00,  ...,  3.1713e-01,\n",
      "            6.3941e-01, -2.4778e-01],\n",
      "          [ 1.8720e-02,  5.8681e-02, -1.2573e-01,  ...,  1.4563e+00,\n",
      "           -2.1310e+00,  2.6825e+00]],\n",
      "\n",
      "         [[ 5.1655e-02,  2.8567e-01,  2.0569e+00,  ...,  3.7512e-01,\n",
      "            2.0002e+00, -3.2895e-02],\n",
      "          [ 2.4572e-01, -3.3205e-01,  9.3320e-01,  ..., -2.8385e-02,\n",
      "            3.6203e-01,  5.9261e-01]],\n",
      "\n",
      "         [[ 1.0072e+00, -1.8463e+00,  1.4009e+00,  ...,  2.6534e-01,\n",
      "            1.2946e+00,  2.3435e-02],\n",
      "          [-3.7798e-01,  1.2348e+00, -1.2486e+00,  ...,  6.7966e-01,\n",
      "           -1.8998e+00,  1.4250e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4325e-02, -1.8577e-01,  1.5817e+00,  ..., -1.7133e-02,\n",
      "            3.4407e+00, -2.5021e-01],\n",
      "          [ 1.8243e-01, -8.7117e-02, -1.3469e-02,  ...,  1.0168e+00,\n",
      "           -1.0642e+00,  1.2489e+00]],\n",
      "\n",
      "         [[-8.6065e-02, -2.5117e-01,  1.8832e+00,  ..., -3.0905e-01,\n",
      "            4.5676e-01, -5.0071e-01],\n",
      "          [ 8.3291e-04,  2.8919e-03, -7.0949e-03,  ...,  1.6695e-02,\n",
      "           -2.0404e-02,  2.6644e-02]],\n",
      "\n",
      "         [[-5.5476e-01,  9.1333e-01,  1.1162e+00,  ...,  5.1947e-02,\n",
      "           -1.7619e-01, -3.3592e-01],\n",
      "          [-1.5369e+00,  1.3146e+00, -1.1218e+00,  ...,  7.5407e-01,\n",
      "           -1.1407e+00,  4.1158e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 4.4814e-01, -4.4681e-01,  2.6062e+00,  ..., -4.7312e-01,\n",
      "            2.7786e-01, -4.1615e-01],\n",
      "          [-1.1388e-01,  1.3932e-01, -2.0549e-01,  ...,  1.1797e+00,\n",
      "            1.2586e-02,  5.9139e-01]],\n",
      "\n",
      "         [[-3.0557e-01,  1.5025e-01,  8.5249e-01,  ...,  1.2625e+00,\n",
      "            3.9149e-01, -1.1643e+00],\n",
      "          [ 1.2543e-01,  5.4238e-02,  1.3718e+00,  ...,  1.3974e+00,\n",
      "           -1.4144e+00,  2.0707e+00]],\n",
      "\n",
      "         [[-4.5827e-02,  1.0023e-02,  4.3408e-01,  ..., -7.1060e-02,\n",
      "            9.3218e-02, -6.2415e-02],\n",
      "          [-7.1723e-01,  1.6512e+00, -1.1869e+00,  ...,  1.9697e+00,\n",
      "           -2.4712e+00,  1.4916e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1508e-01, -7.6472e-02,  1.0943e+00,  ..., -4.0038e-01,\n",
      "            1.7100e+00,  6.2276e-02],\n",
      "          [-1.7791e+00, -8.0340e-02, -6.3544e-01,  ..., -4.9855e-01,\n",
      "           -1.4334e+00, -6.3843e-01]],\n",
      "\n",
      "         [[-2.0000e+00, -4.3319e-01,  1.0665e+00,  ..., -1.5548e+00,\n",
      "           -7.9853e-02,  1.4504e-01],\n",
      "          [-1.8301e+00, -4.2474e-01, -2.4221e-01,  ...,  9.4459e-01,\n",
      "            1.0093e+00,  1.7184e+00]],\n",
      "\n",
      "         [[-4.4676e-01,  1.0772e+00,  9.8975e-01,  ...,  6.0173e-01,\n",
      "           -2.1510e-01, -3.8985e-01],\n",
      "          [-1.5020e+00,  5.5798e-01, -9.0802e-01,  ...,  1.7471e+00,\n",
      "           -1.0599e+00, -1.3121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8422e-02,  5.8422e-03,  1.9848e+00,  ...,  3.1713e-01,\n",
      "            6.3941e-01, -2.4778e-01],\n",
      "          [ 1.8720e-02,  5.8681e-02, -1.2573e-01,  ...,  1.4563e+00,\n",
      "           -2.1310e+00,  2.6825e+00]],\n",
      "\n",
      "         [[ 5.1655e-02,  2.8567e-01,  2.0569e+00,  ...,  3.7512e-01,\n",
      "            2.0002e+00, -3.2895e-02],\n",
      "          [ 2.4572e-01, -3.3205e-01,  9.3320e-01,  ..., -2.8385e-02,\n",
      "            3.6203e-01,  5.9261e-01]],\n",
      "\n",
      "         [[ 1.0072e+00, -1.8463e+00,  1.4009e+00,  ...,  2.6534e-01,\n",
      "            1.2946e+00,  2.3435e-02],\n",
      "          [-3.7798e-01,  1.2348e+00, -1.2486e+00,  ...,  6.7966e-01,\n",
      "           -1.8998e+00,  1.4250e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4325e-02, -1.8577e-01,  1.5817e+00,  ..., -1.7133e-02,\n",
      "            3.4407e+00, -2.5021e-01],\n",
      "          [ 1.8243e-01, -8.7117e-02, -1.3469e-02,  ...,  1.0168e+00,\n",
      "           -1.0642e+00,  1.2489e+00]],\n",
      "\n",
      "         [[-8.6065e-02, -2.5117e-01,  1.8832e+00,  ..., -3.0905e-01,\n",
      "            4.5676e-01, -5.0071e-01],\n",
      "          [ 8.3291e-04,  2.8919e-03, -7.0949e-03,  ...,  1.6695e-02,\n",
      "           -2.0404e-02,  2.6644e-02]],\n",
      "\n",
      "         [[-5.5476e-01,  9.1333e-01,  1.1162e+00,  ...,  5.1947e-02,\n",
      "           -1.7619e-01, -3.3592e-01],\n",
      "          [-1.5369e+00,  1.3146e+00, -1.1218e+00,  ...,  7.5407e-01,\n",
      "           -1.1407e+00,  4.1158e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.7728,  0.8054],\n",
      "        [-0.5923,  0.7476]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:21:50,991] Trial 1 finished with value: 0.7684 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate.loading:Using the latest cached version of the module from /root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Mon Jan 27 17:41:32 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.462800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.4610,  0.2239,  0.1797,  ...,  0.4760,  0.3778, -1.1822],\n",
      "          [ 0.0000,  0.5907,  1.3290,  ...,  0.9129,  1.4973, -0.0060]],\n",
      "\n",
      "         [[-0.0000, -1.3393, -1.5101,  ...,  0.0818, -0.2176,  0.8150],\n",
      "          [-1.1822, -0.3162, -0.8698,  ..., -1.2270, -1.0572,  0.6903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1457, -1.3738, -0.3909,  ...,  1.4034, -0.9132, -0.0941],\n",
      "          [ 0.8644, -0.1621, -1.2901,  ...,  0.0000, -0.3838,  1.0472]],\n",
      "\n",
      "         [[ 0.4409,  0.7840,  0.1379,  ..., -1.3062, -0.5688,  1.2655],\n",
      "          [ 0.7401, -0.7432,  0.3414,  ...,  0.0673, -0.3051,  1.5806]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.6745, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.5804,  0.7750]],\n",
      "\n",
      "         [[ 0.0000, -0.0714, -0.0517,  ...,  1.0718, -1.0277, -0.0000],\n",
      "          [-0.4660, -0.8578,  0.9161,  ...,  0.0000,  0.4014, -0.1455]],\n",
      "\n",
      "         [[-0.3145, -0.2627,  0.4321,  ..., -0.0813, -0.3101,  1.6387],\n",
      "          [ 1.0959,  0.3933, -1.1568,  ..., -0.5177,  0.3194,  0.6137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4476, -1.4941, -0.9139,  ...,  0.1090, -1.0588,  1.1796],\n",
      "          [ 1.1710,  0.5638, -0.9714,  ..., -0.2755, -0.2720,  1.8079]],\n",
      "\n",
      "         [[-0.2865,  0.0000, -0.8569,  ..., -0.9286, -1.2058,  1.6617],\n",
      "          [ 0.9491, -0.3148,  0.3091,  ...,  0.0920, -0.7796,  0.2390]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.0000, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.9520]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.4610,  0.2239,  0.1797,  ...,  0.4760,  0.3778, -1.1822],\n",
      "          [ 0.0000,  0.5907,  1.3290,  ...,  0.9129,  1.4973, -0.0060]],\n",
      "\n",
      "         [[-0.0000, -1.3393, -1.5101,  ...,  0.0818, -0.2176,  0.8150],\n",
      "          [-1.1822, -0.3162, -0.8698,  ..., -1.2270, -1.0572,  0.6903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1457, -1.3738, -0.3909,  ...,  1.4034, -0.9132, -0.0941],\n",
      "          [ 0.8644, -0.1621, -1.2901,  ...,  0.0000, -0.3838,  1.0472]],\n",
      "\n",
      "         [[ 0.4409,  0.7840,  0.1379,  ..., -1.3062, -0.5688,  1.2655],\n",
      "          [ 0.7401, -0.7432,  0.3414,  ...,  0.0673, -0.3051,  1.5806]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.6745, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.5804,  0.7750]],\n",
      "\n",
      "         [[ 0.0000, -0.0714, -0.0517,  ...,  1.0718, -1.0277, -0.0000],\n",
      "          [-0.4660, -0.8578,  0.9161,  ...,  0.0000,  0.4014, -0.1455]],\n",
      "\n",
      "         [[-0.3145, -0.2627,  0.4321,  ..., -0.0813, -0.3101,  1.6387],\n",
      "          [ 1.0959,  0.3933, -1.1568,  ..., -0.5177,  0.3194,  0.6137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4476, -1.4941, -0.9139,  ...,  0.1090, -1.0588,  1.1796],\n",
      "          [ 1.1710,  0.5638, -0.9714,  ..., -0.2755, -0.2720,  1.8079]],\n",
      "\n",
      "         [[-0.2865,  0.0000, -0.8569,  ..., -0.9286, -1.2058,  1.6617],\n",
      "          [ 0.9491, -0.3148,  0.3091,  ...,  0.0920, -0.7796,  0.2390]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.0000, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.9520]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.0000,  0.0000],\n",
      "         [-0.4610,  0.2239,  0.1797,  ...,  0.9129,  1.4973, -0.0060],\n",
      "         [-0.0000, -1.3393, -1.5101,  ..., -1.2270, -1.0572,  0.6903],\n",
      "         ...,\n",
      "         [-1.1457, -1.3738, -0.3909,  ...,  0.0000, -0.3838,  1.0472],\n",
      "         [ 0.4409,  0.7840,  0.1379,  ...,  0.0673, -0.3051,  1.5806],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.0000]],\n",
      "\n",
      "        [[ 0.2704, -0.4656,  0.4714,  ...,  0.3279, -0.5804,  0.7750],\n",
      "         [ 0.0000, -0.0714, -0.0517,  ...,  0.0000,  0.4014, -0.1455],\n",
      "         [-0.3145, -0.2627,  0.4321,  ..., -0.5177,  0.3194,  0.6137],\n",
      "         ...,\n",
      "         [-0.4476, -1.4941, -0.9139,  ..., -0.2755, -0.2720,  1.8079],\n",
      "         [-0.2865,  0.0000, -0.8569,  ...,  0.0920, -0.7796,  0.2390],\n",
      "         [-0.2610, -1.6930, -0.0142,  ...,  1.4009, -0.0577,  0.9520]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.4610,  0.2239,  0.1797,  ...,  0.4760,  0.3778, -1.1822],\n",
      "          [ 0.0000,  0.5907,  1.3290,  ...,  0.9129,  1.4973, -0.0060]],\n",
      "\n",
      "         [[-0.0000, -1.3393, -1.5101,  ...,  0.0818, -0.2176,  0.8150],\n",
      "          [-1.1822, -0.3162, -0.8698,  ..., -1.2270, -1.0572,  0.6903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1457, -1.3738, -0.3909,  ...,  1.4034, -0.9132, -0.0941],\n",
      "          [ 0.8644, -0.1621, -1.2901,  ...,  0.0000, -0.3838,  1.0472]],\n",
      "\n",
      "         [[ 0.4409,  0.7840,  0.1379,  ..., -1.3062, -0.5688,  1.2655],\n",
      "          [ 0.7401, -0.7432,  0.3414,  ...,  0.0673, -0.3051,  1.5806]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.6745, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.5804,  0.7750]],\n",
      "\n",
      "         [[ 0.0000, -0.0714, -0.0517,  ...,  1.0718, -1.0277, -0.0000],\n",
      "          [-0.4660, -0.8578,  0.9161,  ...,  0.0000,  0.4014, -0.1455]],\n",
      "\n",
      "         [[-0.3145, -0.2627,  0.4321,  ..., -0.0813, -0.3101,  1.6387],\n",
      "          [ 1.0959,  0.3933, -1.1568,  ..., -0.5177,  0.3194,  0.6137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4476, -1.4941, -0.9139,  ...,  0.1090, -1.0588,  1.1796],\n",
      "          [ 1.1710,  0.5638, -0.9714,  ..., -0.2755, -0.2720,  1.8079]],\n",
      "\n",
      "         [[-0.2865,  0.0000, -0.8569,  ..., -0.9286, -1.2058,  1.6617],\n",
      "          [ 0.9491, -0.3148,  0.3091,  ...,  0.0920, -0.7796,  0.2390]],\n",
      "\n",
      "         [[-0.2610, -1.6930, -0.0142,  ...,  0.0000, -0.0000,  0.6543],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.9520]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [-0.4610,  0.2239,  0.1797,  ...,  0.4760,  0.3778, -1.1822],\n",
      "          [-0.0000, -1.3393, -1.5101,  ...,  0.0818, -0.2176,  0.8150],\n",
      "          ...,\n",
      "          [-1.1457, -1.3738, -0.3909,  ...,  1.4034, -0.9132, -0.0941],\n",
      "          [ 0.4409,  0.7840,  0.1379,  ..., -1.3062, -0.5688,  1.2655],\n",
      "          [-0.2610, -1.6930, -0.0142,  ...,  0.6745, -0.0000,  0.6543]],\n",
      "\n",
      "         [[-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.5907,  1.3290,  ...,  0.9129,  1.4973, -0.0060],\n",
      "          [-1.1822, -0.3162, -0.8698,  ..., -1.2270, -1.0572,  0.6903],\n",
      "          ...,\n",
      "          [ 0.8644, -0.1621, -1.2901,  ...,  0.0000, -0.3838,  1.0472],\n",
      "          [ 0.7401, -0.7432,  0.3414,  ...,  0.0673, -0.3051,  1.5806],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704, -0.4656,  0.4714,  ..., -0.2097, -0.3814,  0.7671],\n",
      "          [ 0.0000, -0.0714, -0.0517,  ...,  1.0718, -1.0277, -0.0000],\n",
      "          [-0.3145, -0.2627,  0.4321,  ..., -0.0813, -0.3101,  1.6387],\n",
      "          ...,\n",
      "          [-0.4476, -1.4941, -0.9139,  ...,  0.1090, -1.0588,  1.1796],\n",
      "          [-0.2865,  0.0000, -0.8569,  ..., -0.9286, -1.2058,  1.6617],\n",
      "          [-0.2610, -1.6930, -0.0142,  ...,  0.0000, -0.0000,  0.6543]],\n",
      "\n",
      "         [[-0.0330, -0.6522, -0.3759,  ...,  0.3279, -0.5804,  0.7750],\n",
      "          [-0.4660, -0.8578,  0.9161,  ...,  0.0000,  0.4014, -0.1455],\n",
      "          [ 1.0959,  0.3933, -1.1568,  ..., -0.5177,  0.3194,  0.6137],\n",
      "          ...,\n",
      "          [ 1.1710,  0.5638, -0.9714,  ..., -0.2755, -0.2720,  1.8079],\n",
      "          [ 0.9491, -0.3148,  0.3091,  ...,  0.0920, -0.7796,  0.2390],\n",
      "          [ 1.9431, -0.2686,  1.4013,  ...,  1.4009, -0.0577,  0.9520]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.3789e-02, -3.8864e-01,  4.1831e-01,  ..., -3.6478e-01,\n",
      "           -6.6623e-01,  6.9896e-01],\n",
      "          [-4.5664e-01, -1.1995e-02,  1.3536e-01,  ...,  3.5827e-01,\n",
      "            1.1922e-01, -8.4447e-01],\n",
      "          [-6.8363e-02, -1.3541e+00, -1.4636e+00,  ...,  3.5057e-02,\n",
      "           -3.3928e-01,  8.4679e-01],\n",
      "          ...,\n",
      "          [-1.1302e+00, -1.3754e+00, -3.7640e-01,  ...,  1.2694e+00,\n",
      "           -9.4375e-01,  1.1988e-02],\n",
      "          [ 4.6152e-01,  8.3003e-01,  1.4906e-01,  ..., -1.4188e+00,\n",
      "           -6.4253e-01,  1.3781e+00],\n",
      "          [-2.8875e-01, -1.8027e+00, -1.2694e-02,  ...,  7.1096e-01,\n",
      "            5.7927e-03,  7.2006e-01]],\n",
      "\n",
      "         [[-1.8899e-02, -7.2127e-01, -3.8733e-01,  ...,  3.5426e-01,\n",
      "           -1.5798e-02,  3.6479e-02],\n",
      "          [ 5.7157e-03,  6.4370e-01,  1.4647e+00,  ...,  1.0081e+00,\n",
      "            1.6443e+00, -1.1252e-03],\n",
      "          [-1.1431e+00, -3.9017e-01, -8.4651e-01,  ..., -1.1673e+00,\n",
      "           -1.0541e+00,  7.2018e-01],\n",
      "          ...,\n",
      "          [ 9.5742e-01, -1.8288e-01, -1.4200e+00,  ...,  2.1341e-03,\n",
      "           -4.2543e-01,  1.1592e+00],\n",
      "          [ 7.1783e-01, -8.1030e-01,  3.2353e-01,  ...,  9.5859e-02,\n",
      "           -3.1272e-01,  1.5686e+00],\n",
      "          [ 2.0315e+00, -3.2014e-01,  1.4699e+00,  ...,  1.4696e+00,\n",
      "           -8.2945e-02,  2.3899e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8653e-02, -1.5049e-01,  1.1024e-01,  ...,  5.5085e-03,\n",
      "           -2.3075e-01,  2.2392e-01],\n",
      "          [-1.1892e-02, -1.1551e-01, -3.5211e-02,  ...,  1.1111e+00,\n",
      "           -1.0950e+00,  8.3276e-02],\n",
      "          [-3.4608e-01, -2.8337e-01,  4.6936e-01,  ..., -8.0699e-02,\n",
      "           -3.7117e-01,  1.7674e+00],\n",
      "          ...,\n",
      "          [-4.6801e-01, -1.5960e+00, -9.3176e-01,  ...,  1.2569e-01,\n",
      "           -1.1040e+00,  1.2812e+00],\n",
      "          [-2.7394e-01, -6.3824e-02, -7.8084e-01,  ..., -9.0279e-01,\n",
      "           -1.2485e+00,  1.7036e+00],\n",
      "          [-2.6372e-01, -1.7516e+00,  1.1566e-02,  ..., -6.6168e-03,\n",
      "           -4.2444e-02,  7.1721e-01]],\n",
      "\n",
      "         [[-4.7542e-02, -6.8720e-01, -4.0217e-01,  ...,  3.7081e-01,\n",
      "           -6.1272e-01,  8.5676e-01],\n",
      "          [-5.0877e-01, -9.4306e-01,  1.0052e+00,  ...,  1.3531e-02,\n",
      "            4.3087e-01, -1.4459e-01],\n",
      "          [ 1.2041e+00,  4.2629e-01, -1.2720e+00,  ..., -5.6336e-01,\n",
      "            3.4580e-01,  6.8302e-01],\n",
      "          ...,\n",
      "          [-1.7223e-02, -7.5838e-03,  1.4633e-03,  ...,  2.0734e-02,\n",
      "           -6.1126e-03,  2.3738e-02],\n",
      "          [ 9.2018e-01, -3.1366e-01,  3.0814e-01,  ...,  1.3401e-01,\n",
      "           -7.7029e-01,  3.0233e-01],\n",
      "          [ 2.0085e+00, -3.1080e-01,  1.4421e+00,  ...,  1.4632e+00,\n",
      "           -9.6136e-02,  1.0125e+00]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 5.3789e-02, -3.8864e-01,  4.1831e-01,  ..., -3.6478e-01,\n",
      "           -6.6623e-01,  6.9896e-01],\n",
      "          [-1.8899e-02, -7.2127e-01, -3.8733e-01,  ...,  3.5426e-01,\n",
      "           -1.5798e-02,  3.6479e-02]],\n",
      "\n",
      "         [[-4.5664e-01, -1.1995e-02,  1.3536e-01,  ...,  3.5827e-01,\n",
      "            1.1922e-01, -8.4447e-01],\n",
      "          [ 5.7157e-03,  6.4370e-01,  1.4647e+00,  ...,  1.0081e+00,\n",
      "            1.6443e+00, -1.1252e-03]],\n",
      "\n",
      "         [[-6.8363e-02, -1.3541e+00, -1.4636e+00,  ...,  3.5057e-02,\n",
      "           -3.3928e-01,  8.4679e-01],\n",
      "          [-1.1431e+00, -3.9017e-01, -8.4651e-01,  ..., -1.1673e+00,\n",
      "           -1.0541e+00,  7.2018e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1302e+00, -1.3754e+00, -3.7640e-01,  ...,  1.2694e+00,\n",
      "           -9.4375e-01,  1.1988e-02],\n",
      "          [ 9.5742e-01, -1.8288e-01, -1.4200e+00,  ...,  2.1341e-03,\n",
      "           -4.2543e-01,  1.1592e+00]],\n",
      "\n",
      "         [[ 4.6152e-01,  8.3003e-01,  1.4906e-01,  ..., -1.4188e+00,\n",
      "           -6.4253e-01,  1.3781e+00],\n",
      "          [ 7.1783e-01, -8.1030e-01,  3.2353e-01,  ...,  9.5859e-02,\n",
      "           -3.1272e-01,  1.5686e+00]],\n",
      "\n",
      "         [[-2.8875e-01, -1.8027e+00, -1.2694e-02,  ...,  7.1096e-01,\n",
      "            5.7927e-03,  7.2006e-01],\n",
      "          [ 2.0315e+00, -3.2014e-01,  1.4699e+00,  ...,  1.4696e+00,\n",
      "           -8.2945e-02,  2.3899e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8653e-02, -1.5049e-01,  1.1024e-01,  ...,  5.5085e-03,\n",
      "           -2.3075e-01,  2.2392e-01],\n",
      "          [-4.7542e-02, -6.8720e-01, -4.0217e-01,  ...,  3.7081e-01,\n",
      "           -6.1272e-01,  8.5676e-01]],\n",
      "\n",
      "         [[-1.1892e-02, -1.1551e-01, -3.5211e-02,  ...,  1.1111e+00,\n",
      "           -1.0950e+00,  8.3276e-02],\n",
      "          [-5.0877e-01, -9.4306e-01,  1.0052e+00,  ...,  1.3531e-02,\n",
      "            4.3087e-01, -1.4459e-01]],\n",
      "\n",
      "         [[-3.4608e-01, -2.8337e-01,  4.6936e-01,  ..., -8.0699e-02,\n",
      "           -3.7117e-01,  1.7674e+00],\n",
      "          [ 1.2041e+00,  4.2629e-01, -1.2720e+00,  ..., -5.6336e-01,\n",
      "            3.4580e-01,  6.8302e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6801e-01, -1.5960e+00, -9.3176e-01,  ...,  1.2569e-01,\n",
      "           -1.1040e+00,  1.2812e+00],\n",
      "          [-1.7223e-02, -7.5838e-03,  1.4633e-03,  ...,  2.0734e-02,\n",
      "           -6.1126e-03,  2.3738e-02]],\n",
      "\n",
      "         [[-2.7394e-01, -6.3824e-02, -7.8084e-01,  ..., -9.0279e-01,\n",
      "           -1.2485e+00,  1.7036e+00],\n",
      "          [ 9.2018e-01, -3.1366e-01,  3.0814e-01,  ...,  1.3401e-01,\n",
      "           -7.7029e-01,  3.0233e-01]],\n",
      "\n",
      "         [[-2.6372e-01, -1.7516e+00,  1.1566e-02,  ..., -6.6168e-03,\n",
      "           -4.2444e-02,  7.1721e-01],\n",
      "          [ 2.0085e+00, -3.1080e-01,  1.4421e+00,  ...,  1.4632e+00,\n",
      "           -9.6136e-02,  1.0125e+00]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.3789e-02, -3.8864e-01,  4.1831e-01,  ..., -3.6478e-01,\n",
      "           -6.6623e-01,  6.9896e-01],\n",
      "          [-1.8899e-02, -7.2127e-01, -3.8733e-01,  ...,  3.5426e-01,\n",
      "           -1.5798e-02,  3.6479e-02]],\n",
      "\n",
      "         [[-4.5664e-01, -1.1995e-02,  1.3536e-01,  ...,  3.5827e-01,\n",
      "            1.1922e-01, -8.4447e-01],\n",
      "          [ 5.7157e-03,  6.4370e-01,  1.4647e+00,  ...,  1.0081e+00,\n",
      "            1.6443e+00, -1.1252e-03]],\n",
      "\n",
      "         [[-6.8363e-02, -1.3541e+00, -1.4636e+00,  ...,  3.5057e-02,\n",
      "           -3.3928e-01,  8.4679e-01],\n",
      "          [-1.1431e+00, -3.9017e-01, -8.4651e-01,  ..., -1.1673e+00,\n",
      "           -1.0541e+00,  7.2018e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1302e+00, -1.3754e+00, -3.7640e-01,  ...,  1.2694e+00,\n",
      "           -9.4375e-01,  1.1988e-02],\n",
      "          [ 9.5742e-01, -1.8288e-01, -1.4200e+00,  ...,  2.1341e-03,\n",
      "           -4.2543e-01,  1.1592e+00]],\n",
      "\n",
      "         [[ 4.6152e-01,  8.3003e-01,  1.4906e-01,  ..., -1.4188e+00,\n",
      "           -6.4253e-01,  1.3781e+00],\n",
      "          [ 7.1783e-01, -8.1030e-01,  3.2353e-01,  ...,  9.5859e-02,\n",
      "           -3.1272e-01,  1.5686e+00]],\n",
      "\n",
      "         [[-2.8875e-01, -1.8027e+00, -1.2694e-02,  ...,  7.1096e-01,\n",
      "            5.7927e-03,  7.2006e-01],\n",
      "          [ 2.0315e+00, -3.2014e-01,  1.4699e+00,  ...,  1.4696e+00,\n",
      "           -8.2945e-02,  2.3899e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8653e-02, -1.5049e-01,  1.1024e-01,  ...,  5.5085e-03,\n",
      "           -2.3075e-01,  2.2392e-01],\n",
      "          [-4.7542e-02, -6.8720e-01, -4.0217e-01,  ...,  3.7081e-01,\n",
      "           -6.1272e-01,  8.5676e-01]],\n",
      "\n",
      "         [[-1.1892e-02, -1.1551e-01, -3.5211e-02,  ...,  1.1111e+00,\n",
      "           -1.0950e+00,  8.3276e-02],\n",
      "          [-5.0877e-01, -9.4306e-01,  1.0052e+00,  ...,  1.3531e-02,\n",
      "            4.3087e-01, -1.4459e-01]],\n",
      "\n",
      "         [[-3.4608e-01, -2.8337e-01,  4.6936e-01,  ..., -8.0699e-02,\n",
      "           -3.7117e-01,  1.7674e+00],\n",
      "          [ 1.2041e+00,  4.2629e-01, -1.2720e+00,  ..., -5.6336e-01,\n",
      "            3.4580e-01,  6.8302e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6801e-01, -1.5960e+00, -9.3176e-01,  ...,  1.2569e-01,\n",
      "           -1.1040e+00,  1.2812e+00],\n",
      "          [-1.7223e-02, -7.5838e-03,  1.4633e-03,  ...,  2.0734e-02,\n",
      "           -6.1126e-03,  2.3738e-02]],\n",
      "\n",
      "         [[-2.7394e-01, -6.3824e-02, -7.8084e-01,  ..., -9.0279e-01,\n",
      "           -1.2485e+00,  1.7036e+00],\n",
      "          [ 9.2018e-01, -3.1366e-01,  3.0814e-01,  ...,  1.3401e-01,\n",
      "           -7.7029e-01,  3.0233e-01]],\n",
      "\n",
      "         [[-2.6372e-01, -1.7516e+00,  1.1566e-02,  ..., -6.6168e-03,\n",
      "           -4.2444e-02,  7.1721e-01],\n",
      "          [ 2.0085e+00, -3.1080e-01,  1.4421e+00,  ...,  1.4632e+00,\n",
      "           -9.6136e-02,  1.0125e+00]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 5.3789e-02, -3.8864e-01,  4.1831e-01,  ..., -3.6478e-01,\n",
      "           -6.6623e-01,  6.9896e-01],\n",
      "          [-1.8899e-02, -7.2127e-01, -3.8733e-01,  ...,  3.5426e-01,\n",
      "           -1.5798e-02,  3.6479e-02]],\n",
      "\n",
      "         [[-4.5664e-01, -1.1995e-02,  1.3536e-01,  ...,  3.5827e-01,\n",
      "            1.1922e-01, -8.4447e-01],\n",
      "          [ 5.7157e-03,  6.4370e-01,  1.4647e+00,  ...,  1.0081e+00,\n",
      "            1.6443e+00, -1.1252e-03]],\n",
      "\n",
      "         [[-6.8363e-02, -1.3541e+00, -1.4636e+00,  ...,  3.5057e-02,\n",
      "           -3.3928e-01,  8.4679e-01],\n",
      "          [-1.1431e+00, -3.9017e-01, -8.4651e-01,  ..., -1.1673e+00,\n",
      "           -1.0541e+00,  7.2018e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1302e+00, -1.3754e+00, -3.7640e-01,  ...,  1.2694e+00,\n",
      "           -9.4375e-01,  1.1988e-02],\n",
      "          [ 9.5742e-01, -1.8288e-01, -1.4200e+00,  ...,  2.1341e-03,\n",
      "           -4.2543e-01,  1.1592e+00]],\n",
      "\n",
      "         [[ 4.6152e-01,  8.3003e-01,  1.4906e-01,  ..., -1.4188e+00,\n",
      "           -6.4253e-01,  1.3781e+00],\n",
      "          [ 7.1783e-01, -8.1030e-01,  3.2353e-01,  ...,  9.5859e-02,\n",
      "           -3.1272e-01,  1.5686e+00]],\n",
      "\n",
      "         [[-2.8875e-01, -1.8027e+00, -1.2694e-02,  ...,  7.1096e-01,\n",
      "            5.7927e-03,  7.2006e-01],\n",
      "          [ 2.0315e+00, -3.2014e-01,  1.4699e+00,  ...,  1.4696e+00,\n",
      "           -8.2945e-02,  2.3899e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8653e-02, -1.5049e-01,  1.1024e-01,  ...,  5.5085e-03,\n",
      "           -2.3075e-01,  2.2392e-01],\n",
      "          [-4.7542e-02, -6.8720e-01, -4.0217e-01,  ...,  3.7081e-01,\n",
      "           -6.1272e-01,  8.5676e-01]],\n",
      "\n",
      "         [[-1.1892e-02, -1.1551e-01, -3.5211e-02,  ...,  1.1111e+00,\n",
      "           -1.0950e+00,  8.3276e-02],\n",
      "          [-5.0877e-01, -9.4306e-01,  1.0052e+00,  ...,  1.3531e-02,\n",
      "            4.3087e-01, -1.4459e-01]],\n",
      "\n",
      "         [[-3.4608e-01, -2.8337e-01,  4.6936e-01,  ..., -8.0699e-02,\n",
      "           -3.7117e-01,  1.7674e+00],\n",
      "          [ 1.2041e+00,  4.2629e-01, -1.2720e+00,  ..., -5.6336e-01,\n",
      "            3.4580e-01,  6.8302e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6801e-01, -1.5960e+00, -9.3176e-01,  ...,  1.2569e-01,\n",
      "           -1.1040e+00,  1.2812e+00],\n",
      "          [-1.7223e-02, -7.5838e-03,  1.4633e-03,  ...,  2.0734e-02,\n",
      "           -6.1126e-03,  2.3738e-02]],\n",
      "\n",
      "         [[-2.7394e-01, -6.3824e-02, -7.8084e-01,  ..., -9.0279e-01,\n",
      "           -1.2485e+00,  1.7036e+00],\n",
      "          [ 9.2018e-01, -3.1366e-01,  3.0814e-01,  ...,  1.3401e-01,\n",
      "           -7.7029e-01,  3.0233e-01]],\n",
      "\n",
      "         [[-2.6372e-01, -1.7516e+00,  1.1566e-02,  ..., -6.6168e-03,\n",
      "           -4.2444e-02,  7.1721e-01],\n",
      "          [ 2.0085e+00, -3.1080e-01,  1.4421e+00,  ...,  1.4632e+00,\n",
      "           -9.6136e-02,  1.0125e+00]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2661, -0.4441,  0.6079,  ..., -0.1377, -0.4256,  0.5653],\n",
      "          [ 0.0739, -0.5607, -0.2519,  ...,  0.3323, -0.1488, -0.1737]],\n",
      "\n",
      "         [[-0.2647,  0.2079, -0.0463,  ...,  0.4619,  0.5058, -0.8844],\n",
      "          [ 0.2373,  0.7564,  1.5226,  ...,  0.7228,  1.6208,  0.0153]],\n",
      "\n",
      "         [[-0.0998, -1.5021, -1.7898,  ...,  0.0471, -0.0668,  0.8077],\n",
      "          [-1.2407, -0.3789, -0.8857,  ..., -1.3423, -1.1378,  0.3979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2234, -1.3496, -0.2051,  ...,  1.5978, -0.7554, -0.1559],\n",
      "          [ 1.0424, -0.0197, -1.3775,  ..., -0.0756, -0.4074,  0.9736]],\n",
      "\n",
      "         [[ 0.7670,  0.7619,  0.1613,  ..., -1.4359, -0.3484,  1.3974],\n",
      "          [ 0.8681, -0.7641,  0.3527,  ..., -0.1329, -0.3695,  1.4175]],\n",
      "\n",
      "         [[ 0.1165, -1.6094, -0.2709,  ...,  0.6287,  0.1396,  0.6469],\n",
      "          [ 2.1670, -0.1657,  1.4685,  ...,  1.1390, -0.0388, -0.2236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2293, -0.3507,  0.5159,  ...,  0.0638, -0.2369,  0.5368],\n",
      "          [-0.0787, -0.7116, -0.4239,  ...,  0.3648, -0.7687,  0.6999]],\n",
      "\n",
      "         [[-0.2812,  0.0666,  0.1262,  ...,  1.2941, -0.9035, -0.2832],\n",
      "          [-0.4576, -0.8765,  0.6620,  ..., -0.0626,  0.1864, -0.3925]],\n",
      "\n",
      "         [[-0.3157, -0.1855,  0.5087,  ..., -0.0058, -0.0806,  1.5681],\n",
      "          [ 1.1930,  0.4671, -1.1558,  ..., -0.5636,  0.3587,  0.6215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4149, -1.9657, -1.2183,  ...,  0.1409, -1.1441,  1.5137],\n",
      "          [ 0.8221,  0.3531, -0.5955,  ..., -0.3087, -0.1713,  0.8971]],\n",
      "\n",
      "         [[ 0.0821, -0.0204, -0.8343,  ..., -0.8987, -1.1416,  1.7589],\n",
      "          [ 1.0643, -0.1619,  0.3029,  ...,  0.0450, -0.8353,  0.1056]],\n",
      "\n",
      "         [[ 0.0907, -1.7279, -0.0304,  ..., -0.0164,  0.0428,  0.6098],\n",
      "          [ 2.1919, -0.3621,  1.4799,  ...,  0.5015, -0.0775,  0.7121]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2661, -0.4441,  0.6079,  ..., -0.1377, -0.4256,  0.5653],\n",
      "          [ 0.0739, -0.5607, -0.2519,  ...,  0.3323, -0.1488, -0.1737]],\n",
      "\n",
      "         [[-0.2647,  0.2079, -0.0463,  ...,  0.4619,  0.5058, -0.8844],\n",
      "          [ 0.2373,  0.7564,  1.5226,  ...,  0.7228,  1.6208,  0.0153]],\n",
      "\n",
      "         [[-0.0998, -1.5021, -1.7898,  ...,  0.0471, -0.0668,  0.8077],\n",
      "          [-1.2407, -0.3789, -0.8857,  ..., -1.3423, -1.1378,  0.3979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2234, -1.3496, -0.2051,  ...,  1.5978, -0.7554, -0.1559],\n",
      "          [ 1.0424, -0.0197, -1.3775,  ..., -0.0756, -0.4074,  0.9736]],\n",
      "\n",
      "         [[ 0.7670,  0.7619,  0.1613,  ..., -1.4359, -0.3484,  1.3974],\n",
      "          [ 0.8681, -0.7641,  0.3527,  ..., -0.1329, -0.3695,  1.4175]],\n",
      "\n",
      "         [[ 0.1165, -1.6094, -0.2709,  ...,  0.6287,  0.1396,  0.6469],\n",
      "          [ 2.1670, -0.1657,  1.4685,  ...,  1.1390, -0.0388, -0.2236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2293, -0.3507,  0.5159,  ...,  0.0638, -0.2369,  0.5368],\n",
      "          [-0.0787, -0.7116, -0.4239,  ...,  0.3648, -0.7687,  0.6999]],\n",
      "\n",
      "         [[-0.2812,  0.0666,  0.1262,  ...,  1.2941, -0.9035, -0.2832],\n",
      "          [-0.4576, -0.8765,  0.6620,  ..., -0.0626,  0.1864, -0.3925]],\n",
      "\n",
      "         [[-0.3157, -0.1855,  0.5087,  ..., -0.0058, -0.0806,  1.5681],\n",
      "          [ 1.1930,  0.4671, -1.1558,  ..., -0.5636,  0.3587,  0.6215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4149, -1.9657, -1.2183,  ...,  0.1409, -1.1441,  1.5137],\n",
      "          [ 0.8221,  0.3531, -0.5955,  ..., -0.3087, -0.1713,  0.8971]],\n",
      "\n",
      "         [[ 0.0821, -0.0204, -0.8343,  ..., -0.8987, -1.1416,  1.7589],\n",
      "          [ 1.0643, -0.1619,  0.3029,  ...,  0.0450, -0.8353,  0.1056]],\n",
      "\n",
      "         [[ 0.0907, -1.7279, -0.0304,  ..., -0.0164,  0.0428,  0.6098],\n",
      "          [ 2.1919, -0.3621,  1.4799,  ...,  0.5015, -0.0775,  0.7121]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2661, -0.4441,  0.6079,  ...,  0.3323, -0.1488, -0.1737],\n",
      "         [-0.2647,  0.2079, -0.0463,  ...,  0.7228,  1.6208,  0.0153],\n",
      "         [-0.0998, -1.5021, -1.7898,  ..., -1.3423, -1.1378,  0.3979],\n",
      "         ...,\n",
      "         [-1.2234, -1.3496, -0.2051,  ..., -0.0756, -0.4074,  0.9736],\n",
      "         [ 0.7670,  0.7619,  0.1613,  ..., -0.1329, -0.3695,  1.4175],\n",
      "         [ 0.1165, -1.6094, -0.2709,  ...,  1.1390, -0.0388, -0.2236]],\n",
      "\n",
      "        [[ 0.2293, -0.3507,  0.5159,  ...,  0.3648, -0.7687,  0.6999],\n",
      "         [-0.2812,  0.0666,  0.1262,  ..., -0.0626,  0.1864, -0.3925],\n",
      "         [-0.3157, -0.1855,  0.5087,  ..., -0.5636,  0.3587,  0.6215],\n",
      "         ...,\n",
      "         [-0.4149, -1.9657, -1.2183,  ..., -0.3087, -0.1713,  0.8971],\n",
      "         [ 0.0821, -0.0204, -0.8343,  ...,  0.0450, -0.8353,  0.1056],\n",
      "         [ 0.0907, -1.7279, -0.0304,  ...,  0.5015, -0.0775,  0.7121]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2661, -0.4441,  0.6079,  ..., -0.1377, -0.4256,  0.5653],\n",
      "          [ 0.0739, -0.5607, -0.2519,  ...,  0.3323, -0.1488, -0.1737]],\n",
      "\n",
      "         [[-0.2647,  0.2079, -0.0463,  ...,  0.4619,  0.5058, -0.8844],\n",
      "          [ 0.2373,  0.7564,  1.5226,  ...,  0.7228,  1.6208,  0.0153]],\n",
      "\n",
      "         [[-0.0998, -1.5021, -1.7898,  ...,  0.0471, -0.0668,  0.8077],\n",
      "          [-1.2407, -0.3789, -0.8857,  ..., -1.3423, -1.1378,  0.3979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2234, -1.3496, -0.2051,  ...,  1.5978, -0.7554, -0.1559],\n",
      "          [ 1.0424, -0.0197, -1.3775,  ..., -0.0756, -0.4074,  0.9736]],\n",
      "\n",
      "         [[ 0.7670,  0.7619,  0.1613,  ..., -1.4359, -0.3484,  1.3974],\n",
      "          [ 0.8681, -0.7641,  0.3527,  ..., -0.1329, -0.3695,  1.4175]],\n",
      "\n",
      "         [[ 0.1165, -1.6094, -0.2709,  ...,  0.6287,  0.1396,  0.6469],\n",
      "          [ 2.1670, -0.1657,  1.4685,  ...,  1.1390, -0.0388, -0.2236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2293, -0.3507,  0.5159,  ...,  0.0638, -0.2369,  0.5368],\n",
      "          [-0.0787, -0.7116, -0.4239,  ...,  0.3648, -0.7687,  0.6999]],\n",
      "\n",
      "         [[-0.2812,  0.0666,  0.1262,  ...,  1.2941, -0.9035, -0.2832],\n",
      "          [-0.4576, -0.8765,  0.6620,  ..., -0.0626,  0.1864, -0.3925]],\n",
      "\n",
      "         [[-0.3157, -0.1855,  0.5087,  ..., -0.0058, -0.0806,  1.5681],\n",
      "          [ 1.1930,  0.4671, -1.1558,  ..., -0.5636,  0.3587,  0.6215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4149, -1.9657, -1.2183,  ...,  0.1409, -1.1441,  1.5137],\n",
      "          [ 0.8221,  0.3531, -0.5955,  ..., -0.3087, -0.1713,  0.8971]],\n",
      "\n",
      "         [[ 0.0821, -0.0204, -0.8343,  ..., -0.8987, -1.1416,  1.7589],\n",
      "          [ 1.0643, -0.1619,  0.3029,  ...,  0.0450, -0.8353,  0.1056]],\n",
      "\n",
      "         [[ 0.0907, -1.7279, -0.0304,  ..., -0.0164,  0.0428,  0.6098],\n",
      "          [ 2.1919, -0.3621,  1.4799,  ...,  0.5015, -0.0775,  0.7121]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2661, -0.4441,  0.6079,  ..., -0.1377, -0.4256,  0.5653],\n",
      "          [-0.2647,  0.2079, -0.0463,  ...,  0.4619,  0.5058, -0.8844],\n",
      "          [-0.0998, -1.5021, -1.7898,  ...,  0.0471, -0.0668,  0.8077],\n",
      "          ...,\n",
      "          [-1.2234, -1.3496, -0.2051,  ...,  1.5978, -0.7554, -0.1559],\n",
      "          [ 0.7670,  0.7619,  0.1613,  ..., -1.4359, -0.3484,  1.3974],\n",
      "          [ 0.1165, -1.6094, -0.2709,  ...,  0.6287,  0.1396,  0.6469]],\n",
      "\n",
      "         [[ 0.0739, -0.5607, -0.2519,  ...,  0.3323, -0.1488, -0.1737],\n",
      "          [ 0.2373,  0.7564,  1.5226,  ...,  0.7228,  1.6208,  0.0153],\n",
      "          [-1.2407, -0.3789, -0.8857,  ..., -1.3423, -1.1378,  0.3979],\n",
      "          ...,\n",
      "          [ 1.0424, -0.0197, -1.3775,  ..., -0.0756, -0.4074,  0.9736],\n",
      "          [ 0.8681, -0.7641,  0.3527,  ..., -0.1329, -0.3695,  1.4175],\n",
      "          [ 2.1670, -0.1657,  1.4685,  ...,  1.1390, -0.0388, -0.2236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2293, -0.3507,  0.5159,  ...,  0.0638, -0.2369,  0.5368],\n",
      "          [-0.2812,  0.0666,  0.1262,  ...,  1.2941, -0.9035, -0.2832],\n",
      "          [-0.3157, -0.1855,  0.5087,  ..., -0.0058, -0.0806,  1.5681],\n",
      "          ...,\n",
      "          [-0.4149, -1.9657, -1.2183,  ...,  0.1409, -1.1441,  1.5137],\n",
      "          [ 0.0821, -0.0204, -0.8343,  ..., -0.8987, -1.1416,  1.7589],\n",
      "          [ 0.0907, -1.7279, -0.0304,  ..., -0.0164,  0.0428,  0.6098]],\n",
      "\n",
      "         [[-0.0787, -0.7116, -0.4239,  ...,  0.3648, -0.7687,  0.6999],\n",
      "          [-0.4576, -0.8765,  0.6620,  ..., -0.0626,  0.1864, -0.3925],\n",
      "          [ 1.1930,  0.4671, -1.1558,  ..., -0.5636,  0.3587,  0.6215],\n",
      "          ...,\n",
      "          [ 0.8221,  0.3531, -0.5955,  ..., -0.3087, -0.1713,  0.8971],\n",
      "          [ 1.0643, -0.1619,  0.3029,  ...,  0.0450, -0.8353,  0.1056],\n",
      "          [ 2.1919, -0.3621,  1.4799,  ...,  0.5015, -0.0775,  0.7121]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 2.0734e-01, -4.9511e-01,  5.4738e-01,  ..., -1.5078e-01,\n",
      "           -5.2827e-01,  5.7083e-01],\n",
      "          [-2.3663e-01, -1.3221e-01, -1.0329e-01,  ...,  3.4992e-01,\n",
      "            2.4887e-01, -5.0412e-01],\n",
      "          [-8.1725e-03, -3.6102e-02,  1.1074e-03,  ..., -5.9860e-03,\n",
      "           -3.3815e-02,  3.2337e-02],\n",
      "          ...,\n",
      "          [-1.1967e+00, -1.4083e+00, -2.2451e-01,  ...,  1.5547e+00,\n",
      "           -7.8424e-01, -9.2051e-02],\n",
      "          [ 8.2969e-01,  8.1427e-01,  1.7945e-01,  ..., -1.5573e+00,\n",
      "           -3.8813e-01,  1.5233e+00],\n",
      "          [ 9.6691e-02, -1.6730e+00, -3.2016e-01,  ...,  6.2699e-01,\n",
      "            1.5438e-01,  7.2638e-01]],\n",
      "\n",
      "         [[ 1.3168e-01, -6.1718e-01, -1.9697e-01,  ...,  2.9735e-01,\n",
      "           -2.0426e-01, -3.6252e-02],\n",
      "          [ 2.6506e-01,  8.3608e-01,  1.6877e+00,  ...,  8.0165e-01,\n",
      "            1.7941e+00,  1.7666e-02],\n",
      "          [-1.2171e+00, -4.4132e-01, -8.7672e-01,  ..., -1.3383e+00,\n",
      "           -1.1844e+00,  4.3592e-01],\n",
      "          ...,\n",
      "          [ 1.1505e+00, -3.0085e-02, -1.5094e+00,  ..., -8.0445e-02,\n",
      "           -4.5134e-01,  1.0754e+00],\n",
      "          [ 7.9821e-01, -8.0932e-01,  3.0952e-01,  ..., -8.2561e-02,\n",
      "           -4.0983e-01,  1.2742e+00],\n",
      "          [ 2.2086e+00, -2.0921e-01,  1.4979e+00,  ...,  1.1598e+00,\n",
      "           -6.3895e-02, -1.8479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4179e-01, -5.7982e-01,  7.9565e-02,  ...,  8.0501e-02,\n",
      "           -7.4058e-01,  8.5245e-01],\n",
      "          [-3.2481e-01,  8.0122e-02,  1.7656e-01,  ...,  1.3766e+00,\n",
      "           -9.4703e-01, -2.6047e-01],\n",
      "          [-3.4905e-01, -1.9931e-01,  5.4653e-01,  ...,  9.2709e-03,\n",
      "           -1.2823e-01,  1.6808e+00],\n",
      "          ...,\n",
      "          [-4.6072e-01, -2.1832e+00, -1.3528e+00,  ...,  1.5649e-01,\n",
      "           -1.2706e+00,  1.6812e+00],\n",
      "          [ 8.3243e-02, -5.5258e-02, -7.9662e-01,  ..., -8.9016e-01,\n",
      "           -1.2113e+00,  1.8002e+00],\n",
      "          [ 6.9452e-02, -1.8693e+00, -1.1074e-01,  ..., -1.4538e-02,\n",
      "           -6.1316e-02,  7.2982e-01]],\n",
      "\n",
      "         [[-7.1722e-02, -7.7768e-01, -4.5878e-01,  ...,  3.9832e-01,\n",
      "           -8.4584e-01,  7.6664e-01],\n",
      "          [-5.0089e-01, -9.6543e-01,  7.1786e-01,  ..., -5.2773e-02,\n",
      "            1.8641e-01, -4.0528e-01],\n",
      "          [ 1.3007e+00,  4.9567e-01, -1.2620e+00,  ..., -6.0539e-01,\n",
      "            3.7568e-01,  6.9147e-01],\n",
      "          ...,\n",
      "          [ 1.1619e-01, -2.9286e-01, -1.8648e-01,  ...,  2.8897e-01,\n",
      "           -5.0379e-01,  7.5311e-01],\n",
      "          [-3.4660e-02, -1.2986e-01, -5.3944e-02,  ...,  9.0294e-02,\n",
      "           -1.2555e-01,  1.4034e-01],\n",
      "          [ 2.2255e+00, -4.3826e-01,  1.4839e+00,  ...,  5.4807e-01,\n",
      "           -1.5002e-01,  7.7246e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 2.0734e-01, -4.9511e-01,  5.4738e-01,  ..., -1.5078e-01,\n",
      "           -5.2827e-01,  5.7083e-01],\n",
      "          [ 1.3168e-01, -6.1718e-01, -1.9697e-01,  ...,  2.9735e-01,\n",
      "           -2.0426e-01, -3.6252e-02]],\n",
      "\n",
      "         [[-2.3663e-01, -1.3221e-01, -1.0329e-01,  ...,  3.4992e-01,\n",
      "            2.4887e-01, -5.0412e-01],\n",
      "          [ 2.6506e-01,  8.3608e-01,  1.6877e+00,  ...,  8.0165e-01,\n",
      "            1.7941e+00,  1.7666e-02]],\n",
      "\n",
      "         [[-8.1725e-03, -3.6102e-02,  1.1074e-03,  ..., -5.9860e-03,\n",
      "           -3.3815e-02,  3.2337e-02],\n",
      "          [-1.2171e+00, -4.4132e-01, -8.7672e-01,  ..., -1.3383e+00,\n",
      "           -1.1844e+00,  4.3592e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1967e+00, -1.4083e+00, -2.2451e-01,  ...,  1.5547e+00,\n",
      "           -7.8424e-01, -9.2051e-02],\n",
      "          [ 1.1505e+00, -3.0085e-02, -1.5094e+00,  ..., -8.0445e-02,\n",
      "           -4.5134e-01,  1.0754e+00]],\n",
      "\n",
      "         [[ 8.2969e-01,  8.1427e-01,  1.7945e-01,  ..., -1.5573e+00,\n",
      "           -3.8813e-01,  1.5233e+00],\n",
      "          [ 7.9821e-01, -8.0932e-01,  3.0952e-01,  ..., -8.2561e-02,\n",
      "           -4.0983e-01,  1.2742e+00]],\n",
      "\n",
      "         [[ 9.6691e-02, -1.6730e+00, -3.2016e-01,  ...,  6.2699e-01,\n",
      "            1.5438e-01,  7.2638e-01],\n",
      "          [ 2.2086e+00, -2.0921e-01,  1.4979e+00,  ...,  1.1598e+00,\n",
      "           -6.3895e-02, -1.8479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4179e-01, -5.7982e-01,  7.9565e-02,  ...,  8.0501e-02,\n",
      "           -7.4058e-01,  8.5245e-01],\n",
      "          [-7.1722e-02, -7.7768e-01, -4.5878e-01,  ...,  3.9832e-01,\n",
      "           -8.4584e-01,  7.6664e-01]],\n",
      "\n",
      "         [[-3.2481e-01,  8.0122e-02,  1.7656e-01,  ...,  1.3766e+00,\n",
      "           -9.4703e-01, -2.6047e-01],\n",
      "          [-5.0089e-01, -9.6543e-01,  7.1786e-01,  ..., -5.2773e-02,\n",
      "            1.8641e-01, -4.0528e-01]],\n",
      "\n",
      "         [[-3.4905e-01, -1.9931e-01,  5.4653e-01,  ...,  9.2709e-03,\n",
      "           -1.2823e-01,  1.6808e+00],\n",
      "          [ 1.3007e+00,  4.9567e-01, -1.2620e+00,  ..., -6.0539e-01,\n",
      "            3.7568e-01,  6.9147e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6072e-01, -2.1832e+00, -1.3528e+00,  ...,  1.5649e-01,\n",
      "           -1.2706e+00,  1.6812e+00],\n",
      "          [ 1.1619e-01, -2.9286e-01, -1.8648e-01,  ...,  2.8897e-01,\n",
      "           -5.0379e-01,  7.5311e-01]],\n",
      "\n",
      "         [[ 8.3243e-02, -5.5258e-02, -7.9662e-01,  ..., -8.9016e-01,\n",
      "           -1.2113e+00,  1.8002e+00],\n",
      "          [-3.4660e-02, -1.2986e-01, -5.3944e-02,  ...,  9.0294e-02,\n",
      "           -1.2555e-01,  1.4034e-01]],\n",
      "\n",
      "         [[ 6.9452e-02, -1.8693e+00, -1.1074e-01,  ..., -1.4538e-02,\n",
      "           -6.1316e-02,  7.2982e-01],\n",
      "          [ 2.2255e+00, -4.3826e-01,  1.4839e+00,  ...,  5.4807e-01,\n",
      "           -1.5002e-01,  7.7246e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 2.0734e-01, -4.9511e-01,  5.4738e-01,  ..., -1.5078e-01,\n",
      "           -5.2827e-01,  5.7083e-01],\n",
      "          [ 1.3168e-01, -6.1718e-01, -1.9697e-01,  ...,  2.9735e-01,\n",
      "           -2.0426e-01, -3.6252e-02]],\n",
      "\n",
      "         [[-2.3663e-01, -1.3221e-01, -1.0329e-01,  ...,  3.4992e-01,\n",
      "            2.4887e-01, -5.0412e-01],\n",
      "          [ 2.6506e-01,  8.3608e-01,  1.6877e+00,  ...,  8.0165e-01,\n",
      "            1.7941e+00,  1.7666e-02]],\n",
      "\n",
      "         [[-8.1725e-03, -3.6102e-02,  1.1074e-03,  ..., -5.9860e-03,\n",
      "           -3.3815e-02,  3.2337e-02],\n",
      "          [-1.2171e+00, -4.4132e-01, -8.7672e-01,  ..., -1.3383e+00,\n",
      "           -1.1844e+00,  4.3592e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1967e+00, -1.4083e+00, -2.2451e-01,  ...,  1.5547e+00,\n",
      "           -7.8424e-01, -9.2051e-02],\n",
      "          [ 1.1505e+00, -3.0085e-02, -1.5094e+00,  ..., -8.0445e-02,\n",
      "           -4.5134e-01,  1.0754e+00]],\n",
      "\n",
      "         [[ 8.2969e-01,  8.1427e-01,  1.7945e-01,  ..., -1.5573e+00,\n",
      "           -3.8813e-01,  1.5233e+00],\n",
      "          [ 7.9821e-01, -8.0932e-01,  3.0952e-01,  ..., -8.2561e-02,\n",
      "           -4.0983e-01,  1.2742e+00]],\n",
      "\n",
      "         [[ 9.6691e-02, -1.6730e+00, -3.2016e-01,  ...,  6.2699e-01,\n",
      "            1.5438e-01,  7.2638e-01],\n",
      "          [ 2.2086e+00, -2.0921e-01,  1.4979e+00,  ...,  1.1598e+00,\n",
      "           -6.3895e-02, -1.8479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4179e-01, -5.7982e-01,  7.9565e-02,  ...,  8.0501e-02,\n",
      "           -7.4058e-01,  8.5245e-01],\n",
      "          [-7.1722e-02, -7.7768e-01, -4.5878e-01,  ...,  3.9832e-01,\n",
      "           -8.4584e-01,  7.6664e-01]],\n",
      "\n",
      "         [[-3.2481e-01,  8.0122e-02,  1.7656e-01,  ...,  1.3766e+00,\n",
      "           -9.4703e-01, -2.6047e-01],\n",
      "          [-5.0089e-01, -9.6543e-01,  7.1786e-01,  ..., -5.2773e-02,\n",
      "            1.8641e-01, -4.0528e-01]],\n",
      "\n",
      "         [[-3.4905e-01, -1.9931e-01,  5.4653e-01,  ...,  9.2709e-03,\n",
      "           -1.2823e-01,  1.6808e+00],\n",
      "          [ 1.3007e+00,  4.9567e-01, -1.2620e+00,  ..., -6.0539e-01,\n",
      "            3.7568e-01,  6.9147e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6072e-01, -2.1832e+00, -1.3528e+00,  ...,  1.5649e-01,\n",
      "           -1.2706e+00,  1.6812e+00],\n",
      "          [ 1.1619e-01, -2.9286e-01, -1.8648e-01,  ...,  2.8897e-01,\n",
      "           -5.0379e-01,  7.5311e-01]],\n",
      "\n",
      "         [[ 8.3243e-02, -5.5258e-02, -7.9662e-01,  ..., -8.9016e-01,\n",
      "           -1.2113e+00,  1.8002e+00],\n",
      "          [-3.4660e-02, -1.2986e-01, -5.3944e-02,  ...,  9.0294e-02,\n",
      "           -1.2555e-01,  1.4034e-01]],\n",
      "\n",
      "         [[ 6.9452e-02, -1.8693e+00, -1.1074e-01,  ..., -1.4538e-02,\n",
      "           -6.1316e-02,  7.2982e-01],\n",
      "          [ 2.2255e+00, -4.3826e-01,  1.4839e+00,  ...,  5.4807e-01,\n",
      "           -1.5002e-01,  7.7246e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 2.0734e-01, -4.9511e-01,  5.4738e-01,  ..., -1.5078e-01,\n",
      "           -5.2827e-01,  5.7083e-01],\n",
      "          [ 1.3168e-01, -6.1718e-01, -1.9697e-01,  ...,  2.9735e-01,\n",
      "           -2.0426e-01, -3.6252e-02]],\n",
      "\n",
      "         [[-2.3663e-01, -1.3221e-01, -1.0329e-01,  ...,  3.4992e-01,\n",
      "            2.4887e-01, -5.0412e-01],\n",
      "          [ 2.6506e-01,  8.3608e-01,  1.6877e+00,  ...,  8.0165e-01,\n",
      "            1.7941e+00,  1.7666e-02]],\n",
      "\n",
      "         [[-8.1725e-03, -3.6102e-02,  1.1074e-03,  ..., -5.9860e-03,\n",
      "           -3.3815e-02,  3.2337e-02],\n",
      "          [-1.2171e+00, -4.4132e-01, -8.7672e-01,  ..., -1.3383e+00,\n",
      "           -1.1844e+00,  4.3592e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1967e+00, -1.4083e+00, -2.2451e-01,  ...,  1.5547e+00,\n",
      "           -7.8424e-01, -9.2051e-02],\n",
      "          [ 1.1505e+00, -3.0085e-02, -1.5094e+00,  ..., -8.0445e-02,\n",
      "           -4.5134e-01,  1.0754e+00]],\n",
      "\n",
      "         [[ 8.2969e-01,  8.1427e-01,  1.7945e-01,  ..., -1.5573e+00,\n",
      "           -3.8813e-01,  1.5233e+00],\n",
      "          [ 7.9821e-01, -8.0932e-01,  3.0952e-01,  ..., -8.2561e-02,\n",
      "           -4.0983e-01,  1.2742e+00]],\n",
      "\n",
      "         [[ 9.6691e-02, -1.6730e+00, -3.2016e-01,  ...,  6.2699e-01,\n",
      "            1.5438e-01,  7.2638e-01],\n",
      "          [ 2.2086e+00, -2.0921e-01,  1.4979e+00,  ...,  1.1598e+00,\n",
      "           -6.3895e-02, -1.8479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4179e-01, -5.7982e-01,  7.9565e-02,  ...,  8.0501e-02,\n",
      "           -7.4058e-01,  8.5245e-01],\n",
      "          [-7.1722e-02, -7.7768e-01, -4.5878e-01,  ...,  3.9832e-01,\n",
      "           -8.4584e-01,  7.6664e-01]],\n",
      "\n",
      "         [[-3.2481e-01,  8.0122e-02,  1.7656e-01,  ...,  1.3766e+00,\n",
      "           -9.4703e-01, -2.6047e-01],\n",
      "          [-5.0089e-01, -9.6543e-01,  7.1786e-01,  ..., -5.2773e-02,\n",
      "            1.8641e-01, -4.0528e-01]],\n",
      "\n",
      "         [[-3.4905e-01, -1.9931e-01,  5.4653e-01,  ...,  9.2709e-03,\n",
      "           -1.2823e-01,  1.6808e+00],\n",
      "          [ 1.3007e+00,  4.9567e-01, -1.2620e+00,  ..., -6.0539e-01,\n",
      "            3.7568e-01,  6.9147e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6072e-01, -2.1832e+00, -1.3528e+00,  ...,  1.5649e-01,\n",
      "           -1.2706e+00,  1.6812e+00],\n",
      "          [ 1.1619e-01, -2.9286e-01, -1.8648e-01,  ...,  2.8897e-01,\n",
      "           -5.0379e-01,  7.5311e-01]],\n",
      "\n",
      "         [[ 8.3243e-02, -5.5258e-02, -7.9662e-01,  ..., -8.9016e-01,\n",
      "           -1.2113e+00,  1.8002e+00],\n",
      "          [-3.4660e-02, -1.2986e-01, -5.3944e-02,  ...,  9.0294e-02,\n",
      "           -1.2555e-01,  1.4034e-01]],\n",
      "\n",
      "         [[ 6.9452e-02, -1.8693e+00, -1.1074e-01,  ..., -1.4538e-02,\n",
      "           -6.1316e-02,  7.2982e-01],\n",
      "          [ 2.2255e+00, -4.3826e-01,  1.4839e+00,  ...,  5.4807e-01,\n",
      "           -1.5002e-01,  7.7246e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.5740,  0.4797],\n",
      "        [ 0.1882, -0.1013]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:24:23,330] Trial 2 finished with value: 0.75712 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.606900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.388400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.6413,  0.6505, -1.0635,  ...,  0.3369, -0.6378,  0.2918],\n",
      "         [ 0.3891,  0.4381, -0.6917,  ...,  0.5480, -0.0395,  0.3140],\n",
      "         [-0.2127,  0.5764, -0.6600,  ...,  0.1781, -0.0079,  0.3083],\n",
      "         ...,\n",
      "         [ 0.1818,  0.3501, -0.7014,  ...,  0.6831, -0.5097,  0.3901],\n",
      "         [ 0.4489,  0.5905, -0.3563,  ...,  0.3005, -0.1041,  0.1861],\n",
      "         [ 0.5597,  0.8563, -0.7371,  ...,  0.8634, -0.5998,  0.6935]],\n",
      "\n",
      "        [[ 0.6025,  0.5745, -0.8998,  ...,  0.3180, -0.6242,  0.3840],\n",
      "         [ 0.3677,  0.9283, -0.2518,  ...,  0.6241, -0.4948,  0.5198],\n",
      "         [ 0.3701,  0.3185, -0.6790,  ..., -0.0945, -0.4977,  0.2662],\n",
      "         ...,\n",
      "         [ 0.1406,  0.3363, -0.2966,  ...,  0.2473, -0.4095,  0.4450],\n",
      "         [ 0.2659,  0.5694, -0.3954,  ...,  0.0903, -0.1340,  0.1918],\n",
      "         [ 0.7712,  0.6455, -0.6617,  ...,  0.9034, -0.7154,  0.6342]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.6413,  0.6505, -1.0635,  ...,  0.3369, -0.6378,  0.2918],\n",
      "         [ 0.3891,  0.4381, -0.6917,  ...,  0.5480, -0.0395,  0.3140],\n",
      "         [-0.2127,  0.5764, -0.6600,  ...,  0.1781, -0.0079,  0.3083],\n",
      "         ...,\n",
      "         [ 0.1818,  0.3501, -0.7014,  ...,  0.6831, -0.5097,  0.3901],\n",
      "         [ 0.4489,  0.5905, -0.3563,  ...,  0.3005, -0.1041,  0.1861],\n",
      "         [ 0.5597,  0.8563, -0.7371,  ...,  0.8634, -0.5998,  0.6935]],\n",
      "\n",
      "        [[ 0.6025,  0.5745, -0.8998,  ...,  0.3180, -0.6242,  0.3840],\n",
      "         [ 0.3677,  0.9283, -0.2518,  ...,  0.6241, -0.4948,  0.5198],\n",
      "         [ 0.3701,  0.3185, -0.6790,  ..., -0.0945, -0.4977,  0.2662],\n",
      "         ...,\n",
      "         [ 0.1406,  0.3363, -0.2966,  ...,  0.2473, -0.4095,  0.4450],\n",
      "         [ 0.2659,  0.5694, -0.3954,  ...,  0.0903, -0.1340,  0.1918],\n",
      "         [ 0.7712,  0.6455, -0.6617,  ...,  0.9034, -0.7154,  0.6342]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.6413,  0.6505, -1.0635,  ..., -0.3833, -0.0963,  0.5889],\n",
      "          [ 0.0269,  0.2247,  0.1843,  ...,  0.3369, -0.6378,  0.2918]],\n",
      "\n",
      "         [[ 0.3891,  0.4381, -0.6917,  ...,  0.2617,  0.3408, -0.1561],\n",
      "          [-0.0959,  0.1342,  0.9195,  ...,  0.5480, -0.0395,  0.3140]],\n",
      "\n",
      "         [[-0.2127,  0.5764, -0.6600,  ..., -0.2111,  0.0594,  0.4212],\n",
      "          [-0.1487,  0.3206,  0.4979,  ...,  0.1781, -0.0079,  0.3083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1818,  0.3501, -0.7014,  ..., -0.4428, -0.3148,  0.4369],\n",
      "          [-0.2683,  0.3516,  0.5115,  ...,  0.6831, -0.5097,  0.3901]],\n",
      "\n",
      "         [[ 0.4489,  0.5905, -0.3563,  ..., -0.0029, -0.5795,  0.4911],\n",
      "          [-0.5798,  0.6437,  0.6607,  ...,  0.3005, -0.1041,  0.1861]],\n",
      "\n",
      "         [[ 0.5597,  0.8563, -0.7371,  ..., -0.2036, -0.5364,  0.6066],\n",
      "          [-0.2682,  0.3064,  1.0227,  ...,  0.8634, -0.5998,  0.6935]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6025,  0.5745, -0.8998,  ..., -0.2661, -0.1512,  0.4103],\n",
      "          [ 0.0695,  0.2501,  0.0895,  ...,  0.3180, -0.6242,  0.3840]],\n",
      "\n",
      "         [[ 0.3677,  0.9283, -0.2518,  ..., -0.1083, -0.1901,  0.3025],\n",
      "          [ 0.2458,  0.3419,  0.7224,  ...,  0.6241, -0.4948,  0.5198]],\n",
      "\n",
      "         [[ 0.3701,  0.3185, -0.6790,  ..., -0.5154, -0.1963,  0.5224],\n",
      "          [-0.3580,  0.1363,  0.1302,  ..., -0.0945, -0.4977,  0.2662]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1406,  0.3363, -0.2966,  ..., -0.3672,  0.0901,  0.5622],\n",
      "          [-0.4012,  0.1281,  0.4495,  ...,  0.2473, -0.4095,  0.4450]],\n",
      "\n",
      "         [[ 0.2659,  0.5694, -0.3954,  ..., -0.1627, -0.1689,  0.4109],\n",
      "          [-0.3974,  0.3588,  0.8378,  ...,  0.0903, -0.1340,  0.1918]],\n",
      "\n",
      "         [[ 0.7712,  0.6455, -0.6617,  ..., -0.1594, -0.7056,  0.3588],\n",
      "          [-0.2254,  0.4288,  0.9273,  ...,  0.9034, -0.7154,  0.6342]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1200,  0.1057,  0.2870,  ..., -0.0561, -0.0683, -0.3751],\n",
      "         [-0.3554,  0.2421, -0.3916,  ..., -0.0717, -0.4777,  0.0131],\n",
      "         [-0.3616,  0.2575, -0.3387,  ..., -0.0357, -0.1014, -0.3776],\n",
      "         ...,\n",
      "         [-0.6796, -0.1488, -0.0718,  ...,  0.1632, -0.2812,  0.0978],\n",
      "         [-0.8450,  0.4585, -0.4187,  ...,  0.0373, -0.6142, -0.1510],\n",
      "         [-0.6155,  0.0816, -0.4996,  ..., -0.1354, -0.5537, -0.1903]],\n",
      "\n",
      "        [[ 0.1560,  0.1057,  0.2714,  ..., -0.1222, -0.1123, -0.2790],\n",
      "         [ 0.0971, -0.0912,  0.2126,  ...,  0.0454, -0.3696, -0.2079],\n",
      "         [-0.7718, -0.1693, -0.3439,  ...,  0.2121, -0.6695,  0.3069],\n",
      "         ...,\n",
      "         [-0.4522,  0.0681, -0.2384,  ...,  0.2648, -0.4931, -0.0498],\n",
      "         [-0.6411,  0.4515, -0.1374,  ...,  0.2316, -0.2949, -0.0954],\n",
      "         [-0.3842,  0.1306, -0.4582,  ..., -0.2296, -0.4492, -0.0868]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1200,  0.1057,  0.2870,  ..., -0.0561, -0.0683, -0.3751],\n",
      "         [-0.3554,  0.2421, -0.3916,  ..., -0.0717, -0.4777,  0.0131],\n",
      "         [-0.3616,  0.2575, -0.3387,  ..., -0.0357, -0.1014, -0.3776],\n",
      "         ...,\n",
      "         [-0.6796, -0.1488, -0.0718,  ...,  0.1632, -0.2812,  0.0978],\n",
      "         [-0.8450,  0.4585, -0.4187,  ...,  0.0373, -0.6142, -0.1510],\n",
      "         [-0.6155,  0.0816, -0.4996,  ..., -0.1354, -0.5537, -0.1903]],\n",
      "\n",
      "        [[ 0.1560,  0.1057,  0.2714,  ..., -0.1222, -0.1123, -0.2790],\n",
      "         [ 0.0971, -0.0912,  0.2126,  ...,  0.0454, -0.3696, -0.2079],\n",
      "         [-0.7718, -0.1693, -0.3439,  ...,  0.2121, -0.6695,  0.3069],\n",
      "         ...,\n",
      "         [-0.4522,  0.0681, -0.2384,  ...,  0.2648, -0.4931, -0.0498],\n",
      "         [-0.6411,  0.4515, -0.1374,  ...,  0.2316, -0.2949, -0.0954],\n",
      "         [-0.3842,  0.1306, -0.4582,  ..., -0.2296, -0.4492, -0.0868]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.1999e-01,  1.0568e-01,  2.8699e-01,  ..., -8.6079e-02,\n",
      "            1.2525e-01,  2.1659e-01],\n",
      "          [-1.3918e-02,  3.9683e-01,  3.8600e-01,  ..., -5.6057e-02,\n",
      "           -6.8269e-02, -3.7506e-01]],\n",
      "\n",
      "         [[-3.5537e-01,  2.4213e-01, -3.9163e-01,  ...,  1.5364e-01,\n",
      "           -1.4475e-01, -4.9177e-01],\n",
      "          [-2.5779e-01,  1.1444e-02, -4.1942e-02,  ..., -7.1680e-02,\n",
      "           -4.7774e-01,  1.3100e-02]],\n",
      "\n",
      "         [[-3.6158e-01,  2.5752e-01, -3.3871e-01,  ...,  5.4068e-01,\n",
      "            3.3912e-01, -7.7332e-02],\n",
      "          [ 8.4975e-02,  5.9902e-02, -8.6489e-02,  ..., -3.5703e-02,\n",
      "           -1.0142e-01, -3.7764e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.7956e-01, -1.4884e-01, -7.1766e-02,  ...,  1.8181e-01,\n",
      "           -1.1080e-01, -1.0024e+00],\n",
      "          [-4.0391e-01, -4.5506e-01, -2.2038e-01,  ...,  1.6317e-01,\n",
      "           -2.8117e-01,  9.7824e-02]],\n",
      "\n",
      "         [[-8.4505e-01,  4.5850e-01, -4.1869e-01,  ...,  2.4806e-01,\n",
      "           -1.8647e-01, -2.6850e-01],\n",
      "          [-1.9176e-01, -1.6707e-01, -1.1711e-01,  ...,  3.7320e-02,\n",
      "           -6.1423e-01, -1.5097e-01]],\n",
      "\n",
      "         [[-6.1546e-01,  8.1593e-02, -4.9960e-01,  ...,  3.6187e-01,\n",
      "           -4.2961e-01, -3.2892e-01],\n",
      "          [-3.6315e-01, -2.7542e-01,  9.6521e-04,  ..., -1.3540e-01,\n",
      "           -5.5366e-01, -1.9030e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5597e-01,  1.0574e-01,  2.7142e-01,  ..., -1.4912e-01,\n",
      "            8.3244e-02,  8.7857e-02],\n",
      "          [ 7.1738e-02,  4.6817e-01,  3.2140e-01,  ..., -1.2219e-01,\n",
      "           -1.1234e-01, -2.7903e-01]],\n",
      "\n",
      "         [[ 9.7054e-02, -9.1180e-02,  2.1262e-01,  ..., -1.7389e-02,\n",
      "           -1.6529e-02, -3.3072e-01],\n",
      "          [-8.7791e-02, -2.0457e-01,  1.0787e-01,  ...,  4.5384e-02,\n",
      "           -3.6957e-01, -2.0791e-01]],\n",
      "\n",
      "         [[-7.7180e-01, -1.6930e-01, -3.4390e-01,  ...,  8.1729e-01,\n",
      "           -2.1162e-01, -8.9871e-01],\n",
      "          [-5.1515e-01, -3.2699e-01, -1.1900e-01,  ...,  2.1209e-01,\n",
      "           -6.6951e-01,  3.0689e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5221e-01,  6.8107e-02, -2.3844e-01,  ..., -1.0548e-01,\n",
      "            9.3910e-02, -4.3109e-01],\n",
      "          [-3.5870e-01, -4.7257e-01, -2.0344e-01,  ...,  2.6485e-01,\n",
      "           -4.9305e-01, -4.9812e-02]],\n",
      "\n",
      "         [[-6.4106e-01,  4.5153e-01, -1.3741e-01,  ...,  4.1319e-01,\n",
      "           -1.0802e-01, -6.6879e-02],\n",
      "          [-9.4999e-02, -2.9897e-01,  8.3318e-02,  ...,  2.3164e-01,\n",
      "           -2.9492e-01, -9.5447e-02]],\n",
      "\n",
      "         [[-3.8421e-01,  1.3060e-01, -4.5818e-01,  ...,  2.8094e-01,\n",
      "           -3.4811e-01, -6.2948e-01],\n",
      "          [-2.6558e-01, -2.4834e-01,  6.4745e-02,  ..., -2.2959e-01,\n",
      "           -4.4917e-01, -8.6787e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1036, -0.9706,  1.1513,  ..., -1.1434,  1.3690, -1.2601],\n",
      "         [-0.1637, -0.2247,  0.0208,  ..., -0.6832,  0.0937,  0.1995],\n",
      "         [-0.6664, -0.3997,  0.5769,  ..., -1.0895,  1.2701, -0.3515],\n",
      "         ...,\n",
      "         [-0.3927, -0.1645,  0.5654,  ..., -0.5858,  0.6740, -0.6227],\n",
      "         [-0.9679, -0.3953,  0.4381,  ..., -0.9572,  0.6739, -0.4317],\n",
      "         [-0.7621, -0.5174,  0.5068,  ..., -0.7071,  0.7185, -0.4370]],\n",
      "\n",
      "        [[-0.9587, -1.0894,  1.2631,  ..., -1.2418,  1.2736, -1.2239],\n",
      "         [-0.1995, -0.3264,  0.2152,  ..., -0.3785,  0.2380, -0.5209],\n",
      "         [-0.7230, -0.3072,  0.5539,  ..., -0.7125,  0.9972, -0.3152],\n",
      "         ...,\n",
      "         [-0.5297, -0.0837,  0.5991,  ..., -0.4465,  0.9259, -0.4519],\n",
      "         [-0.9411, -0.4950,  0.6355,  ..., -0.9771,  1.0172, -0.6197],\n",
      "         [-0.7725, -0.6463,  0.4403,  ..., -0.6539,  0.7815, -0.4410]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1036, -0.9706,  1.1513,  ..., -1.1434,  1.3690, -1.2601],\n",
      "         [-0.1637, -0.2247,  0.0208,  ..., -0.6832,  0.0937,  0.1995],\n",
      "         [-0.6664, -0.3997,  0.5769,  ..., -1.0895,  1.2701, -0.3515],\n",
      "         ...,\n",
      "         [-0.3927, -0.1645,  0.5654,  ..., -0.5858,  0.6740, -0.6227],\n",
      "         [-0.9679, -0.3953,  0.4381,  ..., -0.9572,  0.6739, -0.4317],\n",
      "         [-0.7621, -0.5174,  0.5068,  ..., -0.7071,  0.7185, -0.4370]],\n",
      "\n",
      "        [[-0.9587, -1.0894,  1.2631,  ..., -1.2418,  1.2736, -1.2239],\n",
      "         [-0.1995, -0.3264,  0.2152,  ..., -0.3785,  0.2380, -0.5209],\n",
      "         [-0.7230, -0.3072,  0.5539,  ..., -0.7125,  0.9972, -0.3152],\n",
      "         ...,\n",
      "         [-0.5297, -0.0837,  0.5991,  ..., -0.4465,  0.9259, -0.4519],\n",
      "         [-0.9411, -0.4950,  0.6355,  ..., -0.9771,  1.0172, -0.6197],\n",
      "         [-0.7725, -0.6463,  0.4403,  ..., -0.6539,  0.7815, -0.4410]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1036, -0.9706,  1.1513,  ...,  0.4906,  0.6805, -1.4807],\n",
      "          [ 1.0313, -0.4030, -1.4582,  ..., -1.1434,  1.3690, -1.2601]],\n",
      "\n",
      "         [[-0.1637, -0.2247,  0.0208,  ...,  0.0015, -0.0370, -0.4659],\n",
      "          [ 0.3442,  0.1194, -0.2693,  ..., -0.6832,  0.0937,  0.1995]],\n",
      "\n",
      "         [[-0.6664, -0.3997,  0.5769,  ...,  0.7909,  0.1301, -0.9536],\n",
      "          [ 0.7362, -0.4801, -0.7869,  ..., -1.0895,  1.2701, -0.3515]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3927, -0.1645,  0.5654,  ...,  0.3313, -0.1069, -0.9042],\n",
      "          [ 0.5113,  0.0291, -0.7929,  ..., -0.5858,  0.6740, -0.6227]],\n",
      "\n",
      "         [[-0.9679, -0.3953,  0.4381,  ...,  0.4417,  0.0174, -0.8819],\n",
      "          [ 1.0637, -0.2508, -0.8718,  ..., -0.9572,  0.6739, -0.4317]],\n",
      "\n",
      "         [[-0.7621, -0.5174,  0.5068,  ...,  0.4228,  0.2236, -0.9033],\n",
      "          [ 0.3002, -0.6010, -0.3678,  ..., -0.7071,  0.7185, -0.4370]]],\n",
      "\n",
      "\n",
      "        [[[-0.9587, -1.0894,  1.2631,  ...,  0.5132,  0.7149, -1.3465],\n",
      "          [ 1.0419, -0.3369, -1.4256,  ..., -1.2418,  1.2736, -1.2239]],\n",
      "\n",
      "         [[-0.1995, -0.3264,  0.2152,  ...,  0.3749,  0.3740, -0.7185],\n",
      "          [ 0.2297, -0.1037, -0.3342,  ..., -0.3785,  0.2380, -0.5209]],\n",
      "\n",
      "         [[-0.7230, -0.3072,  0.5539,  ...,  0.4640,  0.2233, -0.7744],\n",
      "          [ 0.5155, -0.1486, -0.6213,  ..., -0.7125,  0.9972, -0.3152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5297, -0.0837,  0.5991,  ...,  0.4630,  0.0573, -1.0370],\n",
      "          [ 0.5113,  0.1096, -0.8573,  ..., -0.4465,  0.9259, -0.4519]],\n",
      "\n",
      "         [[-0.9411, -0.4950,  0.6355,  ...,  0.6709,  0.0556, -0.9772],\n",
      "          [ 0.8105, -0.1025, -1.1550,  ..., -0.9771,  1.0172, -0.6197]],\n",
      "\n",
      "         [[-0.7725, -0.6463,  0.4403,  ...,  0.2338,  0.4227, -0.9032],\n",
      "          [ 0.4742, -0.4334, -0.5150,  ..., -0.6539,  0.7815, -0.4410]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.6413,  0.6505, -1.0635,  ..., -0.3833, -0.0963,  0.5889],\n",
      "          [ 0.3891,  0.4381, -0.6917,  ...,  0.2617,  0.3408, -0.1561],\n",
      "          [-0.2127,  0.5764, -0.6600,  ..., -0.2111,  0.0594,  0.4212],\n",
      "          ...,\n",
      "          [ 0.1818,  0.3501, -0.7014,  ..., -0.4428, -0.3148,  0.4369],\n",
      "          [ 0.4489,  0.5905, -0.3563,  ..., -0.0029, -0.5795,  0.4911],\n",
      "          [ 0.5597,  0.8563, -0.7371,  ..., -0.2036, -0.5364,  0.6066]],\n",
      "\n",
      "         [[ 0.0269,  0.2247,  0.1843,  ...,  0.3369, -0.6378,  0.2918],\n",
      "          [-0.0959,  0.1342,  0.9195,  ...,  0.5480, -0.0395,  0.3140],\n",
      "          [-0.1487,  0.3206,  0.4979,  ...,  0.1781, -0.0079,  0.3083],\n",
      "          ...,\n",
      "          [-0.2683,  0.3516,  0.5115,  ...,  0.6831, -0.5097,  0.3901],\n",
      "          [-0.5798,  0.6437,  0.6607,  ...,  0.3005, -0.1041,  0.1861],\n",
      "          [-0.2682,  0.3064,  1.0227,  ...,  0.8634, -0.5998,  0.6935]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6025,  0.5745, -0.8998,  ..., -0.2661, -0.1512,  0.4103],\n",
      "          [ 0.3677,  0.9283, -0.2518,  ..., -0.1083, -0.1901,  0.3025],\n",
      "          [ 0.3701,  0.3185, -0.6790,  ..., -0.5154, -0.1963,  0.5224],\n",
      "          ...,\n",
      "          [ 0.1406,  0.3363, -0.2966,  ..., -0.3672,  0.0901,  0.5622],\n",
      "          [ 0.2659,  0.5694, -0.3954,  ..., -0.1627, -0.1689,  0.4109],\n",
      "          [ 0.7712,  0.6455, -0.6617,  ..., -0.1594, -0.7056,  0.3588]],\n",
      "\n",
      "         [[ 0.0695,  0.2501,  0.0895,  ...,  0.3180, -0.6242,  0.3840],\n",
      "          [ 0.2458,  0.3419,  0.7224,  ...,  0.6241, -0.4948,  0.5198],\n",
      "          [-0.3580,  0.1363,  0.1302,  ..., -0.0945, -0.4977,  0.2662],\n",
      "          ...,\n",
      "          [-0.4012,  0.1281,  0.4495,  ...,  0.2473, -0.4095,  0.4450],\n",
      "          [-0.3974,  0.3588,  0.8378,  ...,  0.0903, -0.1340,  0.1918],\n",
      "          [-0.2254,  0.4288,  0.9273,  ...,  0.9034, -0.7154,  0.6342]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.0578,  0.5570, -0.0729,  ..., -0.1135,  0.2226,  0.2752],\n",
      "          [-0.2842,  0.3422, -0.2650,  ...,  0.1643,  0.0094, -0.1972],\n",
      "          [-0.1551,  0.5022, -0.2161,  ...,  0.0448,  0.1034,  0.0047],\n",
      "          ...,\n",
      "          [-0.2355,  0.4569, -0.2627,  ...,  0.1107,  0.0477, -0.1050],\n",
      "          [-0.1614,  0.4491, -0.2005,  ...,  0.0683,  0.0895, -0.0020],\n",
      "          [-0.0540,  0.3387, -0.0919,  ..., -0.0287,  0.0865,  0.0481]],\n",
      "\n",
      "         [[ 0.0481,  0.0193,  0.0992,  ...,  0.0869, -0.0122, -0.2848],\n",
      "          [-0.1222, -0.0982,  0.0156,  ...,  0.0530, -0.2100, -0.2035],\n",
      "          [-0.0132, -0.0115,  0.0465,  ...,  0.0614, -0.0809, -0.2216],\n",
      "          ...,\n",
      "          [-0.0827, -0.1025, -0.0030,  ...,  0.0628, -0.1629, -0.1897],\n",
      "          [-0.0319, -0.0213,  0.0361,  ...,  0.0572, -0.0977, -0.2086],\n",
      "          [-0.0141, -0.0399,  0.0549,  ...,  0.0608, -0.0763, -0.2343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1775,  0.7922,  0.1927,  ..., -0.2039,  0.4276,  0.1922],\n",
      "          [-0.0896,  0.4637,  0.0199,  ..., -0.0044,  0.1661, -0.1141],\n",
      "          [-0.0751,  0.4914,  0.0332,  ..., -0.0140,  0.1939, -0.0927],\n",
      "          ...,\n",
      "          [ 0.0058,  0.4648,  0.0725,  ..., -0.0703,  0.2064, -0.0384],\n",
      "          [ 0.0179,  0.6022,  0.0924,  ..., -0.0818,  0.2809,  0.0080],\n",
      "          [-0.0188,  0.5120,  0.0651,  ..., -0.0268,  0.2052, -0.0392]],\n",
      "\n",
      "         [[ 0.2295,  0.1324,  0.3931,  ..., -0.3036,  0.1988,  0.0488],\n",
      "          [ 0.0277,  0.0054,  0.1556,  ..., -0.0429, -0.1216,  0.0217],\n",
      "          [ 0.0653,  0.0170,  0.1818,  ..., -0.0724, -0.0820,  0.0285],\n",
      "          ...,\n",
      "          [ 0.1120,  0.0786,  0.2249,  ..., -0.1361,  0.0039,  0.0430],\n",
      "          [ 0.1342,  0.0448,  0.2617,  ..., -0.1644,  0.0461,  0.0573],\n",
      "          [-0.0384, -0.0226, -0.0339,  ...,  0.1081, -0.1943,  0.0431]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.0578,  0.5570, -0.0729,  ..., -0.1135,  0.2226,  0.2752],\n",
      "          [ 0.0481,  0.0193,  0.0992,  ...,  0.0869, -0.0122, -0.2848]],\n",
      "\n",
      "         [[-0.2842,  0.3422, -0.2650,  ...,  0.1643,  0.0094, -0.1972],\n",
      "          [-0.1222, -0.0982,  0.0156,  ...,  0.0530, -0.2100, -0.2035]],\n",
      "\n",
      "         [[-0.1551,  0.5022, -0.2161,  ...,  0.0448,  0.1034,  0.0047],\n",
      "          [-0.0132, -0.0115,  0.0465,  ...,  0.0614, -0.0809, -0.2216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2355,  0.4569, -0.2627,  ...,  0.1107,  0.0477, -0.1050],\n",
      "          [-0.0827, -0.1025, -0.0030,  ...,  0.0628, -0.1629, -0.1897]],\n",
      "\n",
      "         [[-0.1614,  0.4491, -0.2005,  ...,  0.0683,  0.0895, -0.0020],\n",
      "          [-0.0319, -0.0213,  0.0361,  ...,  0.0572, -0.0977, -0.2086]],\n",
      "\n",
      "         [[-0.0540,  0.3387, -0.0919,  ..., -0.0287,  0.0865,  0.0481],\n",
      "          [-0.0141, -0.0399,  0.0549,  ...,  0.0608, -0.0763, -0.2343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1775,  0.7922,  0.1927,  ..., -0.2039,  0.4276,  0.1922],\n",
      "          [ 0.2295,  0.1324,  0.3931,  ..., -0.3036,  0.1988,  0.0488]],\n",
      "\n",
      "         [[-0.0896,  0.4637,  0.0199,  ..., -0.0044,  0.1661, -0.1141],\n",
      "          [ 0.0277,  0.0054,  0.1556,  ..., -0.0429, -0.1216,  0.0217]],\n",
      "\n",
      "         [[-0.0751,  0.4914,  0.0332,  ..., -0.0140,  0.1939, -0.0927],\n",
      "          [ 0.0653,  0.0170,  0.1818,  ..., -0.0724, -0.0820,  0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0058,  0.4648,  0.0725,  ..., -0.0703,  0.2064, -0.0384],\n",
      "          [ 0.1120,  0.0786,  0.2249,  ..., -0.1361,  0.0039,  0.0430]],\n",
      "\n",
      "         [[ 0.0179,  0.6022,  0.0924,  ..., -0.0818,  0.2809,  0.0080],\n",
      "          [ 0.1342,  0.0448,  0.2617,  ..., -0.1644,  0.0461,  0.0573]],\n",
      "\n",
      "         [[-0.0188,  0.5120,  0.0651,  ..., -0.0268,  0.2052, -0.0392],\n",
      "          [-0.0384, -0.0226, -0.0339,  ...,  0.1081, -0.1943,  0.0431]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.0578,  0.5570, -0.0729,  ..., -0.1135,  0.2226,  0.2752],\n",
      "          [ 0.0481,  0.0193,  0.0992,  ...,  0.0869, -0.0122, -0.2848]],\n",
      "\n",
      "         [[-0.2842,  0.3422, -0.2650,  ...,  0.1643,  0.0094, -0.1972],\n",
      "          [-0.1222, -0.0982,  0.0156,  ...,  0.0530, -0.2100, -0.2035]],\n",
      "\n",
      "         [[-0.1551,  0.5022, -0.2161,  ...,  0.0448,  0.1034,  0.0047],\n",
      "          [-0.0132, -0.0115,  0.0465,  ...,  0.0614, -0.0809, -0.2216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2355,  0.4569, -0.2627,  ...,  0.1107,  0.0477, -0.1050],\n",
      "          [-0.0827, -0.1025, -0.0030,  ...,  0.0628, -0.1629, -0.1897]],\n",
      "\n",
      "         [[-0.1614,  0.4491, -0.2005,  ...,  0.0683,  0.0895, -0.0020],\n",
      "          [-0.0319, -0.0213,  0.0361,  ...,  0.0572, -0.0977, -0.2086]],\n",
      "\n",
      "         [[-0.0540,  0.3387, -0.0919,  ..., -0.0287,  0.0865,  0.0481],\n",
      "          [-0.0141, -0.0399,  0.0549,  ...,  0.0608, -0.0763, -0.2343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1775,  0.7922,  0.1927,  ..., -0.2039,  0.4276,  0.1922],\n",
      "          [ 0.2295,  0.1324,  0.3931,  ..., -0.3036,  0.1988,  0.0488]],\n",
      "\n",
      "         [[-0.0896,  0.4637,  0.0199,  ..., -0.0044,  0.1661, -0.1141],\n",
      "          [ 0.0277,  0.0054,  0.1556,  ..., -0.0429, -0.1216,  0.0217]],\n",
      "\n",
      "         [[-0.0751,  0.4914,  0.0332,  ..., -0.0140,  0.1939, -0.0927],\n",
      "          [ 0.0653,  0.0170,  0.1818,  ..., -0.0724, -0.0820,  0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0058,  0.4648,  0.0725,  ..., -0.0703,  0.2064, -0.0384],\n",
      "          [ 0.1120,  0.0786,  0.2249,  ..., -0.1361,  0.0039,  0.0430]],\n",
      "\n",
      "         [[ 0.0179,  0.6022,  0.0924,  ..., -0.0818,  0.2809,  0.0080],\n",
      "          [ 0.1342,  0.0448,  0.2617,  ..., -0.1644,  0.0461,  0.0573]],\n",
      "\n",
      "         [[-0.0188,  0.5120,  0.0651,  ..., -0.0268,  0.2052, -0.0392],\n",
      "          [-0.0384, -0.0226, -0.0339,  ...,  0.1081, -0.1943,  0.0431]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.0578,  0.5570, -0.0729,  ..., -0.1135,  0.2226,  0.2752],\n",
      "          [ 0.0481,  0.0193,  0.0992,  ...,  0.0869, -0.0122, -0.2848]],\n",
      "\n",
      "         [[-0.2842,  0.3422, -0.2650,  ...,  0.1643,  0.0094, -0.1972],\n",
      "          [-0.1222, -0.0982,  0.0156,  ...,  0.0530, -0.2100, -0.2035]],\n",
      "\n",
      "         [[-0.1551,  0.5022, -0.2161,  ...,  0.0448,  0.1034,  0.0047],\n",
      "          [-0.0132, -0.0115,  0.0465,  ...,  0.0614, -0.0809, -0.2216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2355,  0.4569, -0.2627,  ...,  0.1107,  0.0477, -0.1050],\n",
      "          [-0.0827, -0.1025, -0.0030,  ...,  0.0628, -0.1629, -0.1897]],\n",
      "\n",
      "         [[-0.1614,  0.4491, -0.2005,  ...,  0.0683,  0.0895, -0.0020],\n",
      "          [-0.0319, -0.0213,  0.0361,  ...,  0.0572, -0.0977, -0.2086]],\n",
      "\n",
      "         [[-0.0540,  0.3387, -0.0919,  ..., -0.0287,  0.0865,  0.0481],\n",
      "          [-0.0141, -0.0399,  0.0549,  ...,  0.0608, -0.0763, -0.2343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1775,  0.7922,  0.1927,  ..., -0.2039,  0.4276,  0.1922],\n",
      "          [ 0.2295,  0.1324,  0.3931,  ..., -0.3036,  0.1988,  0.0488]],\n",
      "\n",
      "         [[-0.0896,  0.4637,  0.0199,  ..., -0.0044,  0.1661, -0.1141],\n",
      "          [ 0.0277,  0.0054,  0.1556,  ..., -0.0429, -0.1216,  0.0217]],\n",
      "\n",
      "         [[-0.0751,  0.4914,  0.0332,  ..., -0.0140,  0.1939, -0.0927],\n",
      "          [ 0.0653,  0.0170,  0.1818,  ..., -0.0724, -0.0820,  0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0058,  0.4648,  0.0725,  ..., -0.0703,  0.2064, -0.0384],\n",
      "          [ 0.1120,  0.0786,  0.2249,  ..., -0.1361,  0.0039,  0.0430]],\n",
      "\n",
      "         [[ 0.0179,  0.6022,  0.0924,  ..., -0.0818,  0.2809,  0.0080],\n",
      "          [ 0.1342,  0.0448,  0.2617,  ..., -0.1644,  0.0461,  0.0573]],\n",
      "\n",
      "         [[-0.0188,  0.5120,  0.0651,  ..., -0.0268,  0.2052, -0.0392],\n",
      "          [-0.0384, -0.0226, -0.0339,  ...,  0.1081, -0.1943,  0.0431]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.2065, -0.3577, -0.4158,  ...,  0.0846,  0.6810,  0.3559],\n",
      "         [ 0.5133, -0.0921, -0.4517,  ...,  0.2684,  0.0156,  0.6044],\n",
      "         [ 0.2257, -0.1513, -0.5178,  ...,  0.3163,  0.6740,  0.5118],\n",
      "         ...,\n",
      "         [ 0.5240, -0.1615, -0.3977,  ...,  0.2801,  0.6183,  0.8463],\n",
      "         [ 0.5705, -0.1256, -0.2822,  ...,  0.2690,  0.7047,  0.6078],\n",
      "         [ 0.7171, -0.2396, -0.0998,  ...,  0.2430,  0.6613,  0.6683]],\n",
      "\n",
      "        [[ 0.0363, -0.1688, -0.2896,  ..., -0.0786,  0.5336,  0.1304],\n",
      "         [ 0.4654, -0.3394, -0.5553,  ...,  0.3101,  0.5418,  0.4144],\n",
      "         [ 0.2028,  0.1334, -0.4551,  ...,  0.2309,  0.4812,  0.4144],\n",
      "         ...,\n",
      "         [ 0.0537,  0.2028, -0.0208,  ..., -0.0590,  0.5539,  0.3847],\n",
      "         [ 0.1706, -0.3920,  0.0632,  ...,  0.1757,  0.7756,  0.4918],\n",
      "         [ 0.8979, -0.2483, -0.1560,  ...,  0.1587,  0.5702,  0.6021]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2065, -0.3577, -0.4158,  ...,  0.0846,  0.6810,  0.3559],\n",
      "         [ 0.5133, -0.0921, -0.4517,  ...,  0.2684,  0.0156,  0.6044],\n",
      "         [ 0.2257, -0.1513, -0.5178,  ...,  0.3163,  0.6740,  0.5118],\n",
      "         ...,\n",
      "         [ 0.5240, -0.1615, -0.3977,  ...,  0.2801,  0.6183,  0.8463],\n",
      "         [ 0.5705, -0.1256, -0.2822,  ...,  0.2690,  0.7047,  0.6078],\n",
      "         [ 0.7171, -0.2396, -0.0998,  ...,  0.2430,  0.6613,  0.6683]],\n",
      "\n",
      "        [[ 0.0363, -0.1688, -0.2896,  ..., -0.0786,  0.5336,  0.1304],\n",
      "         [ 0.4654, -0.3394, -0.5553,  ...,  0.3101,  0.5418,  0.4144],\n",
      "         [ 0.2028,  0.1334, -0.4551,  ...,  0.2309,  0.4812,  0.4144],\n",
      "         ...,\n",
      "         [ 0.0537,  0.2028, -0.0208,  ..., -0.0590,  0.5539,  0.3847],\n",
      "         [ 0.1706, -0.3920,  0.0632,  ...,  0.1757,  0.7756,  0.4918],\n",
      "         [ 0.8979, -0.2483, -0.1560,  ...,  0.1587,  0.5702,  0.6021]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2065, -0.3577, -0.4158,  ...,  0.4936, -0.6239, -0.2992],\n",
      "          [-0.6552, -0.4252, -0.1535,  ...,  0.0846,  0.6810,  0.3559]],\n",
      "\n",
      "         [[ 0.5133, -0.0921, -0.4517,  ...,  0.2782, -0.2230, -0.7278],\n",
      "          [-0.2425, -0.4369,  0.1994,  ...,  0.2684,  0.0156,  0.6044]],\n",
      "\n",
      "         [[ 0.2257, -0.1513, -0.5178,  ...,  0.5546, -0.2682, -0.2540],\n",
      "          [-0.3166, -0.6350,  0.3313,  ...,  0.3163,  0.6740,  0.5118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5240, -0.1615, -0.3977,  ...,  0.4387, -0.7474, -0.5566],\n",
      "          [-0.6319, -0.4132,  0.1938,  ...,  0.2801,  0.6183,  0.8463]],\n",
      "\n",
      "         [[ 0.5705, -0.1256, -0.2822,  ...,  0.4493, -0.4168, -0.5929],\n",
      "          [-0.2800, -0.5750,  0.3355,  ...,  0.2690,  0.7047,  0.6078]],\n",
      "\n",
      "         [[ 0.7171, -0.2396, -0.0998,  ...,  0.4846, -0.6467, -0.7651],\n",
      "          [-0.5856, -0.4919,  0.4310,  ...,  0.2430,  0.6613,  0.6683]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0363, -0.1688, -0.2896,  ...,  0.4287, -0.4259,  0.0540],\n",
      "          [-0.6542, -0.1555, -0.3595,  ..., -0.0786,  0.5336,  0.1304]],\n",
      "\n",
      "         [[ 0.4654, -0.3394, -0.5553,  ...,  0.6601, -0.2886, -0.4429],\n",
      "          [-0.6651, -0.3557,  0.0431,  ...,  0.3101,  0.5418,  0.4144]],\n",
      "\n",
      "         [[ 0.2028,  0.1334, -0.4551,  ...,  0.3765, -0.2647, -0.3593],\n",
      "          [-0.2345, -0.5029,  0.4997,  ...,  0.2309,  0.4812,  0.4144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0537,  0.2028, -0.0208,  ...,  0.3857, -0.6487, -0.3344],\n",
      "          [-0.5418, -0.1336, -0.0314,  ..., -0.0590,  0.5539,  0.3847]],\n",
      "\n",
      "         [[ 0.1706, -0.3920,  0.0632,  ...,  0.1140, -0.3856, -0.4927],\n",
      "          [-0.5568, -0.4812,  0.1800,  ...,  0.1757,  0.7756,  0.4918]],\n",
      "\n",
      "         [[ 0.8979, -0.2483, -0.1560,  ...,  0.4602, -0.6314, -0.7695],\n",
      "          [-0.4973, -0.5838,  0.3598,  ...,  0.1587,  0.5702,  0.6021]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2601,  0.2214, -0.0118,  ..., -0.4564,  0.3383, -0.0825],\n",
      "         [ 1.0534, -0.6235, -0.9190,  ...,  0.1362, -0.8662,  0.2328],\n",
      "         [ 0.3756, -0.3158, -0.5354,  ..., -0.0566, -0.1903,  0.0433],\n",
      "         ...,\n",
      "         [ 0.9599, -0.6878, -0.8128,  ...,  0.1827, -0.6024,  0.5759],\n",
      "         [ 0.7306, -0.4967, -0.5569,  ...,  0.1517, -0.7279,  0.1309],\n",
      "         [ 0.9335, -0.7464, -0.7267,  ...,  0.4178, -0.6474,  0.4150]],\n",
      "\n",
      "        [[-0.7633,  0.4213,  0.3543,  ..., -0.4760,  0.8357, -0.3624],\n",
      "         [ 0.1411,  0.0531,  0.0476,  ...,  0.0696,  0.1789, -0.1038],\n",
      "         [ 0.5039, -0.2825, -0.6689,  ...,  0.1096, -0.2614,  0.0606],\n",
      "         ...,\n",
      "         [ 0.0234, -0.0658, -0.0515,  ..., -0.2304, -0.0346, -0.1876],\n",
      "         [ 0.1937, -0.4142, -0.1595,  ..., -0.2806, -0.0197,  0.0016],\n",
      "         [ 0.9412, -0.9106, -0.6907,  ...,  0.5975, -0.6390,  0.3116]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2601,  0.2214, -0.0118,  ..., -0.4564,  0.3383, -0.0825],\n",
      "         [ 1.0534, -0.6235, -0.9190,  ...,  0.1362, -0.8662,  0.2328],\n",
      "         [ 0.3756, -0.3158, -0.5354,  ..., -0.0566, -0.1903,  0.0433],\n",
      "         ...,\n",
      "         [ 0.9599, -0.6878, -0.8128,  ...,  0.1827, -0.6024,  0.5759],\n",
      "         [ 0.7306, -0.4967, -0.5569,  ...,  0.1517, -0.7279,  0.1309],\n",
      "         [ 0.9335, -0.7464, -0.7267,  ...,  0.4178, -0.6474,  0.4150]],\n",
      "\n",
      "        [[-0.7633,  0.4213,  0.3543,  ..., -0.4760,  0.8357, -0.3624],\n",
      "         [ 0.1411,  0.0531,  0.0476,  ...,  0.0696,  0.1789, -0.1038],\n",
      "         [ 0.5039, -0.2825, -0.6689,  ...,  0.1096, -0.2614,  0.0606],\n",
      "         ...,\n",
      "         [ 0.0234, -0.0658, -0.0515,  ..., -0.2304, -0.0346, -0.1876],\n",
      "         [ 0.1937, -0.4142, -0.1595,  ..., -0.2806, -0.0197,  0.0016],\n",
      "         [ 0.9412, -0.9106, -0.6907,  ...,  0.5975, -0.6390,  0.3116]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-2.6008e-01,  2.2138e-01, -1.1830e-02,  ...,  4.1863e-01,\n",
      "            5.7001e-01, -2.2264e-01],\n",
      "          [ 2.7814e-01,  1.6790e-01, -2.5642e-01,  ..., -4.5640e-01,\n",
      "            3.3830e-01, -8.2515e-02]],\n",
      "\n",
      "         [[ 1.0534e+00, -6.2347e-01, -9.1899e-01,  ..., -4.5603e-01,\n",
      "           -1.0655e+00,  9.8863e-01],\n",
      "          [-6.1698e-01, -7.5703e-01,  9.2652e-01,  ...,  1.3622e-01,\n",
      "           -8.6624e-01,  2.3280e-01]],\n",
      "\n",
      "         [[ 3.7564e-01, -3.1583e-01, -5.3542e-01,  ...,  9.4698e-02,\n",
      "           -6.3410e-01,  8.8665e-01],\n",
      "          [-2.5407e-01, -4.7709e-01,  2.4553e-01,  ..., -5.6649e-02,\n",
      "           -1.9034e-01,  4.3255e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.5989e-01, -6.8783e-01, -8.1275e-01,  ..., -6.5297e-01,\n",
      "           -4.7534e-01,  8.2323e-01],\n",
      "          [-1.0414e+00, -9.9176e-01,  7.0277e-01,  ...,  1.8270e-01,\n",
      "           -6.0242e-01,  5.7586e-01]],\n",
      "\n",
      "         [[ 7.3062e-01, -4.9671e-01, -5.5688e-01,  ..., -2.2112e-01,\n",
      "           -5.4174e-01,  9.2585e-01],\n",
      "          [-5.8451e-01, -9.1398e-01,  4.6828e-01,  ...,  1.5171e-01,\n",
      "           -7.2790e-01,  1.3089e-01]],\n",
      "\n",
      "         [[ 9.3354e-01, -7.4642e-01, -7.2672e-01,  ..., -5.1330e-01,\n",
      "           -7.6743e-01,  1.0639e+00],\n",
      "          [-6.8583e-01, -1.2285e+00,  7.9030e-01,  ...,  4.1776e-01,\n",
      "           -6.4738e-01,  4.1496e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6329e-01,  4.2135e-01,  3.5431e-01,  ...,  8.9268e-01,\n",
      "            9.2744e-01, -8.2648e-01],\n",
      "          [ 5.1067e-01,  4.9050e-01, -8.1730e-01,  ..., -4.7598e-01,\n",
      "            8.3569e-01, -3.6240e-01]],\n",
      "\n",
      "         [[ 1.4110e-01,  5.3127e-02,  4.7641e-02,  ...,  8.7114e-02,\n",
      "            1.1681e-01,  1.5859e-01],\n",
      "          [-3.3914e-01,  2.3726e-01, -3.3241e-01,  ...,  6.9629e-02,\n",
      "            1.7893e-01, -1.0378e-01]],\n",
      "\n",
      "         [[ 5.0393e-01, -2.8253e-01, -6.6890e-01,  ..., -2.9757e-04,\n",
      "           -5.7421e-01,  7.1015e-01],\n",
      "          [-2.6628e-01, -5.3829e-01,  4.8398e-01,  ...,  1.0959e-01,\n",
      "           -2.6137e-01,  6.0638e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3399e-02, -6.5837e-02, -5.1543e-02,  ..., -8.0028e-02,\n",
      "            3.0639e-01,  3.0959e-01],\n",
      "          [-7.6672e-01, -2.6293e-01,  1.5217e-01,  ..., -2.3043e-01,\n",
      "           -3.4577e-02, -1.8757e-01]],\n",
      "\n",
      "         [[ 1.9373e-01, -4.1417e-01, -1.5945e-01,  ...,  2.8096e-01,\n",
      "           -1.5287e-02,  3.9745e-01],\n",
      "          [-4.7647e-01, -1.8537e-01,  1.3769e-02,  ..., -2.8064e-01,\n",
      "           -1.9668e-02,  1.5810e-03]],\n",
      "\n",
      "         [[ 9.4118e-01, -9.1060e-01, -6.9073e-01,  ..., -5.1601e-01,\n",
      "           -8.0613e-01,  9.0307e-01],\n",
      "          [-6.1411e-01, -1.1511e+00,  6.5095e-01,  ...,  5.9748e-01,\n",
      "           -6.3899e-01,  3.1159e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5936,  0.6403,  0.5279,  ..., -0.8723, -0.8534, -0.8506],\n",
      "         [-0.2074,  0.2690,  0.4257,  ..., -0.6349, -0.0494, -0.1664],\n",
      "         [-0.6410,  0.2759,  0.5794,  ..., -0.8285, -0.4747, -0.4192],\n",
      "         ...,\n",
      "         [-0.2262,  0.3437,  0.5524,  ..., -0.6610, -0.7812, -0.0930],\n",
      "         [-0.2919,  0.5134,  0.4493,  ..., -0.9041, -0.3889, -0.3085],\n",
      "         [-0.1893,  0.2083,  0.5040,  ..., -0.9756, -0.3839, -0.2330]],\n",
      "\n",
      "        [[-0.1467,  0.5342,  0.3866,  ..., -0.7043, -0.5556, -0.6486],\n",
      "         [ 0.1067,  0.2263,  0.1966,  ..., -0.3480, -0.1746,  0.1446],\n",
      "         [-0.1702,  0.3281,  0.3395,  ..., -0.6306, -0.6096, -0.5967],\n",
      "         ...,\n",
      "         [-0.0732,  0.3585,  0.3910,  ..., -0.5436, -0.6358, -0.2802],\n",
      "         [-0.1906,  0.2707,  0.3668,  ..., -0.7583, -0.6151, -0.2464],\n",
      "         [-0.0421,  0.3301,  0.5456,  ..., -0.8797, -0.4716, -0.1936]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5936,  0.6403,  0.5279,  ..., -0.8723, -0.8534, -0.8506],\n",
      "         [-0.2074,  0.2690,  0.4257,  ..., -0.6349, -0.0494, -0.1664],\n",
      "         [-0.6410,  0.2759,  0.5794,  ..., -0.8285, -0.4747, -0.4192],\n",
      "         ...,\n",
      "         [-0.2262,  0.3437,  0.5524,  ..., -0.6610, -0.7812, -0.0930],\n",
      "         [-0.2919,  0.5134,  0.4493,  ..., -0.9041, -0.3889, -0.3085],\n",
      "         [-0.1893,  0.2083,  0.5040,  ..., -0.9756, -0.3839, -0.2330]],\n",
      "\n",
      "        [[-0.1467,  0.5342,  0.3866,  ..., -0.7043, -0.5556, -0.6486],\n",
      "         [ 0.1067,  0.2263,  0.1966,  ..., -0.3480, -0.1746,  0.1446],\n",
      "         [-0.1702,  0.3281,  0.3395,  ..., -0.6306, -0.6096, -0.5967],\n",
      "         ...,\n",
      "         [-0.0732,  0.3585,  0.3910,  ..., -0.5436, -0.6358, -0.2802],\n",
      "         [-0.1906,  0.2707,  0.3668,  ..., -0.7583, -0.6151, -0.2464],\n",
      "         [-0.0421,  0.3301,  0.5456,  ..., -0.8797, -0.4716, -0.1936]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5936,  0.6403,  0.5279,  ...,  0.0221,  1.1266,  1.1530],\n",
      "          [ 0.5569,  0.8334, -0.2524,  ..., -0.8723, -0.8534, -0.8506]],\n",
      "\n",
      "         [[-0.2074,  0.2690,  0.4257,  ...,  0.1434,  0.2330,  0.5179],\n",
      "          [ 0.2499,  0.1724, -0.0534,  ..., -0.6349, -0.0494, -0.1664]],\n",
      "\n",
      "         [[-0.6410,  0.2759,  0.5794,  ...,  0.1628,  0.4741,  0.5822],\n",
      "          [ 0.5020,  0.7027,  0.0470,  ..., -0.8285, -0.4747, -0.4192]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2262,  0.3437,  0.5524,  ...,  0.2950,  0.7648,  0.3294],\n",
      "          [ 0.5394,  0.3507, -0.2534,  ..., -0.6610, -0.7812, -0.0930]],\n",
      "\n",
      "         [[-0.2919,  0.5134,  0.4493,  ..., -0.1049,  0.6570,  0.4512],\n",
      "          [ 0.6195,  0.8999, -0.2357,  ..., -0.9041, -0.3889, -0.3085]],\n",
      "\n",
      "         [[-0.1893,  0.2083,  0.5040,  ...,  0.0556,  0.3441,  0.3201],\n",
      "          [ 0.4987,  0.5227, -0.2770,  ..., -0.9756, -0.3839, -0.2330]]],\n",
      "\n",
      "\n",
      "        [[[-0.1467,  0.5342,  0.3866,  ...,  0.1124,  0.9542,  0.7060],\n",
      "          [ 0.2355,  0.5572, -0.2079,  ..., -0.7043, -0.5556, -0.6486]],\n",
      "\n",
      "         [[ 0.1067,  0.2263,  0.1966,  ...,  0.6462,  0.3924,  0.3004],\n",
      "          [ 0.0828, -0.0837,  0.2495,  ..., -0.3480, -0.1746,  0.1446]],\n",
      "\n",
      "         [[-0.1702,  0.3281,  0.3395,  ..., -0.2371,  0.1616,  0.4554],\n",
      "          [ 0.3299,  0.3316, -0.3169,  ..., -0.6306, -0.6096, -0.5967]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0732,  0.3585,  0.3910,  ...,  0.0166,  0.6043, -0.1711],\n",
      "          [ 0.0587,  0.1420, -0.0343,  ..., -0.5436, -0.6358, -0.2802]],\n",
      "\n",
      "         [[-0.1906,  0.2707,  0.3668,  ...,  0.2205,  0.8656,  0.3973],\n",
      "          [ 0.3730,  0.6362,  0.0350,  ..., -0.7583, -0.6151, -0.2464]],\n",
      "\n",
      "         [[-0.0421,  0.3301,  0.5456,  ...,  0.0679,  0.4866,  0.2613],\n",
      "          [ 0.6329,  0.6538, -0.3680,  ..., -0.8797, -0.4716, -0.1936]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2065, -0.3577, -0.4158,  ...,  0.4936, -0.6239, -0.2992],\n",
      "          [ 0.5133, -0.0921, -0.4517,  ...,  0.2782, -0.2230, -0.7278],\n",
      "          [ 0.2257, -0.1513, -0.5178,  ...,  0.5546, -0.2682, -0.2540],\n",
      "          ...,\n",
      "          [ 0.5240, -0.1615, -0.3977,  ...,  0.4387, -0.7474, -0.5566],\n",
      "          [ 0.5705, -0.1256, -0.2822,  ...,  0.4493, -0.4168, -0.5929],\n",
      "          [ 0.7171, -0.2396, -0.0998,  ...,  0.4846, -0.6467, -0.7651]],\n",
      "\n",
      "         [[-0.6552, -0.4252, -0.1535,  ...,  0.0846,  0.6810,  0.3559],\n",
      "          [-0.2425, -0.4369,  0.1994,  ...,  0.2684,  0.0156,  0.6044],\n",
      "          [-0.3166, -0.6350,  0.3313,  ...,  0.3163,  0.6740,  0.5118],\n",
      "          ...,\n",
      "          [-0.6319, -0.4132,  0.1938,  ...,  0.2801,  0.6183,  0.8463],\n",
      "          [-0.2800, -0.5750,  0.3355,  ...,  0.2690,  0.7047,  0.6078],\n",
      "          [-0.5856, -0.4919,  0.4310,  ...,  0.2430,  0.6613,  0.6683]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0363, -0.1688, -0.2896,  ...,  0.4287, -0.4259,  0.0540],\n",
      "          [ 0.4654, -0.3394, -0.5553,  ...,  0.6601, -0.2886, -0.4429],\n",
      "          [ 0.2028,  0.1334, -0.4551,  ...,  0.3765, -0.2647, -0.3593],\n",
      "          ...,\n",
      "          [ 0.0537,  0.2028, -0.0208,  ...,  0.3857, -0.6487, -0.3344],\n",
      "          [ 0.1706, -0.3920,  0.0632,  ...,  0.1140, -0.3856, -0.4927],\n",
      "          [ 0.8979, -0.2483, -0.1560,  ...,  0.4602, -0.6314, -0.7695]],\n",
      "\n",
      "         [[-0.6542, -0.1555, -0.3595,  ..., -0.0786,  0.5336,  0.1304],\n",
      "          [-0.6651, -0.3557,  0.0431,  ...,  0.3101,  0.5418,  0.4144],\n",
      "          [-0.2345, -0.5029,  0.4997,  ...,  0.2309,  0.4812,  0.4144],\n",
      "          ...,\n",
      "          [-0.5418, -0.1336, -0.0314,  ..., -0.0590,  0.5539,  0.3847],\n",
      "          [-0.5568, -0.4812,  0.1800,  ...,  0.1757,  0.7756,  0.4918],\n",
      "          [-0.4973, -0.5838,  0.3598,  ...,  0.1587,  0.5702,  0.6021]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.5301, -0.5434, -0.4878,  ..., -0.0723, -0.3534,  0.6642],\n",
      "          [ 0.6021, -0.5417, -0.5545,  ..., -0.1491, -0.4167,  0.7325],\n",
      "          [ 0.5524, -0.5140, -0.4867,  ..., -0.1578, -0.3405,  0.6224],\n",
      "          ...,\n",
      "          [ 0.3695, -0.3744, -0.3596,  ..., -0.0327, -0.2428,  0.4508],\n",
      "          [ 0.5447, -0.5170, -0.4777,  ..., -0.1494, -0.3330,  0.6154],\n",
      "          [ 0.5994, -0.5572, -0.5278,  ..., -0.1665, -0.4473,  0.7280]],\n",
      "\n",
      "         [[-0.3471, -0.3247,  0.1475,  ...,  0.0358, -0.2571, -0.0073],\n",
      "          [-0.4485, -0.5423,  0.3361,  ...,  0.0319, -0.3882,  0.1199],\n",
      "          [-0.4245, -0.4827,  0.2859,  ...,  0.0297, -0.3506,  0.0865],\n",
      "          ...,\n",
      "          [-0.4410, -0.5042,  0.2949,  ...,  0.0333, -0.3635,  0.0969],\n",
      "          [-0.4182, -0.4537,  0.2580,  ...,  0.0332, -0.3330,  0.0690],\n",
      "          [-0.4027, -0.4135,  0.2167,  ...,  0.0142, -0.3037,  0.0512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450, -0.0026, -0.1564,  ...,  0.2905,  0.3264, -0.1694],\n",
      "          [ 0.0951, -0.0527, -0.1832,  ...,  0.1376,  0.1266, -0.0590],\n",
      "          [ 0.0548, -0.0184, -0.1530,  ...,  0.2147,  0.2868, -0.1417],\n",
      "          ...,\n",
      "          [-0.1275,  0.0821,  0.0101,  ...,  0.2605,  0.4006, -0.2748],\n",
      "          [-0.2075,  0.1217,  0.0310,  ...,  0.3295,  0.5040, -0.3723],\n",
      "          [ 0.1330, -0.0714, -0.1678,  ...,  0.1507,  0.1583,  0.0189]],\n",
      "\n",
      "         [[ 0.0362,  0.1033, -0.1475,  ..., -0.1036,  0.2202, -0.1433],\n",
      "          [-0.1628,  0.0129, -0.1036,  ..., -0.1229,  0.2275, -0.0841],\n",
      "          [-0.0781,  0.1071, -0.1369,  ..., -0.1738,  0.3091, -0.0902],\n",
      "          ...,\n",
      "          [-0.1519,  0.0284, -0.1089,  ..., -0.1320,  0.2392, -0.0689],\n",
      "          [-0.0806,  0.1150, -0.1401,  ..., -0.1443,  0.3021, -0.0755],\n",
      "          [-0.1365,  0.0327, -0.0824,  ..., -0.1285,  0.1967,  0.0184]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.5301, -0.5434, -0.4878,  ..., -0.0723, -0.3534,  0.6642],\n",
      "          [-0.3471, -0.3247,  0.1475,  ...,  0.0358, -0.2571, -0.0073]],\n",
      "\n",
      "         [[ 0.6021, -0.5417, -0.5545,  ..., -0.1491, -0.4167,  0.7325],\n",
      "          [-0.4485, -0.5423,  0.3361,  ...,  0.0319, -0.3882,  0.1199]],\n",
      "\n",
      "         [[ 0.5524, -0.5140, -0.4867,  ..., -0.1578, -0.3405,  0.6224],\n",
      "          [-0.4245, -0.4827,  0.2859,  ...,  0.0297, -0.3506,  0.0865]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3695, -0.3744, -0.3596,  ..., -0.0327, -0.2428,  0.4508],\n",
      "          [-0.4410, -0.5042,  0.2949,  ...,  0.0333, -0.3635,  0.0969]],\n",
      "\n",
      "         [[ 0.5447, -0.5170, -0.4777,  ..., -0.1494, -0.3330,  0.6154],\n",
      "          [-0.4182, -0.4537,  0.2580,  ...,  0.0332, -0.3330,  0.0690]],\n",
      "\n",
      "         [[ 0.5994, -0.5572, -0.5278,  ..., -0.1665, -0.4473,  0.7280],\n",
      "          [-0.4027, -0.4135,  0.2167,  ...,  0.0142, -0.3037,  0.0512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450, -0.0026, -0.1564,  ...,  0.2905,  0.3264, -0.1694],\n",
      "          [ 0.0362,  0.1033, -0.1475,  ..., -0.1036,  0.2202, -0.1433]],\n",
      "\n",
      "         [[ 0.0951, -0.0527, -0.1832,  ...,  0.1376,  0.1266, -0.0590],\n",
      "          [-0.1628,  0.0129, -0.1036,  ..., -0.1229,  0.2275, -0.0841]],\n",
      "\n",
      "         [[ 0.0548, -0.0184, -0.1530,  ...,  0.2147,  0.2868, -0.1417],\n",
      "          [-0.0781,  0.1071, -0.1369,  ..., -0.1738,  0.3091, -0.0902]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1275,  0.0821,  0.0101,  ...,  0.2605,  0.4006, -0.2748],\n",
      "          [-0.1519,  0.0284, -0.1089,  ..., -0.1320,  0.2392, -0.0689]],\n",
      "\n",
      "         [[-0.2075,  0.1217,  0.0310,  ...,  0.3295,  0.5040, -0.3723],\n",
      "          [-0.0806,  0.1150, -0.1401,  ..., -0.1443,  0.3021, -0.0755]],\n",
      "\n",
      "         [[ 0.1330, -0.0714, -0.1678,  ...,  0.1507,  0.1583,  0.0189],\n",
      "          [-0.1365,  0.0327, -0.0824,  ..., -0.1285,  0.1967,  0.0184]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.5301, -0.5434, -0.4878,  ..., -0.0723, -0.3534,  0.6642],\n",
      "          [-0.3471, -0.3247,  0.1475,  ...,  0.0358, -0.2571, -0.0073]],\n",
      "\n",
      "         [[ 0.6021, -0.5417, -0.5545,  ..., -0.1491, -0.4167,  0.7325],\n",
      "          [-0.4485, -0.5423,  0.3361,  ...,  0.0319, -0.3882,  0.1199]],\n",
      "\n",
      "         [[ 0.5524, -0.5140, -0.4867,  ..., -0.1578, -0.3405,  0.6224],\n",
      "          [-0.4245, -0.4827,  0.2859,  ...,  0.0297, -0.3506,  0.0865]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3695, -0.3744, -0.3596,  ..., -0.0327, -0.2428,  0.4508],\n",
      "          [-0.4410, -0.5042,  0.2949,  ...,  0.0333, -0.3635,  0.0969]],\n",
      "\n",
      "         [[ 0.5447, -0.5170, -0.4777,  ..., -0.1494, -0.3330,  0.6154],\n",
      "          [-0.4182, -0.4537,  0.2580,  ...,  0.0332, -0.3330,  0.0690]],\n",
      "\n",
      "         [[ 0.5994, -0.5572, -0.5278,  ..., -0.1665, -0.4473,  0.7280],\n",
      "          [-0.4027, -0.4135,  0.2167,  ...,  0.0142, -0.3037,  0.0512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450, -0.0026, -0.1564,  ...,  0.2905,  0.3264, -0.1694],\n",
      "          [ 0.0362,  0.1033, -0.1475,  ..., -0.1036,  0.2202, -0.1433]],\n",
      "\n",
      "         [[ 0.0951, -0.0527, -0.1832,  ...,  0.1376,  0.1266, -0.0590],\n",
      "          [-0.1628,  0.0129, -0.1036,  ..., -0.1229,  0.2275, -0.0841]],\n",
      "\n",
      "         [[ 0.0548, -0.0184, -0.1530,  ...,  0.2147,  0.2868, -0.1417],\n",
      "          [-0.0781,  0.1071, -0.1369,  ..., -0.1738,  0.3091, -0.0902]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1275,  0.0821,  0.0101,  ...,  0.2605,  0.4006, -0.2748],\n",
      "          [-0.1519,  0.0284, -0.1089,  ..., -0.1320,  0.2392, -0.0689]],\n",
      "\n",
      "         [[-0.2075,  0.1217,  0.0310,  ...,  0.3295,  0.5040, -0.3723],\n",
      "          [-0.0806,  0.1150, -0.1401,  ..., -0.1443,  0.3021, -0.0755]],\n",
      "\n",
      "         [[ 0.1330, -0.0714, -0.1678,  ...,  0.1507,  0.1583,  0.0189],\n",
      "          [-0.1365,  0.0327, -0.0824,  ..., -0.1285,  0.1967,  0.0184]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.5301, -0.5434, -0.4878,  ..., -0.0723, -0.3534,  0.6642],\n",
      "          [-0.3471, -0.3247,  0.1475,  ...,  0.0358, -0.2571, -0.0073]],\n",
      "\n",
      "         [[ 0.6021, -0.5417, -0.5545,  ..., -0.1491, -0.4167,  0.7325],\n",
      "          [-0.4485, -0.5423,  0.3361,  ...,  0.0319, -0.3882,  0.1199]],\n",
      "\n",
      "         [[ 0.5524, -0.5140, -0.4867,  ..., -0.1578, -0.3405,  0.6224],\n",
      "          [-0.4245, -0.4827,  0.2859,  ...,  0.0297, -0.3506,  0.0865]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3695, -0.3744, -0.3596,  ..., -0.0327, -0.2428,  0.4508],\n",
      "          [-0.4410, -0.5042,  0.2949,  ...,  0.0333, -0.3635,  0.0969]],\n",
      "\n",
      "         [[ 0.5447, -0.5170, -0.4777,  ..., -0.1494, -0.3330,  0.6154],\n",
      "          [-0.4182, -0.4537,  0.2580,  ...,  0.0332, -0.3330,  0.0690]],\n",
      "\n",
      "         [[ 0.5994, -0.5572, -0.5278,  ..., -0.1665, -0.4473,  0.7280],\n",
      "          [-0.4027, -0.4135,  0.2167,  ...,  0.0142, -0.3037,  0.0512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450, -0.0026, -0.1564,  ...,  0.2905,  0.3264, -0.1694],\n",
      "          [ 0.0362,  0.1033, -0.1475,  ..., -0.1036,  0.2202, -0.1433]],\n",
      "\n",
      "         [[ 0.0951, -0.0527, -0.1832,  ...,  0.1376,  0.1266, -0.0590],\n",
      "          [-0.1628,  0.0129, -0.1036,  ..., -0.1229,  0.2275, -0.0841]],\n",
      "\n",
      "         [[ 0.0548, -0.0184, -0.1530,  ...,  0.2147,  0.2868, -0.1417],\n",
      "          [-0.0781,  0.1071, -0.1369,  ..., -0.1738,  0.3091, -0.0902]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1275,  0.0821,  0.0101,  ...,  0.2605,  0.4006, -0.2748],\n",
      "          [-0.1519,  0.0284, -0.1089,  ..., -0.1320,  0.2392, -0.0689]],\n",
      "\n",
      "         [[-0.2075,  0.1217,  0.0310,  ...,  0.3295,  0.5040, -0.3723],\n",
      "          [-0.0806,  0.1150, -0.1401,  ..., -0.1443,  0.3021, -0.0755]],\n",
      "\n",
      "         [[ 0.1330, -0.0714, -0.1678,  ...,  0.1507,  0.1583,  0.0189],\n",
      "          [-0.1365,  0.0327, -0.0824,  ..., -0.1285,  0.1967,  0.0184]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.2213,  1.2190],\n",
      "        [ 1.3444, -1.4717]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:27:39,995] Trial 3 finished with value: 0.75964 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.381100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-4.0165e-01,  1.6539e-01, -4.6436e-01,  ...,  2.7283e-01,\n",
      "          -5.7040e-01, -2.4830e-01],\n",
      "         [-3.8620e-01,  3.8718e-01, -4.7328e-01,  ...,  4.0392e-01,\n",
      "          -1.7329e-01,  1.7252e-02],\n",
      "         [ 1.8013e-01, -1.7467e-01, -3.9694e-01,  ...,  1.0745e-01,\n",
      "           3.8377e-02,  2.8123e-01],\n",
      "         ...,\n",
      "         [-2.6758e-01, -3.3028e-02, -3.2299e-01,  ..., -1.8929e-01,\n",
      "          -4.2177e-01, -2.2033e-01],\n",
      "         [-2.7415e-01,  8.9117e-02, -3.3042e-01,  ...,  1.5985e-02,\n",
      "          -1.6230e-01,  3.0945e-01],\n",
      "         [-5.8570e-01,  5.1817e-01, -3.9198e-01,  ...,  4.4097e-01,\n",
      "          -6.6508e-01, -4.3832e-01]],\n",
      "\n",
      "        [[-4.4889e-01,  1.8420e-01, -3.9037e-01,  ...,  3.1033e-01,\n",
      "          -6.8266e-01, -2.0989e-01],\n",
      "         [-7.1793e-01,  4.3429e-01, -4.8114e-01,  ...,  3.4948e-01,\n",
      "          -9.4018e-01, -2.2869e-01],\n",
      "         [-2.5544e-02, -2.2186e-01, -3.9022e-01,  ...,  1.3155e-01,\n",
      "          -1.4003e-01,  4.0937e-01],\n",
      "         ...,\n",
      "         [ 8.2157e-03, -7.3979e-04, -4.4271e-01,  ..., -1.9212e-01,\n",
      "          -3.7336e-01, -1.2736e-01],\n",
      "         [-5.8474e-01, -2.9651e-02,  7.7124e-02,  ...,  1.8826e-01,\n",
      "          -2.5086e-01, -2.7096e-01],\n",
      "         [-4.7111e-01,  4.7423e-01, -3.1215e-01,  ...,  3.7375e-01,\n",
      "          -6.2661e-01, -3.8228e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-4.0165e-01,  1.6539e-01, -4.6436e-01,  ...,  2.7283e-01,\n",
      "          -5.7040e-01, -2.4830e-01],\n",
      "         [-3.8620e-01,  3.8718e-01, -4.7328e-01,  ...,  4.0392e-01,\n",
      "          -1.7329e-01,  1.7252e-02],\n",
      "         [ 1.8013e-01, -1.7467e-01, -3.9694e-01,  ...,  1.0745e-01,\n",
      "           3.8377e-02,  2.8123e-01],\n",
      "         ...,\n",
      "         [-2.6758e-01, -3.3028e-02, -3.2299e-01,  ..., -1.8929e-01,\n",
      "          -4.2177e-01, -2.2033e-01],\n",
      "         [-2.7415e-01,  8.9117e-02, -3.3042e-01,  ...,  1.5985e-02,\n",
      "          -1.6230e-01,  3.0945e-01],\n",
      "         [-5.8570e-01,  5.1817e-01, -3.9198e-01,  ...,  4.4097e-01,\n",
      "          -6.6508e-01, -4.3832e-01]],\n",
      "\n",
      "        [[-4.4889e-01,  1.8420e-01, -3.9037e-01,  ...,  3.1033e-01,\n",
      "          -6.8266e-01, -2.0989e-01],\n",
      "         [-7.1793e-01,  4.3429e-01, -4.8114e-01,  ...,  3.4948e-01,\n",
      "          -9.4018e-01, -2.2869e-01],\n",
      "         [-2.5544e-02, -2.2186e-01, -3.9022e-01,  ...,  1.3155e-01,\n",
      "          -1.4003e-01,  4.0937e-01],\n",
      "         ...,\n",
      "         [ 8.2157e-03, -7.3979e-04, -4.4271e-01,  ..., -1.9212e-01,\n",
      "          -3.7336e-01, -1.2736e-01],\n",
      "         [-5.8474e-01, -2.9651e-02,  7.7124e-02,  ...,  1.8826e-01,\n",
      "          -2.5086e-01, -2.7096e-01],\n",
      "         [-4.7111e-01,  4.7423e-01, -3.1215e-01,  ...,  3.7375e-01,\n",
      "          -6.2661e-01, -3.8228e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-4.0165e-01,  1.6539e-01, -4.6436e-01,  ...,  3.0126e-01,\n",
      "            5.0580e-01,  2.2017e-01],\n",
      "          [-2.1312e-01, -1.2262e-01, -8.2814e-01,  ...,  2.7283e-01,\n",
      "           -5.7040e-01, -2.4830e-01]],\n",
      "\n",
      "         [[-3.8620e-01,  3.8718e-01, -4.7328e-01,  ..., -1.8800e-03,\n",
      "            8.4333e-03, -1.2562e-01],\n",
      "          [-2.7967e-01, -3.7954e-01, -7.0284e-01,  ...,  4.0392e-01,\n",
      "           -1.7329e-01,  1.7252e-02]],\n",
      "\n",
      "         [[ 1.8013e-01, -1.7467e-01, -3.9694e-01,  ..., -7.5362e-02,\n",
      "            2.0189e-01, -9.8096e-02],\n",
      "          [-1.8498e-01,  8.9320e-02, -1.2733e-01,  ...,  1.0745e-01,\n",
      "            3.8377e-02,  2.8123e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6758e-01, -3.3028e-02, -3.2299e-01,  ..., -2.9892e-01,\n",
      "            4.9999e-01,  5.7226e-02],\n",
      "          [-2.1475e-01, -5.0642e-01, -4.1484e-01,  ..., -1.8929e-01,\n",
      "           -4.2177e-01, -2.2033e-01]],\n",
      "\n",
      "         [[-2.7415e-01,  8.9117e-02, -3.3042e-01,  ...,  2.1287e-01,\n",
      "            3.6937e-02,  2.2420e-01],\n",
      "          [-4.0935e-01, -3.3468e-01, -3.9696e-01,  ...,  1.5985e-02,\n",
      "           -1.6230e-01,  3.0945e-01]],\n",
      "\n",
      "         [[-5.8570e-01,  5.1817e-01, -3.9198e-01,  ...,  2.8962e-01,\n",
      "            5.3546e-01,  1.7706e-01],\n",
      "          [-3.3693e-01, -7.0472e-01, -9.6754e-01,  ...,  4.4097e-01,\n",
      "           -6.6508e-01, -4.3832e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4889e-01,  1.8420e-01, -3.9037e-01,  ...,  2.7416e-01,\n",
      "            6.4866e-01,  3.5866e-01],\n",
      "          [-3.7623e-02, -1.7998e-01, -8.7334e-01,  ...,  3.1033e-01,\n",
      "           -6.8266e-01, -2.0989e-01]],\n",
      "\n",
      "         [[-7.1793e-01,  4.3429e-01, -4.8114e-01,  ...,  3.2125e-01,\n",
      "            5.7999e-01,  3.1966e-01],\n",
      "          [-4.8533e-01, -7.6226e-01, -7.6207e-01,  ...,  3.4948e-01,\n",
      "           -9.4018e-01, -2.2869e-01]],\n",
      "\n",
      "         [[-2.5544e-02, -2.2186e-01, -3.9022e-01,  ...,  1.2803e-01,\n",
      "            1.7732e-01, -1.1215e-02],\n",
      "          [-2.5673e-01,  1.3006e-01, -3.9370e-01,  ...,  1.3155e-01,\n",
      "           -1.4003e-01,  4.0937e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.2157e-03, -7.3979e-04, -4.4271e-01,  ...,  1.4112e-01,\n",
      "            1.5584e-01, -4.1993e-01],\n",
      "          [-2.7640e-01, -2.5312e-01, -4.2793e-01,  ..., -1.9212e-01,\n",
      "           -3.7336e-01, -1.2736e-01]],\n",
      "\n",
      "         [[-5.8474e-01, -2.9651e-02,  7.7124e-02,  ...,  9.5008e-02,\n",
      "           -5.2726e-02, -2.2891e-03],\n",
      "          [-4.8782e-01, -4.4651e-01, -2.2320e-01,  ...,  1.8826e-01,\n",
      "           -2.5086e-01, -2.7096e-01]],\n",
      "\n",
      "         [[-4.7111e-01,  4.7423e-01, -3.1215e-01,  ...,  7.6130e-02,\n",
      "            4.5072e-01,  2.1511e-01],\n",
      "          [-7.2283e-02, -6.9540e-01, -8.0652e-01,  ...,  3.7375e-01,\n",
      "           -6.2661e-01, -3.8228e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1260, -0.1473,  0.2246,  ...,  0.0443,  0.2855, -0.0569],\n",
      "         [ 0.1739, -0.1730, -0.7197,  ..., -0.2658, -0.0743, -0.3148],\n",
      "         [ 0.4667, -0.0673, -0.1903,  ..., -0.3456, -0.7306, -0.3044],\n",
      "         ...,\n",
      "         [ 0.4999, -0.3709, -0.7345,  ..., -0.3297, -0.0707, -0.2834],\n",
      "         [ 0.3661,  0.0340, -0.3976,  ..., -0.4155, -0.0294, -0.0916],\n",
      "         [ 0.5962, -0.2870, -0.3182,  ..., -0.4602, -0.0582, -0.4608]],\n",
      "\n",
      "        [[ 0.1676, -0.2004,  0.1504,  ...,  0.0139,  0.1695, -0.1952],\n",
      "         [ 0.2403, -0.3199, -0.2187,  ...,  0.2862,  0.3978, -0.6325],\n",
      "         [ 0.3418,  0.2334, -0.4503,  ..., -0.6705, -0.7485, -0.2019],\n",
      "         ...,\n",
      "         [ 0.6952, -0.2478, -0.1790,  ..., -0.0710,  0.2596, -0.0687],\n",
      "         [ 0.0563, -0.0338, -0.2561,  ..., -0.0362, -0.2318, -0.4342],\n",
      "         [ 0.3952, -0.0990, -0.2210,  ..., -0.2209, -0.1544, -0.5045]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1260, -0.1473,  0.2246,  ...,  0.0443,  0.2855, -0.0569],\n",
      "         [ 0.1739, -0.1730, -0.7197,  ..., -0.2658, -0.0743, -0.3148],\n",
      "         [ 0.4667, -0.0673, -0.1903,  ..., -0.3456, -0.7306, -0.3044],\n",
      "         ...,\n",
      "         [ 0.4999, -0.3709, -0.7345,  ..., -0.3297, -0.0707, -0.2834],\n",
      "         [ 0.3661,  0.0340, -0.3976,  ..., -0.4155, -0.0294, -0.0916],\n",
      "         [ 0.5962, -0.2870, -0.3182,  ..., -0.4602, -0.0582, -0.4608]],\n",
      "\n",
      "        [[ 0.1676, -0.2004,  0.1504,  ...,  0.0139,  0.1695, -0.1952],\n",
      "         [ 0.2403, -0.3199, -0.2187,  ...,  0.2862,  0.3978, -0.6325],\n",
      "         [ 0.3418,  0.2334, -0.4503,  ..., -0.6705, -0.7485, -0.2019],\n",
      "         ...,\n",
      "         [ 0.6952, -0.2478, -0.1790,  ..., -0.0710,  0.2596, -0.0687],\n",
      "         [ 0.0563, -0.0338, -0.2561,  ..., -0.0362, -0.2318, -0.4342],\n",
      "         [ 0.3952, -0.0990, -0.2210,  ..., -0.2209, -0.1544, -0.5045]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1260, -0.1473,  0.2246,  ...,  0.1338, -0.3652, -0.1487],\n",
      "          [ 0.1048, -0.2693, -0.0813,  ...,  0.0443,  0.2855, -0.0569]],\n",
      "\n",
      "         [[ 0.1739, -0.1730, -0.7197,  ..., -0.0771, -0.0999, -0.3087],\n",
      "          [ 0.1311, -0.3239, -0.2890,  ..., -0.2658, -0.0743, -0.3148]],\n",
      "\n",
      "         [[ 0.4667, -0.0673, -0.1903,  ...,  0.6304, -0.1566, -0.2183],\n",
      "          [ 0.0945,  0.4397,  0.2556,  ..., -0.3456, -0.7306, -0.3044]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4999, -0.3709, -0.7345,  ...,  0.2883,  0.0269, -0.5951],\n",
      "          [ 0.5136, -0.1770,  0.1989,  ..., -0.3297, -0.0707, -0.2834]],\n",
      "\n",
      "         [[ 0.3661,  0.0340, -0.3976,  ...,  0.0794, -0.1919, -0.1122],\n",
      "          [ 0.0147,  0.2201,  0.4642,  ..., -0.4155, -0.0294, -0.0916]],\n",
      "\n",
      "         [[ 0.5962, -0.2870, -0.3182,  ...,  0.3986, -0.4079,  0.0203],\n",
      "          [ 0.2134,  0.2262, -0.0630,  ..., -0.4602, -0.0582, -0.4608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1676, -0.2004,  0.1504,  ...,  0.2494, -0.2941, -0.2756],\n",
      "          [ 0.1880, -0.3905, -0.1351,  ...,  0.0139,  0.1695, -0.1952]],\n",
      "\n",
      "         [[ 0.2403, -0.3199, -0.2187,  ..., -0.4558,  0.0014, -0.1640],\n",
      "          [ 0.1067, -0.2396, -0.4720,  ...,  0.2862,  0.3978, -0.6325]],\n",
      "\n",
      "         [[ 0.3418,  0.2334, -0.4503,  ...,  0.7796, -0.0421, -0.2653],\n",
      "          [ 0.3726,  0.4608,  0.6658,  ..., -0.6705, -0.7485, -0.2019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6952, -0.2478, -0.1790,  ..., -0.1960,  0.0518, -0.0958],\n",
      "          [ 0.0531, -0.2293, -0.0261,  ..., -0.0710,  0.2596, -0.0687]],\n",
      "\n",
      "         [[ 0.0563, -0.0338, -0.2561,  ..., -0.0033, -0.1004, -0.0390],\n",
      "          [ 0.2098,  0.2333,  0.1519,  ..., -0.0362, -0.2318, -0.4342]],\n",
      "\n",
      "         [[ 0.3952, -0.0990, -0.2210,  ...,  0.3308, -0.3388,  0.1436],\n",
      "          [ 0.1422,  0.1690, -0.1126,  ..., -0.2209, -0.1544, -0.5045]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8045, -0.8480,  0.2780,  ..., -0.4973,  0.7229,  0.6816],\n",
      "         [ 0.3126, -0.1668,  0.4028,  ..., -0.6006,  0.5115,  0.6124],\n",
      "         [ 0.2605, -0.2538,  0.6488,  ..., -0.3255,  0.1753,  0.3504],\n",
      "         ...,\n",
      "         [ 0.5805, -0.0083, -0.3760,  ..., -0.3560,  0.3145,  0.4253],\n",
      "         [ 0.4779, -0.1765,  0.1243,  ..., -0.4526,  0.1031,  0.7274],\n",
      "         [ 0.3055, -0.2504, -0.0833,  ..., -0.1786,  0.4533,  0.3011]],\n",
      "\n",
      "        [[ 0.7639, -0.9111,  0.2076,  ..., -0.5420,  0.6265,  0.8113],\n",
      "         [ 0.2753, -0.6877,  0.0780,  ..., -0.6142,  0.4436,  0.4554],\n",
      "         [ 0.4543, -0.4623,  0.5274,  ..., -0.6632,  0.4450,  0.8450],\n",
      "         ...,\n",
      "         [ 0.1698, -0.2265, -0.2369,  ..., -0.2164,  0.3391,  0.0476],\n",
      "         [ 0.1789, -0.2983,  0.2241,  ..., -0.5689,  0.2317,  0.1652],\n",
      "         [ 0.1840, -0.4086,  0.1261,  ..., -0.1706,  0.4374,  0.4886]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8045, -0.8480,  0.2780,  ..., -0.4973,  0.7229,  0.6816],\n",
      "         [ 0.3126, -0.1668,  0.4028,  ..., -0.6006,  0.5115,  0.6124],\n",
      "         [ 0.2605, -0.2538,  0.6488,  ..., -0.3255,  0.1753,  0.3504],\n",
      "         ...,\n",
      "         [ 0.5805, -0.0083, -0.3760,  ..., -0.3560,  0.3145,  0.4253],\n",
      "         [ 0.4779, -0.1765,  0.1243,  ..., -0.4526,  0.1031,  0.7274],\n",
      "         [ 0.3055, -0.2504, -0.0833,  ..., -0.1786,  0.4533,  0.3011]],\n",
      "\n",
      "        [[ 0.7639, -0.9111,  0.2076,  ..., -0.5420,  0.6265,  0.8113],\n",
      "         [ 0.2753, -0.6877,  0.0780,  ..., -0.6142,  0.4436,  0.4554],\n",
      "         [ 0.4543, -0.4623,  0.5274,  ..., -0.6632,  0.4450,  0.8450],\n",
      "         ...,\n",
      "         [ 0.1698, -0.2265, -0.2369,  ..., -0.2164,  0.3391,  0.0476],\n",
      "         [ 0.1789, -0.2983,  0.2241,  ..., -0.5689,  0.2317,  0.1652],\n",
      "         [ 0.1840, -0.4086,  0.1261,  ..., -0.1706,  0.4374,  0.4886]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.8045, -0.8480,  0.2780,  ..., -0.4909, -0.5950, -0.8778],\n",
      "          [ 0.3525,  0.5718,  0.9458,  ..., -0.4973,  0.7229,  0.6816]],\n",
      "\n",
      "         [[ 0.3126, -0.1668,  0.4028,  ...,  0.1395, -0.2009, -0.3644],\n",
      "          [ 0.0877,  0.3621,  0.5077,  ..., -0.6006,  0.5115,  0.6124]],\n",
      "\n",
      "         [[ 0.2605, -0.2538,  0.6488,  ..., -0.1744, -0.1942,  0.0419],\n",
      "          [-0.0123,  0.0292,  0.1196,  ..., -0.3255,  0.1753,  0.3504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5805, -0.0083, -0.3760,  ...,  0.0504, -0.2638, -0.1775],\n",
      "          [ 0.1199,  0.4960,  0.2266,  ..., -0.3560,  0.3145,  0.4253]],\n",
      "\n",
      "         [[ 0.4779, -0.1765,  0.1243,  ..., -0.0261, -0.0559, -0.2261],\n",
      "          [ 0.0837,  0.1339,  0.3525,  ..., -0.4526,  0.1031,  0.7274]],\n",
      "\n",
      "         [[ 0.3055, -0.2504, -0.0833,  ..., -0.2208, -0.2962, -0.2899],\n",
      "          [ 0.2915,  0.3432,  0.5816,  ..., -0.1786,  0.4533,  0.3011]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7639, -0.9111,  0.2076,  ..., -0.5988, -0.7052, -0.7621],\n",
      "          [ 0.4566,  0.5690,  0.8142,  ..., -0.5420,  0.6265,  0.8113]],\n",
      "\n",
      "         [[ 0.2753, -0.6877,  0.0780,  ..., -0.3889, -0.5854, -0.3276],\n",
      "          [ 0.2473,  0.4458,  0.8153,  ..., -0.6142,  0.4436,  0.4554]],\n",
      "\n",
      "         [[ 0.4543, -0.4623,  0.5274,  ..., -0.1796, -0.0509,  0.0660],\n",
      "          [ 0.1186, -0.1800,  0.3790,  ..., -0.6632,  0.4450,  0.8450]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1698, -0.2265, -0.2369,  ..., -0.0733, -0.1706, -0.3330],\n",
      "          [-0.0037,  0.2887,  0.2091,  ..., -0.2164,  0.3391,  0.0476]],\n",
      "\n",
      "         [[ 0.1789, -0.2983,  0.2241,  ..., -0.1473,  0.2182, -0.0265],\n",
      "          [-0.0465,  0.1567, -0.2306,  ..., -0.5689,  0.2317,  0.1652]],\n",
      "\n",
      "         [[ 0.1840, -0.4086,  0.1261,  ..., -0.2056, -0.2556, -0.1927],\n",
      "          [ 0.1938,  0.1425,  0.4482,  ..., -0.1706,  0.4374,  0.4886]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-4.0165e-01,  1.6539e-01, -4.6436e-01,  ...,  3.0126e-01,\n",
      "            5.0580e-01,  2.2017e-01],\n",
      "          [-3.8620e-01,  3.8718e-01, -4.7328e-01,  ..., -1.8800e-03,\n",
      "            8.4333e-03, -1.2562e-01],\n",
      "          [ 1.8013e-01, -1.7467e-01, -3.9694e-01,  ..., -7.5362e-02,\n",
      "            2.0189e-01, -9.8096e-02],\n",
      "          ...,\n",
      "          [-2.6758e-01, -3.3028e-02, -3.2299e-01,  ..., -2.9892e-01,\n",
      "            4.9999e-01,  5.7226e-02],\n",
      "          [-2.7415e-01,  8.9117e-02, -3.3042e-01,  ...,  2.1287e-01,\n",
      "            3.6937e-02,  2.2420e-01],\n",
      "          [-5.8570e-01,  5.1817e-01, -3.9198e-01,  ...,  2.8962e-01,\n",
      "            5.3546e-01,  1.7706e-01]],\n",
      "\n",
      "         [[-2.1312e-01, -1.2262e-01, -8.2814e-01,  ...,  2.7283e-01,\n",
      "           -5.7040e-01, -2.4830e-01],\n",
      "          [-2.7967e-01, -3.7954e-01, -7.0284e-01,  ...,  4.0392e-01,\n",
      "           -1.7329e-01,  1.7252e-02],\n",
      "          [-1.8498e-01,  8.9320e-02, -1.2733e-01,  ...,  1.0745e-01,\n",
      "            3.8377e-02,  2.8123e-01],\n",
      "          ...,\n",
      "          [-2.1475e-01, -5.0642e-01, -4.1484e-01,  ..., -1.8929e-01,\n",
      "           -4.2177e-01, -2.2033e-01],\n",
      "          [-4.0935e-01, -3.3468e-01, -3.9696e-01,  ...,  1.5985e-02,\n",
      "           -1.6230e-01,  3.0945e-01],\n",
      "          [-3.3693e-01, -7.0472e-01, -9.6754e-01,  ...,  4.4097e-01,\n",
      "           -6.6508e-01, -4.3832e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4889e-01,  1.8420e-01, -3.9037e-01,  ...,  2.7416e-01,\n",
      "            6.4866e-01,  3.5866e-01],\n",
      "          [-7.1793e-01,  4.3429e-01, -4.8114e-01,  ...,  3.2125e-01,\n",
      "            5.7999e-01,  3.1966e-01],\n",
      "          [-2.5544e-02, -2.2186e-01, -3.9022e-01,  ...,  1.2803e-01,\n",
      "            1.7732e-01, -1.1215e-02],\n",
      "          ...,\n",
      "          [ 8.2157e-03, -7.3979e-04, -4.4271e-01,  ...,  1.4112e-01,\n",
      "            1.5584e-01, -4.1993e-01],\n",
      "          [-5.8474e-01, -2.9651e-02,  7.7124e-02,  ...,  9.5008e-02,\n",
      "           -5.2726e-02, -2.2891e-03],\n",
      "          [-4.7111e-01,  4.7423e-01, -3.1215e-01,  ...,  7.6130e-02,\n",
      "            4.5072e-01,  2.1511e-01]],\n",
      "\n",
      "         [[-3.7623e-02, -1.7998e-01, -8.7334e-01,  ...,  3.1033e-01,\n",
      "           -6.8266e-01, -2.0989e-01],\n",
      "          [-4.8533e-01, -7.6226e-01, -7.6207e-01,  ...,  3.4948e-01,\n",
      "           -9.4018e-01, -2.2869e-01],\n",
      "          [-2.5673e-01,  1.3006e-01, -3.9370e-01,  ...,  1.3155e-01,\n",
      "           -1.4003e-01,  4.0937e-01],\n",
      "          ...,\n",
      "          [-2.7640e-01, -2.5312e-01, -4.2793e-01,  ..., -1.9212e-01,\n",
      "           -3.7336e-01, -1.2736e-01],\n",
      "          [-4.8782e-01, -4.4651e-01, -2.2320e-01,  ...,  1.8826e-01,\n",
      "           -2.5086e-01, -2.7096e-01],\n",
      "          [-7.2283e-02, -6.9540e-01, -8.0652e-01,  ...,  3.7375e-01,\n",
      "           -6.2661e-01, -3.8228e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1500, -0.0842, -0.2125,  ...,  0.4309, -0.1651, -0.1735],\n",
      "          [ 0.1754, -0.1341, -0.2394,  ...,  0.3141, -0.1422, -0.2029],\n",
      "          [ 0.1996, -0.1657, -0.2233,  ...,  0.3278, -0.1707, -0.2130],\n",
      "          ...,\n",
      "          [ 0.1989, -0.1496, -0.2442,  ...,  0.3497, -0.1732, -0.2167],\n",
      "          [ 0.1705, -0.1340, -0.1493,  ...,  0.3407, -0.1602, -0.1741],\n",
      "          [ 0.0939, -0.1153, -0.0763,  ...,  0.0849, -0.0886, -0.1131]],\n",
      "\n",
      "         [[ 0.2767,  0.0489,  0.1424,  ..., -0.2489, -0.1694, -0.3117],\n",
      "          [ 0.2843, -0.0012,  0.1063,  ..., -0.2110, -0.0987, -0.3293],\n",
      "          [ 0.2217, -0.0799,  0.0656,  ..., -0.1222, -0.0295, -0.2934],\n",
      "          ...,\n",
      "          [ 0.2748,  0.0057,  0.0986,  ..., -0.2081, -0.1088, -0.3295],\n",
      "          [ 0.2321, -0.0668,  0.0743,  ..., -0.1281, -0.0444, -0.3052],\n",
      "          [ 0.2422,  0.0399,  0.1253,  ..., -0.1707, -0.0798, -0.2690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1253, -0.0361, -0.1918,  ...,  0.2856,  0.0472, -0.1774],\n",
      "          [ 0.1381, -0.0804, -0.1694,  ...,  0.2341,  0.0046, -0.1786],\n",
      "          [ 0.1493, -0.0975, -0.1757,  ...,  0.2036, -0.0333, -0.1759],\n",
      "          ...,\n",
      "          [ 0.1627, -0.0764, -0.1041,  ...,  0.1842, -0.0094, -0.1138],\n",
      "          [ 0.1734, -0.1060, -0.1870,  ...,  0.1904, -0.0629, -0.1670],\n",
      "          [ 0.0807, -0.0708, -0.1520,  ...,  0.2258, -0.0233, -0.1645]],\n",
      "\n",
      "         [[ 0.0641, -0.1496,  0.1549,  ..., -0.1548, -0.0129, -0.5004],\n",
      "          [ 0.1147, -0.0937,  0.1443,  ..., -0.1379, -0.0441, -0.5013],\n",
      "          [ 0.1128, -0.0812,  0.1152,  ..., -0.1339, -0.0282, -0.4282],\n",
      "          ...,\n",
      "          [ 0.1267, -0.0941,  0.0966,  ..., -0.1212, -0.0195, -0.4255],\n",
      "          [ 0.1406, -0.0516,  0.0997,  ..., -0.1205, -0.0240, -0.4480],\n",
      "          [ 0.2824,  0.1012,  0.2109,  ..., -0.1943, -0.1742, -0.2655]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.1500, -0.0842, -0.2125,  ...,  0.4309, -0.1651, -0.1735],\n",
      "          [ 0.2767,  0.0489,  0.1424,  ..., -0.2489, -0.1694, -0.3117]],\n",
      "\n",
      "         [[ 0.1754, -0.1341, -0.2394,  ...,  0.3141, -0.1422, -0.2029],\n",
      "          [ 0.2843, -0.0012,  0.1063,  ..., -0.2110, -0.0987, -0.3293]],\n",
      "\n",
      "         [[ 0.1996, -0.1657, -0.2233,  ...,  0.3278, -0.1707, -0.2130],\n",
      "          [ 0.2217, -0.0799,  0.0656,  ..., -0.1222, -0.0295, -0.2934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1989, -0.1496, -0.2442,  ...,  0.3497, -0.1732, -0.2167],\n",
      "          [ 0.2748,  0.0057,  0.0986,  ..., -0.2081, -0.1088, -0.3295]],\n",
      "\n",
      "         [[ 0.1705, -0.1340, -0.1493,  ...,  0.3407, -0.1602, -0.1741],\n",
      "          [ 0.2321, -0.0668,  0.0743,  ..., -0.1281, -0.0444, -0.3052]],\n",
      "\n",
      "         [[ 0.0939, -0.1153, -0.0763,  ...,  0.0849, -0.0886, -0.1131],\n",
      "          [ 0.2422,  0.0399,  0.1253,  ..., -0.1707, -0.0798, -0.2690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1253, -0.0361, -0.1918,  ...,  0.2856,  0.0472, -0.1774],\n",
      "          [ 0.0641, -0.1496,  0.1549,  ..., -0.1548, -0.0129, -0.5004]],\n",
      "\n",
      "         [[ 0.1381, -0.0804, -0.1694,  ...,  0.2341,  0.0046, -0.1786],\n",
      "          [ 0.1147, -0.0937,  0.1443,  ..., -0.1379, -0.0441, -0.5013]],\n",
      "\n",
      "         [[ 0.1493, -0.0975, -0.1757,  ...,  0.2036, -0.0333, -0.1759],\n",
      "          [ 0.1128, -0.0812,  0.1152,  ..., -0.1339, -0.0282, -0.4282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1627, -0.0764, -0.1041,  ...,  0.1842, -0.0094, -0.1138],\n",
      "          [ 0.1267, -0.0941,  0.0966,  ..., -0.1212, -0.0195, -0.4255]],\n",
      "\n",
      "         [[ 0.1734, -0.1060, -0.1870,  ...,  0.1904, -0.0629, -0.1670],\n",
      "          [ 0.1406, -0.0516,  0.0997,  ..., -0.1205, -0.0240, -0.4480]],\n",
      "\n",
      "         [[ 0.0807, -0.0708, -0.1520,  ...,  0.2258, -0.0233, -0.1645],\n",
      "          [ 0.2824,  0.1012,  0.2109,  ..., -0.1943, -0.1742, -0.2655]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1500, -0.0842, -0.2125,  ...,  0.4309, -0.1651, -0.1735],\n",
      "          [ 0.2767,  0.0489,  0.1424,  ..., -0.2489, -0.1694, -0.3117]],\n",
      "\n",
      "         [[ 0.1754, -0.1341, -0.2394,  ...,  0.3141, -0.1422, -0.2029],\n",
      "          [ 0.2843, -0.0012,  0.1063,  ..., -0.2110, -0.0987, -0.3293]],\n",
      "\n",
      "         [[ 0.1996, -0.1657, -0.2233,  ...,  0.3278, -0.1707, -0.2130],\n",
      "          [ 0.2217, -0.0799,  0.0656,  ..., -0.1222, -0.0295, -0.2934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1989, -0.1496, -0.2442,  ...,  0.3497, -0.1732, -0.2167],\n",
      "          [ 0.2748,  0.0057,  0.0986,  ..., -0.2081, -0.1088, -0.3295]],\n",
      "\n",
      "         [[ 0.1705, -0.1340, -0.1493,  ...,  0.3407, -0.1602, -0.1741],\n",
      "          [ 0.2321, -0.0668,  0.0743,  ..., -0.1281, -0.0444, -0.3052]],\n",
      "\n",
      "         [[ 0.0939, -0.1153, -0.0763,  ...,  0.0849, -0.0886, -0.1131],\n",
      "          [ 0.2422,  0.0399,  0.1253,  ..., -0.1707, -0.0798, -0.2690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1253, -0.0361, -0.1918,  ...,  0.2856,  0.0472, -0.1774],\n",
      "          [ 0.0641, -0.1496,  0.1549,  ..., -0.1548, -0.0129, -0.5004]],\n",
      "\n",
      "         [[ 0.1381, -0.0804, -0.1694,  ...,  0.2341,  0.0046, -0.1786],\n",
      "          [ 0.1147, -0.0937,  0.1443,  ..., -0.1379, -0.0441, -0.5013]],\n",
      "\n",
      "         [[ 0.1493, -0.0975, -0.1757,  ...,  0.2036, -0.0333, -0.1759],\n",
      "          [ 0.1128, -0.0812,  0.1152,  ..., -0.1339, -0.0282, -0.4282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1627, -0.0764, -0.1041,  ...,  0.1842, -0.0094, -0.1138],\n",
      "          [ 0.1267, -0.0941,  0.0966,  ..., -0.1212, -0.0195, -0.4255]],\n",
      "\n",
      "         [[ 0.1734, -0.1060, -0.1870,  ...,  0.1904, -0.0629, -0.1670],\n",
      "          [ 0.1406, -0.0516,  0.0997,  ..., -0.1205, -0.0240, -0.4480]],\n",
      "\n",
      "         [[ 0.0807, -0.0708, -0.1520,  ...,  0.2258, -0.0233, -0.1645],\n",
      "          [ 0.2824,  0.1012,  0.2109,  ..., -0.1943, -0.1742, -0.2655]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.1500, -0.0842, -0.2125,  ...,  0.4309, -0.1651, -0.1735],\n",
      "          [ 0.2767,  0.0489,  0.1424,  ..., -0.2489, -0.1694, -0.3117]],\n",
      "\n",
      "         [[ 0.1754, -0.1341, -0.2394,  ...,  0.3141, -0.1422, -0.2029],\n",
      "          [ 0.2843, -0.0012,  0.1063,  ..., -0.2110, -0.0987, -0.3293]],\n",
      "\n",
      "         [[ 0.1996, -0.1657, -0.2233,  ...,  0.3278, -0.1707, -0.2130],\n",
      "          [ 0.2217, -0.0799,  0.0656,  ..., -0.1222, -0.0295, -0.2934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1989, -0.1496, -0.2442,  ...,  0.3497, -0.1732, -0.2167],\n",
      "          [ 0.2748,  0.0057,  0.0986,  ..., -0.2081, -0.1088, -0.3295]],\n",
      "\n",
      "         [[ 0.1705, -0.1340, -0.1493,  ...,  0.3407, -0.1602, -0.1741],\n",
      "          [ 0.2321, -0.0668,  0.0743,  ..., -0.1281, -0.0444, -0.3052]],\n",
      "\n",
      "         [[ 0.0939, -0.1153, -0.0763,  ...,  0.0849, -0.0886, -0.1131],\n",
      "          [ 0.2422,  0.0399,  0.1253,  ..., -0.1707, -0.0798, -0.2690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1253, -0.0361, -0.1918,  ...,  0.2856,  0.0472, -0.1774],\n",
      "          [ 0.0641, -0.1496,  0.1549,  ..., -0.1548, -0.0129, -0.5004]],\n",
      "\n",
      "         [[ 0.1381, -0.0804, -0.1694,  ...,  0.2341,  0.0046, -0.1786],\n",
      "          [ 0.1147, -0.0937,  0.1443,  ..., -0.1379, -0.0441, -0.5013]],\n",
      "\n",
      "         [[ 0.1493, -0.0975, -0.1757,  ...,  0.2036, -0.0333, -0.1759],\n",
      "          [ 0.1128, -0.0812,  0.1152,  ..., -0.1339, -0.0282, -0.4282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1627, -0.0764, -0.1041,  ...,  0.1842, -0.0094, -0.1138],\n",
      "          [ 0.1267, -0.0941,  0.0966,  ..., -0.1212, -0.0195, -0.4255]],\n",
      "\n",
      "         [[ 0.1734, -0.1060, -0.1870,  ...,  0.1904, -0.0629, -0.1670],\n",
      "          [ 0.1406, -0.0516,  0.0997,  ..., -0.1205, -0.0240, -0.4480]],\n",
      "\n",
      "         [[ 0.0807, -0.0708, -0.1520,  ...,  0.2258, -0.0233, -0.1645],\n",
      "          [ 0.2824,  0.1012,  0.2109,  ..., -0.1943, -0.1742, -0.2655]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.0884,  0.4728, -0.1490,  ...,  0.0731, -0.1668,  0.3260],\n",
      "         [ 0.0746, -0.0049, -0.4592,  ..., -0.1945, -0.3527,  0.3020],\n",
      "         [ 0.3168, -0.2553, -0.2655,  ..., -0.2029,  0.0402, -0.2505],\n",
      "         ...,\n",
      "         [ 0.1617,  0.2481, -0.2769,  ..., -0.6546, -0.1726,  0.2653],\n",
      "         [ 0.3005, -0.3100, -0.2682,  ..., -0.2427, -0.0913, -0.0814],\n",
      "         [ 0.5059,  0.1835, -0.6406,  ..., -0.4859, -0.2610,  0.3568]],\n",
      "\n",
      "        [[-0.0609,  0.4172, -0.0835,  ...,  0.0656, -0.1003,  0.3213],\n",
      "         [ 0.2853,  0.4119, -0.4969,  ..., -0.6943, -0.2863,  0.3691],\n",
      "         [ 0.1741, -0.0961,  0.0328,  ...,  0.2292, -0.0974,  0.0063],\n",
      "         ...,\n",
      "         [ 0.3631,  0.1142, -0.4215,  ..., -0.2256, -0.1814,  0.3751],\n",
      "         [ 0.4447, -0.1123, -0.3272,  ..., -0.4692, -0.0437, -0.0823],\n",
      "         [ 0.4069,  0.1279, -0.7872,  ..., -0.4289, -0.3201,  0.2555]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0884,  0.4728, -0.1490,  ...,  0.0731, -0.1668,  0.3260],\n",
      "         [ 0.0746, -0.0049, -0.4592,  ..., -0.1945, -0.3527,  0.3020],\n",
      "         [ 0.3168, -0.2553, -0.2655,  ..., -0.2029,  0.0402, -0.2505],\n",
      "         ...,\n",
      "         [ 0.1617,  0.2481, -0.2769,  ..., -0.6546, -0.1726,  0.2653],\n",
      "         [ 0.3005, -0.3100, -0.2682,  ..., -0.2427, -0.0913, -0.0814],\n",
      "         [ 0.5059,  0.1835, -0.6406,  ..., -0.4859, -0.2610,  0.3568]],\n",
      "\n",
      "        [[-0.0609,  0.4172, -0.0835,  ...,  0.0656, -0.1003,  0.3213],\n",
      "         [ 0.2853,  0.4119, -0.4969,  ..., -0.6943, -0.2863,  0.3691],\n",
      "         [ 0.1741, -0.0961,  0.0328,  ...,  0.2292, -0.0974,  0.0063],\n",
      "         ...,\n",
      "         [ 0.3631,  0.1142, -0.4215,  ..., -0.2256, -0.1814,  0.3751],\n",
      "         [ 0.4447, -0.1123, -0.3272,  ..., -0.4692, -0.0437, -0.0823],\n",
      "         [ 0.4069,  0.1279, -0.7872,  ..., -0.4289, -0.3201,  0.2555]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0884,  0.4728, -0.1490,  ...,  0.2295,  0.5602,  0.1889],\n",
      "          [ 0.3118, -0.0570, -0.3501,  ...,  0.0731, -0.1668,  0.3260]],\n",
      "\n",
      "         [[ 0.0746, -0.0049, -0.4592,  ...,  0.4201,  0.6470, -0.4225],\n",
      "          [-0.1616, -0.2818, -0.3316,  ..., -0.1945, -0.3527,  0.3020]],\n",
      "\n",
      "         [[ 0.3168, -0.2553, -0.2655,  ...,  0.2931,  0.0675,  0.0257],\n",
      "          [-0.0608,  0.4997,  0.0215,  ..., -0.2029,  0.0402, -0.2505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1617,  0.2481, -0.2769,  ...,  0.2825,  0.6216,  0.2886],\n",
      "          [ 0.3825, -0.4645, -0.3967,  ..., -0.6546, -0.1726,  0.2653]],\n",
      "\n",
      "         [[ 0.3005, -0.3100, -0.2682,  ...,  0.0327,  0.3916,  0.0472],\n",
      "          [ 0.1201,  0.1104,  0.0255,  ..., -0.2427, -0.0913, -0.0814]],\n",
      "\n",
      "         [[ 0.5059,  0.1835, -0.6406,  ...,  0.4261,  0.8271,  0.3025],\n",
      "          [ 0.0897, -0.5929, -0.5560,  ..., -0.4859, -0.2610,  0.3568]]],\n",
      "\n",
      "\n",
      "        [[[-0.0609,  0.4172, -0.0835,  ...,  0.3280,  0.4656,  0.0769],\n",
      "          [ 0.4289, -0.0971, -0.3024,  ...,  0.0656, -0.1003,  0.3213]],\n",
      "\n",
      "         [[ 0.2853,  0.4119, -0.4969,  ...,  0.4551,  0.8752, -0.0457],\n",
      "          [ 0.3638, -0.4370, -0.2731,  ..., -0.6943, -0.2863,  0.3691]],\n",
      "\n",
      "         [[ 0.1741, -0.0961,  0.0328,  ...,  0.3216, -0.1165, -0.1914],\n",
      "          [ 0.2144,  0.5298, -0.2404,  ...,  0.2292, -0.0974,  0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3631,  0.1142, -0.4215,  ...,  0.3598,  0.6709,  0.3520],\n",
      "          [ 0.2344, -0.5730, -0.1982,  ..., -0.2256, -0.1814,  0.3751]],\n",
      "\n",
      "         [[ 0.4447, -0.1123, -0.3272,  ...,  0.4555, -0.0205,  0.0765],\n",
      "          [ 0.0703,  0.0774,  0.0042,  ..., -0.4692, -0.0437, -0.0823]],\n",
      "\n",
      "         [[ 0.4069,  0.1279, -0.7872,  ...,  0.3934,  0.8276,  0.3498],\n",
      "          [ 0.1208, -0.5704, -0.6027,  ..., -0.4289, -0.3201,  0.2555]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2225, -0.4490,  0.7618,  ..., -0.4922,  0.4121, -0.0294],\n",
      "         [ 0.0455, -0.6393,  0.7220,  ...,  0.0695,  0.7417, -0.4271],\n",
      "         [ 0.3351, -0.4787,  0.3893,  ..., -0.2548,  0.6407, -0.4577],\n",
      "         ...,\n",
      "         [ 0.3150, -0.7212,  0.6330,  ..., -0.3988,  0.8826, -0.6947],\n",
      "         [ 0.0223, -0.5373,  0.8404,  ..., -0.3050,  0.8208, -0.6709],\n",
      "         [-0.4078, -0.3540,  0.5772,  ..., -0.5026,  0.5169, -0.4747]],\n",
      "\n",
      "        [[ 0.2296, -0.2610,  0.7201,  ..., -0.4515,  0.0986,  0.0889],\n",
      "         [-0.1774, -0.0238,  0.1210,  ...,  0.1291, -0.0272, -0.4143],\n",
      "         [ 0.4223, -0.2447,  0.7334,  ..., -0.0402,  0.8426, -0.5564],\n",
      "         ...,\n",
      "         [-0.1236, -0.1031,  0.1238,  ..., -0.2667,  0.3570, -0.1225],\n",
      "         [ 0.0094, -0.3297,  0.2237,  ..., -0.4155,  0.3505,  0.0200],\n",
      "         [-0.4614, -0.1715,  0.4599,  ..., -0.3533,  0.3784, -0.4522]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2225, -0.4490,  0.7618,  ..., -0.4922,  0.4121, -0.0294],\n",
      "         [ 0.0455, -0.6393,  0.7220,  ...,  0.0695,  0.7417, -0.4271],\n",
      "         [ 0.3351, -0.4787,  0.3893,  ..., -0.2548,  0.6407, -0.4577],\n",
      "         ...,\n",
      "         [ 0.3150, -0.7212,  0.6330,  ..., -0.3988,  0.8826, -0.6947],\n",
      "         [ 0.0223, -0.5373,  0.8404,  ..., -0.3050,  0.8208, -0.6709],\n",
      "         [-0.4078, -0.3540,  0.5772,  ..., -0.5026,  0.5169, -0.4747]],\n",
      "\n",
      "        [[ 0.2296, -0.2610,  0.7201,  ..., -0.4515,  0.0986,  0.0889],\n",
      "         [-0.1774, -0.0238,  0.1210,  ...,  0.1291, -0.0272, -0.4143],\n",
      "         [ 0.4223, -0.2447,  0.7334,  ..., -0.0402,  0.8426, -0.5564],\n",
      "         ...,\n",
      "         [-0.1236, -0.1031,  0.1238,  ..., -0.2667,  0.3570, -0.1225],\n",
      "         [ 0.0094, -0.3297,  0.2237,  ..., -0.4155,  0.3505,  0.0200],\n",
      "         [-0.4614, -0.1715,  0.4599,  ..., -0.3533,  0.3784, -0.4522]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2225, -0.4490,  0.7618,  ..., -0.6349,  0.7788,  0.1229],\n",
      "          [-0.3958,  0.4687,  0.1652,  ..., -0.4922,  0.4121, -0.0294]],\n",
      "\n",
      "         [[ 0.0455, -0.6393,  0.7220,  ..., -0.8482,  0.7465,  0.1726],\n",
      "          [-0.6763,  0.2154,  0.4563,  ...,  0.0695,  0.7417, -0.4271]],\n",
      "\n",
      "         [[ 0.3351, -0.4787,  0.3893,  ..., -1.2484,  0.4749,  0.0721],\n",
      "          [-0.3271,  0.3113,  0.8565,  ..., -0.2548,  0.6407, -0.4577]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3150, -0.7212,  0.6330,  ..., -0.8653,  0.7835,  0.3572],\n",
      "          [-0.5274,  0.5023,  0.7213,  ..., -0.3988,  0.8826, -0.6947]],\n",
      "\n",
      "         [[ 0.0223, -0.5373,  0.8404,  ..., -1.0376,  0.3950,  0.0333],\n",
      "          [-0.4357,  0.2758,  0.5528,  ..., -0.3050,  0.8208, -0.6709]],\n",
      "\n",
      "         [[-0.4078, -0.3540,  0.5772,  ..., -0.4940,  0.6177, -0.1252],\n",
      "          [-0.3255, -0.0845,  0.3043,  ..., -0.5026,  0.5169, -0.4747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2296, -0.2610,  0.7201,  ..., -0.1612,  0.8186,  0.1067],\n",
      "          [-0.1236,  0.2047, -0.1184,  ..., -0.4515,  0.0986,  0.0889]],\n",
      "\n",
      "         [[-0.1774, -0.0238,  0.1210,  ...,  0.0677,  0.2143,  0.0511],\n",
      "          [-0.1463, -0.2139, -0.3222,  ...,  0.1291, -0.0272, -0.4143]],\n",
      "\n",
      "         [[ 0.4223, -0.2447,  0.7334,  ..., -1.2332,  0.9433,  0.3462],\n",
      "          [-0.4380,  0.5408,  0.8766,  ..., -0.0402,  0.8426, -0.5564]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1236, -0.1031,  0.1238,  ..., -0.1740,  0.4682, -0.0903],\n",
      "          [-0.2228,  0.3841,  0.4657,  ..., -0.2667,  0.3570, -0.1225]],\n",
      "\n",
      "         [[ 0.0094, -0.3297,  0.2237,  ..., -0.3065,  0.1468, -0.3436],\n",
      "          [ 0.0757, -0.3095,  0.3979,  ..., -0.4155,  0.3505,  0.0200]],\n",
      "\n",
      "         [[-0.4614, -0.1715,  0.4599,  ..., -0.4623,  0.6132, -0.1409],\n",
      "          [-0.2069, -0.1437,  0.2628,  ..., -0.3533,  0.3784, -0.4522]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2608, -0.9750,  0.7235,  ...,  1.3066,  0.5935, -1.0271],\n",
      "         [-0.1835, -0.4301,  0.5021,  ...,  0.6716,  0.5260, -0.6708],\n",
      "         [ 0.1920, -0.1332, -0.1290,  ..., -0.1572,  0.1645, -0.1816],\n",
      "         ...,\n",
      "         [ 0.0795, -0.2745,  0.1223,  ...,  0.3663,  0.6301, -0.7627],\n",
      "         [-0.3132, -0.4930,  0.1073,  ...,  0.3512,  0.4377, -0.0687],\n",
      "         [ 0.0963, -0.3159,  0.5910,  ...,  0.4409,  0.3652, -0.4326]],\n",
      "\n",
      "        [[ 0.0422, -1.2066,  0.8325,  ...,  1.3141,  0.6515, -1.2049],\n",
      "         [-0.1509, -0.4514,  0.4250,  ...,  0.5889,  0.2742, -0.2329],\n",
      "         [ 0.0125, -0.3469,  0.2162,  ...,  0.2181,  0.3211, -0.2677],\n",
      "         ...,\n",
      "         [-0.0403, -0.4855,  0.1647,  ...,  0.2503,  0.3198, -0.5355],\n",
      "         [-0.2437,  0.0118,  0.1319,  ..., -0.2158, -0.0553,  0.0321],\n",
      "         [-0.1643, -0.3780,  0.5806,  ...,  0.5142,  0.4935, -0.5319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2608, -0.9750,  0.7235,  ...,  1.3066,  0.5935, -1.0271],\n",
      "         [-0.1835, -0.4301,  0.5021,  ...,  0.6716,  0.5260, -0.6708],\n",
      "         [ 0.1920, -0.1332, -0.1290,  ..., -0.1572,  0.1645, -0.1816],\n",
      "         ...,\n",
      "         [ 0.0795, -0.2745,  0.1223,  ...,  0.3663,  0.6301, -0.7627],\n",
      "         [-0.3132, -0.4930,  0.1073,  ...,  0.3512,  0.4377, -0.0687],\n",
      "         [ 0.0963, -0.3159,  0.5910,  ...,  0.4409,  0.3652, -0.4326]],\n",
      "\n",
      "        [[ 0.0422, -1.2066,  0.8325,  ...,  1.3141,  0.6515, -1.2049],\n",
      "         [-0.1509, -0.4514,  0.4250,  ...,  0.5889,  0.2742, -0.2329],\n",
      "         [ 0.0125, -0.3469,  0.2162,  ...,  0.2181,  0.3211, -0.2677],\n",
      "         ...,\n",
      "         [-0.0403, -0.4855,  0.1647,  ...,  0.2503,  0.3198, -0.5355],\n",
      "         [-0.2437,  0.0118,  0.1319,  ..., -0.2158, -0.0553,  0.0321],\n",
      "         [-0.1643, -0.3780,  0.5806,  ...,  0.5142,  0.4935, -0.5319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2608, -0.9750,  0.7235,  ..., -0.5712, -0.9160, -0.3790],\n",
      "          [-0.9340,  1.2405,  0.7850,  ...,  1.3066,  0.5935, -1.0271]],\n",
      "\n",
      "         [[-0.1835, -0.4301,  0.5021,  ..., -0.4668, -0.4474, -0.4444],\n",
      "          [-0.5037,  0.7286,  0.4952,  ...,  0.6716,  0.5260, -0.6708]],\n",
      "\n",
      "         [[ 0.1920, -0.1332, -0.1290,  ..., -0.5431, -0.1473, -0.4294],\n",
      "          [-0.0228,  0.6552,  0.2044,  ..., -0.1572,  0.1645, -0.1816]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0795, -0.2745,  0.1223,  ..., -0.4492, -0.4374, -0.1247],\n",
      "          [-0.3718,  0.8227,  0.1594,  ...,  0.3663,  0.6301, -0.7627]],\n",
      "\n",
      "         [[-0.3132, -0.4930,  0.1073,  ..., -0.2237, -0.3044, -0.4519],\n",
      "          [-0.2329,  0.6879,  0.4551,  ...,  0.3512,  0.4377, -0.0687]],\n",
      "\n",
      "         [[ 0.0963, -0.3159,  0.5910,  ..., -0.4070, -0.4529, -0.4851],\n",
      "          [-0.6912,  0.6002,  0.6324,  ...,  0.4409,  0.3652, -0.4326]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0422, -1.2066,  0.8325,  ..., -0.6135, -0.9716, -0.3233],\n",
      "          [-1.0418,  1.0939,  1.0147,  ...,  1.3141,  0.6515, -1.2049]],\n",
      "\n",
      "         [[-0.1509, -0.4514,  0.4250,  ..., -0.1515, -0.3491, -0.2533],\n",
      "          [-0.4147,  0.1206,  0.4420,  ...,  0.5889,  0.2742, -0.2329]],\n",
      "\n",
      "         [[ 0.0125, -0.3469,  0.2162,  ..., -0.6037, -0.6226, -0.7462],\n",
      "          [-0.0859,  0.6097,  0.2475,  ...,  0.2181,  0.3211, -0.2677]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0403, -0.4855,  0.1647,  ..., -0.1401, -0.2641, -0.4353],\n",
      "          [-0.3088,  1.1532,  0.1383,  ...,  0.2503,  0.3198, -0.5355]],\n",
      "\n",
      "         [[-0.2437,  0.0118,  0.1319,  ..., -0.0679, -0.0139, -0.1247],\n",
      "          [ 0.0480,  0.2010,  0.4416,  ..., -0.2158, -0.0553,  0.0321]],\n",
      "\n",
      "         [[-0.1643, -0.3780,  0.5806,  ..., -0.5239, -0.3503, -0.5938],\n",
      "          [-0.6960,  0.6501,  0.7528,  ...,  0.5142,  0.4935, -0.5319]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0884,  0.4728, -0.1490,  ...,  0.2295,  0.5602,  0.1889],\n",
      "          [ 0.0746, -0.0049, -0.4592,  ...,  0.4201,  0.6470, -0.4225],\n",
      "          [ 0.3168, -0.2553, -0.2655,  ...,  0.2931,  0.0675,  0.0257],\n",
      "          ...,\n",
      "          [ 0.1617,  0.2481, -0.2769,  ...,  0.2825,  0.6216,  0.2886],\n",
      "          [ 0.3005, -0.3100, -0.2682,  ...,  0.0327,  0.3916,  0.0472],\n",
      "          [ 0.5059,  0.1835, -0.6406,  ...,  0.4261,  0.8271,  0.3025]],\n",
      "\n",
      "         [[ 0.3118, -0.0570, -0.3501,  ...,  0.0731, -0.1668,  0.3260],\n",
      "          [-0.1616, -0.2818, -0.3316,  ..., -0.1945, -0.3527,  0.3020],\n",
      "          [-0.0608,  0.4997,  0.0215,  ..., -0.2029,  0.0402, -0.2505],\n",
      "          ...,\n",
      "          [ 0.3825, -0.4645, -0.3967,  ..., -0.6546, -0.1726,  0.2653],\n",
      "          [ 0.1201,  0.1104,  0.0255,  ..., -0.2427, -0.0913, -0.0814],\n",
      "          [ 0.0897, -0.5929, -0.5560,  ..., -0.4859, -0.2610,  0.3568]]],\n",
      "\n",
      "\n",
      "        [[[-0.0609,  0.4172, -0.0835,  ...,  0.3280,  0.4656,  0.0769],\n",
      "          [ 0.2853,  0.4119, -0.4969,  ...,  0.4551,  0.8752, -0.0457],\n",
      "          [ 0.1741, -0.0961,  0.0328,  ...,  0.3216, -0.1165, -0.1914],\n",
      "          ...,\n",
      "          [ 0.3631,  0.1142, -0.4215,  ...,  0.3598,  0.6709,  0.3520],\n",
      "          [ 0.4447, -0.1123, -0.3272,  ...,  0.4555, -0.0205,  0.0765],\n",
      "          [ 0.4069,  0.1279, -0.7872,  ...,  0.3934,  0.8276,  0.3498]],\n",
      "\n",
      "         [[ 0.4289, -0.0971, -0.3024,  ...,  0.0656, -0.1003,  0.3213],\n",
      "          [ 0.3638, -0.4370, -0.2731,  ..., -0.6943, -0.2863,  0.3691],\n",
      "          [ 0.2144,  0.5298, -0.2404,  ...,  0.2292, -0.0974,  0.0063],\n",
      "          ...,\n",
      "          [ 0.2344, -0.5730, -0.1982,  ..., -0.2256, -0.1814,  0.3751],\n",
      "          [ 0.0703,  0.0774,  0.0042,  ..., -0.4692, -0.0437, -0.0823],\n",
      "          [ 0.1208, -0.5704, -0.6027,  ..., -0.4289, -0.3201,  0.2555]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1707, -0.4939,  0.5416,  ..., -0.9012,  0.5881,  0.0840],\n",
      "          [ 0.1305, -0.5193,  0.6034,  ..., -0.8266,  0.6215,  0.0964],\n",
      "          [ 0.0538, -0.4876,  0.6056,  ..., -0.6139,  0.5940,  0.0966],\n",
      "          ...,\n",
      "          [ 0.0939, -0.3398,  0.4031,  ..., -0.5265,  0.4581,  0.0629],\n",
      "          [ 0.0530, -0.4448,  0.5462,  ..., -0.5671,  0.5504,  0.0818],\n",
      "          [ 0.0993, -0.4791,  0.5327,  ..., -0.7380,  0.5557,  0.0800]],\n",
      "\n",
      "         [[-0.2845,  0.3096,  0.4212,  ..., -0.2476,  0.5432, -0.4068],\n",
      "          [-0.3583,  0.3338,  0.4542,  ..., -0.3006,  0.6112, -0.4539],\n",
      "          [-0.3914,  0.3348,  0.4526,  ..., -0.3360,  0.6265, -0.4692],\n",
      "          ...,\n",
      "          [-0.3686,  0.3380,  0.4505,  ..., -0.3159,  0.6158, -0.4601],\n",
      "          [-0.3619,  0.3318,  0.4357,  ..., -0.3169,  0.6015, -0.4475],\n",
      "          [-0.3111,  0.3096,  0.4254,  ..., -0.2763,  0.5728, -0.4083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1891, -0.2795,  0.4229,  ..., -0.5953,  0.6327,  0.0211],\n",
      "          [ 0.0833, -0.2003,  0.2813,  ..., -0.3658,  0.4600, -0.0160],\n",
      "          [ 0.0628, -0.2395,  0.3106,  ..., -0.4008,  0.5056, -0.0644],\n",
      "          ...,\n",
      "          [ 0.0146, -0.1465,  0.2873,  ..., -0.2363,  0.3850, -0.0681],\n",
      "          [-0.0206, -0.1609,  0.2987,  ..., -0.2339,  0.4594, -0.0745],\n",
      "          [ 0.1022, -0.2255,  0.2981,  ..., -0.4654,  0.4875,  0.0089]],\n",
      "\n",
      "         [[-0.0566,  0.0928,  0.2475,  ..., -0.1856,  0.2885, -0.1800],\n",
      "          [-0.0227,  0.1157,  0.2609,  ..., -0.3328,  0.2842, -0.1958],\n",
      "          [-0.0019,  0.1232,  0.2604,  ..., -0.3438,  0.2675, -0.1599],\n",
      "          ...,\n",
      "          [-0.0360,  0.1228,  0.2674,  ..., -0.3281,  0.2977, -0.2100],\n",
      "          [-0.0556,  0.1403,  0.1737,  ..., -0.2776,  0.2363, -0.2179],\n",
      "          [-0.0509,  0.1190,  0.2492,  ..., -0.2741,  0.2855, -0.1659]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.1707, -0.4939,  0.5416,  ..., -0.9012,  0.5881,  0.0840],\n",
      "          [-0.2845,  0.3096,  0.4212,  ..., -0.2476,  0.5432, -0.4068]],\n",
      "\n",
      "         [[ 0.1305, -0.5193,  0.6034,  ..., -0.8266,  0.6215,  0.0964],\n",
      "          [-0.3583,  0.3338,  0.4542,  ..., -0.3006,  0.6112, -0.4539]],\n",
      "\n",
      "         [[ 0.0538, -0.4876,  0.6056,  ..., -0.6139,  0.5940,  0.0966],\n",
      "          [-0.3914,  0.3348,  0.4526,  ..., -0.3360,  0.6265, -0.4692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0939, -0.3398,  0.4031,  ..., -0.5265,  0.4581,  0.0629],\n",
      "          [-0.3686,  0.3380,  0.4505,  ..., -0.3159,  0.6158, -0.4601]],\n",
      "\n",
      "         [[ 0.0530, -0.4448,  0.5462,  ..., -0.5671,  0.5504,  0.0818],\n",
      "          [-0.3619,  0.3318,  0.4357,  ..., -0.3169,  0.6015, -0.4475]],\n",
      "\n",
      "         [[ 0.0993, -0.4791,  0.5327,  ..., -0.7380,  0.5557,  0.0800],\n",
      "          [-0.3111,  0.3096,  0.4254,  ..., -0.2763,  0.5728, -0.4083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1891, -0.2795,  0.4229,  ..., -0.5953,  0.6327,  0.0211],\n",
      "          [-0.0566,  0.0928,  0.2475,  ..., -0.1856,  0.2885, -0.1800]],\n",
      "\n",
      "         [[ 0.0833, -0.2003,  0.2813,  ..., -0.3658,  0.4600, -0.0160],\n",
      "          [-0.0227,  0.1157,  0.2609,  ..., -0.3328,  0.2842, -0.1958]],\n",
      "\n",
      "         [[ 0.0628, -0.2395,  0.3106,  ..., -0.4008,  0.5056, -0.0644],\n",
      "          [-0.0019,  0.1232,  0.2604,  ..., -0.3438,  0.2675, -0.1599]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0146, -0.1465,  0.2873,  ..., -0.2363,  0.3850, -0.0681],\n",
      "          [-0.0360,  0.1228,  0.2674,  ..., -0.3281,  0.2977, -0.2100]],\n",
      "\n",
      "         [[-0.0206, -0.1609,  0.2987,  ..., -0.2339,  0.4594, -0.0745],\n",
      "          [-0.0556,  0.1403,  0.1737,  ..., -0.2776,  0.2363, -0.2179]],\n",
      "\n",
      "         [[ 0.1022, -0.2255,  0.2981,  ..., -0.4654,  0.4875,  0.0089],\n",
      "          [-0.0509,  0.1190,  0.2492,  ..., -0.2741,  0.2855, -0.1659]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1707, -0.4939,  0.5416,  ..., -0.9012,  0.5881,  0.0840],\n",
      "          [-0.2845,  0.3096,  0.4212,  ..., -0.2476,  0.5432, -0.4068]],\n",
      "\n",
      "         [[ 0.1305, -0.5193,  0.6034,  ..., -0.8266,  0.6215,  0.0964],\n",
      "          [-0.3583,  0.3338,  0.4542,  ..., -0.3006,  0.6112, -0.4539]],\n",
      "\n",
      "         [[ 0.0538, -0.4876,  0.6056,  ..., -0.6139,  0.5940,  0.0966],\n",
      "          [-0.3914,  0.3348,  0.4526,  ..., -0.3360,  0.6265, -0.4692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0939, -0.3398,  0.4031,  ..., -0.5265,  0.4581,  0.0629],\n",
      "          [-0.3686,  0.3380,  0.4505,  ..., -0.3159,  0.6158, -0.4601]],\n",
      "\n",
      "         [[ 0.0530, -0.4448,  0.5462,  ..., -0.5671,  0.5504,  0.0818],\n",
      "          [-0.3619,  0.3318,  0.4357,  ..., -0.3169,  0.6015, -0.4475]],\n",
      "\n",
      "         [[ 0.0993, -0.4791,  0.5327,  ..., -0.7380,  0.5557,  0.0800],\n",
      "          [-0.3111,  0.3096,  0.4254,  ..., -0.2763,  0.5728, -0.4083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1891, -0.2795,  0.4229,  ..., -0.5953,  0.6327,  0.0211],\n",
      "          [-0.0566,  0.0928,  0.2475,  ..., -0.1856,  0.2885, -0.1800]],\n",
      "\n",
      "         [[ 0.0833, -0.2003,  0.2813,  ..., -0.3658,  0.4600, -0.0160],\n",
      "          [-0.0227,  0.1157,  0.2609,  ..., -0.3328,  0.2842, -0.1958]],\n",
      "\n",
      "         [[ 0.0628, -0.2395,  0.3106,  ..., -0.4008,  0.5056, -0.0644],\n",
      "          [-0.0019,  0.1232,  0.2604,  ..., -0.3438,  0.2675, -0.1599]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0146, -0.1465,  0.2873,  ..., -0.2363,  0.3850, -0.0681],\n",
      "          [-0.0360,  0.1228,  0.2674,  ..., -0.3281,  0.2977, -0.2100]],\n",
      "\n",
      "         [[-0.0206, -0.1609,  0.2987,  ..., -0.2339,  0.4594, -0.0745],\n",
      "          [-0.0556,  0.1403,  0.1737,  ..., -0.2776,  0.2363, -0.2179]],\n",
      "\n",
      "         [[ 0.1022, -0.2255,  0.2981,  ..., -0.4654,  0.4875,  0.0089],\n",
      "          [-0.0509,  0.1190,  0.2492,  ..., -0.2741,  0.2855, -0.1659]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.1707, -0.4939,  0.5416,  ..., -0.9012,  0.5881,  0.0840],\n",
      "          [-0.2845,  0.3096,  0.4212,  ..., -0.2476,  0.5432, -0.4068]],\n",
      "\n",
      "         [[ 0.1305, -0.5193,  0.6034,  ..., -0.8266,  0.6215,  0.0964],\n",
      "          [-0.3583,  0.3338,  0.4542,  ..., -0.3006,  0.6112, -0.4539]],\n",
      "\n",
      "         [[ 0.0538, -0.4876,  0.6056,  ..., -0.6139,  0.5940,  0.0966],\n",
      "          [-0.3914,  0.3348,  0.4526,  ..., -0.3360,  0.6265, -0.4692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0939, -0.3398,  0.4031,  ..., -0.5265,  0.4581,  0.0629],\n",
      "          [-0.3686,  0.3380,  0.4505,  ..., -0.3159,  0.6158, -0.4601]],\n",
      "\n",
      "         [[ 0.0530, -0.4448,  0.5462,  ..., -0.5671,  0.5504,  0.0818],\n",
      "          [-0.3619,  0.3318,  0.4357,  ..., -0.3169,  0.6015, -0.4475]],\n",
      "\n",
      "         [[ 0.0993, -0.4791,  0.5327,  ..., -0.7380,  0.5557,  0.0800],\n",
      "          [-0.3111,  0.3096,  0.4254,  ..., -0.2763,  0.5728, -0.4083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1891, -0.2795,  0.4229,  ..., -0.5953,  0.6327,  0.0211],\n",
      "          [-0.0566,  0.0928,  0.2475,  ..., -0.1856,  0.2885, -0.1800]],\n",
      "\n",
      "         [[ 0.0833, -0.2003,  0.2813,  ..., -0.3658,  0.4600, -0.0160],\n",
      "          [-0.0227,  0.1157,  0.2609,  ..., -0.3328,  0.2842, -0.1958]],\n",
      "\n",
      "         [[ 0.0628, -0.2395,  0.3106,  ..., -0.4008,  0.5056, -0.0644],\n",
      "          [-0.0019,  0.1232,  0.2604,  ..., -0.3438,  0.2675, -0.1599]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0146, -0.1465,  0.2873,  ..., -0.2363,  0.3850, -0.0681],\n",
      "          [-0.0360,  0.1228,  0.2674,  ..., -0.3281,  0.2977, -0.2100]],\n",
      "\n",
      "         [[-0.0206, -0.1609,  0.2987,  ..., -0.2339,  0.4594, -0.0745],\n",
      "          [-0.0556,  0.1403,  0.1737,  ..., -0.2776,  0.2363, -0.2179]],\n",
      "\n",
      "         [[ 0.1022, -0.2255,  0.2981,  ..., -0.4654,  0.4875,  0.0089],\n",
      "          [-0.0509,  0.1190,  0.2492,  ..., -0.2741,  0.2855, -0.1659]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.5482,  1.5647],\n",
      "        [-1.4100,  1.3797]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:30:52,188] Trial 4 finished with value: 0.73336 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.495700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.7331, -2.4637,  1.8748,  ...,  1.2232,  1.1555,  1.3731],\n",
      "          [-0.0000,  0.9298, -0.1804,  ..., -0.3028,  1.3527, -0.0753]],\n",
      "\n",
      "         [[-0.0000, -2.0598,  0.0615,  ..., -0.8757, -0.3752,  1.1580],\n",
      "          [-1.7514,  0.1917,  0.9076,  ..., -0.2913,  2.4625,  0.1497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7303, -1.3097, -0.6641,  ..., -0.0206,  0.3124,  0.1645],\n",
      "          [-1.4204, -0.4070,  0.2543,  ..., -0.0000,  0.6541,  0.2638]],\n",
      "\n",
      "         [[-0.1358, -1.7595, -0.4449,  ..., -1.2140, -0.3486,  0.6561],\n",
      "          [-1.7978,  0.6604,  2.5934,  ...,  0.9461,  0.0981,  0.7728]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.1335,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  1.2283,  0.3543]],\n",
      "\n",
      "         [[-0.0000, -1.8766,  1.6415,  ...,  0.9656,  0.9748,  0.0000],\n",
      "          [-0.7861,  0.6104, -0.1239,  ...,  0.0000,  1.2571, -0.1641]],\n",
      "\n",
      "         [[ 0.1595, -0.2491,  0.7284,  ..., -0.3502,  0.1129,  0.7498],\n",
      "          [-0.1422,  2.2650,  2.7054,  ...,  0.3749,  0.5170,  0.3862]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3836, -1.9373, -0.1939,  ...,  0.5900,  0.8532,  0.8294],\n",
      "          [ 0.2171,  0.5327, -0.3087,  ...,  1.2320,  1.3440, -0.1931]],\n",
      "\n",
      "         [[-0.8656, -0.0000, -0.1454,  ..., -1.3088,  0.6492,  1.6979],\n",
      "          [-1.3321,  1.8219,  1.5485,  ..., -1.9086,  0.5914,  0.2311]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.0000,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.6958]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.7331, -2.4637,  1.8748,  ...,  1.2232,  1.1555,  1.3731],\n",
      "          [-0.0000,  0.9298, -0.1804,  ..., -0.3028,  1.3527, -0.0753]],\n",
      "\n",
      "         [[-0.0000, -2.0598,  0.0615,  ..., -0.8757, -0.3752,  1.1580],\n",
      "          [-1.7514,  0.1917,  0.9076,  ..., -0.2913,  2.4625,  0.1497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7303, -1.3097, -0.6641,  ..., -0.0206,  0.3124,  0.1645],\n",
      "          [-1.4204, -0.4070,  0.2543,  ..., -0.0000,  0.6541,  0.2638]],\n",
      "\n",
      "         [[-0.1358, -1.7595, -0.4449,  ..., -1.2140, -0.3486,  0.6561],\n",
      "          [-1.7978,  0.6604,  2.5934,  ...,  0.9461,  0.0981,  0.7728]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.1335,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  1.2283,  0.3543]],\n",
      "\n",
      "         [[-0.0000, -1.8766,  1.6415,  ...,  0.9656,  0.9748,  0.0000],\n",
      "          [-0.7861,  0.6104, -0.1239,  ...,  0.0000,  1.2571, -0.1641]],\n",
      "\n",
      "         [[ 0.1595, -0.2491,  0.7284,  ..., -0.3502,  0.1129,  0.7498],\n",
      "          [-0.1422,  2.2650,  2.7054,  ...,  0.3749,  0.5170,  0.3862]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3836, -1.9373, -0.1939,  ...,  0.5900,  0.8532,  0.8294],\n",
      "          [ 0.2171,  0.5327, -0.3087,  ...,  1.2320,  1.3440, -0.1931]],\n",
      "\n",
      "         [[-0.8656, -0.0000, -0.1454,  ..., -1.3088,  0.6492,  1.6979],\n",
      "          [-1.3321,  1.8219,  1.5485,  ..., -1.9086,  0.5914,  0.2311]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.0000,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.6958]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  0.0000,  0.0000],\n",
      "         [-0.7331, -2.4637,  1.8748,  ..., -0.3028,  1.3527, -0.0753],\n",
      "         [-0.0000, -2.0598,  0.0615,  ..., -0.2913,  2.4625,  0.1497],\n",
      "         ...,\n",
      "         [-0.7303, -1.3097, -0.6641,  ..., -0.0000,  0.6541,  0.2638],\n",
      "         [-0.1358, -1.7595, -0.4449,  ...,  0.9461,  0.0981,  0.7728],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.0000]],\n",
      "\n",
      "        [[ 0.8790, -1.8706, -0.4269,  ..., -0.3148,  1.2283,  0.3543],\n",
      "         [-0.0000, -1.8766,  1.6415,  ...,  0.0000,  1.2571, -0.1641],\n",
      "         [ 0.1595, -0.2491,  0.7284,  ...,  0.3749,  0.5170,  0.3862],\n",
      "         ...,\n",
      "         [-0.3836, -1.9373, -0.1939,  ...,  1.2320,  1.3440, -0.1931],\n",
      "         [-0.8656, -0.0000, -0.1454,  ..., -1.9086,  0.5914,  0.2311],\n",
      "         [ 0.8548, -2.7437,  1.1014,  ...,  1.7508,  0.0198, -0.6958]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.7331, -2.4637,  1.8748,  ...,  1.2232,  1.1555,  1.3731],\n",
      "          [-0.0000,  0.9298, -0.1804,  ..., -0.3028,  1.3527, -0.0753]],\n",
      "\n",
      "         [[-0.0000, -2.0598,  0.0615,  ..., -0.8757, -0.3752,  1.1580],\n",
      "          [-1.7514,  0.1917,  0.9076,  ..., -0.2913,  2.4625,  0.1497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7303, -1.3097, -0.6641,  ..., -0.0206,  0.3124,  0.1645],\n",
      "          [-1.4204, -0.4070,  0.2543,  ..., -0.0000,  0.6541,  0.2638]],\n",
      "\n",
      "         [[-0.1358, -1.7595, -0.4449,  ..., -1.2140, -0.3486,  0.6561],\n",
      "          [-1.7978,  0.6604,  2.5934,  ...,  0.9461,  0.0981,  0.7728]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.1335,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7800, -0.1617, -0.0570,  ..., -0.3148,  1.2283,  0.3543]],\n",
      "\n",
      "         [[-0.0000, -1.8766,  1.6415,  ...,  0.9656,  0.9748,  0.0000],\n",
      "          [-0.7861,  0.6104, -0.1239,  ...,  0.0000,  1.2571, -0.1641]],\n",
      "\n",
      "         [[ 0.1595, -0.2491,  0.7284,  ..., -0.3502,  0.1129,  0.7498],\n",
      "          [-0.1422,  2.2650,  2.7054,  ...,  0.3749,  0.5170,  0.3862]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3836, -1.9373, -0.1939,  ...,  0.5900,  0.8532,  0.8294],\n",
      "          [ 0.2171,  0.5327, -0.3087,  ...,  1.2320,  1.3440, -0.1931]],\n",
      "\n",
      "         [[-0.8656, -0.0000, -0.1454,  ..., -1.3088,  0.6492,  1.6979],\n",
      "          [-1.3321,  1.8219,  1.5485,  ..., -1.9086,  0.5914,  0.2311]],\n",
      "\n",
      "         [[ 0.8548, -2.7437,  1.1014,  ...,  0.0000,  0.0000,  0.0147],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.6958]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.7331, -2.4637,  1.8748,  ...,  1.2232,  1.1555,  1.3731],\n",
      "          [-0.0000, -2.0598,  0.0615,  ..., -0.8757, -0.3752,  1.1580],\n",
      "          ...,\n",
      "          [-0.7303, -1.3097, -0.6641,  ..., -0.0206,  0.3124,  0.1645],\n",
      "          [-0.1358, -1.7595, -0.4449,  ..., -1.2140, -0.3486,  0.6561],\n",
      "          [ 0.8548, -2.7437,  1.1014,  ...,  0.1335,  0.0000,  0.0147]],\n",
      "\n",
      "         [[-0.7800, -0.1617, -0.0570,  ..., -0.3148,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.9298, -0.1804,  ..., -0.3028,  1.3527, -0.0753],\n",
      "          [-1.7514,  0.1917,  0.9076,  ..., -0.2913,  2.4625,  0.1497],\n",
      "          ...,\n",
      "          [-1.4204, -0.4070,  0.2543,  ..., -0.0000,  0.6541,  0.2638],\n",
      "          [-1.7978,  0.6604,  2.5934,  ...,  0.9461,  0.0981,  0.7728],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8790, -1.8706, -0.4269,  ...,  0.7130,  0.4125,  1.1012],\n",
      "          [-0.0000, -1.8766,  1.6415,  ...,  0.9656,  0.9748,  0.0000],\n",
      "          [ 0.1595, -0.2491,  0.7284,  ..., -0.3502,  0.1129,  0.7498],\n",
      "          ...,\n",
      "          [-0.3836, -1.9373, -0.1939,  ...,  0.5900,  0.8532,  0.8294],\n",
      "          [-0.8656, -0.0000, -0.1454,  ..., -1.3088,  0.6492,  1.6979],\n",
      "          [ 0.8548, -2.7437,  1.1014,  ...,  0.0000,  0.0000,  0.0147]],\n",
      "\n",
      "         [[-0.7800, -0.1617, -0.0570,  ..., -0.3148,  1.2283,  0.3543],\n",
      "          [-0.7861,  0.6104, -0.1239,  ...,  0.0000,  1.2571, -0.1641],\n",
      "          [-0.1422,  2.2650,  2.7054,  ...,  0.3749,  0.5170,  0.3862],\n",
      "          ...,\n",
      "          [ 0.2171,  0.5327, -0.3087,  ...,  1.2320,  1.3440, -0.1931],\n",
      "          [-1.3321,  1.8219,  1.5485,  ..., -1.9086,  0.5914,  0.2311],\n",
      "          [ 0.4134,  1.4773, -0.4903,  ...,  1.7508,  0.0198, -0.6958]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.2242e-01, -2.0139e+00, -4.5370e-01,  ...,  7.7212e-01,\n",
      "            4.4151e-01,  1.1988e+00],\n",
      "          [-7.8250e-01, -2.6785e+00,  2.0033e+00,  ...,  1.3333e+00,\n",
      "            1.2472e+00,  1.5051e+00],\n",
      "          [ 1.5839e-03, -2.2428e+00,  4.2247e-02,  ..., -8.8307e-01,\n",
      "           -3.6841e-01,  1.2620e+00],\n",
      "          ...,\n",
      "          [-8.0678e-01, -1.4564e+00, -7.2475e-01,  ..., -2.2882e-02,\n",
      "            3.4492e-01,  2.0312e-01],\n",
      "          [-1.6157e-01, -1.9510e+00, -4.8936e-01,  ..., -1.3343e+00,\n",
      "           -3.7790e-01,  7.3652e-01],\n",
      "          [ 9.1029e-01, -2.9923e+00,  1.1940e+00,  ...,  1.4978e-01,\n",
      "            5.6299e-03,  3.9637e-02]],\n",
      "\n",
      "         [[-8.0522e-01, -1.4319e-01,  2.7334e-02,  ..., -2.6747e-01,\n",
      "            2.0020e-01, -4.2144e-02],\n",
      "          [-8.4791e-03,  1.0190e+00, -1.8896e-01,  ..., -3.1654e-01,\n",
      "            1.4877e+00, -8.3846e-02],\n",
      "          [-1.9245e+00,  2.0952e-01,  1.0002e+00,  ..., -3.1568e-01,\n",
      "            2.6964e+00,  1.6408e-01],\n",
      "          ...,\n",
      "          [-1.5442e+00, -4.3740e-01,  2.9428e-01,  ..., -1.8452e-03,\n",
      "            7.4338e-01,  2.8485e-01],\n",
      "          [-1.9447e+00,  7.0704e-01,  2.7803e+00,  ...,  1.0072e+00,\n",
      "            1.4016e-01,  8.1988e-01],\n",
      "          [ 4.5473e-01,  1.6336e+00, -5.4076e-01,  ...,  1.9342e+00,\n",
      "            2.5139e-02, -1.5801e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0261e-02, -3.5001e-02,  7.0530e-03,  ...,  1.2823e-02,\n",
      "            2.0882e-02,  1.9931e-02],\n",
      "          [ 4.1811e-03, -2.0749e+00,  1.7758e+00,  ...,  1.0561e+00,\n",
      "            1.0673e+00,  2.8663e-02],\n",
      "          [ 1.5617e-01, -3.2713e-01,  7.8903e-01,  ..., -3.7641e-01,\n",
      "            1.4401e-01,  8.4445e-01],\n",
      "          ...,\n",
      "          [-4.2212e-01, -2.1465e+00, -2.1655e-01,  ...,  6.5335e-01,\n",
      "            9.4165e-01,  9.2630e-01],\n",
      "          [-9.5023e-01, -1.9270e-02, -1.5660e-01,  ..., -1.4314e+00,\n",
      "            7.1881e-01,  1.8734e+00],\n",
      "          [ 9.1672e-01, -2.9866e+00,  1.1982e+00,  ...,  3.0073e-03,\n",
      "            1.6298e-02,  3.5095e-02]],\n",
      "\n",
      "         [[-7.8050e-01, -1.0207e-01, -3.5471e-02,  ..., -2.2927e-01,\n",
      "            1.2941e+00,  3.3258e-01],\n",
      "          [-8.6143e-01,  6.8006e-01, -1.2640e-01,  ...,  1.1204e-02,\n",
      "            1.3846e+00, -1.8020e-01],\n",
      "          [-1.6298e-01,  2.4992e+00,  2.9787e+00,  ...,  4.0940e-01,\n",
      "            5.7818e-01,  4.2377e-01],\n",
      "          ...,\n",
      "          [-1.2345e-02,  8.5228e-03,  7.8264e-03,  ...,  7.4177e-03,\n",
      "            2.6309e-02,  2.4206e-03],\n",
      "          [-1.4264e+00,  1.9618e+00,  1.6671e+00,  ..., -2.0207e+00,\n",
      "            6.5536e-01,  2.4580e-01],\n",
      "          [ 4.5364e-01,  1.6333e+00, -5.3769e-01,  ...,  1.9345e+00,\n",
      "            2.6635e-02, -7.6540e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.2242e-01, -2.0139e+00, -4.5370e-01,  ...,  7.7212e-01,\n",
      "            4.4151e-01,  1.1988e+00],\n",
      "          [-8.0522e-01, -1.4319e-01,  2.7334e-02,  ..., -2.6747e-01,\n",
      "            2.0020e-01, -4.2144e-02]],\n",
      "\n",
      "         [[-7.8250e-01, -2.6785e+00,  2.0033e+00,  ...,  1.3333e+00,\n",
      "            1.2472e+00,  1.5051e+00],\n",
      "          [-8.4791e-03,  1.0190e+00, -1.8896e-01,  ..., -3.1654e-01,\n",
      "            1.4877e+00, -8.3846e-02]],\n",
      "\n",
      "         [[ 1.5839e-03, -2.2428e+00,  4.2247e-02,  ..., -8.8307e-01,\n",
      "           -3.6841e-01,  1.2620e+00],\n",
      "          [-1.9245e+00,  2.0952e-01,  1.0002e+00,  ..., -3.1568e-01,\n",
      "            2.6964e+00,  1.6408e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0678e-01, -1.4564e+00, -7.2475e-01,  ..., -2.2882e-02,\n",
      "            3.4492e-01,  2.0312e-01],\n",
      "          [-1.5442e+00, -4.3740e-01,  2.9428e-01,  ..., -1.8452e-03,\n",
      "            7.4338e-01,  2.8485e-01]],\n",
      "\n",
      "         [[-1.6157e-01, -1.9510e+00, -4.8936e-01,  ..., -1.3343e+00,\n",
      "           -3.7790e-01,  7.3652e-01],\n",
      "          [-1.9447e+00,  7.0704e-01,  2.7803e+00,  ...,  1.0072e+00,\n",
      "            1.4016e-01,  8.1988e-01]],\n",
      "\n",
      "         [[ 9.1029e-01, -2.9923e+00,  1.1940e+00,  ...,  1.4978e-01,\n",
      "            5.6299e-03,  3.9637e-02],\n",
      "          [ 4.5473e-01,  1.6336e+00, -5.4076e-01,  ...,  1.9342e+00,\n",
      "            2.5139e-02, -1.5801e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0261e-02, -3.5001e-02,  7.0530e-03,  ...,  1.2823e-02,\n",
      "            2.0882e-02,  1.9931e-02],\n",
      "          [-7.8050e-01, -1.0207e-01, -3.5471e-02,  ..., -2.2927e-01,\n",
      "            1.2941e+00,  3.3258e-01]],\n",
      "\n",
      "         [[ 4.1811e-03, -2.0749e+00,  1.7758e+00,  ...,  1.0561e+00,\n",
      "            1.0673e+00,  2.8663e-02],\n",
      "          [-8.6143e-01,  6.8006e-01, -1.2640e-01,  ...,  1.1204e-02,\n",
      "            1.3846e+00, -1.8020e-01]],\n",
      "\n",
      "         [[ 1.5617e-01, -3.2713e-01,  7.8903e-01,  ..., -3.7641e-01,\n",
      "            1.4401e-01,  8.4445e-01],\n",
      "          [-1.6298e-01,  2.4992e+00,  2.9787e+00,  ...,  4.0940e-01,\n",
      "            5.7818e-01,  4.2377e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2212e-01, -2.1465e+00, -2.1655e-01,  ...,  6.5335e-01,\n",
      "            9.4165e-01,  9.2630e-01],\n",
      "          [-1.2345e-02,  8.5228e-03,  7.8264e-03,  ...,  7.4177e-03,\n",
      "            2.6309e-02,  2.4206e-03]],\n",
      "\n",
      "         [[-9.5023e-01, -1.9270e-02, -1.5660e-01,  ..., -1.4314e+00,\n",
      "            7.1881e-01,  1.8734e+00],\n",
      "          [-1.4264e+00,  1.9618e+00,  1.6671e+00,  ..., -2.0207e+00,\n",
      "            6.5536e-01,  2.4580e-01]],\n",
      "\n",
      "         [[ 9.1672e-01, -2.9866e+00,  1.1982e+00,  ...,  3.0073e-03,\n",
      "            1.6298e-02,  3.5095e-02],\n",
      "          [ 4.5364e-01,  1.6333e+00, -5.3769e-01,  ...,  1.9345e+00,\n",
      "            2.6635e-02, -7.6540e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.2242e-01, -2.0139e+00, -4.5370e-01,  ...,  7.7212e-01,\n",
      "            4.4151e-01,  1.1988e+00],\n",
      "          [-8.0522e-01, -1.4319e-01,  2.7334e-02,  ..., -2.6747e-01,\n",
      "            2.0020e-01, -4.2144e-02]],\n",
      "\n",
      "         [[-7.8250e-01, -2.6785e+00,  2.0033e+00,  ...,  1.3333e+00,\n",
      "            1.2472e+00,  1.5051e+00],\n",
      "          [-8.4791e-03,  1.0190e+00, -1.8896e-01,  ..., -3.1654e-01,\n",
      "            1.4877e+00, -8.3846e-02]],\n",
      "\n",
      "         [[ 1.5839e-03, -2.2428e+00,  4.2247e-02,  ..., -8.8307e-01,\n",
      "           -3.6841e-01,  1.2620e+00],\n",
      "          [-1.9245e+00,  2.0952e-01,  1.0002e+00,  ..., -3.1568e-01,\n",
      "            2.6964e+00,  1.6408e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0678e-01, -1.4564e+00, -7.2475e-01,  ..., -2.2882e-02,\n",
      "            3.4492e-01,  2.0312e-01],\n",
      "          [-1.5442e+00, -4.3740e-01,  2.9428e-01,  ..., -1.8452e-03,\n",
      "            7.4338e-01,  2.8485e-01]],\n",
      "\n",
      "         [[-1.6157e-01, -1.9510e+00, -4.8936e-01,  ..., -1.3343e+00,\n",
      "           -3.7790e-01,  7.3652e-01],\n",
      "          [-1.9447e+00,  7.0704e-01,  2.7803e+00,  ...,  1.0072e+00,\n",
      "            1.4016e-01,  8.1988e-01]],\n",
      "\n",
      "         [[ 9.1029e-01, -2.9923e+00,  1.1940e+00,  ...,  1.4978e-01,\n",
      "            5.6299e-03,  3.9637e-02],\n",
      "          [ 4.5473e-01,  1.6336e+00, -5.4076e-01,  ...,  1.9342e+00,\n",
      "            2.5139e-02, -1.5801e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0261e-02, -3.5001e-02,  7.0530e-03,  ...,  1.2823e-02,\n",
      "            2.0882e-02,  1.9931e-02],\n",
      "          [-7.8050e-01, -1.0207e-01, -3.5471e-02,  ..., -2.2927e-01,\n",
      "            1.2941e+00,  3.3258e-01]],\n",
      "\n",
      "         [[ 4.1811e-03, -2.0749e+00,  1.7758e+00,  ...,  1.0561e+00,\n",
      "            1.0673e+00,  2.8663e-02],\n",
      "          [-8.6143e-01,  6.8006e-01, -1.2640e-01,  ...,  1.1204e-02,\n",
      "            1.3846e+00, -1.8020e-01]],\n",
      "\n",
      "         [[ 1.5617e-01, -3.2713e-01,  7.8903e-01,  ..., -3.7641e-01,\n",
      "            1.4401e-01,  8.4445e-01],\n",
      "          [-1.6298e-01,  2.4992e+00,  2.9787e+00,  ...,  4.0940e-01,\n",
      "            5.7818e-01,  4.2377e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2212e-01, -2.1465e+00, -2.1655e-01,  ...,  6.5335e-01,\n",
      "            9.4165e-01,  9.2630e-01],\n",
      "          [-1.2345e-02,  8.5228e-03,  7.8264e-03,  ...,  7.4177e-03,\n",
      "            2.6309e-02,  2.4206e-03]],\n",
      "\n",
      "         [[-9.5023e-01, -1.9270e-02, -1.5660e-01,  ..., -1.4314e+00,\n",
      "            7.1881e-01,  1.8734e+00],\n",
      "          [-1.4264e+00,  1.9618e+00,  1.6671e+00,  ..., -2.0207e+00,\n",
      "            6.5536e-01,  2.4580e-01]],\n",
      "\n",
      "         [[ 9.1672e-01, -2.9866e+00,  1.1982e+00,  ...,  3.0073e-03,\n",
      "            1.6298e-02,  3.5095e-02],\n",
      "          [ 4.5364e-01,  1.6333e+00, -5.3769e-01,  ...,  1.9345e+00,\n",
      "            2.6635e-02, -7.6540e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.2242e-01, -2.0139e+00, -4.5370e-01,  ...,  7.7212e-01,\n",
      "            4.4151e-01,  1.1988e+00],\n",
      "          [-8.0522e-01, -1.4319e-01,  2.7334e-02,  ..., -2.6747e-01,\n",
      "            2.0020e-01, -4.2144e-02]],\n",
      "\n",
      "         [[-7.8250e-01, -2.6785e+00,  2.0033e+00,  ...,  1.3333e+00,\n",
      "            1.2472e+00,  1.5051e+00],\n",
      "          [-8.4791e-03,  1.0190e+00, -1.8896e-01,  ..., -3.1654e-01,\n",
      "            1.4877e+00, -8.3846e-02]],\n",
      "\n",
      "         [[ 1.5839e-03, -2.2428e+00,  4.2247e-02,  ..., -8.8307e-01,\n",
      "           -3.6841e-01,  1.2620e+00],\n",
      "          [-1.9245e+00,  2.0952e-01,  1.0002e+00,  ..., -3.1568e-01,\n",
      "            2.6964e+00,  1.6408e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0678e-01, -1.4564e+00, -7.2475e-01,  ..., -2.2882e-02,\n",
      "            3.4492e-01,  2.0312e-01],\n",
      "          [-1.5442e+00, -4.3740e-01,  2.9428e-01,  ..., -1.8452e-03,\n",
      "            7.4338e-01,  2.8485e-01]],\n",
      "\n",
      "         [[-1.6157e-01, -1.9510e+00, -4.8936e-01,  ..., -1.3343e+00,\n",
      "           -3.7790e-01,  7.3652e-01],\n",
      "          [-1.9447e+00,  7.0704e-01,  2.7803e+00,  ...,  1.0072e+00,\n",
      "            1.4016e-01,  8.1988e-01]],\n",
      "\n",
      "         [[ 9.1029e-01, -2.9923e+00,  1.1940e+00,  ...,  1.4978e-01,\n",
      "            5.6299e-03,  3.9637e-02],\n",
      "          [ 4.5473e-01,  1.6336e+00, -5.4076e-01,  ...,  1.9342e+00,\n",
      "            2.5139e-02, -1.5801e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0261e-02, -3.5001e-02,  7.0530e-03,  ...,  1.2823e-02,\n",
      "            2.0882e-02,  1.9931e-02],\n",
      "          [-7.8050e-01, -1.0207e-01, -3.5471e-02,  ..., -2.2927e-01,\n",
      "            1.2941e+00,  3.3258e-01]],\n",
      "\n",
      "         [[ 4.1811e-03, -2.0749e+00,  1.7758e+00,  ...,  1.0561e+00,\n",
      "            1.0673e+00,  2.8663e-02],\n",
      "          [-8.6143e-01,  6.8006e-01, -1.2640e-01,  ...,  1.1204e-02,\n",
      "            1.3846e+00, -1.8020e-01]],\n",
      "\n",
      "         [[ 1.5617e-01, -3.2713e-01,  7.8903e-01,  ..., -3.7641e-01,\n",
      "            1.4401e-01,  8.4445e-01],\n",
      "          [-1.6298e-01,  2.4992e+00,  2.9787e+00,  ...,  4.0940e-01,\n",
      "            5.7818e-01,  4.2377e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2212e-01, -2.1465e+00, -2.1655e-01,  ...,  6.5335e-01,\n",
      "            9.4165e-01,  9.2630e-01],\n",
      "          [-1.2345e-02,  8.5228e-03,  7.8264e-03,  ...,  7.4177e-03,\n",
      "            2.6309e-02,  2.4206e-03]],\n",
      "\n",
      "         [[-9.5023e-01, -1.9270e-02, -1.5660e-01,  ..., -1.4314e+00,\n",
      "            7.1881e-01,  1.8734e+00],\n",
      "          [-1.4264e+00,  1.9618e+00,  1.6671e+00,  ..., -2.0207e+00,\n",
      "            6.5536e-01,  2.4580e-01]],\n",
      "\n",
      "         [[ 9.1672e-01, -2.9866e+00,  1.1982e+00,  ...,  3.0073e-03,\n",
      "            1.6298e-02,  3.5095e-02],\n",
      "          [ 4.5364e-01,  1.6333e+00, -5.3769e-01,  ...,  1.9345e+00,\n",
      "            2.6635e-02, -7.6540e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 8.7234e-01, -1.5734e+00, -3.3166e-01,  ...,  4.4188e-01,\n",
      "            4.2054e-01,  9.5271e-01],\n",
      "          [-8.3173e-01, -2.8943e-01, -6.4335e-02,  ..., -2.5679e-01,\n",
      "            7.9408e-02, -7.9199e-02]],\n",
      "\n",
      "         [[-5.4591e-01, -2.1129e+00,  1.7419e+00,  ...,  9.7102e-01,\n",
      "            9.3675e-01,  1.2414e+00],\n",
      "          [ 4.0751e-02,  8.7864e-01, -1.1208e-01,  ...,  1.6205e-02,\n",
      "            1.0785e+00, -1.2161e-01]],\n",
      "\n",
      "         [[-4.5901e-02, -1.9816e+00, -4.1845e-02,  ..., -9.5595e-01,\n",
      "           -4.1276e-01,  1.0600e+00],\n",
      "          [-1.8058e+00, -5.1261e-02,  7.3045e-01,  ..., -3.5146e-01,\n",
      "            2.3246e+00, -1.7728e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9764e-01, -1.0980e+00, -5.6141e-01,  ..., -2.0774e-01,\n",
      "            1.2683e-01,  1.5204e-01],\n",
      "          [-1.4053e+00, -2.1619e-01,  1.9738e-01,  ...,  1.4874e-01,\n",
      "            4.6687e-01,  3.6291e-01]],\n",
      "\n",
      "         [[ 3.2067e-02, -1.6162e+00, -4.7247e-01,  ..., -1.5338e+00,\n",
      "           -4.5963e-01,  6.2109e-01],\n",
      "          [-1.7279e+00,  6.3850e-01,  2.5230e+00,  ...,  1.2743e+00,\n",
      "            3.6952e-02,  9.4895e-01]],\n",
      "\n",
      "         [[ 9.7084e-01, -2.4078e+00,  1.2241e+00,  ...,  6.0199e-02,\n",
      "           -2.2161e-02,  3.4494e-02],\n",
      "          [ 4.9033e-01,  7.9567e-01, -3.9754e-01,  ...,  2.0419e+00,\n",
      "           -4.2359e-02,  1.5961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0227e-01, -8.8102e-01, -1.8337e-01,  ...,  2.1425e-01,\n",
      "            3.1644e-01,  7.1539e-01],\n",
      "          [-1.0540e+00, -1.3412e-01, -1.2531e-01,  ..., -1.4208e-01,\n",
      "            1.6911e+00,  4.5433e-01]],\n",
      "\n",
      "         [[ 4.1070e-02, -1.7086e+00,  1.6102e+00,  ...,  9.7733e-01,\n",
      "            9.5534e-01,  3.5920e-02],\n",
      "          [-2.9071e-01,  5.2063e-01, -2.3693e-01,  ..., -7.2932e-03,\n",
      "            5.8384e-01, -2.2742e-01]],\n",
      "\n",
      "         [[ 8.8683e-02, -1.7028e-01,  7.6125e-01,  ..., -5.2627e-01,\n",
      "           -1.3190e-01,  6.9066e-01],\n",
      "          [ 3.9241e-03,  2.3914e+00,  2.6528e+00,  ...,  6.1438e-01,\n",
      "            3.4555e-01,  3.3741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0267e-01, -1.9503e+00, -6.3318e-02,  ...,  6.5491e-01,\n",
      "            7.6696e-01,  9.0689e-01],\n",
      "          [ 2.6133e-02,  2.9201e-01, -1.7943e-01,  ...,  9.5168e-01,\n",
      "            6.8265e-01,  2.3371e-01]],\n",
      "\n",
      "         [[-4.2432e-01,  9.1726e-02, -2.1610e-01,  ..., -1.4843e+00,\n",
      "            6.2023e-01,  1.6026e+00],\n",
      "          [-1.3685e+00,  5.2632e-01,  1.4037e+00,  ..., -1.9616e+00,\n",
      "            3.8774e-01,  1.5907e-02]],\n",
      "\n",
      "         [[ 9.7490e-01, -2.5399e+00,  1.1775e+00,  ..., -1.5004e-02,\n",
      "            1.8816e-03,  1.3427e-02],\n",
      "          [ 4.7616e-01,  1.6026e+00, -5.5579e-01,  ...,  9.1642e-01,\n",
      "           -6.8301e-02, -7.0688e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 8.7234e-01, -1.5734e+00, -3.3166e-01,  ...,  4.4188e-01,\n",
      "            4.2054e-01,  9.5271e-01],\n",
      "          [-8.3173e-01, -2.8943e-01, -6.4335e-02,  ..., -2.5679e-01,\n",
      "            7.9408e-02, -7.9199e-02]],\n",
      "\n",
      "         [[-5.4591e-01, -2.1129e+00,  1.7419e+00,  ...,  9.7102e-01,\n",
      "            9.3675e-01,  1.2414e+00],\n",
      "          [ 4.0751e-02,  8.7864e-01, -1.1208e-01,  ...,  1.6205e-02,\n",
      "            1.0785e+00, -1.2161e-01]],\n",
      "\n",
      "         [[-4.5901e-02, -1.9816e+00, -4.1845e-02,  ..., -9.5595e-01,\n",
      "           -4.1276e-01,  1.0600e+00],\n",
      "          [-1.8058e+00, -5.1261e-02,  7.3045e-01,  ..., -3.5146e-01,\n",
      "            2.3246e+00, -1.7728e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9764e-01, -1.0980e+00, -5.6141e-01,  ..., -2.0774e-01,\n",
      "            1.2683e-01,  1.5204e-01],\n",
      "          [-1.4053e+00, -2.1619e-01,  1.9738e-01,  ...,  1.4874e-01,\n",
      "            4.6687e-01,  3.6291e-01]],\n",
      "\n",
      "         [[ 3.2067e-02, -1.6162e+00, -4.7247e-01,  ..., -1.5338e+00,\n",
      "           -4.5963e-01,  6.2109e-01],\n",
      "          [-1.7279e+00,  6.3850e-01,  2.5230e+00,  ...,  1.2743e+00,\n",
      "            3.6952e-02,  9.4895e-01]],\n",
      "\n",
      "         [[ 9.7084e-01, -2.4078e+00,  1.2241e+00,  ...,  6.0199e-02,\n",
      "           -2.2161e-02,  3.4494e-02],\n",
      "          [ 4.9033e-01,  7.9567e-01, -3.9754e-01,  ...,  2.0419e+00,\n",
      "           -4.2359e-02,  1.5961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0227e-01, -8.8102e-01, -1.8337e-01,  ...,  2.1425e-01,\n",
      "            3.1644e-01,  7.1539e-01],\n",
      "          [-1.0540e+00, -1.3412e-01, -1.2531e-01,  ..., -1.4208e-01,\n",
      "            1.6911e+00,  4.5433e-01]],\n",
      "\n",
      "         [[ 4.1070e-02, -1.7086e+00,  1.6102e+00,  ...,  9.7733e-01,\n",
      "            9.5534e-01,  3.5920e-02],\n",
      "          [-2.9071e-01,  5.2063e-01, -2.3693e-01,  ..., -7.2932e-03,\n",
      "            5.8384e-01, -2.2742e-01]],\n",
      "\n",
      "         [[ 8.8683e-02, -1.7028e-01,  7.6125e-01,  ..., -5.2627e-01,\n",
      "           -1.3190e-01,  6.9066e-01],\n",
      "          [ 3.9241e-03,  2.3914e+00,  2.6528e+00,  ...,  6.1438e-01,\n",
      "            3.4555e-01,  3.3741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0267e-01, -1.9503e+00, -6.3318e-02,  ...,  6.5491e-01,\n",
      "            7.6696e-01,  9.0689e-01],\n",
      "          [ 2.6133e-02,  2.9201e-01, -1.7943e-01,  ...,  9.5168e-01,\n",
      "            6.8265e-01,  2.3371e-01]],\n",
      "\n",
      "         [[-4.2432e-01,  9.1726e-02, -2.1610e-01,  ..., -1.4843e+00,\n",
      "            6.2023e-01,  1.6026e+00],\n",
      "          [-1.3685e+00,  5.2632e-01,  1.4037e+00,  ..., -1.9616e+00,\n",
      "            3.8774e-01,  1.5907e-02]],\n",
      "\n",
      "         [[ 9.7490e-01, -2.5399e+00,  1.1775e+00,  ..., -1.5004e-02,\n",
      "            1.8816e-03,  1.3427e-02],\n",
      "          [ 4.7616e-01,  1.6026e+00, -5.5579e-01,  ...,  9.1642e-01,\n",
      "           -6.8301e-02, -7.0688e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.8723, -1.5734, -0.3317,  ..., -0.2568,  0.0794, -0.0792],\n",
      "         [-0.5459, -2.1129,  1.7419,  ...,  0.0162,  1.0785, -0.1216],\n",
      "         [-0.0459, -1.9816, -0.0418,  ..., -0.3515,  2.3246, -0.1773],\n",
      "         ...,\n",
      "         [-0.6976, -1.0980, -0.5614,  ...,  0.1487,  0.4669,  0.3629],\n",
      "         [ 0.0321, -1.6162, -0.4725,  ...,  1.2743,  0.0370,  0.9489],\n",
      "         [ 0.9708, -2.4078,  1.2241,  ...,  2.0419, -0.0424,  0.1596]],\n",
      "\n",
      "        [[ 0.6023, -0.8810, -0.1834,  ..., -0.1421,  1.6911,  0.4543],\n",
      "         [ 0.0411, -1.7086,  1.6102,  ..., -0.0073,  0.5838, -0.2274],\n",
      "         [ 0.0887, -0.1703,  0.7613,  ...,  0.6144,  0.3455,  0.3374],\n",
      "         ...,\n",
      "         [-0.3027, -1.9503, -0.0633,  ...,  0.9517,  0.6826,  0.2337],\n",
      "         [-0.4243,  0.0917, -0.2161,  ..., -1.9616,  0.3877,  0.0159],\n",
      "         [ 0.9749, -2.5399,  1.1775,  ...,  0.9164, -0.0683, -0.7069]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 8.7234e-01, -1.5734e+00, -3.3166e-01,  ...,  4.4188e-01,\n",
      "            4.2054e-01,  9.5271e-01],\n",
      "          [-8.3173e-01, -2.8943e-01, -6.4335e-02,  ..., -2.5679e-01,\n",
      "            7.9408e-02, -7.9199e-02]],\n",
      "\n",
      "         [[-5.4591e-01, -2.1129e+00,  1.7419e+00,  ...,  9.7102e-01,\n",
      "            9.3675e-01,  1.2414e+00],\n",
      "          [ 4.0751e-02,  8.7864e-01, -1.1208e-01,  ...,  1.6205e-02,\n",
      "            1.0785e+00, -1.2161e-01]],\n",
      "\n",
      "         [[-4.5901e-02, -1.9816e+00, -4.1845e-02,  ..., -9.5595e-01,\n",
      "           -4.1276e-01,  1.0600e+00],\n",
      "          [-1.8058e+00, -5.1261e-02,  7.3045e-01,  ..., -3.5146e-01,\n",
      "            2.3246e+00, -1.7728e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9764e-01, -1.0980e+00, -5.6141e-01,  ..., -2.0774e-01,\n",
      "            1.2683e-01,  1.5204e-01],\n",
      "          [-1.4053e+00, -2.1619e-01,  1.9738e-01,  ...,  1.4874e-01,\n",
      "            4.6687e-01,  3.6291e-01]],\n",
      "\n",
      "         [[ 3.2067e-02, -1.6162e+00, -4.7247e-01,  ..., -1.5338e+00,\n",
      "           -4.5963e-01,  6.2109e-01],\n",
      "          [-1.7279e+00,  6.3850e-01,  2.5230e+00,  ...,  1.2743e+00,\n",
      "            3.6952e-02,  9.4895e-01]],\n",
      "\n",
      "         [[ 9.7084e-01, -2.4078e+00,  1.2241e+00,  ...,  6.0199e-02,\n",
      "           -2.2161e-02,  3.4494e-02],\n",
      "          [ 4.9033e-01,  7.9567e-01, -3.9754e-01,  ...,  2.0419e+00,\n",
      "           -4.2359e-02,  1.5961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0227e-01, -8.8102e-01, -1.8337e-01,  ...,  2.1425e-01,\n",
      "            3.1644e-01,  7.1539e-01],\n",
      "          [-1.0540e+00, -1.3412e-01, -1.2531e-01,  ..., -1.4208e-01,\n",
      "            1.6911e+00,  4.5433e-01]],\n",
      "\n",
      "         [[ 4.1070e-02, -1.7086e+00,  1.6102e+00,  ...,  9.7733e-01,\n",
      "            9.5534e-01,  3.5920e-02],\n",
      "          [-2.9071e-01,  5.2063e-01, -2.3693e-01,  ..., -7.2932e-03,\n",
      "            5.8384e-01, -2.2742e-01]],\n",
      "\n",
      "         [[ 8.8683e-02, -1.7028e-01,  7.6125e-01,  ..., -5.2627e-01,\n",
      "           -1.3190e-01,  6.9066e-01],\n",
      "          [ 3.9241e-03,  2.3914e+00,  2.6528e+00,  ...,  6.1438e-01,\n",
      "            3.4555e-01,  3.3741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0267e-01, -1.9503e+00, -6.3318e-02,  ...,  6.5491e-01,\n",
      "            7.6696e-01,  9.0689e-01],\n",
      "          [ 2.6133e-02,  2.9201e-01, -1.7943e-01,  ...,  9.5168e-01,\n",
      "            6.8265e-01,  2.3371e-01]],\n",
      "\n",
      "         [[-4.2432e-01,  9.1726e-02, -2.1610e-01,  ..., -1.4843e+00,\n",
      "            6.2023e-01,  1.6026e+00],\n",
      "          [-1.3685e+00,  5.2632e-01,  1.4037e+00,  ..., -1.9616e+00,\n",
      "            3.8774e-01,  1.5907e-02]],\n",
      "\n",
      "         [[ 9.7490e-01, -2.5399e+00,  1.1775e+00,  ..., -1.5004e-02,\n",
      "            1.8816e-03,  1.3427e-02],\n",
      "          [ 4.7616e-01,  1.6026e+00, -5.5579e-01,  ...,  9.1642e-01,\n",
      "           -6.8301e-02, -7.0688e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 8.7234e-01, -1.5734e+00, -3.3166e-01,  ...,  4.4188e-01,\n",
      "            4.2054e-01,  9.5271e-01],\n",
      "          [-5.4591e-01, -2.1129e+00,  1.7419e+00,  ...,  9.7102e-01,\n",
      "            9.3675e-01,  1.2414e+00],\n",
      "          [-4.5901e-02, -1.9816e+00, -4.1845e-02,  ..., -9.5595e-01,\n",
      "           -4.1276e-01,  1.0600e+00],\n",
      "          ...,\n",
      "          [-6.9764e-01, -1.0980e+00, -5.6141e-01,  ..., -2.0774e-01,\n",
      "            1.2683e-01,  1.5204e-01],\n",
      "          [ 3.2067e-02, -1.6162e+00, -4.7247e-01,  ..., -1.5338e+00,\n",
      "           -4.5963e-01,  6.2109e-01],\n",
      "          [ 9.7084e-01, -2.4078e+00,  1.2241e+00,  ...,  6.0199e-02,\n",
      "           -2.2161e-02,  3.4494e-02]],\n",
      "\n",
      "         [[-8.3173e-01, -2.8943e-01, -6.4335e-02,  ..., -2.5679e-01,\n",
      "            7.9408e-02, -7.9199e-02],\n",
      "          [ 4.0751e-02,  8.7864e-01, -1.1208e-01,  ...,  1.6205e-02,\n",
      "            1.0785e+00, -1.2161e-01],\n",
      "          [-1.8058e+00, -5.1261e-02,  7.3045e-01,  ..., -3.5146e-01,\n",
      "            2.3246e+00, -1.7728e-01],\n",
      "          ...,\n",
      "          [-1.4053e+00, -2.1619e-01,  1.9738e-01,  ...,  1.4874e-01,\n",
      "            4.6687e-01,  3.6291e-01],\n",
      "          [-1.7279e+00,  6.3850e-01,  2.5230e+00,  ...,  1.2743e+00,\n",
      "            3.6952e-02,  9.4895e-01],\n",
      "          [ 4.9033e-01,  7.9567e-01, -3.9754e-01,  ...,  2.0419e+00,\n",
      "           -4.2359e-02,  1.5961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0227e-01, -8.8102e-01, -1.8337e-01,  ...,  2.1425e-01,\n",
      "            3.1644e-01,  7.1539e-01],\n",
      "          [ 4.1070e-02, -1.7086e+00,  1.6102e+00,  ...,  9.7733e-01,\n",
      "            9.5534e-01,  3.5920e-02],\n",
      "          [ 8.8683e-02, -1.7028e-01,  7.6125e-01,  ..., -5.2627e-01,\n",
      "           -1.3190e-01,  6.9066e-01],\n",
      "          ...,\n",
      "          [-3.0267e-01, -1.9503e+00, -6.3318e-02,  ...,  6.5491e-01,\n",
      "            7.6696e-01,  9.0689e-01],\n",
      "          [-4.2432e-01,  9.1726e-02, -2.1610e-01,  ..., -1.4843e+00,\n",
      "            6.2023e-01,  1.6026e+00],\n",
      "          [ 9.7490e-01, -2.5399e+00,  1.1775e+00,  ..., -1.5004e-02,\n",
      "            1.8816e-03,  1.3427e-02]],\n",
      "\n",
      "         [[-1.0540e+00, -1.3412e-01, -1.2531e-01,  ..., -1.4208e-01,\n",
      "            1.6911e+00,  4.5433e-01],\n",
      "          [-2.9071e-01,  5.2063e-01, -2.3693e-01,  ..., -7.2932e-03,\n",
      "            5.8384e-01, -2.2742e-01],\n",
      "          [ 3.9241e-03,  2.3914e+00,  2.6528e+00,  ...,  6.1438e-01,\n",
      "            3.4555e-01,  3.3741e-01],\n",
      "          ...,\n",
      "          [ 2.6133e-02,  2.9201e-01, -1.7943e-01,  ...,  9.5168e-01,\n",
      "            6.8265e-01,  2.3371e-01],\n",
      "          [-1.3685e+00,  5.2632e-01,  1.4037e+00,  ..., -1.9616e+00,\n",
      "            3.8774e-01,  1.5907e-02],\n",
      "          [ 4.7616e-01,  1.6026e+00, -5.5579e-01,  ...,  9.1642e-01,\n",
      "           -6.8301e-02, -7.0688e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.0617e-01, -1.7203e+00, -3.5681e-01,  ...,  4.7625e-01,\n",
      "            4.4960e-01,  1.0459e+00],\n",
      "          [-5.6193e-01, -2.2584e+00,  1.7766e+00,  ...,  1.0190e+00,\n",
      "            9.6951e-01,  1.3407e+00],\n",
      "          [-3.1557e-03, -1.0027e-01, -2.0066e-02,  ...,  2.0534e-02,\n",
      "            2.1895e-02,  6.0277e-02],\n",
      "          ...,\n",
      "          [-7.3692e-01, -1.2134e+00, -6.0209e-01,  ..., -2.2348e-01,\n",
      "            1.3714e-01,  1.8585e-01],\n",
      "          [ 2.3497e-02, -1.7783e+00, -5.1075e-01,  ..., -1.6595e+00,\n",
      "           -4.9296e-01,  6.9277e-01],\n",
      "          [ 9.4731e-01, -2.5586e+00,  1.2611e+00,  ...,  4.3857e-02,\n",
      "           -1.3193e-02,  1.1880e-01]],\n",
      "\n",
      "         [[-6.5872e-01, -3.8571e-01,  1.8057e-01,  ..., -1.1420e-01,\n",
      "            8.5438e-01, -2.7859e-01],\n",
      "          [ 3.5595e-02,  9.4353e-01, -1.0616e-01,  ...,  3.6916e-02,\n",
      "            1.2061e+00, -1.3820e-01],\n",
      "          [-1.9943e+00, -5.6243e-02,  8.0986e-01,  ..., -3.8291e-01,\n",
      "            2.5651e+00, -1.9394e-01],\n",
      "          ...,\n",
      "          [-1.4805e+00, -2.3495e-01,  2.5016e-01,  ...,  1.6015e-01,\n",
      "            5.9909e-01,  3.6268e-01],\n",
      "          [-1.8206e+00,  6.4959e-01,  2.6448e+00,  ...,  1.3310e+00,\n",
      "            1.3703e-01,  9.6274e-01],\n",
      "          [ 5.3849e-01,  8.8139e-01, -4.3722e-01,  ...,  2.2526e+00,\n",
      "           -3.6773e-02,  1.7439e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2692e-02, -1.2702e+00,  5.4152e-03,  ...,  2.1302e-01,\n",
      "            6.1424e-01,  8.7587e-01],\n",
      "          [ 4.2821e-02, -1.8738e+00,  1.7510e+00,  ...,  1.0594e+00,\n",
      "            1.0402e+00,  5.2099e-02],\n",
      "          [ 9.2841e-02, -2.2726e-01,  8.2537e-01,  ..., -5.8135e-01,\n",
      "           -1.1704e-01,  7.7203e-01],\n",
      "          ...,\n",
      "          [-3.3628e-01, -2.1667e+00, -7.0337e-02,  ...,  7.2749e-01,\n",
      "            8.5198e-01,  1.0077e+00],\n",
      "          [-4.6573e-01,  8.9766e-02, -2.3175e-01,  ..., -1.6303e+00,\n",
      "            6.8547e-01,  1.7647e+00],\n",
      "          [ 1.0414e+00, -2.7642e+00,  1.2785e+00,  ..., -1.1261e-02,\n",
      "            2.3544e-02,  3.5653e-02]],\n",
      "\n",
      "         [[-1.1676e+00, -1.4753e-01, -1.3710e-01,  ..., -1.5857e-01,\n",
      "            1.8721e+00,  5.0265e-01],\n",
      "          [-3.1284e-01,  5.8282e-01, -2.3644e-01,  ...,  3.3753e-02,\n",
      "            6.4960e-01, -2.6076e-01],\n",
      "          [-1.4862e-03,  2.6258e+00,  2.9117e+00,  ...,  6.7683e-01,\n",
      "            3.9060e-01,  3.6914e-01],\n",
      "          ...,\n",
      "          [-3.2379e-01,  4.7186e-01,  2.6747e-01,  ...,  7.2592e-01,\n",
      "            9.7953e-01,  1.6510e-01],\n",
      "          [-7.9298e-02,  8.0421e-04, -1.9421e-03,  ..., -9.5055e-04,\n",
      "            1.3835e-01,  2.2175e-02],\n",
      "          [ 5.2185e-01,  1.7691e+00, -6.0868e-01,  ...,  1.0178e+00,\n",
      "           -6.8394e-02, -7.7705e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.0617e-01, -1.7203e+00, -3.5681e-01,  ...,  4.7625e-01,\n",
      "            4.4960e-01,  1.0459e+00],\n",
      "          [-6.5872e-01, -3.8571e-01,  1.8057e-01,  ..., -1.1420e-01,\n",
      "            8.5438e-01, -2.7859e-01]],\n",
      "\n",
      "         [[-5.6193e-01, -2.2584e+00,  1.7766e+00,  ...,  1.0190e+00,\n",
      "            9.6951e-01,  1.3407e+00],\n",
      "          [ 3.5595e-02,  9.4353e-01, -1.0616e-01,  ...,  3.6916e-02,\n",
      "            1.2061e+00, -1.3820e-01]],\n",
      "\n",
      "         [[-3.1557e-03, -1.0027e-01, -2.0066e-02,  ...,  2.0534e-02,\n",
      "            2.1895e-02,  6.0277e-02],\n",
      "          [-1.9943e+00, -5.6243e-02,  8.0986e-01,  ..., -3.8291e-01,\n",
      "            2.5651e+00, -1.9394e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.3692e-01, -1.2134e+00, -6.0209e-01,  ..., -2.2348e-01,\n",
      "            1.3714e-01,  1.8585e-01],\n",
      "          [-1.4805e+00, -2.3495e-01,  2.5016e-01,  ...,  1.6015e-01,\n",
      "            5.9909e-01,  3.6268e-01]],\n",
      "\n",
      "         [[ 2.3497e-02, -1.7783e+00, -5.1075e-01,  ..., -1.6595e+00,\n",
      "           -4.9296e-01,  6.9277e-01],\n",
      "          [-1.8206e+00,  6.4959e-01,  2.6448e+00,  ...,  1.3310e+00,\n",
      "            1.3703e-01,  9.6274e-01]],\n",
      "\n",
      "         [[ 9.4731e-01, -2.5586e+00,  1.2611e+00,  ...,  4.3857e-02,\n",
      "           -1.3193e-02,  1.1880e-01],\n",
      "          [ 5.3849e-01,  8.8139e-01, -4.3722e-01,  ...,  2.2526e+00,\n",
      "           -3.6773e-02,  1.7439e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2692e-02, -1.2702e+00,  5.4152e-03,  ...,  2.1302e-01,\n",
      "            6.1424e-01,  8.7587e-01],\n",
      "          [-1.1676e+00, -1.4753e-01, -1.3710e-01,  ..., -1.5857e-01,\n",
      "            1.8721e+00,  5.0265e-01]],\n",
      "\n",
      "         [[ 4.2821e-02, -1.8738e+00,  1.7510e+00,  ...,  1.0594e+00,\n",
      "            1.0402e+00,  5.2099e-02],\n",
      "          [-3.1284e-01,  5.8282e-01, -2.3644e-01,  ...,  3.3753e-02,\n",
      "            6.4960e-01, -2.6076e-01]],\n",
      "\n",
      "         [[ 9.2841e-02, -2.2726e-01,  8.2537e-01,  ..., -5.8135e-01,\n",
      "           -1.1704e-01,  7.7203e-01],\n",
      "          [-1.4862e-03,  2.6258e+00,  2.9117e+00,  ...,  6.7683e-01,\n",
      "            3.9060e-01,  3.6914e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3628e-01, -2.1667e+00, -7.0337e-02,  ...,  7.2749e-01,\n",
      "            8.5198e-01,  1.0077e+00],\n",
      "          [-3.2379e-01,  4.7186e-01,  2.6747e-01,  ...,  7.2592e-01,\n",
      "            9.7953e-01,  1.6510e-01]],\n",
      "\n",
      "         [[-4.6573e-01,  8.9766e-02, -2.3175e-01,  ..., -1.6303e+00,\n",
      "            6.8547e-01,  1.7647e+00],\n",
      "          [-7.9298e-02,  8.0421e-04, -1.9421e-03,  ..., -9.5055e-04,\n",
      "            1.3835e-01,  2.2175e-02]],\n",
      "\n",
      "         [[ 1.0414e+00, -2.7642e+00,  1.2785e+00,  ..., -1.1261e-02,\n",
      "            2.3544e-02,  3.5653e-02],\n",
      "          [ 5.2185e-01,  1.7691e+00, -6.0868e-01,  ...,  1.0178e+00,\n",
      "           -6.8394e-02, -7.7705e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.0617e-01, -1.7203e+00, -3.5681e-01,  ...,  4.7625e-01,\n",
      "            4.4960e-01,  1.0459e+00],\n",
      "          [-6.5872e-01, -3.8571e-01,  1.8057e-01,  ..., -1.1420e-01,\n",
      "            8.5438e-01, -2.7859e-01]],\n",
      "\n",
      "         [[-5.6193e-01, -2.2584e+00,  1.7766e+00,  ...,  1.0190e+00,\n",
      "            9.6951e-01,  1.3407e+00],\n",
      "          [ 3.5595e-02,  9.4353e-01, -1.0616e-01,  ...,  3.6916e-02,\n",
      "            1.2061e+00, -1.3820e-01]],\n",
      "\n",
      "         [[-3.1557e-03, -1.0027e-01, -2.0066e-02,  ...,  2.0534e-02,\n",
      "            2.1895e-02,  6.0277e-02],\n",
      "          [-1.9943e+00, -5.6243e-02,  8.0986e-01,  ..., -3.8291e-01,\n",
      "            2.5651e+00, -1.9394e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.3692e-01, -1.2134e+00, -6.0209e-01,  ..., -2.2348e-01,\n",
      "            1.3714e-01,  1.8585e-01],\n",
      "          [-1.4805e+00, -2.3495e-01,  2.5016e-01,  ...,  1.6015e-01,\n",
      "            5.9909e-01,  3.6268e-01]],\n",
      "\n",
      "         [[ 2.3497e-02, -1.7783e+00, -5.1075e-01,  ..., -1.6595e+00,\n",
      "           -4.9296e-01,  6.9277e-01],\n",
      "          [-1.8206e+00,  6.4959e-01,  2.6448e+00,  ...,  1.3310e+00,\n",
      "            1.3703e-01,  9.6274e-01]],\n",
      "\n",
      "         [[ 9.4731e-01, -2.5586e+00,  1.2611e+00,  ...,  4.3857e-02,\n",
      "           -1.3193e-02,  1.1880e-01],\n",
      "          [ 5.3849e-01,  8.8139e-01, -4.3722e-01,  ...,  2.2526e+00,\n",
      "           -3.6773e-02,  1.7439e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2692e-02, -1.2702e+00,  5.4152e-03,  ...,  2.1302e-01,\n",
      "            6.1424e-01,  8.7587e-01],\n",
      "          [-1.1676e+00, -1.4753e-01, -1.3710e-01,  ..., -1.5857e-01,\n",
      "            1.8721e+00,  5.0265e-01]],\n",
      "\n",
      "         [[ 4.2821e-02, -1.8738e+00,  1.7510e+00,  ...,  1.0594e+00,\n",
      "            1.0402e+00,  5.2099e-02],\n",
      "          [-3.1284e-01,  5.8282e-01, -2.3644e-01,  ...,  3.3753e-02,\n",
      "            6.4960e-01, -2.6076e-01]],\n",
      "\n",
      "         [[ 9.2841e-02, -2.2726e-01,  8.2537e-01,  ..., -5.8135e-01,\n",
      "           -1.1704e-01,  7.7203e-01],\n",
      "          [-1.4862e-03,  2.6258e+00,  2.9117e+00,  ...,  6.7683e-01,\n",
      "            3.9060e-01,  3.6914e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3628e-01, -2.1667e+00, -7.0337e-02,  ...,  7.2749e-01,\n",
      "            8.5198e-01,  1.0077e+00],\n",
      "          [-3.2379e-01,  4.7186e-01,  2.6747e-01,  ...,  7.2592e-01,\n",
      "            9.7953e-01,  1.6510e-01]],\n",
      "\n",
      "         [[-4.6573e-01,  8.9766e-02, -2.3175e-01,  ..., -1.6303e+00,\n",
      "            6.8547e-01,  1.7647e+00],\n",
      "          [-7.9298e-02,  8.0421e-04, -1.9421e-03,  ..., -9.5055e-04,\n",
      "            1.3835e-01,  2.2175e-02]],\n",
      "\n",
      "         [[ 1.0414e+00, -2.7642e+00,  1.2785e+00,  ..., -1.1261e-02,\n",
      "            2.3544e-02,  3.5653e-02],\n",
      "          [ 5.2185e-01,  1.7691e+00, -6.0868e-01,  ...,  1.0178e+00,\n",
      "           -6.8394e-02, -7.7705e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.0617e-01, -1.7203e+00, -3.5681e-01,  ...,  4.7625e-01,\n",
      "            4.4960e-01,  1.0459e+00],\n",
      "          [-6.5872e-01, -3.8571e-01,  1.8057e-01,  ..., -1.1420e-01,\n",
      "            8.5438e-01, -2.7859e-01]],\n",
      "\n",
      "         [[-5.6193e-01, -2.2584e+00,  1.7766e+00,  ...,  1.0190e+00,\n",
      "            9.6951e-01,  1.3407e+00],\n",
      "          [ 3.5595e-02,  9.4353e-01, -1.0616e-01,  ...,  3.6916e-02,\n",
      "            1.2061e+00, -1.3820e-01]],\n",
      "\n",
      "         [[-3.1557e-03, -1.0027e-01, -2.0066e-02,  ...,  2.0534e-02,\n",
      "            2.1895e-02,  6.0277e-02],\n",
      "          [-1.9943e+00, -5.6243e-02,  8.0986e-01,  ..., -3.8291e-01,\n",
      "            2.5651e+00, -1.9394e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.3692e-01, -1.2134e+00, -6.0209e-01,  ..., -2.2348e-01,\n",
      "            1.3714e-01,  1.8585e-01],\n",
      "          [-1.4805e+00, -2.3495e-01,  2.5016e-01,  ...,  1.6015e-01,\n",
      "            5.9909e-01,  3.6268e-01]],\n",
      "\n",
      "         [[ 2.3497e-02, -1.7783e+00, -5.1075e-01,  ..., -1.6595e+00,\n",
      "           -4.9296e-01,  6.9277e-01],\n",
      "          [-1.8206e+00,  6.4959e-01,  2.6448e+00,  ...,  1.3310e+00,\n",
      "            1.3703e-01,  9.6274e-01]],\n",
      "\n",
      "         [[ 9.4731e-01, -2.5586e+00,  1.2611e+00,  ...,  4.3857e-02,\n",
      "           -1.3193e-02,  1.1880e-01],\n",
      "          [ 5.3849e-01,  8.8139e-01, -4.3722e-01,  ...,  2.2526e+00,\n",
      "           -3.6773e-02,  1.7439e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2692e-02, -1.2702e+00,  5.4152e-03,  ...,  2.1302e-01,\n",
      "            6.1424e-01,  8.7587e-01],\n",
      "          [-1.1676e+00, -1.4753e-01, -1.3710e-01,  ..., -1.5857e-01,\n",
      "            1.8721e+00,  5.0265e-01]],\n",
      "\n",
      "         [[ 4.2821e-02, -1.8738e+00,  1.7510e+00,  ...,  1.0594e+00,\n",
      "            1.0402e+00,  5.2099e-02],\n",
      "          [-3.1284e-01,  5.8282e-01, -2.3644e-01,  ...,  3.3753e-02,\n",
      "            6.4960e-01, -2.6076e-01]],\n",
      "\n",
      "         [[ 9.2841e-02, -2.2726e-01,  8.2537e-01,  ..., -5.8135e-01,\n",
      "           -1.1704e-01,  7.7203e-01],\n",
      "          [-1.4862e-03,  2.6258e+00,  2.9117e+00,  ...,  6.7683e-01,\n",
      "            3.9060e-01,  3.6914e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3628e-01, -2.1667e+00, -7.0337e-02,  ...,  7.2749e-01,\n",
      "            8.5198e-01,  1.0077e+00],\n",
      "          [-3.2379e-01,  4.7186e-01,  2.6747e-01,  ...,  7.2592e-01,\n",
      "            9.7953e-01,  1.6510e-01]],\n",
      "\n",
      "         [[-4.6573e-01,  8.9766e-02, -2.3175e-01,  ..., -1.6303e+00,\n",
      "            6.8547e-01,  1.7647e+00],\n",
      "          [-7.9298e-02,  8.0421e-04, -1.9421e-03,  ..., -9.5055e-04,\n",
      "            1.3835e-01,  2.2175e-02]],\n",
      "\n",
      "         [[ 1.0414e+00, -2.7642e+00,  1.2785e+00,  ..., -1.1261e-02,\n",
      "            2.3544e-02,  3.5653e-02],\n",
      "          [ 5.2185e-01,  1.7691e+00, -6.0868e-01,  ...,  1.0178e+00,\n",
      "           -6.8394e-02, -7.7705e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.1845,  0.3557],\n",
      "        [-0.1496,  0.3977]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:33:23,863] Trial 5 finished with value: 0.71276 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.457100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.3735, -0.4210,  0.4040,  ...,  0.1768,  0.3980,  0.0688],\n",
      "         [ 0.1918, -0.1831,  0.3101,  ...,  0.0644, -0.1249, -0.1850],\n",
      "         [-0.1008,  0.1998,  0.0353,  ...,  0.2601, -0.1002,  0.4631],\n",
      "         ...,\n",
      "         [ 0.4526,  0.0108,  0.4268,  ...,  0.3752,  0.2589,  0.1973],\n",
      "         [ 0.0234, -0.1075,  0.3073,  ..., -0.1786,  0.1953,  0.0490],\n",
      "         [ 0.2598, -0.7721,  0.5375,  ...,  0.0582,  0.6064, -0.3392]],\n",
      "\n",
      "        [[ 0.3296, -0.2746,  0.2805,  ...,  0.0852,  0.3948,  0.2260],\n",
      "         [ 0.4040, -0.4638,  0.7410,  ...,  0.5786,  0.8570, -0.5389],\n",
      "         [ 0.0930, -0.1328,  0.3595,  ...,  0.5435,  0.1326,  0.0026],\n",
      "         ...,\n",
      "         [ 0.2631, -0.1784,  0.2829,  ...,  0.4182,  0.1400, -0.0515],\n",
      "         [ 0.2716,  0.3118,  0.5164,  ...,  0.4486,  0.3133,  0.0555],\n",
      "         [ 0.2420, -0.6337,  0.5421,  ...,  0.2720,  0.6625, -0.4282]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3735, -0.4210,  0.4040,  ...,  0.1768,  0.3980,  0.0688],\n",
      "         [ 0.1918, -0.1831,  0.3101,  ...,  0.0644, -0.1249, -0.1850],\n",
      "         [-0.1008,  0.1998,  0.0353,  ...,  0.2601, -0.1002,  0.4631],\n",
      "         ...,\n",
      "         [ 0.4526,  0.0108,  0.4268,  ...,  0.3752,  0.2589,  0.1973],\n",
      "         [ 0.0234, -0.1075,  0.3073,  ..., -0.1786,  0.1953,  0.0490],\n",
      "         [ 0.2598, -0.7721,  0.5375,  ...,  0.0582,  0.6064, -0.3392]],\n",
      "\n",
      "        [[ 0.3296, -0.2746,  0.2805,  ...,  0.0852,  0.3948,  0.2260],\n",
      "         [ 0.4040, -0.4638,  0.7410,  ...,  0.5786,  0.8570, -0.5389],\n",
      "         [ 0.0930, -0.1328,  0.3595,  ...,  0.5435,  0.1326,  0.0026],\n",
      "         ...,\n",
      "         [ 0.2631, -0.1784,  0.2829,  ...,  0.4182,  0.1400, -0.0515],\n",
      "         [ 0.2716,  0.3118,  0.5164,  ...,  0.4486,  0.3133,  0.0555],\n",
      "         [ 0.2420, -0.6337,  0.5421,  ...,  0.2720,  0.6625, -0.4282]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3735, -0.4210,  0.4040,  ..., -0.0770,  0.2725, -0.3892],\n",
      "          [ 0.4760,  0.2380, -0.4949,  ...,  0.1768,  0.3980,  0.0688]],\n",
      "\n",
      "         [[ 0.1918, -0.1831,  0.3101,  ..., -0.0453,  0.0222, -0.1133],\n",
      "          [ 0.0885,  0.1404, -0.2052,  ...,  0.0644, -0.1249, -0.1850]],\n",
      "\n",
      "         [[-0.1008,  0.1998,  0.0353,  ..., -0.3982, -0.3504, -0.2466],\n",
      "          [-0.2772, -0.2799,  0.3082,  ...,  0.2601, -0.1002,  0.4631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4526,  0.0108,  0.4268,  ...,  0.1253, -0.0234, -0.3813],\n",
      "          [ 0.5106,  0.3022, -0.6782,  ...,  0.3752,  0.2589,  0.1973]],\n",
      "\n",
      "         [[ 0.0234, -0.1075,  0.3073,  ..., -0.2366,  0.0668, -0.2457],\n",
      "          [-0.2122,  0.1779, -0.0939,  ..., -0.1786,  0.1953,  0.0490]],\n",
      "\n",
      "         [[ 0.2598, -0.7721,  0.5375,  ...,  0.6563,  0.5386, -0.3275],\n",
      "          [ 0.5240,  0.3315, -0.5210,  ...,  0.0582,  0.6064, -0.3392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3296, -0.2746,  0.2805,  ..., -0.2666,  0.1867, -0.1613],\n",
      "          [ 0.2405,  0.1703, -0.3903,  ...,  0.0852,  0.3948,  0.2260]],\n",
      "\n",
      "         [[ 0.4040, -0.4638,  0.7410,  ...,  0.1477,  0.6651, -0.3604],\n",
      "          [ 0.3544,  0.5001, -0.7719,  ...,  0.5786,  0.8570, -0.5389]],\n",
      "\n",
      "         [[ 0.0930, -0.1328,  0.3595,  ...,  0.2485,  0.0380, -0.1650],\n",
      "          [ 0.3709, -0.2166, -0.4319,  ...,  0.5435,  0.1326,  0.0026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2631, -0.1784,  0.2829,  ..., -0.1220, -0.0024, -0.5811],\n",
      "          [ 0.5185, -0.0708, -0.2261,  ...,  0.4182,  0.1400, -0.0515]],\n",
      "\n",
      "         [[ 0.2716,  0.3118,  0.5164,  ..., -0.0996, -0.0233,  0.0316],\n",
      "          [ 0.1827,  0.1828, -0.2541,  ...,  0.4486,  0.3133,  0.0555]],\n",
      "\n",
      "         [[ 0.2420, -0.6337,  0.5421,  ...,  0.5677,  0.6274, -0.3087],\n",
      "          [ 0.3731,  0.1210, -0.3236,  ...,  0.2720,  0.6625, -0.4282]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0035, -0.2628, -0.2244,  ..., -0.2085, -0.2700, -0.0377],\n",
      "         [-0.3257, -0.7104, -0.4247,  ...,  0.2918,  0.7267, -0.2413],\n",
      "         [-0.9635, -0.4709, -0.7691,  ...,  0.8629,  0.1904, -0.1871],\n",
      "         ...,\n",
      "         [-0.2361, -0.3545, -0.6504,  ...,  0.2390,  0.2204, -0.1442],\n",
      "         [-0.2402, -0.1661, -0.3379,  ...,  0.3162,  0.0745, -0.7841],\n",
      "         [-0.1887, -0.2244, -0.5592,  ...,  0.3915, -0.0669, -0.3157]],\n",
      "\n",
      "        [[ 0.1589, -0.3927, -0.2144,  ..., -0.2843, -0.1961,  0.0603],\n",
      "         [-0.1583, -0.4875, -0.1793,  ...,  0.2721,  0.4062, -0.0600],\n",
      "         [-0.6017, -0.5625, -0.9561,  ...,  0.9812,  0.5276, -0.1962],\n",
      "         ...,\n",
      "         [-0.5182, -0.4277, -0.8478,  ...,  0.3634,  0.4600, -0.3476],\n",
      "         [ 0.0183,  0.1707, -0.0241,  ..., -0.2339, -0.0328, -0.1289],\n",
      "         [-0.5534, -0.1120, -0.5717,  ...,  0.5894,  0.1513, -0.4415]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0035, -0.2628, -0.2244,  ..., -0.2085, -0.2700, -0.0377],\n",
      "         [-0.3257, -0.7104, -0.4247,  ...,  0.2918,  0.7267, -0.2413],\n",
      "         [-0.9635, -0.4709, -0.7691,  ...,  0.8629,  0.1904, -0.1871],\n",
      "         ...,\n",
      "         [-0.2361, -0.3545, -0.6504,  ...,  0.2390,  0.2204, -0.1442],\n",
      "         [-0.2402, -0.1661, -0.3379,  ...,  0.3162,  0.0745, -0.7841],\n",
      "         [-0.1887, -0.2244, -0.5592,  ...,  0.3915, -0.0669, -0.3157]],\n",
      "\n",
      "        [[ 0.1589, -0.3927, -0.2144,  ..., -0.2843, -0.1961,  0.0603],\n",
      "         [-0.1583, -0.4875, -0.1793,  ...,  0.2721,  0.4062, -0.0600],\n",
      "         [-0.6017, -0.5625, -0.9561,  ...,  0.9812,  0.5276, -0.1962],\n",
      "         ...,\n",
      "         [-0.5182, -0.4277, -0.8478,  ...,  0.3634,  0.4600, -0.3476],\n",
      "         [ 0.0183,  0.1707, -0.0241,  ..., -0.2339, -0.0328, -0.1289],\n",
      "         [-0.5534, -0.1120, -0.5717,  ...,  0.5894,  0.1513, -0.4415]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0035, -0.2628, -0.2244,  ..., -0.0759, -0.0354,  0.2582],\n",
      "          [-0.0028,  0.0414,  0.1663,  ..., -0.2085, -0.2700, -0.0377]],\n",
      "\n",
      "         [[-0.3257, -0.7104, -0.4247,  ...,  0.0088, -0.2390, -0.4107],\n",
      "          [ 0.0307,  0.1799,  0.4683,  ...,  0.2918,  0.7267, -0.2413]],\n",
      "\n",
      "         [[-0.9635, -0.4709, -0.7691,  ..., -0.6302,  0.0479, -0.2596],\n",
      "          [-0.1574, -0.0167,  0.1947,  ...,  0.8629,  0.1904, -0.1871]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2361, -0.3545, -0.6504,  ..., -0.2475,  0.0456, -0.3229],\n",
      "          [-0.4701,  0.2872,  0.2363,  ...,  0.2390,  0.2204, -0.1442]],\n",
      "\n",
      "         [[-0.2402, -0.1661, -0.3379,  ..., -0.5511, -0.2187, -0.3511],\n",
      "          [-0.1219,  0.2677,  0.6477,  ...,  0.3162,  0.0745, -0.7841]],\n",
      "\n",
      "         [[-0.1887, -0.2244, -0.5592,  ..., -0.0759, -0.2233, -0.2432],\n",
      "          [-0.3315,  0.4866,  0.2641,  ...,  0.3915, -0.0669, -0.3157]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1589, -0.3927, -0.2144,  ..., -0.2214,  0.0124,  0.1140],\n",
      "          [ 0.0532,  0.1214, -0.1322,  ..., -0.2843, -0.1961,  0.0603]],\n",
      "\n",
      "         [[-0.1583, -0.4875, -0.1793,  ...,  0.0794,  0.3813, -0.2349],\n",
      "          [-0.1533,  0.0101,  0.6057,  ...,  0.2721,  0.4062, -0.0600]],\n",
      "\n",
      "         [[-0.6017, -0.5625, -0.9561,  ..., -0.4526, -0.0768, -0.4991],\n",
      "          [-0.2508,  0.5217,  0.8844,  ...,  0.9812,  0.5276, -0.1962]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5182, -0.4277, -0.8478,  ..., -0.1017,  0.0039, -0.2151],\n",
      "          [-0.1033,  0.2870,  0.1570,  ...,  0.3634,  0.4600, -0.3476]],\n",
      "\n",
      "         [[ 0.0183,  0.1707, -0.0241,  ..., -0.1284,  0.1819, -0.5569],\n",
      "          [-0.0373,  0.0892,  0.5653,  ..., -0.2339, -0.0328, -0.1289]],\n",
      "\n",
      "         [[-0.5534, -0.1120, -0.5717,  ..., -0.1392, -0.2539, -0.6351],\n",
      "          [-0.2944,  0.4148,  0.4095,  ...,  0.5894,  0.1513, -0.4415]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.9070,  1.3659, -0.8913,  ..., -0.7822, -0.5707,  0.4478],\n",
      "         [-0.3662,  0.3956, -0.4377,  ..., -0.8475, -0.2513, -0.1542],\n",
      "         [-0.1028,  0.3891, -0.2087,  ..., -0.0127, -0.5003, -0.2034],\n",
      "         ...,\n",
      "         [-0.3577,  0.8686, -0.5462,  ..., -0.1954, -0.3044,  0.0079],\n",
      "         [-0.4130,  0.9288, -0.5326,  ..., -0.3336, -0.2290,  0.3190],\n",
      "         [-0.6389,  0.5684, -0.2975,  ..., -0.3256, -0.1789, -0.0556]],\n",
      "\n",
      "        [[-0.8691,  1.3832, -0.9772,  ..., -0.4952, -0.7924,  0.4180],\n",
      "         [-0.4225,  0.5645, -0.6319,  ..., -0.5476, -0.3923,  0.1100],\n",
      "         [-0.2992,  0.4791, -0.5174,  ..., -0.4427, -0.4057,  0.2970],\n",
      "         ...,\n",
      "         [-0.5015,  0.8794, -0.5989,  ..., -0.3721, -0.2278,  0.1625],\n",
      "         [-0.3613,  0.8684, -0.5011,  ..., -0.1942,  0.0157,  0.3611],\n",
      "         [-0.5909,  0.6287, -0.2042,  ..., -0.4176, -0.1213, -0.0317]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.9070,  1.3659, -0.8913,  ..., -0.7822, -0.5707,  0.4478],\n",
      "         [-0.3662,  0.3956, -0.4377,  ..., -0.8475, -0.2513, -0.1542],\n",
      "         [-0.1028,  0.3891, -0.2087,  ..., -0.0127, -0.5003, -0.2034],\n",
      "         ...,\n",
      "         [-0.3577,  0.8686, -0.5462,  ..., -0.1954, -0.3044,  0.0079],\n",
      "         [-0.4130,  0.9288, -0.5326,  ..., -0.3336, -0.2290,  0.3190],\n",
      "         [-0.6389,  0.5684, -0.2975,  ..., -0.3256, -0.1789, -0.0556]],\n",
      "\n",
      "        [[-0.8691,  1.3832, -0.9772,  ..., -0.4952, -0.7924,  0.4180],\n",
      "         [-0.4225,  0.5645, -0.6319,  ..., -0.5476, -0.3923,  0.1100],\n",
      "         [-0.2992,  0.4791, -0.5174,  ..., -0.4427, -0.4057,  0.2970],\n",
      "         ...,\n",
      "         [-0.5015,  0.8794, -0.5989,  ..., -0.3721, -0.2278,  0.1625],\n",
      "         [-0.3613,  0.8684, -0.5011,  ..., -0.1942,  0.0157,  0.3611],\n",
      "         [-0.5909,  0.6287, -0.2042,  ..., -0.4176, -0.1213, -0.0317]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.9070,  1.3659, -0.8913,  ..., -0.9590, -1.6128,  0.7118],\n",
      "          [-1.0699, -0.5624,  1.2677,  ..., -0.7822, -0.5707,  0.4478]],\n",
      "\n",
      "         [[-0.3662,  0.3956, -0.4377,  ..., -0.0106, -0.3278,  0.0753],\n",
      "          [-0.0229, -0.3764,  0.4330,  ..., -0.8475, -0.2513, -0.1542]],\n",
      "\n",
      "         [[-0.1028,  0.3891, -0.2087,  ..., -0.0979, -0.5045,  0.0526],\n",
      "          [-0.1629, -0.1124,  0.1995,  ..., -0.0127, -0.5003, -0.2034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3577,  0.8686, -0.5462,  ..., -0.3648, -0.5563, -0.2651],\n",
      "          [ 0.0455, -0.4888,  0.6500,  ..., -0.1954, -0.3044,  0.0079]],\n",
      "\n",
      "         [[-0.4130,  0.9288, -0.5326,  ..., -0.2528, -0.6901,  0.1071],\n",
      "          [-0.4292, -0.1806,  0.6640,  ..., -0.3336, -0.2290,  0.3190]],\n",
      "\n",
      "         [[-0.6389,  0.5684, -0.2975,  ..., -0.3628, -0.5984,  0.1299],\n",
      "          [-0.4242, -0.3478,  0.1239,  ..., -0.3256, -0.1789, -0.0556]]],\n",
      "\n",
      "\n",
      "        [[[-0.8691,  1.3832, -0.9772,  ..., -0.8892, -1.5967,  0.5743],\n",
      "          [-1.2433, -0.4665,  1.2830,  ..., -0.4952, -0.7924,  0.4180]],\n",
      "\n",
      "         [[-0.4225,  0.5645, -0.6319,  ..., -0.3748, -1.0025, -0.1070],\n",
      "          [-0.0285, -0.4446,  0.6543,  ..., -0.5476, -0.3923,  0.1100]],\n",
      "\n",
      "         [[-0.2992,  0.4791, -0.5174,  ..., -0.3234, -0.7412,  0.2321],\n",
      "          [-0.0927, -0.3671,  0.4773,  ..., -0.4427, -0.4057,  0.2970]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5015,  0.8794, -0.5989,  ..., -0.6112, -0.6284,  0.0694],\n",
      "          [-0.2630, -0.4556,  0.6621,  ..., -0.3721, -0.2278,  0.1625]],\n",
      "\n",
      "         [[-0.3613,  0.8684, -0.5011,  ..., -0.4759, -0.6273,  0.2395],\n",
      "          [-0.3257,  0.0781,  0.8688,  ..., -0.1942,  0.0157,  0.3611]],\n",
      "\n",
      "         [[-0.5909,  0.6287, -0.2042,  ..., -0.4567, -0.6777,  0.1069],\n",
      "          [-0.4213, -0.5455,  0.0098,  ..., -0.4176, -0.1213, -0.0317]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3735, -0.4210,  0.4040,  ..., -0.0770,  0.2725, -0.3892],\n",
      "          [ 0.1918, -0.1831,  0.3101,  ..., -0.0453,  0.0222, -0.1133],\n",
      "          [-0.1008,  0.1998,  0.0353,  ..., -0.3982, -0.3504, -0.2466],\n",
      "          ...,\n",
      "          [ 0.4526,  0.0108,  0.4268,  ...,  0.1253, -0.0234, -0.3813],\n",
      "          [ 0.0234, -0.1075,  0.3073,  ..., -0.2366,  0.0668, -0.2457],\n",
      "          [ 0.2598, -0.7721,  0.5375,  ...,  0.6563,  0.5386, -0.3275]],\n",
      "\n",
      "         [[ 0.4760,  0.2380, -0.4949,  ...,  0.1768,  0.3980,  0.0688],\n",
      "          [ 0.0885,  0.1404, -0.2052,  ...,  0.0644, -0.1249, -0.1850],\n",
      "          [-0.2772, -0.2799,  0.3082,  ...,  0.2601, -0.1002,  0.4631],\n",
      "          ...,\n",
      "          [ 0.5106,  0.3022, -0.6782,  ...,  0.3752,  0.2589,  0.1973],\n",
      "          [-0.2122,  0.1779, -0.0939,  ..., -0.1786,  0.1953,  0.0490],\n",
      "          [ 0.5240,  0.3315, -0.5210,  ...,  0.0582,  0.6064, -0.3392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3296, -0.2746,  0.2805,  ..., -0.2666,  0.1867, -0.1613],\n",
      "          [ 0.4040, -0.4638,  0.7410,  ...,  0.1477,  0.6651, -0.3604],\n",
      "          [ 0.0930, -0.1328,  0.3595,  ...,  0.2485,  0.0380, -0.1650],\n",
      "          ...,\n",
      "          [ 0.2631, -0.1784,  0.2829,  ..., -0.1220, -0.0024, -0.5811],\n",
      "          [ 0.2716,  0.3118,  0.5164,  ..., -0.0996, -0.0233,  0.0316],\n",
      "          [ 0.2420, -0.6337,  0.5421,  ...,  0.5677,  0.6274, -0.3087]],\n",
      "\n",
      "         [[ 0.2405,  0.1703, -0.3903,  ...,  0.0852,  0.3948,  0.2260],\n",
      "          [ 0.3544,  0.5001, -0.7719,  ...,  0.5786,  0.8570, -0.5389],\n",
      "          [ 0.3709, -0.2166, -0.4319,  ...,  0.5435,  0.1326,  0.0026],\n",
      "          ...,\n",
      "          [ 0.5185, -0.0708, -0.2261,  ...,  0.4182,  0.1400, -0.0515],\n",
      "          [ 0.1827,  0.1828, -0.2541,  ...,  0.4486,  0.3133,  0.0555],\n",
      "          [ 0.3731,  0.1210, -0.3236,  ...,  0.2720,  0.6625, -0.4282]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-7.8075e-01, -4.2196e-01, -6.9236e-01,  ..., -5.2963e-01,\n",
      "            4.2670e-02, -2.7083e-01],\n",
      "          [-4.4599e-01, -3.9295e-01, -5.2627e-01,  ..., -2.6185e-01,\n",
      "            3.3195e-02, -2.1902e-01],\n",
      "          [-5.1113e-01, -4.3293e-01, -5.5804e-01,  ..., -2.9245e-01,\n",
      "            3.2151e-02, -2.2165e-01],\n",
      "          ...,\n",
      "          [-5.7123e-01, -4.2983e-01, -5.9032e-01,  ..., -3.5714e-01,\n",
      "            3.1953e-02, -2.4402e-01],\n",
      "          [-6.2570e-01, -3.9519e-01, -6.1224e-01,  ..., -4.1958e-01,\n",
      "            4.8549e-02, -2.3887e-01],\n",
      "          [-1.6541e-01, -2.3739e-01, -2.1625e-01,  ..., -5.8075e-02,\n",
      "            3.9980e-02, -8.0956e-02]],\n",
      "\n",
      "         [[-1.1235e-01,  8.3472e-02,  4.0137e-01,  ...,  7.1411e-01,\n",
      "            2.5198e-01, -3.3684e-01],\n",
      "          [-1.0800e-01,  1.6967e-01,  4.4085e-01,  ...,  4.7185e-01,\n",
      "            2.2561e-01, -3.2742e-01],\n",
      "          [-8.1635e-02,  1.0045e-01,  3.6178e-01,  ...,  3.9375e-01,\n",
      "            1.8727e-01, -2.5889e-01],\n",
      "          ...,\n",
      "          [-1.0343e-01,  1.4048e-01,  4.1943e-01,  ...,  5.3099e-01,\n",
      "            2.4912e-01, -3.2533e-01],\n",
      "          [-9.3498e-02,  9.3045e-02,  3.9008e-01,  ...,  5.5060e-01,\n",
      "            2.2836e-01, -3.0628e-01],\n",
      "          [-6.8274e-02,  1.1227e-01,  3.6920e-01,  ...,  4.5226e-01,\n",
      "            1.3626e-01, -2.9294e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8145e-02,  8.6569e-02,  1.3938e-01,  ...,  4.7158e-01,\n",
      "            6.6596e-01, -8.7621e-02],\n",
      "          [-8.5854e-02, -7.2906e-02, -1.0905e-01,  ...,  2.0016e-01,\n",
      "            4.1703e-01, -1.4435e-01],\n",
      "          [-1.2138e-01, -1.1168e-01, -1.6597e-01,  ...,  1.4047e-01,\n",
      "            3.6159e-01, -1.6036e-01],\n",
      "          ...,\n",
      "          [-5.6706e-02, -6.3146e-02, -7.7259e-02,  ...,  2.4851e-01,\n",
      "            3.4565e-01, -1.3071e-02],\n",
      "          [-8.4790e-02, -6.8999e-02, -1.0569e-01,  ...,  2.0058e-01,\n",
      "            4.1633e-01, -1.4532e-01],\n",
      "          [-5.9855e-02, -6.2354e-02, -6.8153e-02,  ...,  1.4989e-01,\n",
      "            3.6364e-01, -1.4130e-01]],\n",
      "\n",
      "         [[ 8.3778e-02, -3.0270e-01, -3.4114e-02,  ..., -2.8533e-01,\n",
      "           -2.9306e-01,  3.7310e-01],\n",
      "          [ 3.4505e-02, -6.1420e-02,  1.9213e-01,  ..., -9.3601e-02,\n",
      "           -8.2708e-02,  1.1783e-01],\n",
      "          [ 1.0044e-02,  1.9443e-04,  1.7966e-01,  ..., -6.2006e-02,\n",
      "           -2.7840e-02,  6.1216e-02],\n",
      "          ...,\n",
      "          [ 5.6779e-02, -1.3569e-01,  6.8910e-02,  ..., -1.3159e-01,\n",
      "           -1.4228e-01,  2.0033e-01],\n",
      "          [ 2.4894e-02, -7.0347e-02,  2.0148e-01,  ..., -5.1093e-02,\n",
      "           -3.9231e-02,  9.9235e-02],\n",
      "          [-1.0180e-03,  1.5765e-01,  2.5707e-01,  ...,  8.9029e-02,\n",
      "            1.0346e-01, -1.2141e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-7.8075e-01, -4.2196e-01, -6.9236e-01,  ..., -5.2963e-01,\n",
      "            4.2670e-02, -2.7083e-01],\n",
      "          [-1.1235e-01,  8.3472e-02,  4.0137e-01,  ...,  7.1411e-01,\n",
      "            2.5198e-01, -3.3684e-01]],\n",
      "\n",
      "         [[-4.4599e-01, -3.9295e-01, -5.2627e-01,  ..., -2.6185e-01,\n",
      "            3.3195e-02, -2.1902e-01],\n",
      "          [-1.0800e-01,  1.6967e-01,  4.4085e-01,  ...,  4.7185e-01,\n",
      "            2.2561e-01, -3.2742e-01]],\n",
      "\n",
      "         [[-5.1113e-01, -4.3293e-01, -5.5804e-01,  ..., -2.9245e-01,\n",
      "            3.2151e-02, -2.2165e-01],\n",
      "          [-8.1635e-02,  1.0045e-01,  3.6178e-01,  ...,  3.9375e-01,\n",
      "            1.8727e-01, -2.5889e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7123e-01, -4.2983e-01, -5.9032e-01,  ..., -3.5714e-01,\n",
      "            3.1953e-02, -2.4402e-01],\n",
      "          [-1.0343e-01,  1.4048e-01,  4.1943e-01,  ...,  5.3099e-01,\n",
      "            2.4912e-01, -3.2533e-01]],\n",
      "\n",
      "         [[-6.2570e-01, -3.9519e-01, -6.1224e-01,  ..., -4.1958e-01,\n",
      "            4.8549e-02, -2.3887e-01],\n",
      "          [-9.3498e-02,  9.3045e-02,  3.9008e-01,  ...,  5.5060e-01,\n",
      "            2.2836e-01, -3.0628e-01]],\n",
      "\n",
      "         [[-1.6541e-01, -2.3739e-01, -2.1625e-01,  ..., -5.8075e-02,\n",
      "            3.9980e-02, -8.0956e-02],\n",
      "          [-6.8274e-02,  1.1227e-01,  3.6920e-01,  ...,  4.5226e-01,\n",
      "            1.3626e-01, -2.9294e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8145e-02,  8.6569e-02,  1.3938e-01,  ...,  4.7158e-01,\n",
      "            6.6596e-01, -8.7621e-02],\n",
      "          [ 8.3778e-02, -3.0270e-01, -3.4114e-02,  ..., -2.8533e-01,\n",
      "           -2.9306e-01,  3.7310e-01]],\n",
      "\n",
      "         [[-8.5854e-02, -7.2906e-02, -1.0905e-01,  ...,  2.0016e-01,\n",
      "            4.1703e-01, -1.4435e-01],\n",
      "          [ 3.4505e-02, -6.1420e-02,  1.9213e-01,  ..., -9.3601e-02,\n",
      "           -8.2708e-02,  1.1783e-01]],\n",
      "\n",
      "         [[-1.2138e-01, -1.1168e-01, -1.6597e-01,  ...,  1.4047e-01,\n",
      "            3.6159e-01, -1.6036e-01],\n",
      "          [ 1.0044e-02,  1.9443e-04,  1.7966e-01,  ..., -6.2006e-02,\n",
      "           -2.7840e-02,  6.1216e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6706e-02, -6.3146e-02, -7.7259e-02,  ...,  2.4851e-01,\n",
      "            3.4565e-01, -1.3071e-02],\n",
      "          [ 5.6779e-02, -1.3569e-01,  6.8910e-02,  ..., -1.3159e-01,\n",
      "           -1.4228e-01,  2.0033e-01]],\n",
      "\n",
      "         [[-8.4790e-02, -6.8999e-02, -1.0569e-01,  ...,  2.0058e-01,\n",
      "            4.1633e-01, -1.4532e-01],\n",
      "          [ 2.4894e-02, -7.0347e-02,  2.0148e-01,  ..., -5.1093e-02,\n",
      "           -3.9231e-02,  9.9235e-02]],\n",
      "\n",
      "         [[-5.9855e-02, -6.2354e-02, -6.8153e-02,  ...,  1.4989e-01,\n",
      "            3.6364e-01, -1.4130e-01],\n",
      "          [-1.0180e-03,  1.5765e-01,  2.5707e-01,  ...,  8.9029e-02,\n",
      "            1.0346e-01, -1.2141e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-7.8075e-01, -4.2196e-01, -6.9236e-01,  ..., -5.2963e-01,\n",
      "            4.2670e-02, -2.7083e-01],\n",
      "          [-1.1235e-01,  8.3472e-02,  4.0137e-01,  ...,  7.1411e-01,\n",
      "            2.5198e-01, -3.3684e-01]],\n",
      "\n",
      "         [[-4.4599e-01, -3.9295e-01, -5.2627e-01,  ..., -2.6185e-01,\n",
      "            3.3195e-02, -2.1902e-01],\n",
      "          [-1.0800e-01,  1.6967e-01,  4.4085e-01,  ...,  4.7185e-01,\n",
      "            2.2561e-01, -3.2742e-01]],\n",
      "\n",
      "         [[-5.1113e-01, -4.3293e-01, -5.5804e-01,  ..., -2.9245e-01,\n",
      "            3.2151e-02, -2.2165e-01],\n",
      "          [-8.1635e-02,  1.0045e-01,  3.6178e-01,  ...,  3.9375e-01,\n",
      "            1.8727e-01, -2.5889e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7123e-01, -4.2983e-01, -5.9032e-01,  ..., -3.5714e-01,\n",
      "            3.1953e-02, -2.4402e-01],\n",
      "          [-1.0343e-01,  1.4048e-01,  4.1943e-01,  ...,  5.3099e-01,\n",
      "            2.4912e-01, -3.2533e-01]],\n",
      "\n",
      "         [[-6.2570e-01, -3.9519e-01, -6.1224e-01,  ..., -4.1958e-01,\n",
      "            4.8549e-02, -2.3887e-01],\n",
      "          [-9.3498e-02,  9.3045e-02,  3.9008e-01,  ...,  5.5060e-01,\n",
      "            2.2836e-01, -3.0628e-01]],\n",
      "\n",
      "         [[-1.6541e-01, -2.3739e-01, -2.1625e-01,  ..., -5.8075e-02,\n",
      "            3.9980e-02, -8.0956e-02],\n",
      "          [-6.8274e-02,  1.1227e-01,  3.6920e-01,  ...,  4.5226e-01,\n",
      "            1.3626e-01, -2.9294e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8145e-02,  8.6569e-02,  1.3938e-01,  ...,  4.7158e-01,\n",
      "            6.6596e-01, -8.7621e-02],\n",
      "          [ 8.3778e-02, -3.0270e-01, -3.4114e-02,  ..., -2.8533e-01,\n",
      "           -2.9306e-01,  3.7310e-01]],\n",
      "\n",
      "         [[-8.5854e-02, -7.2906e-02, -1.0905e-01,  ...,  2.0016e-01,\n",
      "            4.1703e-01, -1.4435e-01],\n",
      "          [ 3.4505e-02, -6.1420e-02,  1.9213e-01,  ..., -9.3601e-02,\n",
      "           -8.2708e-02,  1.1783e-01]],\n",
      "\n",
      "         [[-1.2138e-01, -1.1168e-01, -1.6597e-01,  ...,  1.4047e-01,\n",
      "            3.6159e-01, -1.6036e-01],\n",
      "          [ 1.0044e-02,  1.9443e-04,  1.7966e-01,  ..., -6.2006e-02,\n",
      "           -2.7840e-02,  6.1216e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6706e-02, -6.3146e-02, -7.7259e-02,  ...,  2.4851e-01,\n",
      "            3.4565e-01, -1.3071e-02],\n",
      "          [ 5.6779e-02, -1.3569e-01,  6.8910e-02,  ..., -1.3159e-01,\n",
      "           -1.4228e-01,  2.0033e-01]],\n",
      "\n",
      "         [[-8.4790e-02, -6.8999e-02, -1.0569e-01,  ...,  2.0058e-01,\n",
      "            4.1633e-01, -1.4532e-01],\n",
      "          [ 2.4894e-02, -7.0347e-02,  2.0148e-01,  ..., -5.1093e-02,\n",
      "           -3.9231e-02,  9.9235e-02]],\n",
      "\n",
      "         [[-5.9855e-02, -6.2354e-02, -6.8153e-02,  ...,  1.4989e-01,\n",
      "            3.6364e-01, -1.4130e-01],\n",
      "          [-1.0180e-03,  1.5765e-01,  2.5707e-01,  ...,  8.9029e-02,\n",
      "            1.0346e-01, -1.2141e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-7.8075e-01, -4.2196e-01, -6.9236e-01,  ..., -5.2963e-01,\n",
      "            4.2670e-02, -2.7083e-01],\n",
      "          [-1.1235e-01,  8.3472e-02,  4.0137e-01,  ...,  7.1411e-01,\n",
      "            2.5198e-01, -3.3684e-01]],\n",
      "\n",
      "         [[-4.4599e-01, -3.9295e-01, -5.2627e-01,  ..., -2.6185e-01,\n",
      "            3.3195e-02, -2.1902e-01],\n",
      "          [-1.0800e-01,  1.6967e-01,  4.4085e-01,  ...,  4.7185e-01,\n",
      "            2.2561e-01, -3.2742e-01]],\n",
      "\n",
      "         [[-5.1113e-01, -4.3293e-01, -5.5804e-01,  ..., -2.9245e-01,\n",
      "            3.2151e-02, -2.2165e-01],\n",
      "          [-8.1635e-02,  1.0045e-01,  3.6178e-01,  ...,  3.9375e-01,\n",
      "            1.8727e-01, -2.5889e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7123e-01, -4.2983e-01, -5.9032e-01,  ..., -3.5714e-01,\n",
      "            3.1953e-02, -2.4402e-01],\n",
      "          [-1.0343e-01,  1.4048e-01,  4.1943e-01,  ...,  5.3099e-01,\n",
      "            2.4912e-01, -3.2533e-01]],\n",
      "\n",
      "         [[-6.2570e-01, -3.9519e-01, -6.1224e-01,  ..., -4.1958e-01,\n",
      "            4.8549e-02, -2.3887e-01],\n",
      "          [-9.3498e-02,  9.3045e-02,  3.9008e-01,  ...,  5.5060e-01,\n",
      "            2.2836e-01, -3.0628e-01]],\n",
      "\n",
      "         [[-1.6541e-01, -2.3739e-01, -2.1625e-01,  ..., -5.8075e-02,\n",
      "            3.9980e-02, -8.0956e-02],\n",
      "          [-6.8274e-02,  1.1227e-01,  3.6920e-01,  ...,  4.5226e-01,\n",
      "            1.3626e-01, -2.9294e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8145e-02,  8.6569e-02,  1.3938e-01,  ...,  4.7158e-01,\n",
      "            6.6596e-01, -8.7621e-02],\n",
      "          [ 8.3778e-02, -3.0270e-01, -3.4114e-02,  ..., -2.8533e-01,\n",
      "           -2.9306e-01,  3.7310e-01]],\n",
      "\n",
      "         [[-8.5854e-02, -7.2906e-02, -1.0905e-01,  ...,  2.0016e-01,\n",
      "            4.1703e-01, -1.4435e-01],\n",
      "          [ 3.4505e-02, -6.1420e-02,  1.9213e-01,  ..., -9.3601e-02,\n",
      "           -8.2708e-02,  1.1783e-01]],\n",
      "\n",
      "         [[-1.2138e-01, -1.1168e-01, -1.6597e-01,  ...,  1.4047e-01,\n",
      "            3.6159e-01, -1.6036e-01],\n",
      "          [ 1.0044e-02,  1.9443e-04,  1.7966e-01,  ..., -6.2006e-02,\n",
      "           -2.7840e-02,  6.1216e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6706e-02, -6.3146e-02, -7.7259e-02,  ...,  2.4851e-01,\n",
      "            3.4565e-01, -1.3071e-02],\n",
      "          [ 5.6779e-02, -1.3569e-01,  6.8910e-02,  ..., -1.3159e-01,\n",
      "           -1.4228e-01,  2.0033e-01]],\n",
      "\n",
      "         [[-8.4790e-02, -6.8999e-02, -1.0569e-01,  ...,  2.0058e-01,\n",
      "            4.1633e-01, -1.4532e-01],\n",
      "          [ 2.4894e-02, -7.0347e-02,  2.0148e-01,  ..., -5.1093e-02,\n",
      "           -3.9231e-02,  9.9235e-02]],\n",
      "\n",
      "         [[-5.9855e-02, -6.2354e-02, -6.8153e-02,  ...,  1.4989e-01,\n",
      "            3.6364e-01, -1.4130e-01],\n",
      "          [-1.0180e-03,  1.5765e-01,  2.5707e-01,  ...,  8.9029e-02,\n",
      "            1.0346e-01, -1.2141e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.3707,  0.2527, -0.5012,  ...,  0.0592,  0.3195, -0.3347],\n",
      "         [-0.3369,  0.0947, -0.4498,  ..., -0.1958, -0.1724, -0.5650],\n",
      "         [-0.4318, -0.0051, -0.0678,  ..., -0.2607,  0.0894,  0.0627],\n",
      "         ...,\n",
      "         [-0.5819, -0.0296, -0.3583,  ..., -0.0352, -0.0940, -0.3498],\n",
      "         [-0.3677, -0.0105, -0.1793,  ..., -0.5480,  0.0919, -0.2461],\n",
      "         [-0.5518,  0.5128, -0.4037,  ...,  0.0453, -0.3501, -0.5123]],\n",
      "\n",
      "        [[ 0.0336,  0.0061, -0.1783,  ...,  0.5117,  0.4193, -0.1646],\n",
      "         [-0.1776,  0.2235, -0.3643,  ...,  0.1890, -0.0125, -0.2771],\n",
      "         [-0.6006,  0.2705, -0.1060,  ..., -0.0016, -0.0729, -0.0568],\n",
      "         ...,\n",
      "         [-0.4476, -0.3184,  0.0628,  ...,  0.1000, -0.1205, -0.0491],\n",
      "         [-0.1682, -0.2291,  0.0488,  ...,  0.1110, -0.0246,  0.0438],\n",
      "         [-0.4490,  0.3638, -0.3127,  ...,  0.2806, -0.3483, -0.3937]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3707,  0.2527, -0.5012,  ...,  0.0592,  0.3195, -0.3347],\n",
      "         [-0.3369,  0.0947, -0.4498,  ..., -0.1958, -0.1724, -0.5650],\n",
      "         [-0.4318, -0.0051, -0.0678,  ..., -0.2607,  0.0894,  0.0627],\n",
      "         ...,\n",
      "         [-0.5819, -0.0296, -0.3583,  ..., -0.0352, -0.0940, -0.3498],\n",
      "         [-0.3677, -0.0105, -0.1793,  ..., -0.5480,  0.0919, -0.2461],\n",
      "         [-0.5518,  0.5128, -0.4037,  ...,  0.0453, -0.3501, -0.5123]],\n",
      "\n",
      "        [[ 0.0336,  0.0061, -0.1783,  ...,  0.5117,  0.4193, -0.1646],\n",
      "         [-0.1776,  0.2235, -0.3643,  ...,  0.1890, -0.0125, -0.2771],\n",
      "         [-0.6006,  0.2705, -0.1060,  ..., -0.0016, -0.0729, -0.0568],\n",
      "         ...,\n",
      "         [-0.4476, -0.3184,  0.0628,  ...,  0.1000, -0.1205, -0.0491],\n",
      "         [-0.1682, -0.2291,  0.0488,  ...,  0.1110, -0.0246,  0.0438],\n",
      "         [-0.4490,  0.3638, -0.3127,  ...,  0.2806, -0.3483, -0.3937]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3707,  0.2527, -0.5012,  ..., -0.1110, -0.1910,  0.2870],\n",
      "          [ 0.3369,  0.5049,  0.0979,  ...,  0.0592,  0.3195, -0.3347]],\n",
      "\n",
      "         [[-0.3369,  0.0947, -0.4498,  ...,  0.2646, -0.2184,  0.2759],\n",
      "          [ 0.0229,  0.1357,  0.3406,  ..., -0.1958, -0.1724, -0.5650]],\n",
      "\n",
      "         [[-0.4318, -0.0051, -0.0678,  ...,  0.0565,  0.1507, -0.2343],\n",
      "          [ 0.0997, -0.0406, -0.3865,  ..., -0.2607,  0.0894,  0.0627]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5819, -0.0296, -0.3583,  ...,  0.2470, -0.0798,  0.3947],\n",
      "          [ 0.2875,  0.2834, -0.3867,  ..., -0.0352, -0.0940, -0.3498]],\n",
      "\n",
      "         [[-0.3677, -0.0105, -0.1793,  ...,  0.0032,  0.1990,  0.0725],\n",
      "          [ 0.1394, -0.1460, -0.2676,  ..., -0.5480,  0.0919, -0.2461]],\n",
      "\n",
      "         [[-0.5518,  0.5128, -0.4037,  ...,  0.2270, -0.5738,  0.6680],\n",
      "          [ 0.6819,  0.6757,  0.1831,  ...,  0.0453, -0.3501, -0.5123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0336,  0.0061, -0.1783,  ..., -0.3544, -0.0561,  0.1038],\n",
      "          [ 0.3850,  0.1972,  0.5375,  ...,  0.5117,  0.4193, -0.1646]],\n",
      "\n",
      "         [[-0.1776,  0.2235, -0.3643,  ...,  0.2075, -0.5420,  0.7932],\n",
      "          [ 0.4774,  0.0550,  0.3863,  ...,  0.1890, -0.0125, -0.2771]],\n",
      "\n",
      "         [[-0.6006,  0.2705, -0.1060,  ...,  0.3394, -0.0077,  0.4796],\n",
      "          [ 0.1336,  0.1364,  0.2177,  ..., -0.0016, -0.0729, -0.0568]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4476, -0.3184,  0.0628,  ..., -0.1014,  0.2398,  0.3324],\n",
      "          [-0.0371,  0.0988, -0.1751,  ...,  0.1000, -0.1205, -0.0491]],\n",
      "\n",
      "         [[-0.1682, -0.2291,  0.0488,  ...,  0.0207,  0.1215,  0.0769],\n",
      "          [ 0.3018, -0.0211,  0.1031,  ...,  0.1110, -0.0246,  0.0438]],\n",
      "\n",
      "         [[-0.4490,  0.3638, -0.3127,  ...,  0.1291, -0.5203,  0.7728],\n",
      "          [ 0.7496,  0.5718,  0.3349,  ...,  0.2806, -0.3483, -0.3937]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8204,  0.3611,  0.7395,  ..., -0.5035, -0.5746,  0.1778],\n",
      "         [ 1.3998,  0.9670,  0.9861,  ..., -0.7424, -0.8132,  0.7649],\n",
      "         [ 1.1274,  0.8052,  0.9027,  ..., -0.4090, -0.8449,  0.2694],\n",
      "         ...,\n",
      "         [ 0.8320,  0.6439,  0.7252,  ..., -0.4586, -0.4986,  0.1410],\n",
      "         [ 1.0110,  0.8681,  0.8714,  ..., -0.3771, -0.6946,  0.5567],\n",
      "         [ 0.7575,  0.3874,  0.7780,  ..., -0.4897, -0.4667,  0.4370]],\n",
      "\n",
      "        [[-0.3489, -0.9019, -0.4925,  ...,  0.5446,  0.6824, -0.8349],\n",
      "         [ 0.1043, -0.0360,  0.0982,  ...,  0.3124,  0.0624, -0.6026],\n",
      "         [ 0.8552,  0.5833,  0.6327,  ..., -0.2244, -0.2825, -0.3448],\n",
      "         ...,\n",
      "         [ 0.0296, -0.1567, -0.2729,  ...,  0.3073,  0.3704, -0.4547],\n",
      "         [-0.3743, -0.5554, -0.3368,  ...,  0.3867,  0.5875, -0.6028],\n",
      "         [ 0.4501,  0.1276,  0.6535,  ..., -0.3604, -0.0970,  0.4168]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.8204,  0.3611,  0.7395,  ..., -0.5035, -0.5746,  0.1778],\n",
      "         [ 1.3998,  0.9670,  0.9861,  ..., -0.7424, -0.8132,  0.7649],\n",
      "         [ 1.1274,  0.8052,  0.9027,  ..., -0.4090, -0.8449,  0.2694],\n",
      "         ...,\n",
      "         [ 0.8320,  0.6439,  0.7252,  ..., -0.4586, -0.4986,  0.1410],\n",
      "         [ 1.0110,  0.8681,  0.8714,  ..., -0.3771, -0.6946,  0.5567],\n",
      "         [ 0.7575,  0.3874,  0.7780,  ..., -0.4897, -0.4667,  0.4370]],\n",
      "\n",
      "        [[-0.3489, -0.9019, -0.4925,  ...,  0.5446,  0.6824, -0.8349],\n",
      "         [ 0.1043, -0.0360,  0.0982,  ...,  0.3124,  0.0624, -0.6026],\n",
      "         [ 0.8552,  0.5833,  0.6327,  ..., -0.2244, -0.2825, -0.3448],\n",
      "         ...,\n",
      "         [ 0.0296, -0.1567, -0.2729,  ...,  0.3073,  0.3704, -0.4547],\n",
      "         [-0.3743, -0.5554, -0.3368,  ...,  0.3867,  0.5875, -0.6028],\n",
      "         [ 0.4501,  0.1276,  0.6535,  ..., -0.3604, -0.0970,  0.4168]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.8204,  0.3611,  0.7395,  ...,  0.8496, -0.6732,  0.8545],\n",
      "          [-0.8747, -0.7163, -0.6936,  ..., -0.5035, -0.5746,  0.1778]],\n",
      "\n",
      "         [[ 1.3998,  0.9670,  0.9861,  ...,  0.9978, -0.6514,  1.0198],\n",
      "          [-0.5442, -0.5204, -0.8143,  ..., -0.7424, -0.8132,  0.7649]],\n",
      "\n",
      "         [[ 1.1274,  0.8052,  0.9027,  ...,  1.2003, -0.5776,  1.1883],\n",
      "          [-0.6477, -0.7622, -0.7878,  ..., -0.4090, -0.8449,  0.2694]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8320,  0.6439,  0.7252,  ...,  1.0616, -0.6147,  1.2379],\n",
      "          [-0.5622, -0.4759, -0.5534,  ..., -0.4586, -0.4986,  0.1410]],\n",
      "\n",
      "         [[ 1.0110,  0.8681,  0.8714,  ...,  0.9847, -0.9071,  1.3514],\n",
      "          [-1.0905, -0.5132, -1.0823,  ..., -0.3771, -0.6946,  0.5567]],\n",
      "\n",
      "         [[ 0.7575,  0.3874,  0.7780,  ...,  0.8451, -0.2318,  0.8953],\n",
      "          [-0.2982, -0.3465, -0.4639,  ..., -0.4897, -0.4667,  0.4370]]],\n",
      "\n",
      "\n",
      "        [[[-0.3489, -0.9019, -0.4925,  ..., -0.2738,  0.3116, -0.6561],\n",
      "          [ 0.2172,  0.2882,  0.4293,  ...,  0.5446,  0.6824, -0.8349]],\n",
      "\n",
      "         [[ 0.1043, -0.0360,  0.0982,  ...,  0.2205,  0.4466, -0.2173],\n",
      "          [ 0.2959,  0.0958, -0.1238,  ...,  0.3124,  0.0624, -0.6026]],\n",
      "\n",
      "         [[ 0.8552,  0.5833,  0.6327,  ...,  0.7947, -0.5565,  0.7285],\n",
      "          [-0.4230, -0.5670, -1.0513,  ..., -0.2244, -0.2825, -0.3448]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0296, -0.1567, -0.2729,  ...,  0.4496, -0.0746, -0.1419],\n",
      "          [ 0.0368,  0.1146,  0.1316,  ...,  0.3073,  0.3704, -0.4547]],\n",
      "\n",
      "         [[-0.3743, -0.5554, -0.3368,  ...,  0.0331,  0.1867, -0.7658],\n",
      "          [ 0.1430,  0.7243,  0.1349,  ...,  0.3867,  0.5875, -0.6028]],\n",
      "\n",
      "         [[ 0.4501,  0.1276,  0.6535,  ...,  0.5113, -0.0650,  0.6247],\n",
      "          [-0.0643, -0.2442, -0.0977,  ..., -0.3604, -0.0970,  0.4168]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0960, -0.3400,  0.4706,  ..., -0.8475,  0.2428,  0.3791],\n",
      "         [ 0.0417, -0.4249,  0.1824,  ..., -0.2695,  0.2064,  0.0499],\n",
      "         [-0.1560, -0.3781,  0.0773,  ..., -0.3459, -0.0941, -0.1607],\n",
      "         ...,\n",
      "         [ 0.0179, -0.2675,  0.0973,  ..., -0.5470,  0.0244,  0.0312],\n",
      "         [ 0.2717, -0.0667,  0.0901,  ..., -0.2346,  0.1992,  0.4385],\n",
      "         [ 0.1686,  0.0085,  0.4364,  ..., -0.4415,  0.2228,  0.0713]],\n",
      "\n",
      "        [[ 0.3844, -0.2031,  0.0725,  ..., -0.7041, -0.2363,  0.2968],\n",
      "         [ 0.0906, -0.0312, -0.1762,  ..., -0.5041,  0.1762,  0.2914],\n",
      "         [-0.1651, -0.3609, -0.0755,  ..., -0.2790, -0.3145, -0.0802],\n",
      "         ...,\n",
      "         [-0.2837, -0.0771, -0.0059,  ..., -0.2802, -0.1373,  0.4587],\n",
      "         [ 0.1199,  0.4067, -0.1575,  ..., -0.1060, -0.2381,  0.3892],\n",
      "         [ 0.3167, -0.0432,  0.3071,  ..., -0.4705,  0.0703,  0.0904]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0960, -0.3400,  0.4706,  ..., -0.8475,  0.2428,  0.3791],\n",
      "         [ 0.0417, -0.4249,  0.1824,  ..., -0.2695,  0.2064,  0.0499],\n",
      "         [-0.1560, -0.3781,  0.0773,  ..., -0.3459, -0.0941, -0.1607],\n",
      "         ...,\n",
      "         [ 0.0179, -0.2675,  0.0973,  ..., -0.5470,  0.0244,  0.0312],\n",
      "         [ 0.2717, -0.0667,  0.0901,  ..., -0.2346,  0.1992,  0.4385],\n",
      "         [ 0.1686,  0.0085,  0.4364,  ..., -0.4415,  0.2228,  0.0713]],\n",
      "\n",
      "        [[ 0.3844, -0.2031,  0.0725,  ..., -0.7041, -0.2363,  0.2968],\n",
      "         [ 0.0906, -0.0312, -0.1762,  ..., -0.5041,  0.1762,  0.2914],\n",
      "         [-0.1651, -0.3609, -0.0755,  ..., -0.2790, -0.3145, -0.0802],\n",
      "         ...,\n",
      "         [-0.2837, -0.0771, -0.0059,  ..., -0.2802, -0.1373,  0.4587],\n",
      "         [ 0.1199,  0.4067, -0.1575,  ..., -0.1060, -0.2381,  0.3892],\n",
      "         [ 0.3167, -0.0432,  0.3071,  ..., -0.4705,  0.0703,  0.0904]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0960, -0.3400,  0.4706,  ..., -0.3613,  1.1635, -1.3725],\n",
      "          [-0.3009, -0.6471, -0.9535,  ..., -0.8475,  0.2428,  0.3791]],\n",
      "\n",
      "         [[ 0.0417, -0.4249,  0.1824,  ...,  0.3949,  0.4204, -0.2697],\n",
      "          [-0.1056, -0.3190, -0.4447,  ..., -0.2695,  0.2064,  0.0499]],\n",
      "\n",
      "         [[-0.1560, -0.3781,  0.0773,  ...,  0.2636,  0.4632, -0.6118],\n",
      "          [ 0.1849, -0.1733, -0.5726,  ..., -0.3459, -0.0941, -0.1607]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0179, -0.2675,  0.0973,  ...,  0.1561,  0.4498, -0.6279],\n",
      "          [-0.3012, -0.1850, -0.6537,  ..., -0.5470,  0.0244,  0.0312]],\n",
      "\n",
      "         [[ 0.2717, -0.0667,  0.0901,  ...,  0.3582,  0.7978, -0.8169],\n",
      "          [ 0.1589, -0.2826, -0.3236,  ..., -0.2346,  0.1992,  0.4385]],\n",
      "\n",
      "         [[ 0.1686,  0.0085,  0.4364,  ..., -0.0651,  0.6722, -0.3842],\n",
      "          [ 0.1296, -0.3246, -0.2759,  ..., -0.4415,  0.2228,  0.0713]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3844, -0.2031,  0.0725,  ..., -0.4609,  0.6974, -1.2717],\n",
      "          [-0.4373, -0.4382, -0.1142,  ..., -0.7041, -0.2363,  0.2968]],\n",
      "\n",
      "         [[ 0.0906, -0.0312, -0.1762,  ...,  0.2068,  0.3314, -0.4470],\n",
      "          [-0.0111, -0.3313,  0.4252,  ..., -0.5041,  0.1762,  0.2914]],\n",
      "\n",
      "         [[-0.1651, -0.3609, -0.0755,  ...,  0.0055, -0.0092, -0.6898],\n",
      "          [ 0.0836, -0.1140, -0.1837,  ..., -0.2790, -0.3145, -0.0802]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2837, -0.0771, -0.0059,  ..., -0.1404,  0.3510, -0.4996],\n",
      "          [-0.4737, -0.0884,  0.1021,  ..., -0.2802, -0.1373,  0.4587]],\n",
      "\n",
      "         [[ 0.1199,  0.4067, -0.1575,  ...,  0.2226,  0.1896, -0.4034],\n",
      "          [-0.1121, -0.0519,  0.4205,  ..., -0.1060, -0.2381,  0.3892]],\n",
      "\n",
      "         [[ 0.3167, -0.0432,  0.3071,  ...,  0.0960,  0.5484, -0.1930],\n",
      "          [ 0.1492, -0.2242, -0.1965,  ..., -0.4705,  0.0703,  0.0904]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3707,  0.2527, -0.5012,  ..., -0.1110, -0.1910,  0.2870],\n",
      "          [-0.3369,  0.0947, -0.4498,  ...,  0.2646, -0.2184,  0.2759],\n",
      "          [-0.4318, -0.0051, -0.0678,  ...,  0.0565,  0.1507, -0.2343],\n",
      "          ...,\n",
      "          [-0.5819, -0.0296, -0.3583,  ...,  0.2470, -0.0798,  0.3947],\n",
      "          [-0.3677, -0.0105, -0.1793,  ...,  0.0032,  0.1990,  0.0725],\n",
      "          [-0.5518,  0.5128, -0.4037,  ...,  0.2270, -0.5738,  0.6680]],\n",
      "\n",
      "         [[ 0.3369,  0.5049,  0.0979,  ...,  0.0592,  0.3195, -0.3347],\n",
      "          [ 0.0229,  0.1357,  0.3406,  ..., -0.1958, -0.1724, -0.5650],\n",
      "          [ 0.0997, -0.0406, -0.3865,  ..., -0.2607,  0.0894,  0.0627],\n",
      "          ...,\n",
      "          [ 0.2875,  0.2834, -0.3867,  ..., -0.0352, -0.0940, -0.3498],\n",
      "          [ 0.1394, -0.1460, -0.2676,  ..., -0.5480,  0.0919, -0.2461],\n",
      "          [ 0.6819,  0.6757,  0.1831,  ...,  0.0453, -0.3501, -0.5123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0336,  0.0061, -0.1783,  ..., -0.3544, -0.0561,  0.1038],\n",
      "          [-0.1776,  0.2235, -0.3643,  ...,  0.2075, -0.5420,  0.7932],\n",
      "          [-0.6006,  0.2705, -0.1060,  ...,  0.3394, -0.0077,  0.4796],\n",
      "          ...,\n",
      "          [-0.4476, -0.3184,  0.0628,  ..., -0.1014,  0.2398,  0.3324],\n",
      "          [-0.1682, -0.2291,  0.0488,  ...,  0.0207,  0.1215,  0.0769],\n",
      "          [-0.4490,  0.3638, -0.3127,  ...,  0.1291, -0.5203,  0.7728]],\n",
      "\n",
      "         [[ 0.3850,  0.1972,  0.5375,  ...,  0.5117,  0.4193, -0.1646],\n",
      "          [ 0.4774,  0.0550,  0.3863,  ...,  0.1890, -0.0125, -0.2771],\n",
      "          [ 0.1336,  0.1364,  0.2177,  ..., -0.0016, -0.0729, -0.0568],\n",
      "          ...,\n",
      "          [-0.0371,  0.0988, -0.1751,  ...,  0.1000, -0.1205, -0.0491],\n",
      "          [ 0.3018, -0.0211,  0.1031,  ...,  0.1110, -0.0246,  0.0438],\n",
      "          [ 0.7496,  0.5718,  0.3349,  ...,  0.2806, -0.3483, -0.3937]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.1389,  0.8283,  0.9292,  ...,  1.0856, -0.7511,  1.2756],\n",
      "          [ 1.0662,  0.7613,  0.8844,  ...,  0.9982, -0.7158,  1.1853],\n",
      "          [ 0.8866,  0.6301,  0.7406,  ...,  0.7997, -0.6255,  0.9915],\n",
      "          ...,\n",
      "          [ 0.7315,  0.4776,  0.6229,  ...,  0.7349, -0.4741,  0.8073],\n",
      "          [ 0.8251,  0.5944,  0.6866,  ...,  0.7412, -0.5929,  0.9330],\n",
      "          [ 0.9989,  0.7345,  0.8207,  ...,  0.9259, -0.6583,  1.1140]],\n",
      "\n",
      "         [[-0.7959, -0.5923, -0.8988,  ..., -0.4910, -0.6969,  0.3767],\n",
      "          [-0.7733, -0.5739, -0.8386,  ..., -0.5359, -0.6769,  0.3717],\n",
      "          [-0.7664, -0.5671, -0.8285,  ..., -0.5351, -0.6684,  0.3685],\n",
      "          ...,\n",
      "          [-0.7869, -0.5809, -0.8553,  ..., -0.5375, -0.6840,  0.3747],\n",
      "          [-0.8083, -0.6031, -0.8916,  ..., -0.5357, -0.7063,  0.3767],\n",
      "          [-0.7092, -0.5416, -0.7973,  ..., -0.4925, -0.6279,  0.3233]]],\n",
      "\n",
      "\n",
      "        [[[-0.3587, -0.6058, -0.2453,  ..., -0.3153,  0.1462, -0.6072],\n",
      "          [-0.0292, -0.1643,  0.0034,  ..., -0.0676,  0.0115, -0.1458],\n",
      "          [-0.0613, -0.2438, -0.0682,  ...,  0.0073,  0.0271, -0.2513],\n",
      "          ...,\n",
      "          [-0.1927, -0.3867, -0.1576,  ..., -0.0899,  0.0857, -0.4063],\n",
      "          [-0.1442, -0.3567, -0.1403,  ..., -0.0345,  0.0919, -0.3436],\n",
      "          [-0.0656, -0.2538, -0.0314,  ..., -0.0166,  0.0443, -0.2174]],\n",
      "\n",
      "         [[ 0.1036,  0.1601,  0.0353,  ...,  0.2013,  0.2414, -0.2973],\n",
      "          [ 0.3123,  0.2234,  0.0838,  ...,  0.2825,  0.3381, -0.4803],\n",
      "          [ 0.2752,  0.2098,  0.0750,  ...,  0.2555,  0.3247, -0.4325],\n",
      "          ...,\n",
      "          [ 0.3367,  0.2356,  0.1040,  ...,  0.2932,  0.3506, -0.4901],\n",
      "          [ 0.2527,  0.1106,  0.0283,  ...,  0.2179,  0.2416, -0.3868],\n",
      "          [ 0.2289,  0.1579,  0.0389,  ...,  0.1521,  0.2162, -0.3314]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.1389,  0.8283,  0.9292,  ...,  1.0856, -0.7511,  1.2756],\n",
      "          [-0.7959, -0.5923, -0.8988,  ..., -0.4910, -0.6969,  0.3767]],\n",
      "\n",
      "         [[ 1.0662,  0.7613,  0.8844,  ...,  0.9982, -0.7158,  1.1853],\n",
      "          [-0.7733, -0.5739, -0.8386,  ..., -0.5359, -0.6769,  0.3717]],\n",
      "\n",
      "         [[ 0.8866,  0.6301,  0.7406,  ...,  0.7997, -0.6255,  0.9915],\n",
      "          [-0.7664, -0.5671, -0.8285,  ..., -0.5351, -0.6684,  0.3685]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7315,  0.4776,  0.6229,  ...,  0.7349, -0.4741,  0.8073],\n",
      "          [-0.7869, -0.5809, -0.8553,  ..., -0.5375, -0.6840,  0.3747]],\n",
      "\n",
      "         [[ 0.8251,  0.5944,  0.6866,  ...,  0.7412, -0.5929,  0.9330],\n",
      "          [-0.8083, -0.6031, -0.8916,  ..., -0.5357, -0.7063,  0.3767]],\n",
      "\n",
      "         [[ 0.9989,  0.7345,  0.8207,  ...,  0.9259, -0.6583,  1.1140],\n",
      "          [-0.7092, -0.5416, -0.7973,  ..., -0.4925, -0.6279,  0.3233]]],\n",
      "\n",
      "\n",
      "        [[[-0.3587, -0.6058, -0.2453,  ..., -0.3153,  0.1462, -0.6072],\n",
      "          [ 0.1036,  0.1601,  0.0353,  ...,  0.2013,  0.2414, -0.2973]],\n",
      "\n",
      "         [[-0.0292, -0.1643,  0.0034,  ..., -0.0676,  0.0115, -0.1458],\n",
      "          [ 0.3123,  0.2234,  0.0838,  ...,  0.2825,  0.3381, -0.4803]],\n",
      "\n",
      "         [[-0.0613, -0.2438, -0.0682,  ...,  0.0073,  0.0271, -0.2513],\n",
      "          [ 0.2752,  0.2098,  0.0750,  ...,  0.2555,  0.3247, -0.4325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1927, -0.3867, -0.1576,  ..., -0.0899,  0.0857, -0.4063],\n",
      "          [ 0.3367,  0.2356,  0.1040,  ...,  0.2932,  0.3506, -0.4901]],\n",
      "\n",
      "         [[-0.1442, -0.3567, -0.1403,  ..., -0.0345,  0.0919, -0.3436],\n",
      "          [ 0.2527,  0.1106,  0.0283,  ...,  0.2179,  0.2416, -0.3868]],\n",
      "\n",
      "         [[-0.0656, -0.2538, -0.0314,  ..., -0.0166,  0.0443, -0.2174],\n",
      "          [ 0.2289,  0.1579,  0.0389,  ...,  0.1521,  0.2162, -0.3314]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.1389,  0.8283,  0.9292,  ...,  1.0856, -0.7511,  1.2756],\n",
      "          [-0.7959, -0.5923, -0.8988,  ..., -0.4910, -0.6969,  0.3767]],\n",
      "\n",
      "         [[ 1.0662,  0.7613,  0.8844,  ...,  0.9982, -0.7158,  1.1853],\n",
      "          [-0.7733, -0.5739, -0.8386,  ..., -0.5359, -0.6769,  0.3717]],\n",
      "\n",
      "         [[ 0.8866,  0.6301,  0.7406,  ...,  0.7997, -0.6255,  0.9915],\n",
      "          [-0.7664, -0.5671, -0.8285,  ..., -0.5351, -0.6684,  0.3685]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7315,  0.4776,  0.6229,  ...,  0.7349, -0.4741,  0.8073],\n",
      "          [-0.7869, -0.5809, -0.8553,  ..., -0.5375, -0.6840,  0.3747]],\n",
      "\n",
      "         [[ 0.8251,  0.5944,  0.6866,  ...,  0.7412, -0.5929,  0.9330],\n",
      "          [-0.8083, -0.6031, -0.8916,  ..., -0.5357, -0.7063,  0.3767]],\n",
      "\n",
      "         [[ 0.9989,  0.7345,  0.8207,  ...,  0.9259, -0.6583,  1.1140],\n",
      "          [-0.7092, -0.5416, -0.7973,  ..., -0.4925, -0.6279,  0.3233]]],\n",
      "\n",
      "\n",
      "        [[[-0.3587, -0.6058, -0.2453,  ..., -0.3153,  0.1462, -0.6072],\n",
      "          [ 0.1036,  0.1601,  0.0353,  ...,  0.2013,  0.2414, -0.2973]],\n",
      "\n",
      "         [[-0.0292, -0.1643,  0.0034,  ..., -0.0676,  0.0115, -0.1458],\n",
      "          [ 0.3123,  0.2234,  0.0838,  ...,  0.2825,  0.3381, -0.4803]],\n",
      "\n",
      "         [[-0.0613, -0.2438, -0.0682,  ...,  0.0073,  0.0271, -0.2513],\n",
      "          [ 0.2752,  0.2098,  0.0750,  ...,  0.2555,  0.3247, -0.4325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1927, -0.3867, -0.1576,  ..., -0.0899,  0.0857, -0.4063],\n",
      "          [ 0.3367,  0.2356,  0.1040,  ...,  0.2932,  0.3506, -0.4901]],\n",
      "\n",
      "         [[-0.1442, -0.3567, -0.1403,  ..., -0.0345,  0.0919, -0.3436],\n",
      "          [ 0.2527,  0.1106,  0.0283,  ...,  0.2179,  0.2416, -0.3868]],\n",
      "\n",
      "         [[-0.0656, -0.2538, -0.0314,  ..., -0.0166,  0.0443, -0.2174],\n",
      "          [ 0.2289,  0.1579,  0.0389,  ...,  0.1521,  0.2162, -0.3314]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.1389,  0.8283,  0.9292,  ...,  1.0856, -0.7511,  1.2756],\n",
      "          [-0.7959, -0.5923, -0.8988,  ..., -0.4910, -0.6969,  0.3767]],\n",
      "\n",
      "         [[ 1.0662,  0.7613,  0.8844,  ...,  0.9982, -0.7158,  1.1853],\n",
      "          [-0.7733, -0.5739, -0.8386,  ..., -0.5359, -0.6769,  0.3717]],\n",
      "\n",
      "         [[ 0.8866,  0.6301,  0.7406,  ...,  0.7997, -0.6255,  0.9915],\n",
      "          [-0.7664, -0.5671, -0.8285,  ..., -0.5351, -0.6684,  0.3685]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7315,  0.4776,  0.6229,  ...,  0.7349, -0.4741,  0.8073],\n",
      "          [-0.7869, -0.5809, -0.8553,  ..., -0.5375, -0.6840,  0.3747]],\n",
      "\n",
      "         [[ 0.8251,  0.5944,  0.6866,  ...,  0.7412, -0.5929,  0.9330],\n",
      "          [-0.8083, -0.6031, -0.8916,  ..., -0.5357, -0.7063,  0.3767]],\n",
      "\n",
      "         [[ 0.9989,  0.7345,  0.8207,  ...,  0.9259, -0.6583,  1.1140],\n",
      "          [-0.7092, -0.5416, -0.7973,  ..., -0.4925, -0.6279,  0.3233]]],\n",
      "\n",
      "\n",
      "        [[[-0.3587, -0.6058, -0.2453,  ..., -0.3153,  0.1462, -0.6072],\n",
      "          [ 0.1036,  0.1601,  0.0353,  ...,  0.2013,  0.2414, -0.2973]],\n",
      "\n",
      "         [[-0.0292, -0.1643,  0.0034,  ..., -0.0676,  0.0115, -0.1458],\n",
      "          [ 0.3123,  0.2234,  0.0838,  ...,  0.2825,  0.3381, -0.4803]],\n",
      "\n",
      "         [[-0.0613, -0.2438, -0.0682,  ...,  0.0073,  0.0271, -0.2513],\n",
      "          [ 0.2752,  0.2098,  0.0750,  ...,  0.2555,  0.3247, -0.4325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1927, -0.3867, -0.1576,  ..., -0.0899,  0.0857, -0.4063],\n",
      "          [ 0.3367,  0.2356,  0.1040,  ...,  0.2932,  0.3506, -0.4901]],\n",
      "\n",
      "         [[-0.1442, -0.3567, -0.1403,  ..., -0.0345,  0.0919, -0.3436],\n",
      "          [ 0.2527,  0.1106,  0.0283,  ...,  0.2179,  0.2416, -0.3868]],\n",
      "\n",
      "         [[-0.0656, -0.2538, -0.0314,  ..., -0.0166,  0.0443, -0.2174],\n",
      "          [ 0.2289,  0.1579,  0.0389,  ...,  0.1521,  0.2162, -0.3314]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.6229,  1.6287],\n",
      "        [ 1.5327, -1.4643]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:36:37,584] Trial 6 finished with value: 0.73624 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.357700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.3067, -0.3178,  0.6425,  ...,  0.1591, -0.1093,  0.4691],\n",
      "         [ 0.1686, -0.0170,  0.3521,  ...,  0.1465,  0.1055,  0.2567],\n",
      "         [ 0.4158, -0.2117,  0.1419,  ...,  0.2601,  0.3063, -0.0788],\n",
      "         ...,\n",
      "         [-0.1462, -0.0198,  0.5083,  ..., -0.0713,  0.5155,  0.5806],\n",
      "         [ 0.1621, -0.2845, -0.1237,  ...,  0.1611,  0.1869,  0.2252],\n",
      "         [ 0.1725,  0.0233,  0.3819,  ..., -0.4919,  0.1430,  0.7002]],\n",
      "\n",
      "        [[ 0.1652, -0.2806,  0.7525,  ...,  0.2159, -0.0448,  0.3897],\n",
      "         [-0.2532,  0.0408,  0.3052,  ..., -0.1516,  0.1740,  0.4652],\n",
      "         [ 0.2805, -0.2482,  0.0026,  ...,  0.1424,  0.4446,  0.2016],\n",
      "         ...,\n",
      "         [-0.1965, -0.0344, -0.0821,  ..., -0.0982,  0.4580,  0.8490],\n",
      "         [ 0.3142,  0.2259,  0.3259,  ..., -0.0083,  0.0101,  0.1007],\n",
      "         [ 0.1843,  0.1200,  0.2223,  ..., -0.3277,  0.0033,  0.5977]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3067, -0.3178,  0.6425,  ...,  0.1591, -0.1093,  0.4691],\n",
      "         [ 0.1686, -0.0170,  0.3521,  ...,  0.1465,  0.1055,  0.2567],\n",
      "         [ 0.4158, -0.2117,  0.1419,  ...,  0.2601,  0.3063, -0.0788],\n",
      "         ...,\n",
      "         [-0.1462, -0.0198,  0.5083,  ..., -0.0713,  0.5155,  0.5806],\n",
      "         [ 0.1621, -0.2845, -0.1237,  ...,  0.1611,  0.1869,  0.2252],\n",
      "         [ 0.1725,  0.0233,  0.3819,  ..., -0.4919,  0.1430,  0.7002]],\n",
      "\n",
      "        [[ 0.1652, -0.2806,  0.7525,  ...,  0.2159, -0.0448,  0.3897],\n",
      "         [-0.2532,  0.0408,  0.3052,  ..., -0.1516,  0.1740,  0.4652],\n",
      "         [ 0.2805, -0.2482,  0.0026,  ...,  0.1424,  0.4446,  0.2016],\n",
      "         ...,\n",
      "         [-0.1965, -0.0344, -0.0821,  ..., -0.0982,  0.4580,  0.8490],\n",
      "         [ 0.3142,  0.2259,  0.3259,  ..., -0.0083,  0.0101,  0.1007],\n",
      "         [ 0.1843,  0.1200,  0.2223,  ..., -0.3277,  0.0033,  0.5977]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.0670e-01, -3.1779e-01,  6.4245e-01,  ...,  2.7979e-01,\n",
      "            1.5959e-01,  2.5285e-02],\n",
      "          [ 2.6349e-01,  2.1069e-01,  2.3778e-01,  ...,  1.5909e-01,\n",
      "           -1.0933e-01,  4.6913e-01]],\n",
      "\n",
      "         [[ 1.6861e-01, -1.6963e-02,  3.5213e-01,  ...,  4.6156e-01,\n",
      "           -2.5573e-01,  4.7012e-01],\n",
      "          [ 6.5072e-02, -5.8003e-01,  3.7523e-01,  ...,  1.4652e-01,\n",
      "            1.0550e-01,  2.5669e-01]],\n",
      "\n",
      "         [[ 4.1581e-01, -2.1171e-01,  1.4186e-01,  ...,  3.2534e-01,\n",
      "            1.9945e-01, -2.1428e-02],\n",
      "          [-3.2930e-01, -6.2543e-01, -1.4453e-01,  ...,  2.6008e-01,\n",
      "            3.0626e-01, -7.8832e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4616e-01, -1.9771e-02,  5.0835e-01,  ...,  6.7996e-01,\n",
      "           -5.2345e-01,  2.0017e-01],\n",
      "          [ 2.2550e-01, -4.8376e-01,  3.8079e-01,  ..., -7.1313e-02,\n",
      "            5.1546e-01,  5.8058e-01]],\n",
      "\n",
      "         [[ 1.6209e-01, -2.8451e-01, -1.2371e-01,  ...,  2.2315e-01,\n",
      "            3.7742e-01,  5.7168e-02],\n",
      "          [ 3.9885e-02,  7.1847e-03,  6.1061e-04,  ...,  1.6112e-01,\n",
      "            1.8692e-01,  2.2516e-01]],\n",
      "\n",
      "         [[ 1.7250e-01,  2.3260e-02,  3.8191e-01,  ...,  3.3562e-01,\n",
      "           -1.3698e-01, -1.8584e-01],\n",
      "          [ 5.7895e-01, -5.7815e-01,  2.7249e-01,  ..., -4.9194e-01,\n",
      "            1.4300e-01,  7.0017e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6519e-01, -2.8056e-01,  7.5254e-01,  ...,  1.3871e-01,\n",
      "            6.1414e-02, -1.3411e-01],\n",
      "          [ 3.6666e-01,  2.7096e-01,  2.6185e-01,  ...,  2.1595e-01,\n",
      "           -4.4781e-02,  3.8970e-01]],\n",
      "\n",
      "         [[-2.5322e-01,  4.0769e-02,  3.0515e-01,  ...,  6.9330e-01,\n",
      "           -2.0052e-01,  3.1479e-01],\n",
      "          [ 3.7219e-01, -6.2935e-01,  8.3197e-01,  ..., -1.5161e-01,\n",
      "            1.7400e-01,  4.6522e-01]],\n",
      "\n",
      "         [[ 2.8047e-01, -2.4815e-01,  2.5729e-03,  ...,  4.2425e-01,\n",
      "           -1.6065e-01,  6.0083e-01],\n",
      "          [ 1.1109e-01, -4.8147e-01,  2.9196e-01,  ...,  1.4235e-01,\n",
      "            4.4465e-01,  2.0160e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9647e-01, -3.4372e-02, -8.2141e-02,  ...,  6.8877e-01,\n",
      "           -3.6218e-01, -3.2390e-03],\n",
      "          [ 2.2533e-01, -5.4317e-01,  4.2018e-01,  ..., -9.8166e-02,\n",
      "            4.5802e-01,  8.4902e-01]],\n",
      "\n",
      "         [[ 3.1417e-01,  2.2595e-01,  3.2591e-01,  ...,  5.4661e-01,\n",
      "           -2.3459e-01, -7.0471e-02],\n",
      "          [-1.3693e-01,  2.0491e-02,  4.4226e-01,  ..., -8.2629e-03,\n",
      "            1.0058e-02,  1.0070e-01]],\n",
      "\n",
      "         [[ 1.8429e-01,  1.2004e-01,  2.2235e-01,  ...,  2.0391e-01,\n",
      "           -6.2807e-02, -1.7221e-01],\n",
      "          [ 4.8829e-01, -3.6760e-01,  1.4197e-01,  ..., -3.2772e-01,\n",
      "            3.2947e-03,  5.9769e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1296, -0.3476,  0.0449,  ...,  0.1166,  0.3962,  0.3726],\n",
      "         [ 0.2301,  0.0262,  0.2908,  ..., -0.0725,  0.2561,  0.0928],\n",
      "         [ 0.4213, -0.2137, -0.2548,  ...,  0.5194, -0.2536,  0.0737],\n",
      "         ...,\n",
      "         [ 0.3155,  0.0765, -0.1952,  ..., -0.3273,  0.2822, -0.5342],\n",
      "         [ 0.7855,  0.2012, -0.6067,  ..., -0.3252,  0.1292, -1.0608],\n",
      "         [ 0.4274, -0.1698, -0.0945,  ..., -0.1229, -0.2172, -0.3825]],\n",
      "\n",
      "        [[ 0.1845, -0.1493,  0.0732,  ..., -0.1452,  0.4226,  0.3340],\n",
      "         [ 0.1094, -0.4966,  0.2967,  ..., -0.0716,  0.2475,  0.3641],\n",
      "         [ 0.8099,  0.2474, -0.1045,  ...,  0.3280, -0.4342,  0.0382],\n",
      "         ...,\n",
      "         [ 0.5742, -0.3610, -0.2379,  ...,  0.0195,  0.3617, -0.1202],\n",
      "         [ 0.4593, -0.4138, -0.0922,  ..., -0.2665,  0.3154, -0.2618],\n",
      "         [ 0.2405, -0.2119, -0.0130,  ..., -0.2051, -0.2261, -0.3120]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1296, -0.3476,  0.0449,  ...,  0.1166,  0.3962,  0.3726],\n",
      "         [ 0.2301,  0.0262,  0.2908,  ..., -0.0725,  0.2561,  0.0928],\n",
      "         [ 0.4213, -0.2137, -0.2548,  ...,  0.5194, -0.2536,  0.0737],\n",
      "         ...,\n",
      "         [ 0.3155,  0.0765, -0.1952,  ..., -0.3273,  0.2822, -0.5342],\n",
      "         [ 0.7855,  0.2012, -0.6067,  ..., -0.3252,  0.1292, -1.0608],\n",
      "         [ 0.4274, -0.1698, -0.0945,  ..., -0.1229, -0.2172, -0.3825]],\n",
      "\n",
      "        [[ 0.1845, -0.1493,  0.0732,  ..., -0.1452,  0.4226,  0.3340],\n",
      "         [ 0.1094, -0.4966,  0.2967,  ..., -0.0716,  0.2475,  0.3641],\n",
      "         [ 0.8099,  0.2474, -0.1045,  ...,  0.3280, -0.4342,  0.0382],\n",
      "         ...,\n",
      "         [ 0.5742, -0.3610, -0.2379,  ...,  0.0195,  0.3617, -0.1202],\n",
      "         [ 0.4593, -0.4138, -0.0922,  ..., -0.2665,  0.3154, -0.2618],\n",
      "         [ 0.2405, -0.2119, -0.0130,  ..., -0.2051, -0.2261, -0.3120]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1296, -0.3476,  0.0449,  ...,  0.2406,  0.1266,  0.2057],\n",
      "          [-0.1852, -0.0389,  0.0887,  ...,  0.1166,  0.3962,  0.3726]],\n",
      "\n",
      "         [[ 0.2301,  0.0262,  0.2908,  ...,  0.1548,  0.1053,  0.0799],\n",
      "          [-0.5474, -0.3536,  0.4443,  ..., -0.0725,  0.2561,  0.0928]],\n",
      "\n",
      "         [[ 0.4213, -0.2137, -0.2548,  ..., -0.1369,  0.1519,  0.4635],\n",
      "          [-0.1526, -0.0715,  0.5116,  ...,  0.5194, -0.2536,  0.0737]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3155,  0.0765, -0.1952,  ..., -0.4278, -0.4278,  0.7996],\n",
      "          [-0.3573, -0.3745,  0.0516,  ..., -0.3273,  0.2822, -0.5342]],\n",
      "\n",
      "         [[ 0.7855,  0.2012, -0.6067,  ..., -0.1078, -0.1558,  0.0721],\n",
      "          [-0.0406, -0.6935,  0.4333,  ..., -0.3252,  0.1292, -1.0608]],\n",
      "\n",
      "         [[ 0.4274, -0.1698, -0.0945,  ..., -0.3106, -0.0062,  0.0762],\n",
      "          [-0.2761, -0.1253,  0.5528,  ..., -0.1229, -0.2172, -0.3825]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1845, -0.1493,  0.0732,  ...,  0.2374,  0.0527,  0.2293],\n",
      "          [-0.1883,  0.0854,  0.2055,  ..., -0.1452,  0.4226,  0.3340]],\n",
      "\n",
      "         [[ 0.1094, -0.4966,  0.2967,  ...,  0.2317,  0.0263,  0.2123],\n",
      "          [-0.4175, -0.1293,  0.1054,  ..., -0.0716,  0.2475,  0.3641]],\n",
      "\n",
      "         [[ 0.8099,  0.2474, -0.1045,  ..., -0.2247, -0.4031,  0.4732],\n",
      "          [ 0.0017, -0.5590,  0.7160,  ...,  0.3280, -0.4342,  0.0382]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5742, -0.3610, -0.2379,  ..., -0.2285, -0.1874,  0.6558],\n",
      "          [-0.3999, -0.4694, -0.5033,  ...,  0.0195,  0.3617, -0.1202]],\n",
      "\n",
      "         [[ 0.4593, -0.4138, -0.0922,  ...,  0.2021,  0.3002,  0.3346],\n",
      "          [-0.1200, -0.2063,  0.1401,  ..., -0.2665,  0.3154, -0.2618]],\n",
      "\n",
      "         [[ 0.2405, -0.2119, -0.0130,  ..., -0.4047,  0.1020,  0.0551],\n",
      "          [-0.1083, -0.1899,  0.3737,  ..., -0.2051, -0.2261, -0.3120]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.0610e+00, -1.5907e-01, -2.5408e-02,  ...,  7.4317e-01,\n",
      "          -9.8685e-01, -1.2215e+00],\n",
      "         [ 2.0013e-01, -3.0259e-01, -2.8371e-01,  ...,  4.2884e-01,\n",
      "          -3.7704e-01, -1.4216e-01],\n",
      "         [ 1.9653e-01, -3.3418e-01,  1.2932e-01,  ...,  2.9229e-01,\n",
      "          -4.2610e-01, -1.0503e+00],\n",
      "         ...,\n",
      "         [ 3.3106e-01,  1.4507e-01, -4.6805e-01,  ...,  3.5614e-01,\n",
      "          -6.1037e-01, -3.7286e-01],\n",
      "         [ 1.7552e-01,  2.3061e-02, -2.7897e-02,  ...,  4.1878e-02,\n",
      "          -1.2294e-01, -7.9213e-01],\n",
      "         [-2.0996e-01,  1.0211e-01, -1.2302e-01,  ..., -1.2146e-01,\n",
      "          -3.3823e-02,  2.3312e-01]],\n",
      "\n",
      "        [[ 9.0098e-01, -2.0843e-01,  3.7915e-03,  ...,  6.8732e-01,\n",
      "          -8.5252e-01, -1.1661e+00],\n",
      "         [ 3.4035e-01, -3.1354e-01, -1.6899e-04,  ...,  2.4198e-01,\n",
      "          -4.2976e-01, -6.0208e-01],\n",
      "         [ 4.2130e-01, -2.2098e-02, -7.6776e-02,  ...,  2.8448e-01,\n",
      "          -2.2555e-01, -4.7073e-01],\n",
      "         ...,\n",
      "         [ 5.0422e-01,  2.6806e-01, -9.3921e-02,  ...,  2.1547e-01,\n",
      "          -7.2001e-01, -6.4407e-01],\n",
      "         [ 4.3349e-01, -4.4814e-01, -1.6228e-02,  ...,  2.4615e-01,\n",
      "          -5.2308e-01, -9.9858e-01],\n",
      "         [-2.6147e-01,  1.4844e-01, -2.4013e-01,  ..., -6.1605e-02,\n",
      "          -8.6865e-02,  2.8914e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.0610e+00, -1.5907e-01, -2.5408e-02,  ...,  7.4317e-01,\n",
      "          -9.8685e-01, -1.2215e+00],\n",
      "         [ 2.0013e-01, -3.0259e-01, -2.8371e-01,  ...,  4.2884e-01,\n",
      "          -3.7704e-01, -1.4216e-01],\n",
      "         [ 1.9653e-01, -3.3418e-01,  1.2932e-01,  ...,  2.9229e-01,\n",
      "          -4.2610e-01, -1.0503e+00],\n",
      "         ...,\n",
      "         [ 3.3106e-01,  1.4507e-01, -4.6805e-01,  ...,  3.5614e-01,\n",
      "          -6.1037e-01, -3.7286e-01],\n",
      "         [ 1.7552e-01,  2.3061e-02, -2.7897e-02,  ...,  4.1878e-02,\n",
      "          -1.2294e-01, -7.9213e-01],\n",
      "         [-2.0996e-01,  1.0211e-01, -1.2302e-01,  ..., -1.2146e-01,\n",
      "          -3.3823e-02,  2.3312e-01]],\n",
      "\n",
      "        [[ 9.0098e-01, -2.0843e-01,  3.7915e-03,  ...,  6.8732e-01,\n",
      "          -8.5252e-01, -1.1661e+00],\n",
      "         [ 3.4035e-01, -3.1354e-01, -1.6899e-04,  ...,  2.4198e-01,\n",
      "          -4.2976e-01, -6.0208e-01],\n",
      "         [ 4.2130e-01, -2.2098e-02, -7.6776e-02,  ...,  2.8448e-01,\n",
      "          -2.2555e-01, -4.7073e-01],\n",
      "         ...,\n",
      "         [ 5.0422e-01,  2.6806e-01, -9.3921e-02,  ...,  2.1547e-01,\n",
      "          -7.2001e-01, -6.4407e-01],\n",
      "         [ 4.3349e-01, -4.4814e-01, -1.6228e-02,  ...,  2.4615e-01,\n",
      "          -5.2308e-01, -9.9858e-01],\n",
      "         [-2.6147e-01,  1.4844e-01, -2.4013e-01,  ..., -6.1605e-02,\n",
      "          -8.6865e-02,  2.8914e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.0610e+00, -1.5907e-01, -2.5408e-02,  ..., -1.1472e+00,\n",
      "            1.0513e+00, -4.2695e-01],\n",
      "          [-9.7601e-01,  6.3215e-01,  6.0031e-02,  ...,  7.4317e-01,\n",
      "           -9.8685e-01, -1.2215e+00]],\n",
      "\n",
      "         [[ 2.0013e-01, -3.0259e-01, -2.8371e-01,  ..., -5.9942e-01,\n",
      "            6.6622e-01, -3.9388e-01],\n",
      "          [-5.5453e-01,  1.8570e-01, -6.5291e-02,  ...,  4.2884e-01,\n",
      "           -3.7704e-01, -1.4216e-01]],\n",
      "\n",
      "         [[ 1.9653e-01, -3.3418e-01,  1.2932e-01,  ..., -4.7686e-01,\n",
      "            7.4778e-01,  1.4588e-01],\n",
      "          [-2.2334e-01,  4.9084e-01, -1.3317e-01,  ...,  2.9229e-01,\n",
      "           -4.2610e-01, -1.0503e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3106e-01,  1.4507e-01, -4.6805e-01,  ..., -4.7975e-01,\n",
      "            3.1445e-01, -5.2910e-01],\n",
      "          [-7.8706e-01,  4.0589e-01,  8.1459e-01,  ...,  3.5614e-01,\n",
      "           -6.1037e-01, -3.7286e-01]],\n",
      "\n",
      "         [[ 1.7552e-01,  2.3061e-02, -2.7897e-02,  ..., -3.1373e-01,\n",
      "            3.9068e-01, -7.2720e-02],\n",
      "          [-8.1306e-01, -3.3096e-02,  4.1220e-01,  ...,  4.1878e-02,\n",
      "           -1.2294e-01, -7.9213e-01]],\n",
      "\n",
      "         [[-2.0996e-01,  1.0211e-01, -1.2302e-01,  ..., -9.0896e-01,\n",
      "           -1.9021e-01, -5.4238e-02],\n",
      "          [-4.2722e-01, -1.5853e-01, -4.8556e-02,  ..., -1.2146e-01,\n",
      "           -3.3823e-02,  2.3312e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0098e-01, -2.0843e-01,  3.7915e-03,  ..., -1.2549e+00,\n",
      "            8.1520e-01, -4.3378e-01],\n",
      "          [-1.0585e+00,  6.9359e-01, -1.3876e-01,  ...,  6.8732e-01,\n",
      "           -8.5252e-01, -1.1661e+00]],\n",
      "\n",
      "         [[ 3.4035e-01, -3.1354e-01, -1.6899e-04,  ..., -1.0251e+00,\n",
      "            7.9360e-01,  1.6174e-01],\n",
      "          [-7.0330e-01,  1.5868e-01,  1.2906e-01,  ...,  2.4198e-01,\n",
      "           -4.2976e-01, -6.0208e-01]],\n",
      "\n",
      "         [[ 4.2130e-01, -2.2098e-02, -7.6776e-02,  ..., -3.5541e-01,\n",
      "            3.6787e-01, -1.8402e-01],\n",
      "          [-2.9654e-01,  1.5936e-01,  7.5023e-02,  ...,  2.8448e-01,\n",
      "           -2.2555e-01, -4.7073e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.0422e-01,  2.6806e-01, -9.3921e-02,  ..., -4.0216e-01,\n",
      "            5.7104e-01, -4.6040e-01],\n",
      "          [-4.9360e-01,  4.4385e-01,  7.2012e-01,  ...,  2.1547e-01,\n",
      "           -7.2001e-01, -6.4407e-01]],\n",
      "\n",
      "         [[ 4.3349e-01, -4.4814e-01, -1.6228e-02,  ..., -4.9473e-01,\n",
      "            7.2958e-01, -1.2150e-01],\n",
      "          [-8.6630e-01,  1.0344e-01,  1.0423e-01,  ...,  2.4615e-01,\n",
      "           -5.2308e-01, -9.9858e-01]],\n",
      "\n",
      "         [[-2.6147e-01,  1.4844e-01, -2.4013e-01,  ..., -1.0034e+00,\n",
      "           -1.3694e-01, -1.2943e-01],\n",
      "          [-5.0166e-01,  9.0498e-03, -9.9190e-02,  ..., -6.1605e-02,\n",
      "           -8.6865e-02,  2.8914e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.0670e-01, -3.1779e-01,  6.4245e-01,  ...,  2.7979e-01,\n",
      "            1.5959e-01,  2.5285e-02],\n",
      "          [ 1.6861e-01, -1.6963e-02,  3.5213e-01,  ...,  4.6156e-01,\n",
      "           -2.5573e-01,  4.7012e-01],\n",
      "          [ 4.1581e-01, -2.1171e-01,  1.4186e-01,  ...,  3.2534e-01,\n",
      "            1.9945e-01, -2.1428e-02],\n",
      "          ...,\n",
      "          [-1.4616e-01, -1.9771e-02,  5.0835e-01,  ...,  6.7996e-01,\n",
      "           -5.2345e-01,  2.0017e-01],\n",
      "          [ 1.6209e-01, -2.8451e-01, -1.2371e-01,  ...,  2.2315e-01,\n",
      "            3.7742e-01,  5.7168e-02],\n",
      "          [ 1.7250e-01,  2.3260e-02,  3.8191e-01,  ...,  3.3562e-01,\n",
      "           -1.3698e-01, -1.8584e-01]],\n",
      "\n",
      "         [[ 2.6349e-01,  2.1069e-01,  2.3778e-01,  ...,  1.5909e-01,\n",
      "           -1.0933e-01,  4.6913e-01],\n",
      "          [ 6.5072e-02, -5.8003e-01,  3.7523e-01,  ...,  1.4652e-01,\n",
      "            1.0550e-01,  2.5669e-01],\n",
      "          [-3.2930e-01, -6.2543e-01, -1.4453e-01,  ...,  2.6008e-01,\n",
      "            3.0626e-01, -7.8832e-02],\n",
      "          ...,\n",
      "          [ 2.2550e-01, -4.8376e-01,  3.8079e-01,  ..., -7.1313e-02,\n",
      "            5.1546e-01,  5.8058e-01],\n",
      "          [ 3.9885e-02,  7.1847e-03,  6.1061e-04,  ...,  1.6112e-01,\n",
      "            1.8692e-01,  2.2516e-01],\n",
      "          [ 5.7895e-01, -5.7815e-01,  2.7249e-01,  ..., -4.9194e-01,\n",
      "            1.4300e-01,  7.0017e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6519e-01, -2.8056e-01,  7.5254e-01,  ...,  1.3871e-01,\n",
      "            6.1414e-02, -1.3411e-01],\n",
      "          [-2.5322e-01,  4.0769e-02,  3.0515e-01,  ...,  6.9330e-01,\n",
      "           -2.0052e-01,  3.1479e-01],\n",
      "          [ 2.8047e-01, -2.4815e-01,  2.5729e-03,  ...,  4.2425e-01,\n",
      "           -1.6065e-01,  6.0083e-01],\n",
      "          ...,\n",
      "          [-1.9647e-01, -3.4372e-02, -8.2141e-02,  ...,  6.8877e-01,\n",
      "           -3.6218e-01, -3.2390e-03],\n",
      "          [ 3.1417e-01,  2.2595e-01,  3.2591e-01,  ...,  5.4661e-01,\n",
      "           -2.3459e-01, -7.0471e-02],\n",
      "          [ 1.8429e-01,  1.2004e-01,  2.2235e-01,  ...,  2.0391e-01,\n",
      "           -6.2807e-02, -1.7221e-01]],\n",
      "\n",
      "         [[ 3.6666e-01,  2.7096e-01,  2.6185e-01,  ...,  2.1595e-01,\n",
      "           -4.4781e-02,  3.8970e-01],\n",
      "          [ 3.7219e-01, -6.2935e-01,  8.3197e-01,  ..., -1.5161e-01,\n",
      "            1.7400e-01,  4.6522e-01],\n",
      "          [ 1.1109e-01, -4.8147e-01,  2.9196e-01,  ...,  1.4235e-01,\n",
      "            4.4465e-01,  2.0160e-01],\n",
      "          ...,\n",
      "          [ 2.2533e-01, -5.4317e-01,  4.2018e-01,  ..., -9.8166e-02,\n",
      "            4.5802e-01,  8.4902e-01],\n",
      "          [-1.3693e-01,  2.0491e-02,  4.4226e-01,  ..., -8.2629e-03,\n",
      "            1.0058e-02,  1.0070e-01],\n",
      "          [ 4.8829e-01, -3.6760e-01,  1.4197e-01,  ..., -3.2772e-01,\n",
      "            3.2947e-03,  5.9769e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.3733, -0.0823, -0.1819,  ..., -0.1301, -0.0353,  0.2828],\n",
      "          [ 0.3644, -0.0976, -0.1129,  ..., -0.1026, -0.0338,  0.2820],\n",
      "          [ 0.3697, -0.1141, -0.1039,  ..., -0.1054, -0.0265,  0.2896],\n",
      "          ...,\n",
      "          [ 0.3755, -0.1036, -0.1100,  ..., -0.1129, -0.0464,  0.2938],\n",
      "          [ 0.3610, -0.0934, -0.1687,  ..., -0.1315, -0.0794,  0.2911],\n",
      "          [ 0.2559, -0.0954, -0.0503,  ..., -0.0195, -0.0271,  0.1293]],\n",
      "\n",
      "         [[-0.1659, -0.2769,  0.2621,  ..., -0.0401,  0.0095, -0.1968],\n",
      "          [-0.1972, -0.2723,  0.2814,  ..., -0.0505,  0.0201, -0.1982],\n",
      "          [-0.1862, -0.2815,  0.2558,  ..., -0.0207,  0.0445, -0.1849],\n",
      "          ...,\n",
      "          [-0.1766, -0.2879,  0.2749,  ..., -0.0590, -0.0148, -0.2583],\n",
      "          [-0.1965, -0.2699,  0.2567,  ..., -0.0286,  0.0357, -0.1795],\n",
      "          [-0.1211, -0.2226,  0.2395,  ..., -0.0378, -0.0215, -0.2030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2685, -0.2217, -0.0581,  ...,  0.0335,  0.1035,  0.1929],\n",
      "          [ 0.2971, -0.2238, -0.0401,  ...,  0.0190,  0.0749,  0.2370],\n",
      "          [ 0.3062, -0.2022, -0.0396,  ..., -0.0126,  0.0433,  0.2586],\n",
      "          ...,\n",
      "          [ 0.1939, -0.0994, -0.0374,  ..., -0.0555,  0.0284,  0.1412],\n",
      "          [ 0.2952, -0.2209, -0.0386,  ...,  0.0167,  0.0624,  0.2481],\n",
      "          [ 0.2455, -0.1842, -0.0073,  ...,  0.0288,  0.0673,  0.1925]],\n",
      "\n",
      "         [[-0.2845, -0.1522,  0.0485,  ..., -0.0045, -0.0918,  0.1209],\n",
      "          [-0.2430, -0.1570,  0.1451,  ..., -0.0665, -0.0505,  0.0482],\n",
      "          [-0.2559, -0.1209,  0.1600,  ..., -0.0761,  0.0254,  0.0040],\n",
      "          ...,\n",
      "          [-0.2314, -0.1172,  0.1353,  ..., -0.0279, -0.0876,  0.0878],\n",
      "          [-0.2648, -0.2073,  0.0695,  ..., -0.0396, -0.0764,  0.0053],\n",
      "          [-0.1034, -0.1596,  0.1704,  ..., -0.1047, -0.0286, -0.0810]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.3733, -0.0823, -0.1819,  ..., -0.1301, -0.0353,  0.2828],\n",
      "          [-0.1659, -0.2769,  0.2621,  ..., -0.0401,  0.0095, -0.1968]],\n",
      "\n",
      "         [[ 0.3644, -0.0976, -0.1129,  ..., -0.1026, -0.0338,  0.2820],\n",
      "          [-0.1972, -0.2723,  0.2814,  ..., -0.0505,  0.0201, -0.1982]],\n",
      "\n",
      "         [[ 0.3697, -0.1141, -0.1039,  ..., -0.1054, -0.0265,  0.2896],\n",
      "          [-0.1862, -0.2815,  0.2558,  ..., -0.0207,  0.0445, -0.1849]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3755, -0.1036, -0.1100,  ..., -0.1129, -0.0464,  0.2938],\n",
      "          [-0.1766, -0.2879,  0.2749,  ..., -0.0590, -0.0148, -0.2583]],\n",
      "\n",
      "         [[ 0.3610, -0.0934, -0.1687,  ..., -0.1315, -0.0794,  0.2911],\n",
      "          [-0.1965, -0.2699,  0.2567,  ..., -0.0286,  0.0357, -0.1795]],\n",
      "\n",
      "         [[ 0.2559, -0.0954, -0.0503,  ..., -0.0195, -0.0271,  0.1293],\n",
      "          [-0.1211, -0.2226,  0.2395,  ..., -0.0378, -0.0215, -0.2030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2685, -0.2217, -0.0581,  ...,  0.0335,  0.1035,  0.1929],\n",
      "          [-0.2845, -0.1522,  0.0485,  ..., -0.0045, -0.0918,  0.1209]],\n",
      "\n",
      "         [[ 0.2971, -0.2238, -0.0401,  ...,  0.0190,  0.0749,  0.2370],\n",
      "          [-0.2430, -0.1570,  0.1451,  ..., -0.0665, -0.0505,  0.0482]],\n",
      "\n",
      "         [[ 0.3062, -0.2022, -0.0396,  ..., -0.0126,  0.0433,  0.2586],\n",
      "          [-0.2559, -0.1209,  0.1600,  ..., -0.0761,  0.0254,  0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1939, -0.0994, -0.0374,  ..., -0.0555,  0.0284,  0.1412],\n",
      "          [-0.2314, -0.1172,  0.1353,  ..., -0.0279, -0.0876,  0.0878]],\n",
      "\n",
      "         [[ 0.2952, -0.2209, -0.0386,  ...,  0.0167,  0.0624,  0.2481],\n",
      "          [-0.2648, -0.2073,  0.0695,  ..., -0.0396, -0.0764,  0.0053]],\n",
      "\n",
      "         [[ 0.2455, -0.1842, -0.0073,  ...,  0.0288,  0.0673,  0.1925],\n",
      "          [-0.1034, -0.1596,  0.1704,  ..., -0.1047, -0.0286, -0.0810]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.3733, -0.0823, -0.1819,  ..., -0.1301, -0.0353,  0.2828],\n",
      "          [-0.1659, -0.2769,  0.2621,  ..., -0.0401,  0.0095, -0.1968]],\n",
      "\n",
      "         [[ 0.3644, -0.0976, -0.1129,  ..., -0.1026, -0.0338,  0.2820],\n",
      "          [-0.1972, -0.2723,  0.2814,  ..., -0.0505,  0.0201, -0.1982]],\n",
      "\n",
      "         [[ 0.3697, -0.1141, -0.1039,  ..., -0.1054, -0.0265,  0.2896],\n",
      "          [-0.1862, -0.2815,  0.2558,  ..., -0.0207,  0.0445, -0.1849]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3755, -0.1036, -0.1100,  ..., -0.1129, -0.0464,  0.2938],\n",
      "          [-0.1766, -0.2879,  0.2749,  ..., -0.0590, -0.0148, -0.2583]],\n",
      "\n",
      "         [[ 0.3610, -0.0934, -0.1687,  ..., -0.1315, -0.0794,  0.2911],\n",
      "          [-0.1965, -0.2699,  0.2567,  ..., -0.0286,  0.0357, -0.1795]],\n",
      "\n",
      "         [[ 0.2559, -0.0954, -0.0503,  ..., -0.0195, -0.0271,  0.1293],\n",
      "          [-0.1211, -0.2226,  0.2395,  ..., -0.0378, -0.0215, -0.2030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2685, -0.2217, -0.0581,  ...,  0.0335,  0.1035,  0.1929],\n",
      "          [-0.2845, -0.1522,  0.0485,  ..., -0.0045, -0.0918,  0.1209]],\n",
      "\n",
      "         [[ 0.2971, -0.2238, -0.0401,  ...,  0.0190,  0.0749,  0.2370],\n",
      "          [-0.2430, -0.1570,  0.1451,  ..., -0.0665, -0.0505,  0.0482]],\n",
      "\n",
      "         [[ 0.3062, -0.2022, -0.0396,  ..., -0.0126,  0.0433,  0.2586],\n",
      "          [-0.2559, -0.1209,  0.1600,  ..., -0.0761,  0.0254,  0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1939, -0.0994, -0.0374,  ..., -0.0555,  0.0284,  0.1412],\n",
      "          [-0.2314, -0.1172,  0.1353,  ..., -0.0279, -0.0876,  0.0878]],\n",
      "\n",
      "         [[ 0.2952, -0.2209, -0.0386,  ...,  0.0167,  0.0624,  0.2481],\n",
      "          [-0.2648, -0.2073,  0.0695,  ..., -0.0396, -0.0764,  0.0053]],\n",
      "\n",
      "         [[ 0.2455, -0.1842, -0.0073,  ...,  0.0288,  0.0673,  0.1925],\n",
      "          [-0.1034, -0.1596,  0.1704,  ..., -0.1047, -0.0286, -0.0810]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.3733, -0.0823, -0.1819,  ..., -0.1301, -0.0353,  0.2828],\n",
      "          [-0.1659, -0.2769,  0.2621,  ..., -0.0401,  0.0095, -0.1968]],\n",
      "\n",
      "         [[ 0.3644, -0.0976, -0.1129,  ..., -0.1026, -0.0338,  0.2820],\n",
      "          [-0.1972, -0.2723,  0.2814,  ..., -0.0505,  0.0201, -0.1982]],\n",
      "\n",
      "         [[ 0.3697, -0.1141, -0.1039,  ..., -0.1054, -0.0265,  0.2896],\n",
      "          [-0.1862, -0.2815,  0.2558,  ..., -0.0207,  0.0445, -0.1849]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3755, -0.1036, -0.1100,  ..., -0.1129, -0.0464,  0.2938],\n",
      "          [-0.1766, -0.2879,  0.2749,  ..., -0.0590, -0.0148, -0.2583]],\n",
      "\n",
      "         [[ 0.3610, -0.0934, -0.1687,  ..., -0.1315, -0.0794,  0.2911],\n",
      "          [-0.1965, -0.2699,  0.2567,  ..., -0.0286,  0.0357, -0.1795]],\n",
      "\n",
      "         [[ 0.2559, -0.0954, -0.0503,  ..., -0.0195, -0.0271,  0.1293],\n",
      "          [-0.1211, -0.2226,  0.2395,  ..., -0.0378, -0.0215, -0.2030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2685, -0.2217, -0.0581,  ...,  0.0335,  0.1035,  0.1929],\n",
      "          [-0.2845, -0.1522,  0.0485,  ..., -0.0045, -0.0918,  0.1209]],\n",
      "\n",
      "         [[ 0.2971, -0.2238, -0.0401,  ...,  0.0190,  0.0749,  0.2370],\n",
      "          [-0.2430, -0.1570,  0.1451,  ..., -0.0665, -0.0505,  0.0482]],\n",
      "\n",
      "         [[ 0.3062, -0.2022, -0.0396,  ..., -0.0126,  0.0433,  0.2586],\n",
      "          [-0.2559, -0.1209,  0.1600,  ..., -0.0761,  0.0254,  0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1939, -0.0994, -0.0374,  ..., -0.0555,  0.0284,  0.1412],\n",
      "          [-0.2314, -0.1172,  0.1353,  ..., -0.0279, -0.0876,  0.0878]],\n",
      "\n",
      "         [[ 0.2952, -0.2209, -0.0386,  ...,  0.0167,  0.0624,  0.2481],\n",
      "          [-0.2648, -0.2073,  0.0695,  ..., -0.0396, -0.0764,  0.0053]],\n",
      "\n",
      "         [[ 0.2455, -0.1842, -0.0073,  ...,  0.0288,  0.0673,  0.1925],\n",
      "          [-0.1034, -0.1596,  0.1704,  ..., -0.1047, -0.0286, -0.0810]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[-3.5149e-01,  1.3535e-02,  2.1269e-01,  ..., -4.8528e-02,\n",
      "          -4.5513e-01, -2.0651e-01],\n",
      "         [ 2.8497e-01, -1.8839e-01,  5.3453e-01,  ..., -2.5787e-01,\n",
      "          -4.5145e-01, -5.0650e-02],\n",
      "         [ 6.8062e-02,  4.4710e-02,  5.8501e-01,  ..., -3.8344e-01,\n",
      "          -6.6075e-02,  1.2356e-01],\n",
      "         ...,\n",
      "         [ 7.4687e-01,  2.7346e-01,  8.5444e-01,  ..., -7.4115e-01,\n",
      "          -9.5171e-01, -1.8169e-01],\n",
      "         [-2.5163e-01, -1.7736e-01,  7.5200e-02,  ..., -1.6345e-01,\n",
      "          -1.2531e-01,  2.3155e-01],\n",
      "         [-4.5745e-02, -2.7469e-01,  3.1014e-01,  ...,  1.3673e-01,\n",
      "          -7.4071e-01,  4.6657e-01]],\n",
      "\n",
      "        [[-2.9065e-01,  1.0818e-01,  3.2399e-01,  ..., -2.2797e-01,\n",
      "          -1.2493e-01, -2.0100e-01],\n",
      "         [ 3.9058e-01,  1.9583e-01,  9.8670e-01,  ..., -1.1173e-01,\n",
      "          -8.8588e-01, -9.7975e-04],\n",
      "         [ 2.9839e-02, -3.5070e-01,  2.7439e-01,  ..., -3.7578e-01,\n",
      "          -6.8767e-01,  2.8722e-01],\n",
      "         ...,\n",
      "         [ 2.1292e-01,  3.9013e-01,  8.0525e-01,  ..., -3.0856e-01,\n",
      "          -3.6335e-01,  1.7987e-02],\n",
      "         [-2.5244e-01,  1.7271e-01,  1.8940e-01,  ..., -1.6769e-02,\n",
      "          -2.0287e-01,  1.2350e-01],\n",
      "         [-1.1714e-01, -3.1966e-01,  2.6585e-01,  ..., -9.3721e-02,\n",
      "          -7.4782e-01,  4.0978e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-3.5149e-01,  1.3535e-02,  2.1269e-01,  ..., -4.8528e-02,\n",
      "          -4.5513e-01, -2.0651e-01],\n",
      "         [ 2.8497e-01, -1.8839e-01,  5.3453e-01,  ..., -2.5787e-01,\n",
      "          -4.5145e-01, -5.0650e-02],\n",
      "         [ 6.8062e-02,  4.4710e-02,  5.8501e-01,  ..., -3.8344e-01,\n",
      "          -6.6075e-02,  1.2356e-01],\n",
      "         ...,\n",
      "         [ 7.4687e-01,  2.7346e-01,  8.5444e-01,  ..., -7.4115e-01,\n",
      "          -9.5171e-01, -1.8169e-01],\n",
      "         [-2.5163e-01, -1.7736e-01,  7.5200e-02,  ..., -1.6345e-01,\n",
      "          -1.2531e-01,  2.3155e-01],\n",
      "         [-4.5745e-02, -2.7469e-01,  3.1014e-01,  ...,  1.3673e-01,\n",
      "          -7.4071e-01,  4.6657e-01]],\n",
      "\n",
      "        [[-2.9065e-01,  1.0818e-01,  3.2399e-01,  ..., -2.2797e-01,\n",
      "          -1.2493e-01, -2.0100e-01],\n",
      "         [ 3.9058e-01,  1.9583e-01,  9.8670e-01,  ..., -1.1173e-01,\n",
      "          -8.8588e-01, -9.7975e-04],\n",
      "         [ 2.9839e-02, -3.5070e-01,  2.7439e-01,  ..., -3.7578e-01,\n",
      "          -6.8767e-01,  2.8722e-01],\n",
      "         ...,\n",
      "         [ 2.1292e-01,  3.9013e-01,  8.0525e-01,  ..., -3.0856e-01,\n",
      "          -3.6335e-01,  1.7987e-02],\n",
      "         [-2.5244e-01,  1.7271e-01,  1.8940e-01,  ..., -1.6769e-02,\n",
      "          -2.0287e-01,  1.2350e-01],\n",
      "         [-1.1714e-01, -3.1966e-01,  2.6585e-01,  ..., -9.3721e-02,\n",
      "          -7.4782e-01,  4.0978e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-3.5149e-01,  1.3535e-02,  2.1269e-01,  ..., -1.2527e-01,\n",
      "           -1.2235e-01, -1.6120e-01],\n",
      "          [ 5.7657e-01, -2.4809e-01,  2.3552e-01,  ..., -4.8528e-02,\n",
      "           -4.5513e-01, -2.0651e-01]],\n",
      "\n",
      "         [[ 2.8497e-01, -1.8839e-01,  5.3453e-01,  ..., -1.1431e-01,\n",
      "            2.2897e-01,  7.4397e-02],\n",
      "          [ 2.6628e-01, -1.1168e-01, -9.3878e-02,  ..., -2.5787e-01,\n",
      "           -4.5145e-01, -5.0650e-02]],\n",
      "\n",
      "         [[ 6.8062e-02,  4.4710e-02,  5.8501e-01,  ...,  2.3804e-01,\n",
      "           -1.5696e-01,  2.7390e-01],\n",
      "          [ 6.8497e-01, -5.5063e-01,  4.5870e-01,  ..., -3.8344e-01,\n",
      "           -6.6075e-02,  1.2356e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.4687e-01,  2.7346e-01,  8.5444e-01,  ..., -4.6125e-01,\n",
      "            2.6812e-01, -3.0020e-01],\n",
      "          [ 2.7060e-01, -1.0179e-01, -1.8004e-01,  ..., -7.4115e-01,\n",
      "           -9.5171e-01, -1.8169e-01]],\n",
      "\n",
      "         [[-2.5163e-01, -1.7736e-01,  7.5200e-02,  ..., -7.4184e-02,\n",
      "            1.8480e-01,  3.8655e-01],\n",
      "          [ 1.0450e-01,  5.6679e-03,  4.5218e-01,  ..., -1.6345e-01,\n",
      "           -1.2531e-01,  2.3155e-01]],\n",
      "\n",
      "         [[-4.5745e-02, -2.7469e-01,  3.1014e-01,  ..., -3.0868e-01,\n",
      "            5.4507e-02,  9.3502e-02],\n",
      "          [ 1.1511e-01, -1.4470e-01,  1.4323e-01,  ...,  1.3673e-01,\n",
      "           -7.4071e-01,  4.6657e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9065e-01,  1.0818e-01,  3.2399e-01,  ..., -2.1980e-01,\n",
      "           -1.3431e-01, -8.5589e-02],\n",
      "          [ 5.6805e-01, -5.0660e-01,  2.8928e-01,  ..., -2.2797e-01,\n",
      "           -1.2493e-01, -2.0100e-01]],\n",
      "\n",
      "         [[ 3.9058e-01,  1.9583e-01,  9.8670e-01,  ..., -4.5200e-01,\n",
      "            2.8859e-01,  2.4073e-01],\n",
      "          [ 2.5588e-01, -1.2689e-01, -2.9947e-01,  ..., -1.1173e-01,\n",
      "           -8.8588e-01, -9.7975e-04]],\n",
      "\n",
      "         [[ 2.9839e-02, -3.5070e-01,  2.7439e-01,  ...,  3.7089e-02,\n",
      "            1.8700e-01,  4.2900e-01],\n",
      "          [ 1.8656e-01, -4.6511e-01, -3.2247e-01,  ..., -3.7578e-01,\n",
      "           -6.8767e-01,  2.8722e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1292e-01,  3.9013e-01,  8.0525e-01,  ..., -1.7360e-01,\n",
      "            5.5543e-01,  8.1959e-02],\n",
      "          [ 5.7266e-01, -1.0547e-01,  5.6103e-01,  ..., -3.0856e-01,\n",
      "           -3.6335e-01,  1.7987e-02]],\n",
      "\n",
      "         [[-2.5244e-01,  1.7271e-01,  1.8940e-01,  ...,  8.2510e-02,\n",
      "            2.5208e-01,  2.6945e-01],\n",
      "          [ 5.1674e-01, -1.1492e-01,  6.8401e-01,  ..., -1.6769e-02,\n",
      "           -2.0287e-01,  1.2350e-01]],\n",
      "\n",
      "         [[-1.1714e-01, -3.1966e-01,  2.6585e-01,  ..., -3.2750e-01,\n",
      "           -8.2915e-02,  8.7605e-02],\n",
      "          [ 1.9843e-01, -1.9145e-01,  1.6058e-01,  ..., -9.3721e-02,\n",
      "           -7.4782e-01,  4.0978e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5566,  0.0086, -0.0583,  ..., -0.0637,  0.3626, -0.2675],\n",
      "         [ 0.5066, -0.3063, -0.3927,  ..., -0.6020,  0.3018, -0.0643],\n",
      "         [ 0.8070, -0.3432,  0.1610,  ...,  0.1462,  0.2882,  0.3783],\n",
      "         ...,\n",
      "         [ 0.8737, -0.6378, -0.2099,  ..., -0.0943,  0.3818,  0.2771],\n",
      "         [ 0.9818, -0.9275, -0.4327,  ..., -0.4851,  0.5079,  0.6028],\n",
      "         [ 0.8391, -0.3945,  0.0469,  ..., -0.2663,  0.7303,  0.0501]],\n",
      "\n",
      "        [[ 0.2666,  0.1129,  0.3826,  ...,  0.2311,  0.5226, -0.5310],\n",
      "         [ 0.3388, -0.0484,  0.2839,  ...,  0.0736,  0.0997, -0.5758],\n",
      "         [ 0.8131, -0.7666,  0.0036,  ..., -0.1125,  0.3355,  0.1614],\n",
      "         ...,\n",
      "         [ 0.5673, -0.2257,  0.0132,  ...,  0.3488,  0.2031, -0.3599],\n",
      "         [ 0.4259, -0.2272,  0.1201,  ..., -0.3116, -0.0140,  0.3310],\n",
      "         [ 0.9088, -0.1469,  0.2940,  ..., -0.1127,  0.6136, -0.0609]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5566,  0.0086, -0.0583,  ..., -0.0637,  0.3626, -0.2675],\n",
      "         [ 0.5066, -0.3063, -0.3927,  ..., -0.6020,  0.3018, -0.0643],\n",
      "         [ 0.8070, -0.3432,  0.1610,  ...,  0.1462,  0.2882,  0.3783],\n",
      "         ...,\n",
      "         [ 0.8737, -0.6378, -0.2099,  ..., -0.0943,  0.3818,  0.2771],\n",
      "         [ 0.9818, -0.9275, -0.4327,  ..., -0.4851,  0.5079,  0.6028],\n",
      "         [ 0.8391, -0.3945,  0.0469,  ..., -0.2663,  0.7303,  0.0501]],\n",
      "\n",
      "        [[ 0.2666,  0.1129,  0.3826,  ...,  0.2311,  0.5226, -0.5310],\n",
      "         [ 0.3388, -0.0484,  0.2839,  ...,  0.0736,  0.0997, -0.5758],\n",
      "         [ 0.8131, -0.7666,  0.0036,  ..., -0.1125,  0.3355,  0.1614],\n",
      "         ...,\n",
      "         [ 0.5673, -0.2257,  0.0132,  ...,  0.3488,  0.2031, -0.3599],\n",
      "         [ 0.4259, -0.2272,  0.1201,  ..., -0.3116, -0.0140,  0.3310],\n",
      "         [ 0.9088, -0.1469,  0.2940,  ..., -0.1127,  0.6136, -0.0609]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5566,  0.0086, -0.0583,  ..., -0.0116,  0.2095, -0.0614],\n",
      "          [-0.2040, -0.3693,  0.1322,  ..., -0.0637,  0.3626, -0.2675]],\n",
      "\n",
      "         [[ 0.5066, -0.3063, -0.3927,  ...,  0.1785, -0.6170, -0.0262],\n",
      "          [-0.4045, -0.4241, -0.1194,  ..., -0.6020,  0.3018, -0.0643]],\n",
      "\n",
      "         [[ 0.8070, -0.3432,  0.1610,  ...,  0.7237, -0.3434, -0.0250],\n",
      "          [-0.5037, -0.0222,  0.3642,  ...,  0.1462,  0.2882,  0.3783]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8737, -0.6378, -0.2099,  ...,  0.6743, -0.2401, -0.1775],\n",
      "          [-0.4380,  0.0048,  0.1343,  ..., -0.0943,  0.3818,  0.2771]],\n",
      "\n",
      "         [[ 0.9818, -0.9275, -0.4327,  ...,  0.9280, -0.7900, -0.5008],\n",
      "          [-1.1687,  0.0871,  0.3710,  ..., -0.4851,  0.5079,  0.6028]],\n",
      "\n",
      "         [[ 0.8391, -0.3945,  0.0469,  ...,  1.0190, -0.2415, -0.1486],\n",
      "          [-0.2092, -0.6184,  0.1523,  ..., -0.2663,  0.7303,  0.0501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2666,  0.1129,  0.3826,  ..., -0.2324,  0.4160, -0.0610],\n",
      "          [ 0.0466, -0.3873,  0.0698,  ...,  0.2311,  0.5226, -0.5310]],\n",
      "\n",
      "         [[ 0.3388, -0.0484,  0.2839,  ..., -0.1013,  0.0119, -0.0639],\n",
      "          [-0.0050, -0.4743, -0.0315,  ...,  0.0736,  0.0997, -0.5758]],\n",
      "\n",
      "         [[ 0.8131, -0.7666,  0.0036,  ...,  0.9334, -0.4517, -0.2735],\n",
      "          [-0.5805,  0.2194,  0.2533,  ..., -0.1125,  0.3355,  0.1614]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5673, -0.2257,  0.0132,  ...,  0.4658, -0.1353,  0.0354],\n",
      "          [-0.4456, -0.2102, -0.3910,  ...,  0.3488,  0.2031, -0.3599]],\n",
      "\n",
      "         [[ 0.4259, -0.2272,  0.1201,  ...,  0.4186,  0.0988, -0.1894],\n",
      "          [-0.3374, -0.3655, -0.1847,  ..., -0.3116, -0.0140,  0.3310]],\n",
      "\n",
      "         [[ 0.9088, -0.1469,  0.2940,  ...,  0.7913, -0.1227,  0.0467],\n",
      "          [ 0.0839, -0.6306,  0.0637,  ..., -0.1127,  0.6136, -0.0609]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.0833, -0.8044, -1.1001,  ...,  0.0267,  1.5316, -0.4518],\n",
      "         [-0.2894, -0.0455, -0.3938,  ...,  0.0953,  1.0325,  0.0470],\n",
      "         [-0.4297, -0.1802, -0.3876,  ..., -0.2330,  0.5212, -0.0318],\n",
      "         ...,\n",
      "         [-0.5874, -0.3576, -0.0133,  ..., -0.0097,  0.8431, -0.4561],\n",
      "         [-0.3315, -0.1517,  0.0181,  ...,  0.1974,  0.5656,  0.0558],\n",
      "         [-0.0294, -0.4586, -0.0647,  ...,  0.0549,  0.7168, -0.1772]],\n",
      "\n",
      "        [[-1.3529, -0.7348, -1.0414,  ..., -0.0781,  1.2461, -0.4994],\n",
      "         [-0.4042, -0.4491, -0.5911,  ..., -0.0243,  0.8381, -0.1988],\n",
      "         [-0.1763, -0.1474, -0.3635,  ..., -0.1340,  0.2187, -0.0450],\n",
      "         ...,\n",
      "         [-0.6653, -0.3094, -0.2829,  ..., -0.1051,  1.0977, -0.4264],\n",
      "         [-0.4373, -0.3617, -0.5690,  ...,  0.0885,  0.5336, -0.0462],\n",
      "         [-0.0690, -0.5347, -0.0614,  ...,  0.0948,  0.7922, -0.1514]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.0833, -0.8044, -1.1001,  ...,  0.0267,  1.5316, -0.4518],\n",
      "         [-0.2894, -0.0455, -0.3938,  ...,  0.0953,  1.0325,  0.0470],\n",
      "         [-0.4297, -0.1802, -0.3876,  ..., -0.2330,  0.5212, -0.0318],\n",
      "         ...,\n",
      "         [-0.5874, -0.3576, -0.0133,  ..., -0.0097,  0.8431, -0.4561],\n",
      "         [-0.3315, -0.1517,  0.0181,  ...,  0.1974,  0.5656,  0.0558],\n",
      "         [-0.0294, -0.4586, -0.0647,  ...,  0.0549,  0.7168, -0.1772]],\n",
      "\n",
      "        [[-1.3529, -0.7348, -1.0414,  ..., -0.0781,  1.2461, -0.4994],\n",
      "         [-0.4042, -0.4491, -0.5911,  ..., -0.0243,  0.8381, -0.1988],\n",
      "         [-0.1763, -0.1474, -0.3635,  ..., -0.1340,  0.2187, -0.0450],\n",
      "         ...,\n",
      "         [-0.6653, -0.3094, -0.2829,  ..., -0.1051,  1.0977, -0.4264],\n",
      "         [-0.4373, -0.3617, -0.5690,  ...,  0.0885,  0.5336, -0.0462],\n",
      "         [-0.0690, -0.5347, -0.0614,  ...,  0.0948,  0.7922, -0.1514]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.0833, -0.8044, -1.1001,  ...,  0.5422, -0.4227,  0.5613],\n",
      "          [ 0.3408,  0.6002,  1.0115,  ...,  0.0267,  1.5316, -0.4518]],\n",
      "\n",
      "         [[-0.2894, -0.0455, -0.3938,  ..., -0.0673, -0.4349, -0.0431],\n",
      "          [ 0.4748,  0.3419,  0.5987,  ...,  0.0953,  1.0325,  0.0470]],\n",
      "\n",
      "         [[-0.4297, -0.1802, -0.3876,  ...,  0.3703, -0.0181, -0.1154],\n",
      "          [-0.1441,  0.2734,  0.3505,  ..., -0.2330,  0.5212, -0.0318]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5874, -0.3576, -0.0133,  ...,  0.4841, -0.1785, -0.2256],\n",
      "          [ 0.0606,  0.2273, -0.2625,  ..., -0.0097,  0.8431, -0.4561]],\n",
      "\n",
      "         [[-0.3315, -0.1517,  0.0181,  ...,  0.4464, -0.1776, -0.0231],\n",
      "          [ 0.1014,  0.1722,  0.0712,  ...,  0.1974,  0.5656,  0.0558]],\n",
      "\n",
      "         [[-0.0294, -0.4586, -0.0647,  ...,  0.6600, -0.1888, -0.2556],\n",
      "          [-0.2461, -0.1705, -0.1773,  ...,  0.0549,  0.7168, -0.1772]]],\n",
      "\n",
      "\n",
      "        [[[-1.3529, -0.7348, -1.0414,  ...,  0.5606, -0.4022,  0.6764],\n",
      "          [ 0.6400,  0.3793,  0.7863,  ..., -0.0781,  1.2461, -0.4994]],\n",
      "\n",
      "         [[-0.4042, -0.4491, -0.5911,  ...,  0.1768, -0.2724,  0.0494],\n",
      "          [ 0.2328,  0.1981,  0.4313,  ..., -0.0243,  0.8381, -0.1988]],\n",
      "\n",
      "         [[-0.1763, -0.1474, -0.3635,  ...,  0.1469, -0.2832, -0.0902],\n",
      "          [-0.1487,  0.2733,  0.1161,  ..., -0.1340,  0.2187, -0.0450]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6653, -0.3094, -0.2829,  ...,  0.4970, -0.2861, -0.2001],\n",
      "          [ 0.3320,  0.5404,  0.1344,  ..., -0.1051,  1.0977, -0.4264]],\n",
      "\n",
      "         [[-0.4373, -0.3617, -0.5690,  ...,  0.7282, -0.6536,  0.1215],\n",
      "          [ 0.0682,  0.1438,  0.3859,  ...,  0.0885,  0.5336, -0.0462]],\n",
      "\n",
      "         [[-0.0690, -0.5347, -0.0614,  ...,  0.5861, -0.1262, -0.3218],\n",
      "          [-0.2225, -0.2051, -0.2432,  ...,  0.0948,  0.7922, -0.1514]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-3.5149e-01,  1.3535e-02,  2.1269e-01,  ..., -1.2527e-01,\n",
      "           -1.2235e-01, -1.6120e-01],\n",
      "          [ 2.8497e-01, -1.8839e-01,  5.3453e-01,  ..., -1.1431e-01,\n",
      "            2.2897e-01,  7.4397e-02],\n",
      "          [ 6.8062e-02,  4.4710e-02,  5.8501e-01,  ...,  2.3804e-01,\n",
      "           -1.5696e-01,  2.7390e-01],\n",
      "          ...,\n",
      "          [ 7.4687e-01,  2.7346e-01,  8.5444e-01,  ..., -4.6125e-01,\n",
      "            2.6812e-01, -3.0020e-01],\n",
      "          [-2.5163e-01, -1.7736e-01,  7.5200e-02,  ..., -7.4184e-02,\n",
      "            1.8480e-01,  3.8655e-01],\n",
      "          [-4.5745e-02, -2.7469e-01,  3.1014e-01,  ..., -3.0868e-01,\n",
      "            5.4507e-02,  9.3502e-02]],\n",
      "\n",
      "         [[ 5.7657e-01, -2.4809e-01,  2.3552e-01,  ..., -4.8528e-02,\n",
      "           -4.5513e-01, -2.0651e-01],\n",
      "          [ 2.6628e-01, -1.1168e-01, -9.3878e-02,  ..., -2.5787e-01,\n",
      "           -4.5145e-01, -5.0650e-02],\n",
      "          [ 6.8497e-01, -5.5063e-01,  4.5870e-01,  ..., -3.8344e-01,\n",
      "           -6.6075e-02,  1.2356e-01],\n",
      "          ...,\n",
      "          [ 2.7060e-01, -1.0179e-01, -1.8004e-01,  ..., -7.4115e-01,\n",
      "           -9.5171e-01, -1.8169e-01],\n",
      "          [ 1.0450e-01,  5.6679e-03,  4.5218e-01,  ..., -1.6345e-01,\n",
      "           -1.2531e-01,  2.3155e-01],\n",
      "          [ 1.1511e-01, -1.4470e-01,  1.4323e-01,  ...,  1.3673e-01,\n",
      "           -7.4071e-01,  4.6657e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9065e-01,  1.0818e-01,  3.2399e-01,  ..., -2.1980e-01,\n",
      "           -1.3431e-01, -8.5589e-02],\n",
      "          [ 3.9058e-01,  1.9583e-01,  9.8670e-01,  ..., -4.5200e-01,\n",
      "            2.8859e-01,  2.4073e-01],\n",
      "          [ 2.9839e-02, -3.5070e-01,  2.7439e-01,  ...,  3.7089e-02,\n",
      "            1.8700e-01,  4.2900e-01],\n",
      "          ...,\n",
      "          [ 2.1292e-01,  3.9013e-01,  8.0525e-01,  ..., -1.7360e-01,\n",
      "            5.5543e-01,  8.1959e-02],\n",
      "          [-2.5244e-01,  1.7271e-01,  1.8940e-01,  ...,  8.2510e-02,\n",
      "            2.5208e-01,  2.6945e-01],\n",
      "          [-1.1714e-01, -3.1966e-01,  2.6585e-01,  ..., -3.2750e-01,\n",
      "           -8.2915e-02,  8.7605e-02]],\n",
      "\n",
      "         [[ 5.6805e-01, -5.0660e-01,  2.8928e-01,  ..., -2.2797e-01,\n",
      "           -1.2493e-01, -2.0100e-01],\n",
      "          [ 2.5588e-01, -1.2689e-01, -2.9947e-01,  ..., -1.1173e-01,\n",
      "           -8.8588e-01, -9.7975e-04],\n",
      "          [ 1.8656e-01, -4.6511e-01, -3.2247e-01,  ..., -3.7578e-01,\n",
      "           -6.8767e-01,  2.8722e-01],\n",
      "          ...,\n",
      "          [ 5.7266e-01, -1.0547e-01,  5.6103e-01,  ..., -3.0856e-01,\n",
      "           -3.6335e-01,  1.7987e-02],\n",
      "          [ 5.1674e-01, -1.1492e-01,  6.8401e-01,  ..., -1.6769e-02,\n",
      "           -2.0287e-01,  1.2350e-01],\n",
      "          [ 1.9843e-01, -1.9145e-01,  1.6058e-01,  ..., -9.3721e-02,\n",
      "           -7.4782e-01,  4.0978e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.8699, -0.5068, -0.2046,  ...,  0.6391, -0.3274, -0.2343],\n",
      "          [ 0.8575, -0.5128, -0.1746,  ...,  0.6398, -0.3379, -0.2000],\n",
      "          [ 0.7438, -0.4646, -0.1937,  ...,  0.5410, -0.2950, -0.1893],\n",
      "          ...,\n",
      "          [ 0.6112, -0.2730, -0.0653,  ...,  0.4353, -0.1412, -0.1095],\n",
      "          [ 0.7435, -0.4629, -0.1841,  ...,  0.5394, -0.2898, -0.1817],\n",
      "          [ 0.7923, -0.5064, -0.1479,  ...,  0.6397, -0.3544, -0.1778]],\n",
      "\n",
      "         [[-0.6354, -0.2099,  0.1367,  ..., -0.0077,  0.5395,  0.0875],\n",
      "          [-0.5898, -0.2149,  0.1546,  ..., -0.0331,  0.5079,  0.1194],\n",
      "          [-0.5932, -0.2153,  0.1507,  ..., -0.0469,  0.5188,  0.1098],\n",
      "          ...,\n",
      "          [-0.5893, -0.2093,  0.1558,  ..., -0.0407,  0.5108,  0.1153],\n",
      "          [-0.5703, -0.2167,  0.1556,  ..., -0.0401,  0.5058,  0.1139],\n",
      "          [-0.5145, -0.2331,  0.1326,  ..., -0.0245,  0.4773,  0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4368, -0.1161,  0.0458,  ...,  0.3081,  0.2000,  0.0925],\n",
      "          [ 0.3377, -0.0952,  0.0440,  ...,  0.2405,  0.1032,  0.0864],\n",
      "          [ 0.4496, -0.1554,  0.0721,  ...,  0.3376,  0.0892,  0.0537],\n",
      "          ...,\n",
      "          [ 0.3160, -0.1023,  0.0953,  ...,  0.2309,  0.0733, -0.0343],\n",
      "          [ 0.3790, -0.0781,  0.1035,  ...,  0.2481,  0.1428,  0.0554],\n",
      "          [ 0.4222, -0.1609,  0.0226,  ...,  0.3447,  0.0745,  0.0400]],\n",
      "\n",
      "         [[-0.1124, -0.3212, -0.0194,  ...,  0.0438,  0.1700, -0.2398],\n",
      "          [-0.2123, -0.3919, -0.0260,  ...,  0.0963,  0.3335, -0.2699],\n",
      "          [-0.2095, -0.3602, -0.0181,  ...,  0.0864,  0.3186, -0.2390],\n",
      "          ...,\n",
      "          [-0.2015, -0.4020, -0.0223,  ...,  0.1070,  0.3297, -0.2911],\n",
      "          [-0.1580, -0.3381,  0.0062,  ...,  0.1460,  0.3335, -0.3287],\n",
      "          [-0.1481, -0.2807,  0.0217,  ...,  0.0602,  0.2973, -0.1464]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.8699, -0.5068, -0.2046,  ...,  0.6391, -0.3274, -0.2343],\n",
      "          [-0.6354, -0.2099,  0.1367,  ..., -0.0077,  0.5395,  0.0875]],\n",
      "\n",
      "         [[ 0.8575, -0.5128, -0.1746,  ...,  0.6398, -0.3379, -0.2000],\n",
      "          [-0.5898, -0.2149,  0.1546,  ..., -0.0331,  0.5079,  0.1194]],\n",
      "\n",
      "         [[ 0.7438, -0.4646, -0.1937,  ...,  0.5410, -0.2950, -0.1893],\n",
      "          [-0.5932, -0.2153,  0.1507,  ..., -0.0469,  0.5188,  0.1098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6112, -0.2730, -0.0653,  ...,  0.4353, -0.1412, -0.1095],\n",
      "          [-0.5893, -0.2093,  0.1558,  ..., -0.0407,  0.5108,  0.1153]],\n",
      "\n",
      "         [[ 0.7435, -0.4629, -0.1841,  ...,  0.5394, -0.2898, -0.1817],\n",
      "          [-0.5703, -0.2167,  0.1556,  ..., -0.0401,  0.5058,  0.1139]],\n",
      "\n",
      "         [[ 0.7923, -0.5064, -0.1479,  ...,  0.6397, -0.3544, -0.1778],\n",
      "          [-0.5145, -0.2331,  0.1326,  ..., -0.0245,  0.4773,  0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4368, -0.1161,  0.0458,  ...,  0.3081,  0.2000,  0.0925],\n",
      "          [-0.1124, -0.3212, -0.0194,  ...,  0.0438,  0.1700, -0.2398]],\n",
      "\n",
      "         [[ 0.3377, -0.0952,  0.0440,  ...,  0.2405,  0.1032,  0.0864],\n",
      "          [-0.2123, -0.3919, -0.0260,  ...,  0.0963,  0.3335, -0.2699]],\n",
      "\n",
      "         [[ 0.4496, -0.1554,  0.0721,  ...,  0.3376,  0.0892,  0.0537],\n",
      "          [-0.2095, -0.3602, -0.0181,  ...,  0.0864,  0.3186, -0.2390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3160, -0.1023,  0.0953,  ...,  0.2309,  0.0733, -0.0343],\n",
      "          [-0.2015, -0.4020, -0.0223,  ...,  0.1070,  0.3297, -0.2911]],\n",
      "\n",
      "         [[ 0.3790, -0.0781,  0.1035,  ...,  0.2481,  0.1428,  0.0554],\n",
      "          [-0.1580, -0.3381,  0.0062,  ...,  0.1460,  0.3335, -0.3287]],\n",
      "\n",
      "         [[ 0.4222, -0.1609,  0.0226,  ...,  0.3447,  0.0745,  0.0400],\n",
      "          [-0.1481, -0.2807,  0.0217,  ...,  0.0602,  0.2973, -0.1464]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.8699, -0.5068, -0.2046,  ...,  0.6391, -0.3274, -0.2343],\n",
      "          [-0.6354, -0.2099,  0.1367,  ..., -0.0077,  0.5395,  0.0875]],\n",
      "\n",
      "         [[ 0.8575, -0.5128, -0.1746,  ...,  0.6398, -0.3379, -0.2000],\n",
      "          [-0.5898, -0.2149,  0.1546,  ..., -0.0331,  0.5079,  0.1194]],\n",
      "\n",
      "         [[ 0.7438, -0.4646, -0.1937,  ...,  0.5410, -0.2950, -0.1893],\n",
      "          [-0.5932, -0.2153,  0.1507,  ..., -0.0469,  0.5188,  0.1098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6112, -0.2730, -0.0653,  ...,  0.4353, -0.1412, -0.1095],\n",
      "          [-0.5893, -0.2093,  0.1558,  ..., -0.0407,  0.5108,  0.1153]],\n",
      "\n",
      "         [[ 0.7435, -0.4629, -0.1841,  ...,  0.5394, -0.2898, -0.1817],\n",
      "          [-0.5703, -0.2167,  0.1556,  ..., -0.0401,  0.5058,  0.1139]],\n",
      "\n",
      "         [[ 0.7923, -0.5064, -0.1479,  ...,  0.6397, -0.3544, -0.1778],\n",
      "          [-0.5145, -0.2331,  0.1326,  ..., -0.0245,  0.4773,  0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4368, -0.1161,  0.0458,  ...,  0.3081,  0.2000,  0.0925],\n",
      "          [-0.1124, -0.3212, -0.0194,  ...,  0.0438,  0.1700, -0.2398]],\n",
      "\n",
      "         [[ 0.3377, -0.0952,  0.0440,  ...,  0.2405,  0.1032,  0.0864],\n",
      "          [-0.2123, -0.3919, -0.0260,  ...,  0.0963,  0.3335, -0.2699]],\n",
      "\n",
      "         [[ 0.4496, -0.1554,  0.0721,  ...,  0.3376,  0.0892,  0.0537],\n",
      "          [-0.2095, -0.3602, -0.0181,  ...,  0.0864,  0.3186, -0.2390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3160, -0.1023,  0.0953,  ...,  0.2309,  0.0733, -0.0343],\n",
      "          [-0.2015, -0.4020, -0.0223,  ...,  0.1070,  0.3297, -0.2911]],\n",
      "\n",
      "         [[ 0.3790, -0.0781,  0.1035,  ...,  0.2481,  0.1428,  0.0554],\n",
      "          [-0.1580, -0.3381,  0.0062,  ...,  0.1460,  0.3335, -0.3287]],\n",
      "\n",
      "         [[ 0.4222, -0.1609,  0.0226,  ...,  0.3447,  0.0745,  0.0400],\n",
      "          [-0.1481, -0.2807,  0.0217,  ...,  0.0602,  0.2973, -0.1464]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.8699, -0.5068, -0.2046,  ...,  0.6391, -0.3274, -0.2343],\n",
      "          [-0.6354, -0.2099,  0.1367,  ..., -0.0077,  0.5395,  0.0875]],\n",
      "\n",
      "         [[ 0.8575, -0.5128, -0.1746,  ...,  0.6398, -0.3379, -0.2000],\n",
      "          [-0.5898, -0.2149,  0.1546,  ..., -0.0331,  0.5079,  0.1194]],\n",
      "\n",
      "         [[ 0.7438, -0.4646, -0.1937,  ...,  0.5410, -0.2950, -0.1893],\n",
      "          [-0.5932, -0.2153,  0.1507,  ..., -0.0469,  0.5188,  0.1098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6112, -0.2730, -0.0653,  ...,  0.4353, -0.1412, -0.1095],\n",
      "          [-0.5893, -0.2093,  0.1558,  ..., -0.0407,  0.5108,  0.1153]],\n",
      "\n",
      "         [[ 0.7435, -0.4629, -0.1841,  ...,  0.5394, -0.2898, -0.1817],\n",
      "          [-0.5703, -0.2167,  0.1556,  ..., -0.0401,  0.5058,  0.1139]],\n",
      "\n",
      "         [[ 0.7923, -0.5064, -0.1479,  ...,  0.6397, -0.3544, -0.1778],\n",
      "          [-0.5145, -0.2331,  0.1326,  ..., -0.0245,  0.4773,  0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4368, -0.1161,  0.0458,  ...,  0.3081,  0.2000,  0.0925],\n",
      "          [-0.1124, -0.3212, -0.0194,  ...,  0.0438,  0.1700, -0.2398]],\n",
      "\n",
      "         [[ 0.3377, -0.0952,  0.0440,  ...,  0.2405,  0.1032,  0.0864],\n",
      "          [-0.2123, -0.3919, -0.0260,  ...,  0.0963,  0.3335, -0.2699]],\n",
      "\n",
      "         [[ 0.4496, -0.1554,  0.0721,  ...,  0.3376,  0.0892,  0.0537],\n",
      "          [-0.2095, -0.3602, -0.0181,  ...,  0.0864,  0.3186, -0.2390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3160, -0.1023,  0.0953,  ...,  0.2309,  0.0733, -0.0343],\n",
      "          [-0.2015, -0.4020, -0.0223,  ...,  0.1070,  0.3297, -0.2911]],\n",
      "\n",
      "         [[ 0.3790, -0.0781,  0.1035,  ...,  0.2481,  0.1428,  0.0554],\n",
      "          [-0.1580, -0.3381,  0.0062,  ...,  0.1460,  0.3335, -0.3287]],\n",
      "\n",
      "         [[ 0.4222, -0.1609,  0.0226,  ...,  0.3447,  0.0745,  0.0400],\n",
      "          [-0.1481, -0.2807,  0.0217,  ...,  0.0602,  0.2973, -0.1464]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.9564,  1.8069],\n",
      "        [-0.6224,  0.5015]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:40:10,268] Trial 7 finished with value: 0.79192 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.635600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.450700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.9059, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -1.4420]],\n",
      "\n",
      "         [[ 0.0000,  0.7944,  1.1623,  ..., -1.5913, -1.0899,  0.0000],\n",
      "          [-1.4321, -0.7785, -0.2772,  ...,  0.1840, -0.2558, -0.5538]],\n",
      "\n",
      "         [[ 1.1070,  1.8952,  0.7449,  ..., -0.4968, -0.0000,  0.5368],\n",
      "          [-0.2901, -1.2590, -0.7078,  ...,  0.5939, -0.5331,  0.2254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0850,  0.5438,  0.7833,  ...,  0.2022,  0.1126,  1.1231],\n",
      "          [-1.4623,  0.5447,  0.7909,  ...,  0.0000, -0.4430,  1.2036]],\n",
      "\n",
      "         [[ 1.7938,  0.4794, -1.2981,  ..., -1.0850, -1.1162,  0.8970],\n",
      "          [-0.5420, -1.8831,  0.5545,  ...,  0.0000, -0.0894, -0.5719]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.0000, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -0.0000]],\n",
      "\n",
      "         [[ 0.7111, -0.1487, -0.0645,  ..., -1.5786, -1.3178, -0.5324],\n",
      "          [-2.0334, -0.7434, -0.1151,  ...,  1.5512,  1.1743, -0.0644]],\n",
      "\n",
      "         [[ 1.5919,  0.0000, -1.0555,  ...,  0.0000, -1.8704,  0.8535],\n",
      "          [-1.9110, -0.1874,  0.4350,  ...,  0.0000,  0.0000,  1.4998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2486,  1.7938,  2.0083,  ..., -0.4554, -1.2766,  0.1387],\n",
      "          [-0.8758, -0.6833,  0.0000,  ...,  0.6221,  1.1186,  0.0056]],\n",
      "\n",
      "         [[ 0.8664, -0.3641, -1.4814,  ..., -1.4684, -0.5337,  0.8314],\n",
      "          [-1.0901, -0.1236, -1.2132,  ..., -0.2018, -0.4849, -0.8490]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.9059, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -1.4420]],\n",
      "\n",
      "         [[ 0.0000,  0.7944,  1.1623,  ..., -1.5913, -1.0899,  0.0000],\n",
      "          [-1.4321, -0.7785, -0.2772,  ...,  0.1840, -0.2558, -0.5538]],\n",
      "\n",
      "         [[ 1.1070,  1.8952,  0.7449,  ..., -0.4968, -0.0000,  0.5368],\n",
      "          [-0.2901, -1.2590, -0.7078,  ...,  0.5939, -0.5331,  0.2254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0850,  0.5438,  0.7833,  ...,  0.2022,  0.1126,  1.1231],\n",
      "          [-1.4623,  0.5447,  0.7909,  ...,  0.0000, -0.4430,  1.2036]],\n",
      "\n",
      "         [[ 1.7938,  0.4794, -1.2981,  ..., -1.0850, -1.1162,  0.8970],\n",
      "          [-0.5420, -1.8831,  0.5545,  ...,  0.0000, -0.0894, -0.5719]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.0000, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -0.0000]],\n",
      "\n",
      "         [[ 0.7111, -0.1487, -0.0645,  ..., -1.5786, -1.3178, -0.5324],\n",
      "          [-2.0334, -0.7434, -0.1151,  ...,  1.5512,  1.1743, -0.0644]],\n",
      "\n",
      "         [[ 1.5919,  0.0000, -1.0555,  ...,  0.0000, -1.8704,  0.8535],\n",
      "          [-1.9110, -0.1874,  0.4350,  ...,  0.0000,  0.0000,  1.4998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2486,  1.7938,  2.0083,  ..., -0.4554, -1.2766,  0.1387],\n",
      "          [-0.8758, -0.6833,  0.0000,  ...,  0.6221,  1.1186,  0.0056]],\n",
      "\n",
      "         [[ 0.8664, -0.3641, -1.4814,  ..., -1.4684, -0.5337,  0.8314],\n",
      "          [-1.0901, -0.1236, -1.2132,  ..., -0.2018, -0.4849, -0.8490]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -1.4420],\n",
      "         [ 0.0000,  0.7944,  1.1623,  ...,  0.1840, -0.2558, -0.5538],\n",
      "         [ 1.1070,  1.8952,  0.7449,  ...,  0.5939, -0.5331,  0.2254],\n",
      "         ...,\n",
      "         [ 1.0850,  0.5438,  0.7833,  ...,  0.0000, -0.4430,  1.2036],\n",
      "         [ 1.7938,  0.4794, -1.2981,  ...,  0.0000, -0.0894, -0.5719],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]],\n",
      "\n",
      "        [[-0.0250, -0.0499,  0.0239,  ...,  2.0281,  0.3773, -0.0000],\n",
      "         [ 0.7111, -0.1487, -0.0645,  ...,  1.5512,  1.1743, -0.0644],\n",
      "         [ 1.5919,  0.0000, -1.0555,  ...,  0.0000,  0.0000,  1.4998],\n",
      "         ...,\n",
      "         [ 0.2486,  1.7938,  2.0083,  ...,  0.6221,  1.1186,  0.0056],\n",
      "         [ 0.8664, -0.3641, -1.4814,  ..., -0.2018, -0.4849, -0.8490],\n",
      "         [ 0.3774, -0.3283, -1.1809,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.9059, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -1.4420]],\n",
      "\n",
      "         [[ 0.0000,  0.7944,  1.1623,  ..., -1.5913, -1.0899,  0.0000],\n",
      "          [-1.4321, -0.7785, -0.2772,  ...,  0.1840, -0.2558, -0.5538]],\n",
      "\n",
      "         [[ 1.1070,  1.8952,  0.7449,  ..., -0.4968, -0.0000,  0.5368],\n",
      "          [-0.2901, -1.2590, -0.7078,  ...,  0.5939, -0.5331,  0.2254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0850,  0.5438,  0.7833,  ...,  0.2022,  0.1126,  1.1231],\n",
      "          [-1.4623,  0.5447,  0.7909,  ...,  0.0000, -0.4430,  1.2036]],\n",
      "\n",
      "         [[ 1.7938,  0.4794, -1.2981,  ..., -1.0850, -1.1162,  0.8970],\n",
      "          [-0.5420, -1.8831,  0.5545,  ...,  0.0000, -0.0894, -0.5719]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.0000, -0.3537],\n",
      "          [-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -0.0000]],\n",
      "\n",
      "         [[ 0.7111, -0.1487, -0.0645,  ..., -1.5786, -1.3178, -0.5324],\n",
      "          [-2.0334, -0.7434, -0.1151,  ...,  1.5512,  1.1743, -0.0644]],\n",
      "\n",
      "         [[ 1.5919,  0.0000, -1.0555,  ...,  0.0000, -1.8704,  0.8535],\n",
      "          [-1.9110, -0.1874,  0.4350,  ...,  0.0000,  0.0000,  1.4998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2486,  1.7938,  2.0083,  ..., -0.4554, -1.2766,  0.1387],\n",
      "          [-0.8758, -0.6833,  0.0000,  ...,  0.6221,  1.1186,  0.0056]],\n",
      "\n",
      "         [[ 0.8664, -0.3641, -1.4814,  ..., -1.4684, -0.5337,  0.8314],\n",
      "          [-1.0901, -0.1236, -1.2132,  ..., -0.2018, -0.4849, -0.8490]],\n",
      "\n",
      "         [[ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.9059, -0.3537],\n",
      "          [ 0.0000,  0.7944,  1.1623,  ..., -1.5913, -1.0899,  0.0000],\n",
      "          [ 1.1070,  1.8952,  0.7449,  ..., -0.4968, -0.0000,  0.5368],\n",
      "          ...,\n",
      "          [ 1.0850,  0.5438,  0.7833,  ...,  0.2022,  0.1126,  1.1231],\n",
      "          [ 1.7938,  0.4794, -1.2981,  ..., -1.0850, -1.1162,  0.8970],\n",
      "          [ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410]],\n",
      "\n",
      "         [[-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -1.4420],\n",
      "          [-1.4321, -0.7785, -0.2772,  ...,  0.1840, -0.2558, -0.5538],\n",
      "          [-0.2901, -1.2590, -0.7078,  ...,  0.5939, -0.5331,  0.2254],\n",
      "          ...,\n",
      "          [-1.4623,  0.5447,  0.7909,  ...,  0.0000, -0.4430,  1.2036],\n",
      "          [-0.5420, -1.8831,  0.5545,  ...,  0.0000, -0.0894, -0.5719],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250, -0.0499,  0.0239,  ..., -0.5444, -0.0000, -0.3537],\n",
      "          [ 0.7111, -0.1487, -0.0645,  ..., -1.5786, -1.3178, -0.5324],\n",
      "          [ 1.5919,  0.0000, -1.0555,  ...,  0.0000, -1.8704,  0.8535],\n",
      "          ...,\n",
      "          [ 0.2486,  1.7938,  2.0083,  ..., -0.4554, -1.2766,  0.1387],\n",
      "          [ 0.8664, -0.3641, -1.4814,  ..., -1.4684, -0.5337,  0.8314],\n",
      "          [ 0.3774, -0.3283, -1.1809,  ..., -0.2894,  0.0631, -0.5410]],\n",
      "\n",
      "         [[-2.6651,  0.1668,  0.1407,  ...,  2.0281,  0.3773, -0.0000],\n",
      "          [-2.0334, -0.7434, -0.1151,  ...,  1.5512,  1.1743, -0.0644],\n",
      "          [-1.9110, -0.1874,  0.4350,  ...,  0.0000,  0.0000,  1.4998],\n",
      "          ...,\n",
      "          [-0.8758, -0.6833,  0.0000,  ...,  0.6221,  1.1186,  0.0056],\n",
      "          [-1.0901, -0.1236, -1.2132,  ..., -0.2018, -0.4849, -0.8490],\n",
      "          [ 0.0952,  1.4716,  1.5551,  ...,  0.9127,  0.5338,  0.8469]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.4353e-01,  1.6494e-01,  1.8644e-03,  ..., -6.0282e-01,\n",
      "           -9.8783e-01, -1.4407e-01],\n",
      "          [ 1.8333e-02,  8.8893e-01,  1.2762e+00,  ..., -1.7565e+00,\n",
      "           -1.1972e+00,  2.9229e-03],\n",
      "          [ 1.2297e+00,  2.1048e+00,  8.2729e-01,  ..., -5.5239e-01,\n",
      "           -6.3533e-04,  5.9592e-01],\n",
      "          ...,\n",
      "          [ 1.2057e+00,  6.0700e-01,  8.6446e-01,  ...,  2.1671e-01,\n",
      "            1.2014e-01,  1.2401e+00],\n",
      "          [ 1.9920e+00,  5.3477e-01, -1.4366e+00,  ..., -1.2045e+00,\n",
      "           -1.2401e+00,  9.9142e-01],\n",
      "          [ 4.2017e-01, -3.5837e-01, -1.3071e+00,  ..., -3.2100e-01,\n",
      "            6.7381e-02, -5.9814e-01]],\n",
      "\n",
      "         [[-2.9611e+00,  1.8525e-01,  1.5638e-01,  ...,  2.2532e+00,\n",
      "            4.1912e-01, -1.6021e+00],\n",
      "          [-1.5882e+00, -8.6799e-01, -2.9758e-01,  ...,  2.0748e-01,\n",
      "           -2.7389e-01, -6.1333e-01],\n",
      "          [-3.5510e-01, -1.3746e+00, -7.6393e-01,  ...,  6.5385e-01,\n",
      "           -5.7635e-01,  2.3255e-01],\n",
      "          ...,\n",
      "          [-1.6195e+00,  5.9481e-01,  8.7121e-01,  ...,  1.4174e-03,\n",
      "           -4.8945e-01,  1.3255e+00],\n",
      "          [-6.0688e-01, -2.0812e+00,  6.1017e-01,  ...,  2.7779e-03,\n",
      "           -9.9682e-02, -6.3238e-01],\n",
      "          [ 1.0413e-01,  1.6313e+00,  1.7249e+00,  ...,  1.0135e+00,\n",
      "            5.9216e-01,  9.3889e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3153e-02,  5.6900e-02, -3.9655e-01,  ..., -6.6531e-01,\n",
      "           -3.0309e-01, -2.9671e-01],\n",
      "          [ 7.8527e-01, -1.6250e-01, -7.5202e-02,  ..., -1.7501e+00,\n",
      "           -1.4599e+00, -5.9161e-01],\n",
      "          [ 1.7646e+00, -1.1796e-03, -1.1694e+00,  ..., -2.0181e-03,\n",
      "           -2.0751e+00,  9.4366e-01],\n",
      "          ...,\n",
      "          [ 2.7474e-01,  1.9839e+00,  2.2175e+00,  ..., -5.0721e-01,\n",
      "           -1.4138e+00,  1.5102e-01],\n",
      "          [ 9.5719e-01, -4.0294e-01, -1.6430e+00,  ..., -1.6302e+00,\n",
      "           -5.9243e-01,  9.1394e-01],\n",
      "          [ 4.1728e-01, -3.5946e-01, -1.3108e+00,  ..., -3.2746e-01,\n",
      "            6.8631e-02, -6.0111e-01]],\n",
      "\n",
      "         [[-2.9612e+00,  1.8533e-01,  1.5638e-01,  ...,  2.2533e+00,\n",
      "            4.1915e-01, -1.4338e-06],\n",
      "          [-2.2591e+00, -8.2495e-01, -1.2776e-01,  ...,  1.7224e+00,\n",
      "            1.3031e+00, -7.1883e-02],\n",
      "          [-2.1104e+00, -2.0527e-01,  4.7680e-01,  ...,  8.6856e-03,\n",
      "            1.0262e-03,  1.6425e+00],\n",
      "          ...,\n",
      "          [-1.5767e-02, -4.0601e-04,  3.7652e-04,  ...,  6.9681e-03,\n",
      "            9.1030e-04, -9.7463e-04],\n",
      "          [-1.2101e+00, -1.3723e-01, -1.3424e+00,  ..., -2.2342e-01,\n",
      "           -5.3709e-01, -9.3995e-01],\n",
      "          [ 1.0323e-01,  1.6327e+00,  1.7256e+00,  ...,  1.0134e+00,\n",
      "            5.9213e-01,  9.3952e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 5.4353e-01,  1.6494e-01,  1.8644e-03,  ..., -6.0282e-01,\n",
      "           -9.8783e-01, -1.4407e-01],\n",
      "          [-2.9611e+00,  1.8525e-01,  1.5638e-01,  ...,  2.2532e+00,\n",
      "            4.1912e-01, -1.6021e+00]],\n",
      "\n",
      "         [[ 1.8333e-02,  8.8893e-01,  1.2762e+00,  ..., -1.7565e+00,\n",
      "           -1.1972e+00,  2.9229e-03],\n",
      "          [-1.5882e+00, -8.6799e-01, -2.9758e-01,  ...,  2.0748e-01,\n",
      "           -2.7389e-01, -6.1333e-01]],\n",
      "\n",
      "         [[ 1.2297e+00,  2.1048e+00,  8.2729e-01,  ..., -5.5239e-01,\n",
      "           -6.3533e-04,  5.9592e-01],\n",
      "          [-3.5510e-01, -1.3746e+00, -7.6393e-01,  ...,  6.5385e-01,\n",
      "           -5.7635e-01,  2.3255e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2057e+00,  6.0700e-01,  8.6446e-01,  ...,  2.1671e-01,\n",
      "            1.2014e-01,  1.2401e+00],\n",
      "          [-1.6195e+00,  5.9481e-01,  8.7121e-01,  ...,  1.4174e-03,\n",
      "           -4.8945e-01,  1.3255e+00]],\n",
      "\n",
      "         [[ 1.9920e+00,  5.3477e-01, -1.4366e+00,  ..., -1.2045e+00,\n",
      "           -1.2401e+00,  9.9142e-01],\n",
      "          [-6.0688e-01, -2.0812e+00,  6.1017e-01,  ...,  2.7779e-03,\n",
      "           -9.9682e-02, -6.3238e-01]],\n",
      "\n",
      "         [[ 4.2017e-01, -3.5837e-01, -1.3071e+00,  ..., -3.2100e-01,\n",
      "            6.7381e-02, -5.9814e-01],\n",
      "          [ 1.0413e-01,  1.6313e+00,  1.7249e+00,  ...,  1.0135e+00,\n",
      "            5.9216e-01,  9.3889e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3153e-02,  5.6900e-02, -3.9655e-01,  ..., -6.6531e-01,\n",
      "           -3.0309e-01, -2.9671e-01],\n",
      "          [-2.9612e+00,  1.8533e-01,  1.5638e-01,  ...,  2.2533e+00,\n",
      "            4.1915e-01, -1.4338e-06]],\n",
      "\n",
      "         [[ 7.8527e-01, -1.6250e-01, -7.5202e-02,  ..., -1.7501e+00,\n",
      "           -1.4599e+00, -5.9161e-01],\n",
      "          [-2.2591e+00, -8.2495e-01, -1.2776e-01,  ...,  1.7224e+00,\n",
      "            1.3031e+00, -7.1883e-02]],\n",
      "\n",
      "         [[ 1.7646e+00, -1.1796e-03, -1.1694e+00,  ..., -2.0181e-03,\n",
      "           -2.0751e+00,  9.4366e-01],\n",
      "          [-2.1104e+00, -2.0527e-01,  4.7680e-01,  ...,  8.6856e-03,\n",
      "            1.0262e-03,  1.6425e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7474e-01,  1.9839e+00,  2.2175e+00,  ..., -5.0721e-01,\n",
      "           -1.4138e+00,  1.5102e-01],\n",
      "          [-1.5767e-02, -4.0601e-04,  3.7652e-04,  ...,  6.9681e-03,\n",
      "            9.1030e-04, -9.7463e-04]],\n",
      "\n",
      "         [[ 9.5719e-01, -4.0294e-01, -1.6430e+00,  ..., -1.6302e+00,\n",
      "           -5.9243e-01,  9.1394e-01],\n",
      "          [-1.2101e+00, -1.3723e-01, -1.3424e+00,  ..., -2.2342e-01,\n",
      "           -5.3709e-01, -9.3995e-01]],\n",
      "\n",
      "         [[ 4.1728e-01, -3.5946e-01, -1.3108e+00,  ..., -3.2746e-01,\n",
      "            6.8631e-02, -6.0111e-01],\n",
      "          [ 1.0323e-01,  1.6327e+00,  1.7256e+00,  ...,  1.0134e+00,\n",
      "            5.9213e-01,  9.3952e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 5.4353e-01,  1.6494e-01,  1.8644e-03,  ..., -6.0282e-01,\n",
      "           -9.8783e-01, -1.4407e-01],\n",
      "          [-2.9611e+00,  1.8525e-01,  1.5638e-01,  ...,  2.2532e+00,\n",
      "            4.1912e-01, -1.6021e+00]],\n",
      "\n",
      "         [[ 1.8333e-02,  8.8893e-01,  1.2762e+00,  ..., -1.7565e+00,\n",
      "           -1.1972e+00,  2.9229e-03],\n",
      "          [-1.5882e+00, -8.6799e-01, -2.9758e-01,  ...,  2.0748e-01,\n",
      "           -2.7389e-01, -6.1333e-01]],\n",
      "\n",
      "         [[ 1.2297e+00,  2.1048e+00,  8.2729e-01,  ..., -5.5239e-01,\n",
      "           -6.3533e-04,  5.9592e-01],\n",
      "          [-3.5510e-01, -1.3746e+00, -7.6393e-01,  ...,  6.5385e-01,\n",
      "           -5.7635e-01,  2.3255e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2057e+00,  6.0700e-01,  8.6446e-01,  ...,  2.1671e-01,\n",
      "            1.2014e-01,  1.2401e+00],\n",
      "          [-1.6195e+00,  5.9481e-01,  8.7121e-01,  ...,  1.4174e-03,\n",
      "           -4.8945e-01,  1.3255e+00]],\n",
      "\n",
      "         [[ 1.9920e+00,  5.3477e-01, -1.4366e+00,  ..., -1.2045e+00,\n",
      "           -1.2401e+00,  9.9142e-01],\n",
      "          [-6.0688e-01, -2.0812e+00,  6.1017e-01,  ...,  2.7779e-03,\n",
      "           -9.9682e-02, -6.3238e-01]],\n",
      "\n",
      "         [[ 4.2017e-01, -3.5837e-01, -1.3071e+00,  ..., -3.2100e-01,\n",
      "            6.7381e-02, -5.9814e-01],\n",
      "          [ 1.0413e-01,  1.6313e+00,  1.7249e+00,  ...,  1.0135e+00,\n",
      "            5.9216e-01,  9.3889e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3153e-02,  5.6900e-02, -3.9655e-01,  ..., -6.6531e-01,\n",
      "           -3.0309e-01, -2.9671e-01],\n",
      "          [-2.9612e+00,  1.8533e-01,  1.5638e-01,  ...,  2.2533e+00,\n",
      "            4.1915e-01, -1.4338e-06]],\n",
      "\n",
      "         [[ 7.8527e-01, -1.6250e-01, -7.5202e-02,  ..., -1.7501e+00,\n",
      "           -1.4599e+00, -5.9161e-01],\n",
      "          [-2.2591e+00, -8.2495e-01, -1.2776e-01,  ...,  1.7224e+00,\n",
      "            1.3031e+00, -7.1883e-02]],\n",
      "\n",
      "         [[ 1.7646e+00, -1.1796e-03, -1.1694e+00,  ..., -2.0181e-03,\n",
      "           -2.0751e+00,  9.4366e-01],\n",
      "          [-2.1104e+00, -2.0527e-01,  4.7680e-01,  ...,  8.6856e-03,\n",
      "            1.0262e-03,  1.6425e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7474e-01,  1.9839e+00,  2.2175e+00,  ..., -5.0721e-01,\n",
      "           -1.4138e+00,  1.5102e-01],\n",
      "          [-1.5767e-02, -4.0601e-04,  3.7652e-04,  ...,  6.9681e-03,\n",
      "            9.1030e-04, -9.7463e-04]],\n",
      "\n",
      "         [[ 9.5719e-01, -4.0294e-01, -1.6430e+00,  ..., -1.6302e+00,\n",
      "           -5.9243e-01,  9.1394e-01],\n",
      "          [-1.2101e+00, -1.3723e-01, -1.3424e+00,  ..., -2.2342e-01,\n",
      "           -5.3709e-01, -9.3995e-01]],\n",
      "\n",
      "         [[ 4.1728e-01, -3.5946e-01, -1.3108e+00,  ..., -3.2746e-01,\n",
      "            6.8631e-02, -6.0111e-01],\n",
      "          [ 1.0323e-01,  1.6327e+00,  1.7256e+00,  ...,  1.0134e+00,\n",
      "            5.9213e-01,  9.3952e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 5.4353e-01,  1.6494e-01,  1.8644e-03,  ..., -6.0282e-01,\n",
      "           -9.8783e-01, -1.4407e-01],\n",
      "          [-2.9611e+00,  1.8525e-01,  1.5638e-01,  ...,  2.2532e+00,\n",
      "            4.1912e-01, -1.6021e+00]],\n",
      "\n",
      "         [[ 1.8333e-02,  8.8893e-01,  1.2762e+00,  ..., -1.7565e+00,\n",
      "           -1.1972e+00,  2.9229e-03],\n",
      "          [-1.5882e+00, -8.6799e-01, -2.9758e-01,  ...,  2.0748e-01,\n",
      "           -2.7389e-01, -6.1333e-01]],\n",
      "\n",
      "         [[ 1.2297e+00,  2.1048e+00,  8.2729e-01,  ..., -5.5239e-01,\n",
      "           -6.3533e-04,  5.9592e-01],\n",
      "          [-3.5510e-01, -1.3746e+00, -7.6393e-01,  ...,  6.5385e-01,\n",
      "           -5.7635e-01,  2.3255e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2057e+00,  6.0700e-01,  8.6446e-01,  ...,  2.1671e-01,\n",
      "            1.2014e-01,  1.2401e+00],\n",
      "          [-1.6195e+00,  5.9481e-01,  8.7121e-01,  ...,  1.4174e-03,\n",
      "           -4.8945e-01,  1.3255e+00]],\n",
      "\n",
      "         [[ 1.9920e+00,  5.3477e-01, -1.4366e+00,  ..., -1.2045e+00,\n",
      "           -1.2401e+00,  9.9142e-01],\n",
      "          [-6.0688e-01, -2.0812e+00,  6.1017e-01,  ...,  2.7779e-03,\n",
      "           -9.9682e-02, -6.3238e-01]],\n",
      "\n",
      "         [[ 4.2017e-01, -3.5837e-01, -1.3071e+00,  ..., -3.2100e-01,\n",
      "            6.7381e-02, -5.9814e-01],\n",
      "          [ 1.0413e-01,  1.6313e+00,  1.7249e+00,  ...,  1.0135e+00,\n",
      "            5.9216e-01,  9.3889e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3153e-02,  5.6900e-02, -3.9655e-01,  ..., -6.6531e-01,\n",
      "           -3.0309e-01, -2.9671e-01],\n",
      "          [-2.9612e+00,  1.8533e-01,  1.5638e-01,  ...,  2.2533e+00,\n",
      "            4.1915e-01, -1.4338e-06]],\n",
      "\n",
      "         [[ 7.8527e-01, -1.6250e-01, -7.5202e-02,  ..., -1.7501e+00,\n",
      "           -1.4599e+00, -5.9161e-01],\n",
      "          [-2.2591e+00, -8.2495e-01, -1.2776e-01,  ...,  1.7224e+00,\n",
      "            1.3031e+00, -7.1883e-02]],\n",
      "\n",
      "         [[ 1.7646e+00, -1.1796e-03, -1.1694e+00,  ..., -2.0181e-03,\n",
      "           -2.0751e+00,  9.4366e-01],\n",
      "          [-2.1104e+00, -2.0527e-01,  4.7680e-01,  ...,  8.6856e-03,\n",
      "            1.0262e-03,  1.6425e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7474e-01,  1.9839e+00,  2.2175e+00,  ..., -5.0721e-01,\n",
      "           -1.4138e+00,  1.5102e-01],\n",
      "          [-1.5767e-02, -4.0601e-04,  3.7652e-04,  ...,  6.9681e-03,\n",
      "            9.1030e-04, -9.7463e-04]],\n",
      "\n",
      "         [[ 9.5719e-01, -4.0294e-01, -1.6430e+00,  ..., -1.6302e+00,\n",
      "           -5.9243e-01,  9.1394e-01],\n",
      "          [-1.2101e+00, -1.3723e-01, -1.3424e+00,  ..., -2.2342e-01,\n",
      "           -5.3709e-01, -9.3995e-01]],\n",
      "\n",
      "         [[ 4.1728e-01, -3.5946e-01, -1.3108e+00,  ..., -3.2746e-01,\n",
      "            6.8631e-02, -6.0111e-01],\n",
      "          [ 1.0323e-01,  1.6327e+00,  1.7256e+00,  ...,  1.0134e+00,\n",
      "            5.9213e-01,  9.3952e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.4815e-01,  5.0003e-02,  4.6687e-01,  ..., -3.9710e-02,\n",
      "           -9.3943e-01,  5.6518e-02],\n",
      "          [-2.3454e+00,  2.3681e-01,  1.5393e-01,  ...,  2.3533e+00,\n",
      "            8.3830e-02, -1.4876e+00]],\n",
      "\n",
      "         [[-2.9108e-02,  9.6289e-01,  1.6883e+00,  ..., -1.3072e+00,\n",
      "           -9.9455e-01,  3.5053e-01],\n",
      "          [-1.2979e+00, -7.7845e-01, -1.5443e-01,  ...,  2.8342e-01,\n",
      "           -2.6519e-01, -6.5408e-01]],\n",
      "\n",
      "         [[ 1.1106e+00,  1.9093e+00,  7.2518e-01,  ...,  1.7830e-01,\n",
      "           -4.9339e-02,  9.6189e-01],\n",
      "          [-1.2058e-01, -5.2921e-01, -5.4270e-01,  ...,  8.3350e-01,\n",
      "           -8.0718e-01,  6.2441e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1408e+00,  6.0714e-01,  1.1242e+00,  ...,  6.6293e-01,\n",
      "            2.0932e-01,  1.5828e+00],\n",
      "          [-1.4977e+00,  6.4870e-01,  7.7629e-01,  ...,  8.3091e-02,\n",
      "           -2.0313e-01,  2.8513e-01]],\n",
      "\n",
      "         [[ 1.8862e+00,  5.4134e-01, -1.1563e+00,  ..., -6.3275e-01,\n",
      "           -1.0006e+00,  9.5401e-01],\n",
      "          [-5.1673e-01, -1.6632e+00,  7.7187e-01,  ...,  2.3472e-01,\n",
      "           -2.0382e-01, -7.6974e-01]],\n",
      "\n",
      "         [[ 2.9084e-01, -3.2227e-01, -5.6270e-01,  ..., -1.3231e-03,\n",
      "            1.0639e-01, -3.8129e-01],\n",
      "          [ 3.8118e-01,  8.9311e-01,  1.7998e+00,  ...,  1.0483e+00,\n",
      "            5.2885e-01,  8.5690e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2710e-01, -1.0013e-02,  1.0172e-02,  ..., -4.9868e-01,\n",
      "           -2.8892e-01, -7.0109e-02],\n",
      "          [-2.6704e+00,  1.3497e-01,  1.9396e-01,  ...,  2.4947e+00,\n",
      "            6.1955e-02, -1.1467e-01]],\n",
      "\n",
      "         [[ 3.0871e-01, -6.7597e-01, -2.5410e-01,  ..., -1.3054e+00,\n",
      "           -1.1977e+00, -6.5045e-01],\n",
      "          [-1.7630e+00, -5.6475e-01, -1.4547e-01,  ...,  1.5171e+00,\n",
      "            1.2240e+00, -1.7158e-02]],\n",
      "\n",
      "         [[ 6.5371e-01,  1.1730e-01, -9.6743e-01,  ...,  4.9505e-01,\n",
      "           -1.8584e+00,  1.2016e+00],\n",
      "          [-1.8901e+00, -1.6829e-01,  5.0172e-01,  ...,  2.4338e-01,\n",
      "           -3.5794e-01,  1.3989e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6019e-02,  2.3703e+00,  2.6294e+00,  ..., -5.9626e-01,\n",
      "           -1.6022e+00,  3.3009e-01],\n",
      "          [-3.0912e-01, -2.9494e-01, -9.4514e-03,  ...,  5.7861e-01,\n",
      "            5.7125e-01, -2.7649e-01]],\n",
      "\n",
      "         [[ 4.3425e-01, -6.6775e-01, -1.6632e+00,  ..., -1.2780e+00,\n",
      "           -2.8579e-01,  9.3012e-01],\n",
      "          [-9.4716e-01,  3.2529e-02, -1.1264e+00,  ..., -4.5929e-02,\n",
      "           -4.5072e-01, -1.0532e+00]],\n",
      "\n",
      "         [[ 1.9954e-01, -4.9740e-01, -1.3555e+00,  ..., -3.2690e-01,\n",
      "            1.9810e-01, -4.4375e-01],\n",
      "          [ 3.4906e-01,  1.7135e+00,  1.6748e+00,  ...,  9.8525e-01,\n",
      "            5.1150e-01,  7.9588e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.4815e-01,  5.0003e-02,  4.6687e-01,  ..., -3.9710e-02,\n",
      "           -9.3943e-01,  5.6518e-02],\n",
      "          [-2.3454e+00,  2.3681e-01,  1.5393e-01,  ...,  2.3533e+00,\n",
      "            8.3830e-02, -1.4876e+00]],\n",
      "\n",
      "         [[-2.9108e-02,  9.6289e-01,  1.6883e+00,  ..., -1.3072e+00,\n",
      "           -9.9455e-01,  3.5053e-01],\n",
      "          [-1.2979e+00, -7.7845e-01, -1.5443e-01,  ...,  2.8342e-01,\n",
      "           -2.6519e-01, -6.5408e-01]],\n",
      "\n",
      "         [[ 1.1106e+00,  1.9093e+00,  7.2518e-01,  ...,  1.7830e-01,\n",
      "           -4.9339e-02,  9.6189e-01],\n",
      "          [-1.2058e-01, -5.2921e-01, -5.4270e-01,  ...,  8.3350e-01,\n",
      "           -8.0718e-01,  6.2441e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1408e+00,  6.0714e-01,  1.1242e+00,  ...,  6.6293e-01,\n",
      "            2.0932e-01,  1.5828e+00],\n",
      "          [-1.4977e+00,  6.4870e-01,  7.7629e-01,  ...,  8.3091e-02,\n",
      "           -2.0313e-01,  2.8513e-01]],\n",
      "\n",
      "         [[ 1.8862e+00,  5.4134e-01, -1.1563e+00,  ..., -6.3275e-01,\n",
      "           -1.0006e+00,  9.5401e-01],\n",
      "          [-5.1673e-01, -1.6632e+00,  7.7187e-01,  ...,  2.3472e-01,\n",
      "           -2.0382e-01, -7.6974e-01]],\n",
      "\n",
      "         [[ 2.9084e-01, -3.2227e-01, -5.6270e-01,  ..., -1.3231e-03,\n",
      "            1.0639e-01, -3.8129e-01],\n",
      "          [ 3.8118e-01,  8.9311e-01,  1.7998e+00,  ...,  1.0483e+00,\n",
      "            5.2885e-01,  8.5690e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2710e-01, -1.0013e-02,  1.0172e-02,  ..., -4.9868e-01,\n",
      "           -2.8892e-01, -7.0109e-02],\n",
      "          [-2.6704e+00,  1.3497e-01,  1.9396e-01,  ...,  2.4947e+00,\n",
      "            6.1955e-02, -1.1467e-01]],\n",
      "\n",
      "         [[ 3.0871e-01, -6.7597e-01, -2.5410e-01,  ..., -1.3054e+00,\n",
      "           -1.1977e+00, -6.5045e-01],\n",
      "          [-1.7630e+00, -5.6475e-01, -1.4547e-01,  ...,  1.5171e+00,\n",
      "            1.2240e+00, -1.7158e-02]],\n",
      "\n",
      "         [[ 6.5371e-01,  1.1730e-01, -9.6743e-01,  ...,  4.9505e-01,\n",
      "           -1.8584e+00,  1.2016e+00],\n",
      "          [-1.8901e+00, -1.6829e-01,  5.0172e-01,  ...,  2.4338e-01,\n",
      "           -3.5794e-01,  1.3989e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6019e-02,  2.3703e+00,  2.6294e+00,  ..., -5.9626e-01,\n",
      "           -1.6022e+00,  3.3009e-01],\n",
      "          [-3.0912e-01, -2.9494e-01, -9.4514e-03,  ...,  5.7861e-01,\n",
      "            5.7125e-01, -2.7649e-01]],\n",
      "\n",
      "         [[ 4.3425e-01, -6.6775e-01, -1.6632e+00,  ..., -1.2780e+00,\n",
      "           -2.8579e-01,  9.3012e-01],\n",
      "          [-9.4716e-01,  3.2529e-02, -1.1264e+00,  ..., -4.5929e-02,\n",
      "           -4.5072e-01, -1.0532e+00]],\n",
      "\n",
      "         [[ 1.9954e-01, -4.9740e-01, -1.3555e+00,  ..., -3.2690e-01,\n",
      "            1.9810e-01, -4.4375e-01],\n",
      "          [ 3.4906e-01,  1.7135e+00,  1.6748e+00,  ...,  9.8525e-01,\n",
      "            5.1150e-01,  7.9588e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1482,  0.0500,  0.4669,  ...,  2.3533,  0.0838, -1.4876],\n",
      "         [-0.0291,  0.9629,  1.6883,  ...,  0.2834, -0.2652, -0.6541],\n",
      "         [ 1.1106,  1.9093,  0.7252,  ...,  0.8335, -0.8072,  0.0624],\n",
      "         ...,\n",
      "         [ 1.1408,  0.6071,  1.1242,  ...,  0.0831, -0.2031,  0.2851],\n",
      "         [ 1.8862,  0.5413, -1.1563,  ...,  0.2347, -0.2038, -0.7697],\n",
      "         [ 0.2908, -0.3223, -0.5627,  ...,  1.0483,  0.5288,  0.8569]],\n",
      "\n",
      "        [[-0.5271, -0.0100,  0.0102,  ...,  2.4947,  0.0620, -0.1147],\n",
      "         [ 0.3087, -0.6760, -0.2541,  ...,  1.5171,  1.2240, -0.0172],\n",
      "         [ 0.6537,  0.1173, -0.9674,  ...,  0.2434, -0.3579,  1.3989],\n",
      "         ...,\n",
      "         [ 0.0460,  2.3703,  2.6294,  ...,  0.5786,  0.5712, -0.2765],\n",
      "         [ 0.4342, -0.6678, -1.6632,  ..., -0.0459, -0.4507, -1.0532],\n",
      "         [ 0.1995, -0.4974, -1.3555,  ...,  0.9852,  0.5115,  0.7959]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.4815e-01,  5.0003e-02,  4.6687e-01,  ..., -3.9710e-02,\n",
      "           -9.3943e-01,  5.6518e-02],\n",
      "          [-2.3454e+00,  2.3681e-01,  1.5393e-01,  ...,  2.3533e+00,\n",
      "            8.3830e-02, -1.4876e+00]],\n",
      "\n",
      "         [[-2.9108e-02,  9.6289e-01,  1.6883e+00,  ..., -1.3072e+00,\n",
      "           -9.9455e-01,  3.5053e-01],\n",
      "          [-1.2979e+00, -7.7845e-01, -1.5443e-01,  ...,  2.8342e-01,\n",
      "           -2.6519e-01, -6.5408e-01]],\n",
      "\n",
      "         [[ 1.1106e+00,  1.9093e+00,  7.2518e-01,  ...,  1.7830e-01,\n",
      "           -4.9339e-02,  9.6189e-01],\n",
      "          [-1.2058e-01, -5.2921e-01, -5.4270e-01,  ...,  8.3350e-01,\n",
      "           -8.0718e-01,  6.2441e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1408e+00,  6.0714e-01,  1.1242e+00,  ...,  6.6293e-01,\n",
      "            2.0932e-01,  1.5828e+00],\n",
      "          [-1.4977e+00,  6.4870e-01,  7.7629e-01,  ...,  8.3091e-02,\n",
      "           -2.0313e-01,  2.8513e-01]],\n",
      "\n",
      "         [[ 1.8862e+00,  5.4134e-01, -1.1563e+00,  ..., -6.3275e-01,\n",
      "           -1.0006e+00,  9.5401e-01],\n",
      "          [-5.1673e-01, -1.6632e+00,  7.7187e-01,  ...,  2.3472e-01,\n",
      "           -2.0382e-01, -7.6974e-01]],\n",
      "\n",
      "         [[ 2.9084e-01, -3.2227e-01, -5.6270e-01,  ..., -1.3231e-03,\n",
      "            1.0639e-01, -3.8129e-01],\n",
      "          [ 3.8118e-01,  8.9311e-01,  1.7998e+00,  ...,  1.0483e+00,\n",
      "            5.2885e-01,  8.5690e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2710e-01, -1.0013e-02,  1.0172e-02,  ..., -4.9868e-01,\n",
      "           -2.8892e-01, -7.0109e-02],\n",
      "          [-2.6704e+00,  1.3497e-01,  1.9396e-01,  ...,  2.4947e+00,\n",
      "            6.1955e-02, -1.1467e-01]],\n",
      "\n",
      "         [[ 3.0871e-01, -6.7597e-01, -2.5410e-01,  ..., -1.3054e+00,\n",
      "           -1.1977e+00, -6.5045e-01],\n",
      "          [-1.7630e+00, -5.6475e-01, -1.4547e-01,  ...,  1.5171e+00,\n",
      "            1.2240e+00, -1.7158e-02]],\n",
      "\n",
      "         [[ 6.5371e-01,  1.1730e-01, -9.6743e-01,  ...,  4.9505e-01,\n",
      "           -1.8584e+00,  1.2016e+00],\n",
      "          [-1.8901e+00, -1.6829e-01,  5.0172e-01,  ...,  2.4338e-01,\n",
      "           -3.5794e-01,  1.3989e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6019e-02,  2.3703e+00,  2.6294e+00,  ..., -5.9626e-01,\n",
      "           -1.6022e+00,  3.3009e-01],\n",
      "          [-3.0912e-01, -2.9494e-01, -9.4514e-03,  ...,  5.7861e-01,\n",
      "            5.7125e-01, -2.7649e-01]],\n",
      "\n",
      "         [[ 4.3425e-01, -6.6775e-01, -1.6632e+00,  ..., -1.2780e+00,\n",
      "           -2.8579e-01,  9.3012e-01],\n",
      "          [-9.4716e-01,  3.2529e-02, -1.1264e+00,  ..., -4.5929e-02,\n",
      "           -4.5072e-01, -1.0532e+00]],\n",
      "\n",
      "         [[ 1.9954e-01, -4.9740e-01, -1.3555e+00,  ..., -3.2690e-01,\n",
      "            1.9810e-01, -4.4375e-01],\n",
      "          [ 3.4906e-01,  1.7135e+00,  1.6748e+00,  ...,  9.8525e-01,\n",
      "            5.1150e-01,  7.9588e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.4815e-01,  5.0003e-02,  4.6687e-01,  ..., -3.9710e-02,\n",
      "           -9.3943e-01,  5.6518e-02],\n",
      "          [-2.9108e-02,  9.6289e-01,  1.6883e+00,  ..., -1.3072e+00,\n",
      "           -9.9455e-01,  3.5053e-01],\n",
      "          [ 1.1106e+00,  1.9093e+00,  7.2518e-01,  ...,  1.7830e-01,\n",
      "           -4.9339e-02,  9.6189e-01],\n",
      "          ...,\n",
      "          [ 1.1408e+00,  6.0714e-01,  1.1242e+00,  ...,  6.6293e-01,\n",
      "            2.0932e-01,  1.5828e+00],\n",
      "          [ 1.8862e+00,  5.4134e-01, -1.1563e+00,  ..., -6.3275e-01,\n",
      "           -1.0006e+00,  9.5401e-01],\n",
      "          [ 2.9084e-01, -3.2227e-01, -5.6270e-01,  ..., -1.3231e-03,\n",
      "            1.0639e-01, -3.8129e-01]],\n",
      "\n",
      "         [[-2.3454e+00,  2.3681e-01,  1.5393e-01,  ...,  2.3533e+00,\n",
      "            8.3830e-02, -1.4876e+00],\n",
      "          [-1.2979e+00, -7.7845e-01, -1.5443e-01,  ...,  2.8342e-01,\n",
      "           -2.6519e-01, -6.5408e-01],\n",
      "          [-1.2058e-01, -5.2921e-01, -5.4270e-01,  ...,  8.3350e-01,\n",
      "           -8.0718e-01,  6.2441e-02],\n",
      "          ...,\n",
      "          [-1.4977e+00,  6.4870e-01,  7.7629e-01,  ...,  8.3091e-02,\n",
      "           -2.0313e-01,  2.8513e-01],\n",
      "          [-5.1673e-01, -1.6632e+00,  7.7187e-01,  ...,  2.3472e-01,\n",
      "           -2.0382e-01, -7.6974e-01],\n",
      "          [ 3.8118e-01,  8.9311e-01,  1.7998e+00,  ...,  1.0483e+00,\n",
      "            5.2885e-01,  8.5690e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2710e-01, -1.0013e-02,  1.0172e-02,  ..., -4.9868e-01,\n",
      "           -2.8892e-01, -7.0109e-02],\n",
      "          [ 3.0871e-01, -6.7597e-01, -2.5410e-01,  ..., -1.3054e+00,\n",
      "           -1.1977e+00, -6.5045e-01],\n",
      "          [ 6.5371e-01,  1.1730e-01, -9.6743e-01,  ...,  4.9505e-01,\n",
      "           -1.8584e+00,  1.2016e+00],\n",
      "          ...,\n",
      "          [ 4.6019e-02,  2.3703e+00,  2.6294e+00,  ..., -5.9626e-01,\n",
      "           -1.6022e+00,  3.3009e-01],\n",
      "          [ 4.3425e-01, -6.6775e-01, -1.6632e+00,  ..., -1.2780e+00,\n",
      "           -2.8579e-01,  9.3012e-01],\n",
      "          [ 1.9954e-01, -4.9740e-01, -1.3555e+00,  ..., -3.2690e-01,\n",
      "            1.9810e-01, -4.4375e-01]],\n",
      "\n",
      "         [[-2.6704e+00,  1.3497e-01,  1.9396e-01,  ...,  2.4947e+00,\n",
      "            6.1955e-02, -1.1467e-01],\n",
      "          [-1.7630e+00, -5.6475e-01, -1.4547e-01,  ...,  1.5171e+00,\n",
      "            1.2240e+00, -1.7158e-02],\n",
      "          [-1.8901e+00, -1.6829e-01,  5.0172e-01,  ...,  2.4338e-01,\n",
      "           -3.5794e-01,  1.3989e+00],\n",
      "          ...,\n",
      "          [-3.0912e-01, -2.9494e-01, -9.4514e-03,  ...,  5.7861e-01,\n",
      "            5.7125e-01, -2.7649e-01],\n",
      "          [-9.4716e-01,  3.2529e-02, -1.1264e+00,  ..., -4.5929e-02,\n",
      "           -4.5072e-01, -1.0532e+00],\n",
      "          [ 3.4906e-01,  1.7135e+00,  1.6748e+00,  ...,  9.8525e-01,\n",
      "            5.1150e-01,  7.9588e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 2.0835e-02,  7.4353e-04,  3.7791e-01,  ..., -9.2583e-02,\n",
      "           -9.6411e-01,  2.6416e-01],\n",
      "          [-2.7114e-02,  1.0700e+00,  1.8663e+00,  ..., -1.4465e+00,\n",
      "           -1.0994e+00,  3.9053e-01],\n",
      "          [ 2.3178e-04,  2.8715e-04,  3.5852e-04,  ..., -3.6939e-04,\n",
      "           -3.7127e-04,  1.3057e-04],\n",
      "          ...,\n",
      "          [ 1.2665e+00,  6.7526e-01,  1.2466e+00,  ...,  7.3502e-01,\n",
      "            2.3085e-01,  1.7551e+00],\n",
      "          [ 2.0940e+00,  6.0122e-01, -1.2829e+00,  ..., -7.0263e-01,\n",
      "           -1.1112e+00,  1.0588e+00],\n",
      "          [ 3.2650e-01, -3.5091e-01, -6.2157e-01,  ..., -1.0291e-03,\n",
      "            1.1583e-01, -4.1912e-01]],\n",
      "\n",
      "         [[-2.6057e+00,  2.6281e-01,  1.7096e-01,  ...,  2.6143e+00,\n",
      "            9.3118e-02, -1.6526e+00],\n",
      "          [-1.4558e+00, -8.7287e-01, -1.6802e-01,  ...,  3.2438e-01,\n",
      "           -2.8787e-01, -7.1987e-01],\n",
      "          [-2.5072e-01, -5.7386e-01, -5.3542e-01,  ...,  9.0584e-01,\n",
      "           -8.1725e-01,  2.2277e-02],\n",
      "          ...,\n",
      "          [-1.6650e+00,  7.0561e-01,  8.5084e-01,  ...,  1.0224e-01,\n",
      "           -2.2420e-01,  3.0425e-01],\n",
      "          [-5.8305e-01, -1.8310e+00,  8.4704e-01,  ...,  2.6221e-01,\n",
      "           -2.2353e-01, -8.5414e-01],\n",
      "          [ 4.2019e-01,  9.8855e-01,  1.9946e+00,  ...,  1.1640e+00,\n",
      "            5.8529e-01,  9.4889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7331e-01,  5.2801e-01, -4.2028e-01,  ..., -9.4255e-01,\n",
      "           -2.9589e-01, -1.9760e-01],\n",
      "          [ 3.3820e-01, -7.4240e-01, -2.8485e-01,  ..., -1.4451e+00,\n",
      "           -1.3209e+00, -7.1976e-01],\n",
      "          [ 7.2609e-01,  1.3037e-01, -1.0744e+00,  ...,  5.4962e-01,\n",
      "           -2.0642e+00,  1.3345e+00],\n",
      "          ...,\n",
      "          [ 5.1131e-02,  2.6337e+00,  2.9215e+00,  ..., -6.6251e-01,\n",
      "           -1.7802e+00,  3.6676e-01],\n",
      "          [ 4.8085e-01, -7.4002e-01, -1.8455e+00,  ..., -1.4186e+00,\n",
      "           -3.1732e-01,  1.0304e+00],\n",
      "          [ 2.2051e-01, -5.4999e-01, -1.4996e+00,  ..., -3.6367e-01,\n",
      "            2.1665e-01, -4.8900e-01]],\n",
      "\n",
      "         [[-2.9670e+00,  1.4995e-01,  2.1549e-01,  ...,  2.7717e+00,\n",
      "            6.8833e-02, -1.2742e-01],\n",
      "          [-1.9588e+00, -6.2597e-01, -1.6108e-01,  ...,  1.6841e+00,\n",
      "            1.3562e+00, -2.0235e-02],\n",
      "          [-2.0890e+00, -1.8207e-01,  5.4301e-01,  ...,  2.7916e-01,\n",
      "           -3.9749e-01,  1.4895e+00],\n",
      "          ...,\n",
      "          [-1.2626e+00, -8.6296e-02, -6.3145e-02,  ...,  8.4769e-01,\n",
      "            8.6587e-02, -3.3617e-01],\n",
      "          [-2.6066e-02,  1.3820e-03, -7.4557e-04,  ...,  1.5765e-02,\n",
      "           -5.4108e-03, -5.4818e-03],\n",
      "          [ 3.8345e-01,  1.9004e+00,  1.8570e+00,  ...,  1.0942e+00,\n",
      "            5.6603e-01,  8.8172e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 2.0835e-02,  7.4353e-04,  3.7791e-01,  ..., -9.2583e-02,\n",
      "           -9.6411e-01,  2.6416e-01],\n",
      "          [-2.6057e+00,  2.6281e-01,  1.7096e-01,  ...,  2.6143e+00,\n",
      "            9.3118e-02, -1.6526e+00]],\n",
      "\n",
      "         [[-2.7114e-02,  1.0700e+00,  1.8663e+00,  ..., -1.4465e+00,\n",
      "           -1.0994e+00,  3.9053e-01],\n",
      "          [-1.4558e+00, -8.7287e-01, -1.6802e-01,  ...,  3.2438e-01,\n",
      "           -2.8787e-01, -7.1987e-01]],\n",
      "\n",
      "         [[ 2.3178e-04,  2.8715e-04,  3.5852e-04,  ..., -3.6939e-04,\n",
      "           -3.7127e-04,  1.3057e-04],\n",
      "          [-2.5072e-01, -5.7386e-01, -5.3542e-01,  ...,  9.0584e-01,\n",
      "           -8.1725e-01,  2.2277e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2665e+00,  6.7526e-01,  1.2466e+00,  ...,  7.3502e-01,\n",
      "            2.3085e-01,  1.7551e+00],\n",
      "          [-1.6650e+00,  7.0561e-01,  8.5084e-01,  ...,  1.0224e-01,\n",
      "           -2.2420e-01,  3.0425e-01]],\n",
      "\n",
      "         [[ 2.0940e+00,  6.0122e-01, -1.2829e+00,  ..., -7.0263e-01,\n",
      "           -1.1112e+00,  1.0588e+00],\n",
      "          [-5.8305e-01, -1.8310e+00,  8.4704e-01,  ...,  2.6221e-01,\n",
      "           -2.2353e-01, -8.5414e-01]],\n",
      "\n",
      "         [[ 3.2650e-01, -3.5091e-01, -6.2157e-01,  ..., -1.0291e-03,\n",
      "            1.1583e-01, -4.1912e-01],\n",
      "          [ 4.2019e-01,  9.8855e-01,  1.9946e+00,  ...,  1.1640e+00,\n",
      "            5.8529e-01,  9.4889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7331e-01,  5.2801e-01, -4.2028e-01,  ..., -9.4255e-01,\n",
      "           -2.9589e-01, -1.9760e-01],\n",
      "          [-2.9670e+00,  1.4995e-01,  2.1549e-01,  ...,  2.7717e+00,\n",
      "            6.8833e-02, -1.2742e-01]],\n",
      "\n",
      "         [[ 3.3820e-01, -7.4240e-01, -2.8485e-01,  ..., -1.4451e+00,\n",
      "           -1.3209e+00, -7.1976e-01],\n",
      "          [-1.9588e+00, -6.2597e-01, -1.6108e-01,  ...,  1.6841e+00,\n",
      "            1.3562e+00, -2.0235e-02]],\n",
      "\n",
      "         [[ 7.2609e-01,  1.3037e-01, -1.0744e+00,  ...,  5.4962e-01,\n",
      "           -2.0642e+00,  1.3345e+00],\n",
      "          [-2.0890e+00, -1.8207e-01,  5.4301e-01,  ...,  2.7916e-01,\n",
      "           -3.9749e-01,  1.4895e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1131e-02,  2.6337e+00,  2.9215e+00,  ..., -6.6251e-01,\n",
      "           -1.7802e+00,  3.6676e-01],\n",
      "          [-1.2626e+00, -8.6296e-02, -6.3145e-02,  ...,  8.4769e-01,\n",
      "            8.6587e-02, -3.3617e-01]],\n",
      "\n",
      "         [[ 4.8085e-01, -7.4002e-01, -1.8455e+00,  ..., -1.4186e+00,\n",
      "           -3.1732e-01,  1.0304e+00],\n",
      "          [-2.6066e-02,  1.3820e-03, -7.4557e-04,  ...,  1.5765e-02,\n",
      "           -5.4108e-03, -5.4818e-03]],\n",
      "\n",
      "         [[ 2.2051e-01, -5.4999e-01, -1.4996e+00,  ..., -3.6367e-01,\n",
      "            2.1665e-01, -4.8900e-01],\n",
      "          [ 3.8345e-01,  1.9004e+00,  1.8570e+00,  ...,  1.0942e+00,\n",
      "            5.6603e-01,  8.8172e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 2.0835e-02,  7.4353e-04,  3.7791e-01,  ..., -9.2583e-02,\n",
      "           -9.6411e-01,  2.6416e-01],\n",
      "          [-2.6057e+00,  2.6281e-01,  1.7096e-01,  ...,  2.6143e+00,\n",
      "            9.3118e-02, -1.6526e+00]],\n",
      "\n",
      "         [[-2.7114e-02,  1.0700e+00,  1.8663e+00,  ..., -1.4465e+00,\n",
      "           -1.0994e+00,  3.9053e-01],\n",
      "          [-1.4558e+00, -8.7287e-01, -1.6802e-01,  ...,  3.2438e-01,\n",
      "           -2.8787e-01, -7.1987e-01]],\n",
      "\n",
      "         [[ 2.3178e-04,  2.8715e-04,  3.5852e-04,  ..., -3.6939e-04,\n",
      "           -3.7127e-04,  1.3057e-04],\n",
      "          [-2.5072e-01, -5.7386e-01, -5.3542e-01,  ...,  9.0584e-01,\n",
      "           -8.1725e-01,  2.2277e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2665e+00,  6.7526e-01,  1.2466e+00,  ...,  7.3502e-01,\n",
      "            2.3085e-01,  1.7551e+00],\n",
      "          [-1.6650e+00,  7.0561e-01,  8.5084e-01,  ...,  1.0224e-01,\n",
      "           -2.2420e-01,  3.0425e-01]],\n",
      "\n",
      "         [[ 2.0940e+00,  6.0122e-01, -1.2829e+00,  ..., -7.0263e-01,\n",
      "           -1.1112e+00,  1.0588e+00],\n",
      "          [-5.8305e-01, -1.8310e+00,  8.4704e-01,  ...,  2.6221e-01,\n",
      "           -2.2353e-01, -8.5414e-01]],\n",
      "\n",
      "         [[ 3.2650e-01, -3.5091e-01, -6.2157e-01,  ..., -1.0291e-03,\n",
      "            1.1583e-01, -4.1912e-01],\n",
      "          [ 4.2019e-01,  9.8855e-01,  1.9946e+00,  ...,  1.1640e+00,\n",
      "            5.8529e-01,  9.4889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7331e-01,  5.2801e-01, -4.2028e-01,  ..., -9.4255e-01,\n",
      "           -2.9589e-01, -1.9760e-01],\n",
      "          [-2.9670e+00,  1.4995e-01,  2.1549e-01,  ...,  2.7717e+00,\n",
      "            6.8833e-02, -1.2742e-01]],\n",
      "\n",
      "         [[ 3.3820e-01, -7.4240e-01, -2.8485e-01,  ..., -1.4451e+00,\n",
      "           -1.3209e+00, -7.1976e-01],\n",
      "          [-1.9588e+00, -6.2597e-01, -1.6108e-01,  ...,  1.6841e+00,\n",
      "            1.3562e+00, -2.0235e-02]],\n",
      "\n",
      "         [[ 7.2609e-01,  1.3037e-01, -1.0744e+00,  ...,  5.4962e-01,\n",
      "           -2.0642e+00,  1.3345e+00],\n",
      "          [-2.0890e+00, -1.8207e-01,  5.4301e-01,  ...,  2.7916e-01,\n",
      "           -3.9749e-01,  1.4895e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1131e-02,  2.6337e+00,  2.9215e+00,  ..., -6.6251e-01,\n",
      "           -1.7802e+00,  3.6676e-01],\n",
      "          [-1.2626e+00, -8.6296e-02, -6.3145e-02,  ...,  8.4769e-01,\n",
      "            8.6587e-02, -3.3617e-01]],\n",
      "\n",
      "         [[ 4.8085e-01, -7.4002e-01, -1.8455e+00,  ..., -1.4186e+00,\n",
      "           -3.1732e-01,  1.0304e+00],\n",
      "          [-2.6066e-02,  1.3820e-03, -7.4557e-04,  ...,  1.5765e-02,\n",
      "           -5.4108e-03, -5.4818e-03]],\n",
      "\n",
      "         [[ 2.2051e-01, -5.4999e-01, -1.4996e+00,  ..., -3.6367e-01,\n",
      "            2.1665e-01, -4.8900e-01],\n",
      "          [ 3.8345e-01,  1.9004e+00,  1.8570e+00,  ...,  1.0942e+00,\n",
      "            5.6603e-01,  8.8172e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 2.0835e-02,  7.4353e-04,  3.7791e-01,  ..., -9.2583e-02,\n",
      "           -9.6411e-01,  2.6416e-01],\n",
      "          [-2.6057e+00,  2.6281e-01,  1.7096e-01,  ...,  2.6143e+00,\n",
      "            9.3118e-02, -1.6526e+00]],\n",
      "\n",
      "         [[-2.7114e-02,  1.0700e+00,  1.8663e+00,  ..., -1.4465e+00,\n",
      "           -1.0994e+00,  3.9053e-01],\n",
      "          [-1.4558e+00, -8.7287e-01, -1.6802e-01,  ...,  3.2438e-01,\n",
      "           -2.8787e-01, -7.1987e-01]],\n",
      "\n",
      "         [[ 2.3178e-04,  2.8715e-04,  3.5852e-04,  ..., -3.6939e-04,\n",
      "           -3.7127e-04,  1.3057e-04],\n",
      "          [-2.5072e-01, -5.7386e-01, -5.3542e-01,  ...,  9.0584e-01,\n",
      "           -8.1725e-01,  2.2277e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2665e+00,  6.7526e-01,  1.2466e+00,  ...,  7.3502e-01,\n",
      "            2.3085e-01,  1.7551e+00],\n",
      "          [-1.6650e+00,  7.0561e-01,  8.5084e-01,  ...,  1.0224e-01,\n",
      "           -2.2420e-01,  3.0425e-01]],\n",
      "\n",
      "         [[ 2.0940e+00,  6.0122e-01, -1.2829e+00,  ..., -7.0263e-01,\n",
      "           -1.1112e+00,  1.0588e+00],\n",
      "          [-5.8305e-01, -1.8310e+00,  8.4704e-01,  ...,  2.6221e-01,\n",
      "           -2.2353e-01, -8.5414e-01]],\n",
      "\n",
      "         [[ 3.2650e-01, -3.5091e-01, -6.2157e-01,  ..., -1.0291e-03,\n",
      "            1.1583e-01, -4.1912e-01],\n",
      "          [ 4.2019e-01,  9.8855e-01,  1.9946e+00,  ...,  1.1640e+00,\n",
      "            5.8529e-01,  9.4889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7331e-01,  5.2801e-01, -4.2028e-01,  ..., -9.4255e-01,\n",
      "           -2.9589e-01, -1.9760e-01],\n",
      "          [-2.9670e+00,  1.4995e-01,  2.1549e-01,  ...,  2.7717e+00,\n",
      "            6.8833e-02, -1.2742e-01]],\n",
      "\n",
      "         [[ 3.3820e-01, -7.4240e-01, -2.8485e-01,  ..., -1.4451e+00,\n",
      "           -1.3209e+00, -7.1976e-01],\n",
      "          [-1.9588e+00, -6.2597e-01, -1.6108e-01,  ...,  1.6841e+00,\n",
      "            1.3562e+00, -2.0235e-02]],\n",
      "\n",
      "         [[ 7.2609e-01,  1.3037e-01, -1.0744e+00,  ...,  5.4962e-01,\n",
      "           -2.0642e+00,  1.3345e+00],\n",
      "          [-2.0890e+00, -1.8207e-01,  5.4301e-01,  ...,  2.7916e-01,\n",
      "           -3.9749e-01,  1.4895e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1131e-02,  2.6337e+00,  2.9215e+00,  ..., -6.6251e-01,\n",
      "           -1.7802e+00,  3.6676e-01],\n",
      "          [-1.2626e+00, -8.6296e-02, -6.3145e-02,  ...,  8.4769e-01,\n",
      "            8.6587e-02, -3.3617e-01]],\n",
      "\n",
      "         [[ 4.8085e-01, -7.4002e-01, -1.8455e+00,  ..., -1.4186e+00,\n",
      "           -3.1732e-01,  1.0304e+00],\n",
      "          [-2.6066e-02,  1.3820e-03, -7.4557e-04,  ...,  1.5765e-02,\n",
      "           -5.4108e-03, -5.4818e-03]],\n",
      "\n",
      "         [[ 2.2051e-01, -5.4999e-01, -1.4996e+00,  ..., -3.6367e-01,\n",
      "            2.1665e-01, -4.8900e-01],\n",
      "          [ 3.8345e-01,  1.9004e+00,  1.8570e+00,  ...,  1.0942e+00,\n",
      "            5.6603e-01,  8.8172e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.6228,  0.7838],\n",
      "        [ 0.3862, -0.8311]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:42:51,737] Trial 8 finished with value: 0.70168 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.453900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.6973, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.2489]],\n",
      "\n",
      "         [[-0.0000, -1.6193, -0.4598,  ..., -0.8056,  0.2981,  0.0000],\n",
      "          [-0.7461,  1.6115,  1.1518,  ...,  0.5032, -0.9325,  1.0400]],\n",
      "\n",
      "         [[-0.4997,  1.8190, -1.1060,  ...,  0.0655, -0.0000,  0.3980],\n",
      "          [ 0.8034,  1.1221, -0.0206,  ...,  0.8478,  1.1994,  0.0279]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8169, -0.0119, -0.4536,  ..., -0.9042, -2.3186, -0.5380],\n",
      "          [ 0.6494,  0.3279,  0.3943,  ..., -0.0000, -0.1308, -0.5119]],\n",
      "\n",
      "         [[-0.7978, -0.5634, -1.3197,  ...,  0.4453, -1.0636,  0.2595],\n",
      "          [ 0.6354,  1.6530,  0.5107,  ..., -0.0000, -1.5089,  0.8070]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "\n",
      "\n",
      "        [[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.0000, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.0000]],\n",
      "\n",
      "         [[-2.6440,  0.0173, -0.7323,  ..., -0.7286, -1.1879,  1.5922],\n",
      "          [-0.8151,  1.7304,  0.0472,  ...,  0.2557,  0.1512,  0.5416]],\n",
      "\n",
      "         [[-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.5335,  1.6594],\n",
      "          [ 0.7254,  1.5112, -1.1422,  ..., -0.0000, -0.0000,  1.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7299, -1.9206, -0.7837,  ..., -0.7120, -2.3027, -0.4846],\n",
      "          [ 0.7892,  1.8889,  0.0000,  ...,  0.7165, -0.3872, -0.8370]],\n",
      "\n",
      "         [[ 0.0263,  0.9362, -1.4482,  ..., -0.1449, -1.0205, -0.0701],\n",
      "          [-1.3506,  1.5469, -0.3016,  ..., -1.1962, -1.6402,  1.6523]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.6973, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.2489]],\n",
      "\n",
      "         [[-0.0000, -1.6193, -0.4598,  ..., -0.8056,  0.2981,  0.0000],\n",
      "          [-0.7461,  1.6115,  1.1518,  ...,  0.5032, -0.9325,  1.0400]],\n",
      "\n",
      "         [[-0.4997,  1.8190, -1.1060,  ...,  0.0655, -0.0000,  0.3980],\n",
      "          [ 0.8034,  1.1221, -0.0206,  ...,  0.8478,  1.1994,  0.0279]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8169, -0.0119, -0.4536,  ..., -0.9042, -2.3186, -0.5380],\n",
      "          [ 0.6494,  0.3279,  0.3943,  ..., -0.0000, -0.1308, -0.5119]],\n",
      "\n",
      "         [[-0.7978, -0.5634, -1.3197,  ...,  0.4453, -1.0636,  0.2595],\n",
      "          [ 0.6354,  1.6530,  0.5107,  ..., -0.0000, -1.5089,  0.8070]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "\n",
      "\n",
      "        [[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.0000, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.0000]],\n",
      "\n",
      "         [[-2.6440,  0.0173, -0.7323,  ..., -0.7286, -1.1879,  1.5922],\n",
      "          [-0.8151,  1.7304,  0.0472,  ...,  0.2557,  0.1512,  0.5416]],\n",
      "\n",
      "         [[-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.5335,  1.6594],\n",
      "          [ 0.7254,  1.5112, -1.1422,  ..., -0.0000, -0.0000,  1.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7299, -1.9206, -0.7837,  ..., -0.7120, -2.3027, -0.4846],\n",
      "          [ 0.7892,  1.8889,  0.0000,  ...,  0.7165, -0.3872, -0.8370]],\n",
      "\n",
      "         [[ 0.0263,  0.9362, -1.4482,  ..., -0.1449, -1.0205, -0.0701],\n",
      "          [-1.3506,  1.5469, -0.3016,  ..., -1.1962, -1.6402,  1.6523]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.2489],\n",
      "         [-0.0000, -1.6193, -0.4598,  ...,  0.5032, -0.9325,  1.0400],\n",
      "         [-0.4997,  1.8190, -1.1060,  ...,  0.8478,  1.1994,  0.0279],\n",
      "         ...,\n",
      "         [-1.8169, -0.0119, -0.4536,  ..., -0.0000, -0.1308, -0.5119],\n",
      "         [-0.7978, -0.5634, -1.3197,  ..., -0.0000, -1.5089,  0.8070],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]],\n",
      "\n",
      "        [[-1.1140,  1.2499, -1.5262,  ..., -1.3086, -0.0889, -0.0000],\n",
      "         [-2.6440,  0.0173, -0.7323,  ...,  0.2557,  0.1512,  0.5416],\n",
      "         [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.0000,  1.0663],\n",
      "         ...,\n",
      "         [-0.7299, -1.9206, -0.7837,  ...,  0.7165, -0.3872, -0.8370],\n",
      "         [ 0.0263,  0.9362, -1.4482,  ..., -1.1962, -1.6402,  1.6523],\n",
      "         [-0.6766,  0.2183, -2.6249,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.6973, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.2489]],\n",
      "\n",
      "         [[-0.0000, -1.6193, -0.4598,  ..., -0.8056,  0.2981,  0.0000],\n",
      "          [-0.7461,  1.6115,  1.1518,  ...,  0.5032, -0.9325,  1.0400]],\n",
      "\n",
      "         [[-0.4997,  1.8190, -1.1060,  ...,  0.0655, -0.0000,  0.3980],\n",
      "          [ 0.8034,  1.1221, -0.0206,  ...,  0.8478,  1.1994,  0.0279]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8169, -0.0119, -0.4536,  ..., -0.9042, -2.3186, -0.5380],\n",
      "          [ 0.6494,  0.3279,  0.3943,  ..., -0.0000, -0.1308, -0.5119]],\n",
      "\n",
      "         [[-0.7978, -0.5634, -1.3197,  ...,  0.4453, -1.0636,  0.2595],\n",
      "          [ 0.6354,  1.6530,  0.5107,  ..., -0.0000, -1.5089,  0.8070]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "\n",
      "\n",
      "        [[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.0000, -0.5225],\n",
      "          [-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.0000]],\n",
      "\n",
      "         [[-2.6440,  0.0173, -0.7323,  ..., -0.7286, -1.1879,  1.5922],\n",
      "          [-0.8151,  1.7304,  0.0472,  ...,  0.2557,  0.1512,  0.5416]],\n",
      "\n",
      "         [[-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.5335,  1.6594],\n",
      "          [ 0.7254,  1.5112, -1.1422,  ..., -0.0000, -0.0000,  1.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7299, -1.9206, -0.7837,  ..., -0.7120, -2.3027, -0.4846],\n",
      "          [ 0.7892,  1.8889,  0.0000,  ...,  0.7165, -0.3872, -0.8370]],\n",
      "\n",
      "         [[ 0.0263,  0.9362, -1.4482,  ..., -0.1449, -1.0205, -0.0701],\n",
      "          [-1.3506,  1.5469, -0.3016,  ..., -1.1962, -1.6402,  1.6523]],\n",
      "\n",
      "         [[-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.6973, -0.5225],\n",
      "          [-0.0000, -1.6193, -0.4598,  ..., -0.8056,  0.2981,  0.0000],\n",
      "          [-0.4997,  1.8190, -1.1060,  ...,  0.0655, -0.0000,  0.3980],\n",
      "          ...,\n",
      "          [-1.8169, -0.0119, -0.4536,  ..., -0.9042, -2.3186, -0.5380],\n",
      "          [-0.7978, -0.5634, -1.3197,  ...,  0.4453, -1.0636,  0.2595],\n",
      "          [-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092]],\n",
      "\n",
      "         [[-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.2489],\n",
      "          [-0.7461,  1.6115,  1.1518,  ...,  0.5032, -0.9325,  1.0400],\n",
      "          [ 0.8034,  1.1221, -0.0206,  ...,  0.8478,  1.1994,  0.0279],\n",
      "          ...,\n",
      "          [ 0.6494,  0.3279,  0.3943,  ..., -0.0000, -0.1308, -0.5119],\n",
      "          [ 0.6354,  1.6530,  0.5107,  ..., -0.0000, -1.5089,  0.8070],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]],\n",
      "\n",
      "\n",
      "        [[[-1.1140,  1.2499, -1.5262,  ...,  1.0593, -0.0000, -0.5225],\n",
      "          [-2.6440,  0.0173, -0.7323,  ..., -0.7286, -1.1879,  1.5922],\n",
      "          [-1.6120,  0.0000, -1.2913,  ..., -0.0000, -0.5335,  1.6594],\n",
      "          ...,\n",
      "          [-0.7299, -1.9206, -0.7837,  ..., -0.7120, -2.3027, -0.4846],\n",
      "          [ 0.0263,  0.9362, -1.4482,  ..., -0.1449, -1.0205, -0.0701],\n",
      "          [-0.6766,  0.2183, -2.6249,  ...,  1.5625, -1.2729, -1.8092]],\n",
      "\n",
      "         [[-0.2354,  1.5093,  0.3794,  ..., -1.3086, -0.0889, -0.0000],\n",
      "          [-0.8151,  1.7304,  0.0472,  ...,  0.2557,  0.1512,  0.5416],\n",
      "          [ 0.7254,  1.5112, -1.1422,  ..., -0.0000, -0.0000,  1.0663],\n",
      "          ...,\n",
      "          [ 0.7892,  1.8889,  0.0000,  ...,  0.7165, -0.3872, -0.8370],\n",
      "          [-1.3506,  1.5469, -0.3016,  ..., -1.1962, -1.6402,  1.6523],\n",
      "          [-1.9859, -0.1079, -0.3133,  ..., -0.2487, -0.5589,  0.3633]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.2264e+00,  1.3739e+00, -1.6845e+00,  ...,  1.1662e+00,\n",
      "           -7.6980e-01, -5.7344e-01],\n",
      "          [-4.6835e-03, -1.7897e+00, -5.1527e-01,  ..., -8.8878e-01,\n",
      "            3.2281e-01, -2.4413e-03],\n",
      "          [-5.5553e-01,  2.0141e+00, -1.2298e+00,  ...,  7.3543e-02,\n",
      "           -3.6110e-03,  4.4021e-01],\n",
      "          ...,\n",
      "          [-2.0118e+00, -1.1008e-02, -5.1039e-01,  ..., -9.9545e-01,\n",
      "           -2.5662e+00, -5.9621e-01],\n",
      "          [-8.7754e-01, -5.5519e-01, -1.4449e+00,  ...,  4.3753e-01,\n",
      "           -1.1761e+00,  2.6318e-01],\n",
      "          [-7.5174e-01,  2.4218e-01, -2.9154e+00,  ...,  1.7349e+00,\n",
      "           -1.4141e+00, -2.0091e+00]],\n",
      "\n",
      "         [[-1.6225e-01,  1.6286e+00,  3.9801e-01,  ..., -1.0861e+00,\n",
      "           -2.2796e-01, -1.2672e-01],\n",
      "          [-8.1077e-01,  1.7830e+00,  1.2648e+00,  ...,  5.4926e-01,\n",
      "           -1.0229e+00,  1.1394e+00],\n",
      "          [ 8.8606e-01,  1.2481e+00, -1.8877e-02,  ...,  9.3351e-01,\n",
      "            1.3188e+00,  3.2638e-02],\n",
      "          ...,\n",
      "          [ 6.9015e-01,  4.1286e-01,  4.3263e-01,  ..., -3.0134e-03,\n",
      "           -1.7626e-01, -5.2169e-01],\n",
      "          [ 7.0366e-01,  1.8345e+00,  5.6617e-01,  ..., -1.2859e-03,\n",
      "           -1.6724e+00,  8.9339e-01],\n",
      "          [-2.1311e+00, -8.6822e-02, -3.2910e-01,  ..., -2.7438e-01,\n",
      "           -6.1538e-01,  3.9199e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9767e-02, -2.7041e-03, -2.0972e-02,  ...,  8.2577e-03,\n",
      "           -1.9292e-02, -5.0572e-04],\n",
      "          [-2.9146e+00,  1.5747e-02, -8.3060e-01,  ..., -7.9022e-01,\n",
      "           -1.3163e+00,  1.7481e+00],\n",
      "          [-1.7820e+00,  4.2976e-03, -1.4372e+00,  ...,  5.8519e-03,\n",
      "           -5.9952e-01,  1.8166e+00],\n",
      "          ...,\n",
      "          [-8.3268e-01, -1.8795e+00, -9.1774e-01,  ..., -6.4168e-01,\n",
      "           -2.3481e+00, -5.0214e-01],\n",
      "          [-1.6341e-02,  1.0020e+00, -1.6127e+00,  ..., -1.3812e-01,\n",
      "           -1.1277e+00, -7.7602e-02],\n",
      "          [-7.5195e-01,  2.4261e-01, -2.9154e+00,  ...,  1.7348e+00,\n",
      "           -1.4138e+00, -2.0083e+00]],\n",
      "\n",
      "         [[-1.4931e-01,  1.5084e+00,  2.7837e-01,  ..., -1.1789e+00,\n",
      "           -1.2896e-01,  1.6268e-01],\n",
      "          [-8.9331e-01,  1.8997e+00,  4.9539e-02,  ...,  2.7422e-01,\n",
      "            1.6110e-01,  5.9863e-01],\n",
      "          [ 7.9763e-01,  1.6680e+00, -1.2545e+00,  ..., -5.2731e-03,\n",
      "           -2.0212e-03,  1.1753e+00],\n",
      "          ...,\n",
      "          [-9.9837e-04,  2.9900e-03, -2.2241e-04,  ..., -1.2934e-03,\n",
      "           -7.1475e-04,  2.2769e-03],\n",
      "          [-1.4964e+00,  1.7167e+00, -3.3463e-01,  ..., -1.3252e+00,\n",
      "           -1.8177e+00,  1.8318e+00],\n",
      "          [-2.0787e+00, -7.6571e-02, -3.3222e-01,  ..., -2.8300e-01,\n",
      "           -6.0625e-01,  4.1621e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-1.2264e+00,  1.3739e+00, -1.6845e+00,  ...,  1.1662e+00,\n",
      "           -7.6980e-01, -5.7344e-01],\n",
      "          [-1.6225e-01,  1.6286e+00,  3.9801e-01,  ..., -1.0861e+00,\n",
      "           -2.2796e-01, -1.2672e-01]],\n",
      "\n",
      "         [[-4.6835e-03, -1.7897e+00, -5.1527e-01,  ..., -8.8878e-01,\n",
      "            3.2281e-01, -2.4413e-03],\n",
      "          [-8.1077e-01,  1.7830e+00,  1.2648e+00,  ...,  5.4926e-01,\n",
      "           -1.0229e+00,  1.1394e+00]],\n",
      "\n",
      "         [[-5.5553e-01,  2.0141e+00, -1.2298e+00,  ...,  7.3543e-02,\n",
      "           -3.6110e-03,  4.4021e-01],\n",
      "          [ 8.8606e-01,  1.2481e+00, -1.8877e-02,  ...,  9.3351e-01,\n",
      "            1.3188e+00,  3.2638e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0118e+00, -1.1008e-02, -5.1039e-01,  ..., -9.9545e-01,\n",
      "           -2.5662e+00, -5.9621e-01],\n",
      "          [ 6.9015e-01,  4.1286e-01,  4.3263e-01,  ..., -3.0134e-03,\n",
      "           -1.7626e-01, -5.2169e-01]],\n",
      "\n",
      "         [[-8.7754e-01, -5.5519e-01, -1.4449e+00,  ...,  4.3753e-01,\n",
      "           -1.1761e+00,  2.6318e-01],\n",
      "          [ 7.0366e-01,  1.8345e+00,  5.6617e-01,  ..., -1.2859e-03,\n",
      "           -1.6724e+00,  8.9339e-01]],\n",
      "\n",
      "         [[-7.5174e-01,  2.4218e-01, -2.9154e+00,  ...,  1.7349e+00,\n",
      "           -1.4141e+00, -2.0091e+00],\n",
      "          [-2.1311e+00, -8.6822e-02, -3.2910e-01,  ..., -2.7438e-01,\n",
      "           -6.1538e-01,  3.9199e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9767e-02, -2.7041e-03, -2.0972e-02,  ...,  8.2577e-03,\n",
      "           -1.9292e-02, -5.0572e-04],\n",
      "          [-1.4931e-01,  1.5084e+00,  2.7837e-01,  ..., -1.1789e+00,\n",
      "           -1.2896e-01,  1.6268e-01]],\n",
      "\n",
      "         [[-2.9146e+00,  1.5747e-02, -8.3060e-01,  ..., -7.9022e-01,\n",
      "           -1.3163e+00,  1.7481e+00],\n",
      "          [-8.9331e-01,  1.8997e+00,  4.9539e-02,  ...,  2.7422e-01,\n",
      "            1.6110e-01,  5.9863e-01]],\n",
      "\n",
      "         [[-1.7820e+00,  4.2976e-03, -1.4372e+00,  ...,  5.8519e-03,\n",
      "           -5.9952e-01,  1.8166e+00],\n",
      "          [ 7.9763e-01,  1.6680e+00, -1.2545e+00,  ..., -5.2731e-03,\n",
      "           -2.0212e-03,  1.1753e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.3268e-01, -1.8795e+00, -9.1774e-01,  ..., -6.4168e-01,\n",
      "           -2.3481e+00, -5.0214e-01],\n",
      "          [-9.9837e-04,  2.9900e-03, -2.2241e-04,  ..., -1.2934e-03,\n",
      "           -7.1475e-04,  2.2769e-03]],\n",
      "\n",
      "         [[-1.6341e-02,  1.0020e+00, -1.6127e+00,  ..., -1.3812e-01,\n",
      "           -1.1277e+00, -7.7602e-02],\n",
      "          [-1.4964e+00,  1.7167e+00, -3.3463e-01,  ..., -1.3252e+00,\n",
      "           -1.8177e+00,  1.8318e+00]],\n",
      "\n",
      "         [[-7.5195e-01,  2.4261e-01, -2.9154e+00,  ...,  1.7348e+00,\n",
      "           -1.4138e+00, -2.0083e+00],\n",
      "          [-2.0787e+00, -7.6571e-02, -3.3222e-01,  ..., -2.8300e-01,\n",
      "           -6.0625e-01,  4.1621e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.2264e+00,  1.3739e+00, -1.6845e+00,  ...,  1.1662e+00,\n",
      "           -7.6980e-01, -5.7344e-01],\n",
      "          [-1.6225e-01,  1.6286e+00,  3.9801e-01,  ..., -1.0861e+00,\n",
      "           -2.2796e-01, -1.2672e-01]],\n",
      "\n",
      "         [[-4.6835e-03, -1.7897e+00, -5.1527e-01,  ..., -8.8878e-01,\n",
      "            3.2281e-01, -2.4413e-03],\n",
      "          [-8.1077e-01,  1.7830e+00,  1.2648e+00,  ...,  5.4926e-01,\n",
      "           -1.0229e+00,  1.1394e+00]],\n",
      "\n",
      "         [[-5.5553e-01,  2.0141e+00, -1.2298e+00,  ...,  7.3543e-02,\n",
      "           -3.6110e-03,  4.4021e-01],\n",
      "          [ 8.8606e-01,  1.2481e+00, -1.8877e-02,  ...,  9.3351e-01,\n",
      "            1.3188e+00,  3.2638e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0118e+00, -1.1008e-02, -5.1039e-01,  ..., -9.9545e-01,\n",
      "           -2.5662e+00, -5.9621e-01],\n",
      "          [ 6.9015e-01,  4.1286e-01,  4.3263e-01,  ..., -3.0134e-03,\n",
      "           -1.7626e-01, -5.2169e-01]],\n",
      "\n",
      "         [[-8.7754e-01, -5.5519e-01, -1.4449e+00,  ...,  4.3753e-01,\n",
      "           -1.1761e+00,  2.6318e-01],\n",
      "          [ 7.0366e-01,  1.8345e+00,  5.6617e-01,  ..., -1.2859e-03,\n",
      "           -1.6724e+00,  8.9339e-01]],\n",
      "\n",
      "         [[-7.5174e-01,  2.4218e-01, -2.9154e+00,  ...,  1.7349e+00,\n",
      "           -1.4141e+00, -2.0091e+00],\n",
      "          [-2.1311e+00, -8.6822e-02, -3.2910e-01,  ..., -2.7438e-01,\n",
      "           -6.1538e-01,  3.9199e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9767e-02, -2.7041e-03, -2.0972e-02,  ...,  8.2577e-03,\n",
      "           -1.9292e-02, -5.0572e-04],\n",
      "          [-1.4931e-01,  1.5084e+00,  2.7837e-01,  ..., -1.1789e+00,\n",
      "           -1.2896e-01,  1.6268e-01]],\n",
      "\n",
      "         [[-2.9146e+00,  1.5747e-02, -8.3060e-01,  ..., -7.9022e-01,\n",
      "           -1.3163e+00,  1.7481e+00],\n",
      "          [-8.9331e-01,  1.8997e+00,  4.9539e-02,  ...,  2.7422e-01,\n",
      "            1.6110e-01,  5.9863e-01]],\n",
      "\n",
      "         [[-1.7820e+00,  4.2976e-03, -1.4372e+00,  ...,  5.8519e-03,\n",
      "           -5.9952e-01,  1.8166e+00],\n",
      "          [ 7.9763e-01,  1.6680e+00, -1.2545e+00,  ..., -5.2731e-03,\n",
      "           -2.0212e-03,  1.1753e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.3268e-01, -1.8795e+00, -9.1774e-01,  ..., -6.4168e-01,\n",
      "           -2.3481e+00, -5.0214e-01],\n",
      "          [-9.9837e-04,  2.9900e-03, -2.2241e-04,  ..., -1.2934e-03,\n",
      "           -7.1475e-04,  2.2769e-03]],\n",
      "\n",
      "         [[-1.6341e-02,  1.0020e+00, -1.6127e+00,  ..., -1.3812e-01,\n",
      "           -1.1277e+00, -7.7602e-02],\n",
      "          [-1.4964e+00,  1.7167e+00, -3.3463e-01,  ..., -1.3252e+00,\n",
      "           -1.8177e+00,  1.8318e+00]],\n",
      "\n",
      "         [[-7.5195e-01,  2.4261e-01, -2.9154e+00,  ...,  1.7348e+00,\n",
      "           -1.4138e+00, -2.0083e+00],\n",
      "          [-2.0787e+00, -7.6571e-02, -3.3222e-01,  ..., -2.8300e-01,\n",
      "           -6.0625e-01,  4.1621e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-1.2264e+00,  1.3739e+00, -1.6845e+00,  ...,  1.1662e+00,\n",
      "           -7.6980e-01, -5.7344e-01],\n",
      "          [-1.6225e-01,  1.6286e+00,  3.9801e-01,  ..., -1.0861e+00,\n",
      "           -2.2796e-01, -1.2672e-01]],\n",
      "\n",
      "         [[-4.6835e-03, -1.7897e+00, -5.1527e-01,  ..., -8.8878e-01,\n",
      "            3.2281e-01, -2.4413e-03],\n",
      "          [-8.1077e-01,  1.7830e+00,  1.2648e+00,  ...,  5.4926e-01,\n",
      "           -1.0229e+00,  1.1394e+00]],\n",
      "\n",
      "         [[-5.5553e-01,  2.0141e+00, -1.2298e+00,  ...,  7.3543e-02,\n",
      "           -3.6110e-03,  4.4021e-01],\n",
      "          [ 8.8606e-01,  1.2481e+00, -1.8877e-02,  ...,  9.3351e-01,\n",
      "            1.3188e+00,  3.2638e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0118e+00, -1.1008e-02, -5.1039e-01,  ..., -9.9545e-01,\n",
      "           -2.5662e+00, -5.9621e-01],\n",
      "          [ 6.9015e-01,  4.1286e-01,  4.3263e-01,  ..., -3.0134e-03,\n",
      "           -1.7626e-01, -5.2169e-01]],\n",
      "\n",
      "         [[-8.7754e-01, -5.5519e-01, -1.4449e+00,  ...,  4.3753e-01,\n",
      "           -1.1761e+00,  2.6318e-01],\n",
      "          [ 7.0366e-01,  1.8345e+00,  5.6617e-01,  ..., -1.2859e-03,\n",
      "           -1.6724e+00,  8.9339e-01]],\n",
      "\n",
      "         [[-7.5174e-01,  2.4218e-01, -2.9154e+00,  ...,  1.7349e+00,\n",
      "           -1.4141e+00, -2.0091e+00],\n",
      "          [-2.1311e+00, -8.6822e-02, -3.2910e-01,  ..., -2.7438e-01,\n",
      "           -6.1538e-01,  3.9199e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9767e-02, -2.7041e-03, -2.0972e-02,  ...,  8.2577e-03,\n",
      "           -1.9292e-02, -5.0572e-04],\n",
      "          [-1.4931e-01,  1.5084e+00,  2.7837e-01,  ..., -1.1789e+00,\n",
      "           -1.2896e-01,  1.6268e-01]],\n",
      "\n",
      "         [[-2.9146e+00,  1.5747e-02, -8.3060e-01,  ..., -7.9022e-01,\n",
      "           -1.3163e+00,  1.7481e+00],\n",
      "          [-8.9331e-01,  1.8997e+00,  4.9539e-02,  ...,  2.7422e-01,\n",
      "            1.6110e-01,  5.9863e-01]],\n",
      "\n",
      "         [[-1.7820e+00,  4.2976e-03, -1.4372e+00,  ...,  5.8519e-03,\n",
      "           -5.9952e-01,  1.8166e+00],\n",
      "          [ 7.9763e-01,  1.6680e+00, -1.2545e+00,  ..., -5.2731e-03,\n",
      "           -2.0212e-03,  1.1753e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.3268e-01, -1.8795e+00, -9.1774e-01,  ..., -6.4168e-01,\n",
      "           -2.3481e+00, -5.0214e-01],\n",
      "          [-9.9837e-04,  2.9900e-03, -2.2241e-04,  ..., -1.2934e-03,\n",
      "           -7.1475e-04,  2.2769e-03]],\n",
      "\n",
      "         [[-1.6341e-02,  1.0020e+00, -1.6127e+00,  ..., -1.3812e-01,\n",
      "           -1.1277e+00, -7.7602e-02],\n",
      "          [-1.4964e+00,  1.7167e+00, -3.3463e-01,  ..., -1.3252e+00,\n",
      "           -1.8177e+00,  1.8318e+00]],\n",
      "\n",
      "         [[-7.5195e-01,  2.4261e-01, -2.9154e+00,  ...,  1.7348e+00,\n",
      "           -1.4138e+00, -2.0083e+00],\n",
      "          [-2.0787e+00, -7.6571e-02, -3.3222e-01,  ..., -2.8300e-01,\n",
      "           -6.0625e-01,  4.1621e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ...,  4.6278e-01,\n",
      "           -7.8411e-01, -7.8728e-01],\n",
      "          [-1.6898e-01,  1.7928e+00,  7.2307e-01,  ..., -1.7298e+00,\n",
      "           -2.9629e-01, -3.2156e-01]],\n",
      "\n",
      "         [[ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ..., -5.0059e-01,\n",
      "            2.2858e-01, -1.0340e-01],\n",
      "          [-7.5633e-01,  1.6384e+00,  1.4203e+00,  ...,  5.0526e-01,\n",
      "           -9.4750e-01,  7.7258e-01]],\n",
      "\n",
      "         [[-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  1.5347e-01,\n",
      "           -1.8890e-01,  1.6671e-01],\n",
      "          [ 8.5672e-01,  4.5324e-01,  3.2262e-01,  ...,  3.9724e-01,\n",
      "            9.2342e-01, -1.5072e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -6.3554e-01,\n",
      "           -2.4482e+00, -8.3288e-01],\n",
      "          [ 6.3840e-01,  4.4888e-01,  7.6914e-01,  ..., -3.4970e-01,\n",
      "           -5.4013e-02, -3.3646e-01]],\n",
      "\n",
      "         [[-7.5708e-01, -4.8968e-01, -1.3566e+00,  ...,  6.6122e-01,\n",
      "           -1.1550e+00,  2.5824e-01],\n",
      "          [ 6.4939e-01,  1.7005e+00,  9.4808e-01,  ..., -4.2441e-01,\n",
      "           -1.8286e+00,  9.7240e-01]],\n",
      "\n",
      "         [[-4.3464e-01,  3.3441e-01, -1.4876e+00,  ...,  1.7171e+00,\n",
      "           -1.1925e+00, -1.8586e+00],\n",
      "          [-1.6698e+00, -1.1338e-01, -1.7398e-01,  ..., -4.0257e-01,\n",
      "           -5.8036e-01,  1.2654e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ...,  5.8636e-01,\n",
      "           -9.6822e-02, -6.1756e-01],\n",
      "          [-2.4870e-01,  2.1938e+00,  6.8853e-01,  ..., -2.1426e+00,\n",
      "           -2.0905e-01, -1.0188e-01]],\n",
      "\n",
      "         [[-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -2.3144e-01,\n",
      "           -9.2101e-01,  1.5480e+00],\n",
      "          [-1.0448e+00,  1.8169e+00,  9.9322e-02,  ..., -1.3186e-02,\n",
      "            6.2959e-01,  2.0978e-01]],\n",
      "\n",
      "         [[-6.4557e-01, -7.7935e-03, -1.6542e+00,  ...,  1.5895e-01,\n",
      "           -6.8619e-01,  1.3578e+00],\n",
      "          [ 1.0208e+00,  1.6190e+00, -8.7959e-01,  ..., -2.0733e-01,\n",
      "           -1.5266e-01,  1.2289e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -8.0243e-01,\n",
      "           -2.9504e+00, -8.7790e-01],\n",
      "          [ 8.0110e-01,  1.1525e+00,  3.7383e-01,  ..., -2.6979e-03,\n",
      "           -4.5430e-01, -5.2038e-01]],\n",
      "\n",
      "         [[ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ...,  7.7008e-02,\n",
      "           -1.1729e+00, -3.8027e-01],\n",
      "          [-1.1727e+00,  1.4718e+00,  1.5951e-01,  ..., -1.5390e+00,\n",
      "           -8.8609e-01,  1.4624e+00]],\n",
      "\n",
      "         [[-5.0235e-01,  2.7519e-01, -3.0937e+00,  ...,  1.5604e+00,\n",
      "           -1.3142e+00, -1.9667e+00],\n",
      "          [-1.8238e+00, -2.0953e-01, -2.0895e-01,  ..., -4.6284e-01,\n",
      "           -6.0812e-01,  8.2794e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ...,  4.6278e-01,\n",
      "           -7.8411e-01, -7.8728e-01],\n",
      "          [-1.6898e-01,  1.7928e+00,  7.2307e-01,  ..., -1.7298e+00,\n",
      "           -2.9629e-01, -3.2156e-01]],\n",
      "\n",
      "         [[ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ..., -5.0059e-01,\n",
      "            2.2858e-01, -1.0340e-01],\n",
      "          [-7.5633e-01,  1.6384e+00,  1.4203e+00,  ...,  5.0526e-01,\n",
      "           -9.4750e-01,  7.7258e-01]],\n",
      "\n",
      "         [[-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  1.5347e-01,\n",
      "           -1.8890e-01,  1.6671e-01],\n",
      "          [ 8.5672e-01,  4.5324e-01,  3.2262e-01,  ...,  3.9724e-01,\n",
      "            9.2342e-01, -1.5072e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -6.3554e-01,\n",
      "           -2.4482e+00, -8.3288e-01],\n",
      "          [ 6.3840e-01,  4.4888e-01,  7.6914e-01,  ..., -3.4970e-01,\n",
      "           -5.4013e-02, -3.3646e-01]],\n",
      "\n",
      "         [[-7.5708e-01, -4.8968e-01, -1.3566e+00,  ...,  6.6122e-01,\n",
      "           -1.1550e+00,  2.5824e-01],\n",
      "          [ 6.4939e-01,  1.7005e+00,  9.4808e-01,  ..., -4.2441e-01,\n",
      "           -1.8286e+00,  9.7240e-01]],\n",
      "\n",
      "         [[-4.3464e-01,  3.3441e-01, -1.4876e+00,  ...,  1.7171e+00,\n",
      "           -1.1925e+00, -1.8586e+00],\n",
      "          [-1.6698e+00, -1.1338e-01, -1.7398e-01,  ..., -4.0257e-01,\n",
      "           -5.8036e-01,  1.2654e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ...,  5.8636e-01,\n",
      "           -9.6822e-02, -6.1756e-01],\n",
      "          [-2.4870e-01,  2.1938e+00,  6.8853e-01,  ..., -2.1426e+00,\n",
      "           -2.0905e-01, -1.0188e-01]],\n",
      "\n",
      "         [[-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -2.3144e-01,\n",
      "           -9.2101e-01,  1.5480e+00],\n",
      "          [-1.0448e+00,  1.8169e+00,  9.9322e-02,  ..., -1.3186e-02,\n",
      "            6.2959e-01,  2.0978e-01]],\n",
      "\n",
      "         [[-6.4557e-01, -7.7935e-03, -1.6542e+00,  ...,  1.5895e-01,\n",
      "           -6.8619e-01,  1.3578e+00],\n",
      "          [ 1.0208e+00,  1.6190e+00, -8.7959e-01,  ..., -2.0733e-01,\n",
      "           -1.5266e-01,  1.2289e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -8.0243e-01,\n",
      "           -2.9504e+00, -8.7790e-01],\n",
      "          [ 8.0110e-01,  1.1525e+00,  3.7383e-01,  ..., -2.6979e-03,\n",
      "           -4.5430e-01, -5.2038e-01]],\n",
      "\n",
      "         [[ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ...,  7.7008e-02,\n",
      "           -1.1729e+00, -3.8027e-01],\n",
      "          [-1.1727e+00,  1.4718e+00,  1.5951e-01,  ..., -1.5390e+00,\n",
      "           -8.8609e-01,  1.4624e+00]],\n",
      "\n",
      "         [[-5.0235e-01,  2.7519e-01, -3.0937e+00,  ...,  1.5604e+00,\n",
      "           -1.3142e+00, -1.9667e+00],\n",
      "          [-1.8238e+00, -2.0953e-01, -2.0895e-01,  ..., -4.6284e-01,\n",
      "           -6.0812e-01,  8.2794e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ..., -1.7298e+00,\n",
      "          -2.9629e-01, -3.2156e-01],\n",
      "         [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ...,  5.0526e-01,\n",
      "          -9.4750e-01,  7.7258e-01],\n",
      "         [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  3.9724e-01,\n",
      "           9.2342e-01, -1.5072e-02],\n",
      "         ...,\n",
      "         [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -3.4970e-01,\n",
      "          -5.4013e-02, -3.3646e-01],\n",
      "         [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ..., -4.2441e-01,\n",
      "          -1.8286e+00,  9.7240e-01],\n",
      "         [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ..., -4.0257e-01,\n",
      "          -5.8036e-01,  1.2654e-01]],\n",
      "\n",
      "        [[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ..., -2.1426e+00,\n",
      "          -2.0905e-01, -1.0188e-01],\n",
      "         [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -1.3186e-02,\n",
      "           6.2959e-01,  2.0978e-01],\n",
      "         [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ..., -2.0733e-01,\n",
      "          -1.5266e-01,  1.2289e+00],\n",
      "         ...,\n",
      "         [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -2.6979e-03,\n",
      "          -4.5430e-01, -5.2038e-01],\n",
      "         [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ..., -1.5390e+00,\n",
      "          -8.8609e-01,  1.4624e+00],\n",
      "         [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ..., -4.6284e-01,\n",
      "          -6.0812e-01,  8.2794e-02]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ...,  4.6278e-01,\n",
      "           -7.8411e-01, -7.8728e-01],\n",
      "          [-1.6898e-01,  1.7928e+00,  7.2307e-01,  ..., -1.7298e+00,\n",
      "           -2.9629e-01, -3.2156e-01]],\n",
      "\n",
      "         [[ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ..., -5.0059e-01,\n",
      "            2.2858e-01, -1.0340e-01],\n",
      "          [-7.5633e-01,  1.6384e+00,  1.4203e+00,  ...,  5.0526e-01,\n",
      "           -9.4750e-01,  7.7258e-01]],\n",
      "\n",
      "         [[-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  1.5347e-01,\n",
      "           -1.8890e-01,  1.6671e-01],\n",
      "          [ 8.5672e-01,  4.5324e-01,  3.2262e-01,  ...,  3.9724e-01,\n",
      "            9.2342e-01, -1.5072e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -6.3554e-01,\n",
      "           -2.4482e+00, -8.3288e-01],\n",
      "          [ 6.3840e-01,  4.4888e-01,  7.6914e-01,  ..., -3.4970e-01,\n",
      "           -5.4013e-02, -3.3646e-01]],\n",
      "\n",
      "         [[-7.5708e-01, -4.8968e-01, -1.3566e+00,  ...,  6.6122e-01,\n",
      "           -1.1550e+00,  2.5824e-01],\n",
      "          [ 6.4939e-01,  1.7005e+00,  9.4808e-01,  ..., -4.2441e-01,\n",
      "           -1.8286e+00,  9.7240e-01]],\n",
      "\n",
      "         [[-4.3464e-01,  3.3441e-01, -1.4876e+00,  ...,  1.7171e+00,\n",
      "           -1.1925e+00, -1.8586e+00],\n",
      "          [-1.6698e+00, -1.1338e-01, -1.7398e-01,  ..., -4.0257e-01,\n",
      "           -5.8036e-01,  1.2654e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ...,  5.8636e-01,\n",
      "           -9.6822e-02, -6.1756e-01],\n",
      "          [-2.4870e-01,  2.1938e+00,  6.8853e-01,  ..., -2.1426e+00,\n",
      "           -2.0905e-01, -1.0188e-01]],\n",
      "\n",
      "         [[-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -2.3144e-01,\n",
      "           -9.2101e-01,  1.5480e+00],\n",
      "          [-1.0448e+00,  1.8169e+00,  9.9322e-02,  ..., -1.3186e-02,\n",
      "            6.2959e-01,  2.0978e-01]],\n",
      "\n",
      "         [[-6.4557e-01, -7.7935e-03, -1.6542e+00,  ...,  1.5895e-01,\n",
      "           -6.8619e-01,  1.3578e+00],\n",
      "          [ 1.0208e+00,  1.6190e+00, -8.7959e-01,  ..., -2.0733e-01,\n",
      "           -1.5266e-01,  1.2289e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -8.0243e-01,\n",
      "           -2.9504e+00, -8.7790e-01],\n",
      "          [ 8.0110e-01,  1.1525e+00,  3.7383e-01,  ..., -2.6979e-03,\n",
      "           -4.5430e-01, -5.2038e-01]],\n",
      "\n",
      "         [[ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ...,  7.7008e-02,\n",
      "           -1.1729e+00, -3.8027e-01],\n",
      "          [-1.1727e+00,  1.4718e+00,  1.5951e-01,  ..., -1.5390e+00,\n",
      "           -8.8609e-01,  1.4624e+00]],\n",
      "\n",
      "         [[-5.0235e-01,  2.7519e-01, -3.0937e+00,  ...,  1.5604e+00,\n",
      "           -1.3142e+00, -1.9667e+00],\n",
      "          [-1.8238e+00, -2.0953e-01, -2.0895e-01,  ..., -4.6284e-01,\n",
      "           -6.0812e-01,  8.2794e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1638e+00,  1.2131e+00, -1.6538e+00,  ...,  4.6278e-01,\n",
      "           -7.8411e-01, -7.8728e-01],\n",
      "          [ 1.5979e-04, -1.4297e+00, -5.2574e-01,  ..., -5.0059e-01,\n",
      "            2.2858e-01, -1.0340e-01],\n",
      "          [-4.5229e-01,  1.6507e+00, -1.0526e+00,  ...,  1.5347e-01,\n",
      "           -1.8890e-01,  1.6671e-01],\n",
      "          ...,\n",
      "          [-1.7251e+00, -1.4527e-02, -9.2621e-01,  ..., -6.3554e-01,\n",
      "           -2.4482e+00, -8.3288e-01],\n",
      "          [-7.5708e-01, -4.8968e-01, -1.3566e+00,  ...,  6.6122e-01,\n",
      "           -1.1550e+00,  2.5824e-01],\n",
      "          [-4.3464e-01,  3.3441e-01, -1.4876e+00,  ...,  1.7171e+00,\n",
      "           -1.1925e+00, -1.8586e+00]],\n",
      "\n",
      "         [[-1.6898e-01,  1.7928e+00,  7.2307e-01,  ..., -1.7298e+00,\n",
      "           -2.9629e-01, -3.2156e-01],\n",
      "          [-7.5633e-01,  1.6384e+00,  1.4203e+00,  ...,  5.0526e-01,\n",
      "           -9.4750e-01,  7.7258e-01],\n",
      "          [ 8.5672e-01,  4.5324e-01,  3.2262e-01,  ...,  3.9724e-01,\n",
      "            9.2342e-01, -1.5072e-02],\n",
      "          ...,\n",
      "          [ 6.3840e-01,  4.4888e-01,  7.6914e-01,  ..., -3.4970e-01,\n",
      "           -5.4013e-02, -3.3646e-01],\n",
      "          [ 6.4939e-01,  1.7005e+00,  9.4808e-01,  ..., -4.2441e-01,\n",
      "           -1.8286e+00,  9.7240e-01],\n",
      "          [-1.6698e+00, -1.1338e-01, -1.7398e-01,  ..., -4.0257e-01,\n",
      "           -5.8036e-01,  1.2654e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9109e-01,  6.3715e-01, -1.1278e+00,  ...,  5.8636e-01,\n",
      "           -9.6822e-02, -6.1756e-01],\n",
      "          [-2.4477e+00,  3.6027e-01, -9.2045e-01,  ..., -2.3144e-01,\n",
      "           -9.2101e-01,  1.5480e+00],\n",
      "          [-6.4557e-01, -7.7935e-03, -1.6542e+00,  ...,  1.5895e-01,\n",
      "           -6.8619e-01,  1.3578e+00],\n",
      "          ...,\n",
      "          [-7.7848e-01, -2.2584e+00, -1.0115e+00,  ..., -8.0243e-01,\n",
      "           -2.9504e+00, -8.7790e-01],\n",
      "          [ 3.9434e-02,  9.6892e-01, -1.7632e+00,  ...,  7.7008e-02,\n",
      "           -1.1729e+00, -3.8027e-01],\n",
      "          [-5.0235e-01,  2.7519e-01, -3.0937e+00,  ...,  1.5604e+00,\n",
      "           -1.3142e+00, -1.9667e+00]],\n",
      "\n",
      "         [[-2.4870e-01,  2.1938e+00,  6.8853e-01,  ..., -2.1426e+00,\n",
      "           -2.0905e-01, -1.0188e-01],\n",
      "          [-1.0448e+00,  1.8169e+00,  9.9322e-02,  ..., -1.3186e-02,\n",
      "            6.2959e-01,  2.0978e-01],\n",
      "          [ 1.0208e+00,  1.6190e+00, -8.7959e-01,  ..., -2.0733e-01,\n",
      "           -1.5266e-01,  1.2289e+00],\n",
      "          ...,\n",
      "          [ 8.0110e-01,  1.1525e+00,  3.7383e-01,  ..., -2.6979e-03,\n",
      "           -4.5430e-01, -5.2038e-01],\n",
      "          [-1.1727e+00,  1.4718e+00,  1.5951e-01,  ..., -1.5390e+00,\n",
      "           -8.8609e-01,  1.4624e+00],\n",
      "          [-1.8238e+00, -2.0953e-01, -2.0895e-01,  ..., -4.6284e-01,\n",
      "           -6.0812e-01,  8.2794e-02]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.2963e+00,  1.3031e+00, -1.8161e+00,  ...,  4.8900e-01,\n",
      "           -9.0493e-01, -8.6432e-01],\n",
      "          [-6.3748e-03, -1.5751e+00, -5.9111e-01,  ..., -5.4994e-01,\n",
      "            2.3986e-01, -1.1928e-01],\n",
      "          [-1.0095e-02,  2.2909e-03, -2.0081e-02,  ...,  6.3503e-03,\n",
      "           -1.4847e-02, -7.9639e-03],\n",
      "          ...,\n",
      "          [-1.9078e+00, -9.4382e-03, -1.0321e+00,  ..., -6.9728e-01,\n",
      "           -2.7039e+00, -9.2310e-01],\n",
      "          [-8.3472e-01, -4.7699e-01, -1.4673e+00,  ...,  6.1888e-01,\n",
      "           -1.2716e+00,  1.9534e-01],\n",
      "          [-4.8331e-01,  3.7006e-01, -1.6513e+00,  ...,  1.9024e+00,\n",
      "           -1.3242e+00, -2.0606e+00]],\n",
      "\n",
      "         [[-1.4394e-01,  2.0198e+00,  6.8159e-01,  ..., -1.7519e+00,\n",
      "           -6.1069e-01, -2.3025e-01],\n",
      "          [-7.9813e-01,  1.8052e+00,  1.5388e+00,  ...,  5.0000e-01,\n",
      "           -1.0304e+00,  8.2253e-01],\n",
      "          [ 9.0638e-01,  5.6484e-01,  3.7214e-01,  ...,  3.6584e-01,\n",
      "            9.3912e-01, -1.5410e-02],\n",
      "          ...,\n",
      "          [ 5.9160e-01,  7.1963e-01,  8.2091e-01,  ..., -4.8979e-01,\n",
      "           -2.4964e-01, -2.7017e-01],\n",
      "          [ 7.0387e-01,  1.8943e+00,  1.0377e+00,  ..., -4.9555e-01,\n",
      "           -2.0158e+00,  1.0545e+00],\n",
      "          [-1.7420e+00, -3.2266e-02, -1.4100e-01,  ..., -4.6553e-01,\n",
      "           -6.5227e-01,  1.3128e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6085e-01, -5.6235e-01, -1.2876e+00,  ...,  1.8541e-02,\n",
      "           -1.4954e+00, -4.5794e-01],\n",
      "          [-2.6751e+00,  3.8707e-01, -1.0220e+00,  ..., -2.4601e-01,\n",
      "           -1.0105e+00,  1.6966e+00],\n",
      "          [-7.1443e-01, -2.8803e-02, -1.8264e+00,  ...,  1.6606e-01,\n",
      "           -7.9096e-01,  1.4639e+00],\n",
      "          ...,\n",
      "          [-8.6453e-01, -2.5067e+00, -1.1245e+00,  ..., -8.9065e-01,\n",
      "           -3.2764e+00, -9.7479e-01],\n",
      "          [-9.6927e-03,  9.0676e-01, -1.9217e+00,  ...,  5.3160e-02,\n",
      "           -1.3817e+00, -4.4194e-01],\n",
      "          [-5.5805e-01,  3.0472e-01, -3.4340e+00,  ...,  1.7306e+00,\n",
      "           -1.4605e+00, -2.1824e+00]],\n",
      "\n",
      "         [[-2.7521e-01,  2.4303e+00,  7.6213e-01,  ..., -2.3727e+00,\n",
      "           -2.3176e-01, -1.1177e-01],\n",
      "          [-1.1332e+00,  2.0203e+00,  1.2441e-01,  ..., -7.2869e-02,\n",
      "            6.7034e-01,  2.2543e-01],\n",
      "          [ 1.1042e+00,  1.7870e+00, -9.3143e-01,  ..., -2.8889e-01,\n",
      "           -1.8424e-01,  1.3359e+00],\n",
      "          ...,\n",
      "          [ 4.2443e-01,  1.2251e+00,  2.6637e-01,  ..., -1.0768e+00,\n",
      "           -5.7984e-01,  2.3744e-01],\n",
      "          [ 9.3903e-04,  2.4517e-02,  3.6887e-03,  ..., -2.4823e-02,\n",
      "           -8.3993e-03,  9.1117e-03],\n",
      "          [-1.8948e+00, -1.4727e-01, -2.0688e-01,  ..., -5.5069e-01,\n",
      "           -6.5483e-01,  1.1672e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-1.2963e+00,  1.3031e+00, -1.8161e+00,  ...,  4.8900e-01,\n",
      "           -9.0493e-01, -8.6432e-01],\n",
      "          [-1.4394e-01,  2.0198e+00,  6.8159e-01,  ..., -1.7519e+00,\n",
      "           -6.1069e-01, -2.3025e-01]],\n",
      "\n",
      "         [[-6.3748e-03, -1.5751e+00, -5.9111e-01,  ..., -5.4994e-01,\n",
      "            2.3986e-01, -1.1928e-01],\n",
      "          [-7.9813e-01,  1.8052e+00,  1.5388e+00,  ...,  5.0000e-01,\n",
      "           -1.0304e+00,  8.2253e-01]],\n",
      "\n",
      "         [[-1.0095e-02,  2.2909e-03, -2.0081e-02,  ...,  6.3503e-03,\n",
      "           -1.4847e-02, -7.9639e-03],\n",
      "          [ 9.0638e-01,  5.6484e-01,  3.7214e-01,  ...,  3.6584e-01,\n",
      "            9.3912e-01, -1.5410e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9078e+00, -9.4382e-03, -1.0321e+00,  ..., -6.9728e-01,\n",
      "           -2.7039e+00, -9.2310e-01],\n",
      "          [ 5.9160e-01,  7.1963e-01,  8.2091e-01,  ..., -4.8979e-01,\n",
      "           -2.4964e-01, -2.7017e-01]],\n",
      "\n",
      "         [[-8.3472e-01, -4.7699e-01, -1.4673e+00,  ...,  6.1888e-01,\n",
      "           -1.2716e+00,  1.9534e-01],\n",
      "          [ 7.0387e-01,  1.8943e+00,  1.0377e+00,  ..., -4.9555e-01,\n",
      "           -2.0158e+00,  1.0545e+00]],\n",
      "\n",
      "         [[-4.8331e-01,  3.7006e-01, -1.6513e+00,  ...,  1.9024e+00,\n",
      "           -1.3242e+00, -2.0606e+00],\n",
      "          [-1.7420e+00, -3.2266e-02, -1.4100e-01,  ..., -4.6553e-01,\n",
      "           -6.5227e-01,  1.3128e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6085e-01, -5.6235e-01, -1.2876e+00,  ...,  1.8541e-02,\n",
      "           -1.4954e+00, -4.5794e-01],\n",
      "          [-2.7521e-01,  2.4303e+00,  7.6213e-01,  ..., -2.3727e+00,\n",
      "           -2.3176e-01, -1.1177e-01]],\n",
      "\n",
      "         [[-2.6751e+00,  3.8707e-01, -1.0220e+00,  ..., -2.4601e-01,\n",
      "           -1.0105e+00,  1.6966e+00],\n",
      "          [-1.1332e+00,  2.0203e+00,  1.2441e-01,  ..., -7.2869e-02,\n",
      "            6.7034e-01,  2.2543e-01]],\n",
      "\n",
      "         [[-7.1443e-01, -2.8803e-02, -1.8264e+00,  ...,  1.6606e-01,\n",
      "           -7.9096e-01,  1.4639e+00],\n",
      "          [ 1.1042e+00,  1.7870e+00, -9.3143e-01,  ..., -2.8889e-01,\n",
      "           -1.8424e-01,  1.3359e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6453e-01, -2.5067e+00, -1.1245e+00,  ..., -8.9065e-01,\n",
      "           -3.2764e+00, -9.7479e-01],\n",
      "          [ 4.2443e-01,  1.2251e+00,  2.6637e-01,  ..., -1.0768e+00,\n",
      "           -5.7984e-01,  2.3744e-01]],\n",
      "\n",
      "         [[-9.6927e-03,  9.0676e-01, -1.9217e+00,  ...,  5.3160e-02,\n",
      "           -1.3817e+00, -4.4194e-01],\n",
      "          [ 9.3903e-04,  2.4517e-02,  3.6887e-03,  ..., -2.4823e-02,\n",
      "           -8.3993e-03,  9.1117e-03]],\n",
      "\n",
      "         [[-5.5805e-01,  3.0472e-01, -3.4340e+00,  ...,  1.7306e+00,\n",
      "           -1.4605e+00, -2.1824e+00],\n",
      "          [-1.8948e+00, -1.4727e-01, -2.0688e-01,  ..., -5.5069e-01,\n",
      "           -6.5483e-01,  1.1672e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.2963e+00,  1.3031e+00, -1.8161e+00,  ...,  4.8900e-01,\n",
      "           -9.0493e-01, -8.6432e-01],\n",
      "          [-1.4394e-01,  2.0198e+00,  6.8159e-01,  ..., -1.7519e+00,\n",
      "           -6.1069e-01, -2.3025e-01]],\n",
      "\n",
      "         [[-6.3748e-03, -1.5751e+00, -5.9111e-01,  ..., -5.4994e-01,\n",
      "            2.3986e-01, -1.1928e-01],\n",
      "          [-7.9813e-01,  1.8052e+00,  1.5388e+00,  ...,  5.0000e-01,\n",
      "           -1.0304e+00,  8.2253e-01]],\n",
      "\n",
      "         [[-1.0095e-02,  2.2909e-03, -2.0081e-02,  ...,  6.3503e-03,\n",
      "           -1.4847e-02, -7.9639e-03],\n",
      "          [ 9.0638e-01,  5.6484e-01,  3.7214e-01,  ...,  3.6584e-01,\n",
      "            9.3912e-01, -1.5410e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9078e+00, -9.4382e-03, -1.0321e+00,  ..., -6.9728e-01,\n",
      "           -2.7039e+00, -9.2310e-01],\n",
      "          [ 5.9160e-01,  7.1963e-01,  8.2091e-01,  ..., -4.8979e-01,\n",
      "           -2.4964e-01, -2.7017e-01]],\n",
      "\n",
      "         [[-8.3472e-01, -4.7699e-01, -1.4673e+00,  ...,  6.1888e-01,\n",
      "           -1.2716e+00,  1.9534e-01],\n",
      "          [ 7.0387e-01,  1.8943e+00,  1.0377e+00,  ..., -4.9555e-01,\n",
      "           -2.0158e+00,  1.0545e+00]],\n",
      "\n",
      "         [[-4.8331e-01,  3.7006e-01, -1.6513e+00,  ...,  1.9024e+00,\n",
      "           -1.3242e+00, -2.0606e+00],\n",
      "          [-1.7420e+00, -3.2266e-02, -1.4100e-01,  ..., -4.6553e-01,\n",
      "           -6.5227e-01,  1.3128e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6085e-01, -5.6235e-01, -1.2876e+00,  ...,  1.8541e-02,\n",
      "           -1.4954e+00, -4.5794e-01],\n",
      "          [-2.7521e-01,  2.4303e+00,  7.6213e-01,  ..., -2.3727e+00,\n",
      "           -2.3176e-01, -1.1177e-01]],\n",
      "\n",
      "         [[-2.6751e+00,  3.8707e-01, -1.0220e+00,  ..., -2.4601e-01,\n",
      "           -1.0105e+00,  1.6966e+00],\n",
      "          [-1.1332e+00,  2.0203e+00,  1.2441e-01,  ..., -7.2869e-02,\n",
      "            6.7034e-01,  2.2543e-01]],\n",
      "\n",
      "         [[-7.1443e-01, -2.8803e-02, -1.8264e+00,  ...,  1.6606e-01,\n",
      "           -7.9096e-01,  1.4639e+00],\n",
      "          [ 1.1042e+00,  1.7870e+00, -9.3143e-01,  ..., -2.8889e-01,\n",
      "           -1.8424e-01,  1.3359e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6453e-01, -2.5067e+00, -1.1245e+00,  ..., -8.9065e-01,\n",
      "           -3.2764e+00, -9.7479e-01],\n",
      "          [ 4.2443e-01,  1.2251e+00,  2.6637e-01,  ..., -1.0768e+00,\n",
      "           -5.7984e-01,  2.3744e-01]],\n",
      "\n",
      "         [[-9.6927e-03,  9.0676e-01, -1.9217e+00,  ...,  5.3160e-02,\n",
      "           -1.3817e+00, -4.4194e-01],\n",
      "          [ 9.3903e-04,  2.4517e-02,  3.6887e-03,  ..., -2.4823e-02,\n",
      "           -8.3993e-03,  9.1117e-03]],\n",
      "\n",
      "         [[-5.5805e-01,  3.0472e-01, -3.4340e+00,  ...,  1.7306e+00,\n",
      "           -1.4605e+00, -2.1824e+00],\n",
      "          [-1.8948e+00, -1.4727e-01, -2.0688e-01,  ..., -5.5069e-01,\n",
      "           -6.5483e-01,  1.1672e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-1.2963e+00,  1.3031e+00, -1.8161e+00,  ...,  4.8900e-01,\n",
      "           -9.0493e-01, -8.6432e-01],\n",
      "          [-1.4394e-01,  2.0198e+00,  6.8159e-01,  ..., -1.7519e+00,\n",
      "           -6.1069e-01, -2.3025e-01]],\n",
      "\n",
      "         [[-6.3748e-03, -1.5751e+00, -5.9111e-01,  ..., -5.4994e-01,\n",
      "            2.3986e-01, -1.1928e-01],\n",
      "          [-7.9813e-01,  1.8052e+00,  1.5388e+00,  ...,  5.0000e-01,\n",
      "           -1.0304e+00,  8.2253e-01]],\n",
      "\n",
      "         [[-1.0095e-02,  2.2909e-03, -2.0081e-02,  ...,  6.3503e-03,\n",
      "           -1.4847e-02, -7.9639e-03],\n",
      "          [ 9.0638e-01,  5.6484e-01,  3.7214e-01,  ...,  3.6584e-01,\n",
      "            9.3912e-01, -1.5410e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9078e+00, -9.4382e-03, -1.0321e+00,  ..., -6.9728e-01,\n",
      "           -2.7039e+00, -9.2310e-01],\n",
      "          [ 5.9160e-01,  7.1963e-01,  8.2091e-01,  ..., -4.8979e-01,\n",
      "           -2.4964e-01, -2.7017e-01]],\n",
      "\n",
      "         [[-8.3472e-01, -4.7699e-01, -1.4673e+00,  ...,  6.1888e-01,\n",
      "           -1.2716e+00,  1.9534e-01],\n",
      "          [ 7.0387e-01,  1.8943e+00,  1.0377e+00,  ..., -4.9555e-01,\n",
      "           -2.0158e+00,  1.0545e+00]],\n",
      "\n",
      "         [[-4.8331e-01,  3.7006e-01, -1.6513e+00,  ...,  1.9024e+00,\n",
      "           -1.3242e+00, -2.0606e+00],\n",
      "          [-1.7420e+00, -3.2266e-02, -1.4100e-01,  ..., -4.6553e-01,\n",
      "           -6.5227e-01,  1.3128e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6085e-01, -5.6235e-01, -1.2876e+00,  ...,  1.8541e-02,\n",
      "           -1.4954e+00, -4.5794e-01],\n",
      "          [-2.7521e-01,  2.4303e+00,  7.6213e-01,  ..., -2.3727e+00,\n",
      "           -2.3176e-01, -1.1177e-01]],\n",
      "\n",
      "         [[-2.6751e+00,  3.8707e-01, -1.0220e+00,  ..., -2.4601e-01,\n",
      "           -1.0105e+00,  1.6966e+00],\n",
      "          [-1.1332e+00,  2.0203e+00,  1.2441e-01,  ..., -7.2869e-02,\n",
      "            6.7034e-01,  2.2543e-01]],\n",
      "\n",
      "         [[-7.1443e-01, -2.8803e-02, -1.8264e+00,  ...,  1.6606e-01,\n",
      "           -7.9096e-01,  1.4639e+00],\n",
      "          [ 1.1042e+00,  1.7870e+00, -9.3143e-01,  ..., -2.8889e-01,\n",
      "           -1.8424e-01,  1.3359e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6453e-01, -2.5067e+00, -1.1245e+00,  ..., -8.9065e-01,\n",
      "           -3.2764e+00, -9.7479e-01],\n",
      "          [ 4.2443e-01,  1.2251e+00,  2.6637e-01,  ..., -1.0768e+00,\n",
      "           -5.7984e-01,  2.3744e-01]],\n",
      "\n",
      "         [[-9.6927e-03,  9.0676e-01, -1.9217e+00,  ...,  5.3160e-02,\n",
      "           -1.3817e+00, -4.4194e-01],\n",
      "          [ 9.3903e-04,  2.4517e-02,  3.6887e-03,  ..., -2.4823e-02,\n",
      "           -8.3993e-03,  9.1117e-03]],\n",
      "\n",
      "         [[-5.5805e-01,  3.0472e-01, -3.4340e+00,  ...,  1.7306e+00,\n",
      "           -1.4605e+00, -2.1824e+00],\n",
      "          [-1.8948e+00, -1.4727e-01, -2.0688e-01,  ..., -5.5069e-01,\n",
      "           -6.5483e-01,  1.1672e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.8890,  0.6420],\n",
      "        [-0.3223,  0.1013]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:45:32,455] Trial 9 finished with value: 0.74868 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.822.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.351000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 3.0610e-01, -1.7357e-01,  3.0787e-01,  ...,  3.4177e-01,\n",
      "          -1.2125e-01, -5.1074e-01],\n",
      "         [ 4.9862e-01,  2.0884e-01, -1.9419e-02,  ...,  1.7596e-01,\n",
      "          -1.0909e-01, -4.3631e-01],\n",
      "         [ 1.2686e-01, -2.1827e-01,  3.0885e-02,  ...,  1.9302e-01,\n",
      "          -5.9524e-01, -3.6274e-01],\n",
      "         ...,\n",
      "         [ 1.1466e-01, -4.8930e-01,  9.6999e-02,  ...,  6.4887e-01,\n",
      "          -1.6113e-01, -7.3533e-01],\n",
      "         [ 3.3413e-01, -3.5542e-01, -1.5014e-01,  ...,  4.9677e-02,\n",
      "          -3.2030e-01, -3.8917e-01],\n",
      "         [ 9.6545e-01,  4.0524e-01,  1.8833e-01,  ...,  7.4115e-01,\n",
      "          -5.1347e-01, -7.8222e-01]],\n",
      "\n",
      "        [[ 5.8868e-04, -1.1549e-01,  3.8414e-01,  ...,  5.2395e-01,\n",
      "           3.3361e-02, -7.0540e-01],\n",
      "         [ 9.1126e-01, -1.1472e-02,  2.7785e-01,  ...,  2.7156e-01,\n",
      "          -2.4732e-01, -7.0307e-01],\n",
      "         [ 4.8865e-01, -2.0130e-01, -8.0412e-02,  ...,  8.5339e-02,\n",
      "          -1.0572e-01, -3.2170e-01],\n",
      "         ...,\n",
      "         [ 8.5890e-03, -4.3309e-01, -1.0311e-01,  ...,  1.7941e-01,\n",
      "          -4.7892e-01, -2.1223e-01],\n",
      "         [-9.8291e-02, -5.6453e-01, -2.4438e-01,  ...,  7.6737e-01,\n",
      "           1.2600e-01, -6.1502e-01],\n",
      "         [ 9.9288e-01,  1.8999e-01,  2.9849e-01,  ...,  7.1997e-01,\n",
      "          -6.0879e-01, -8.9957e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.0610e-01, -1.7357e-01,  3.0787e-01,  ...,  3.4177e-01,\n",
      "          -1.2125e-01, -5.1074e-01],\n",
      "         [ 4.9862e-01,  2.0884e-01, -1.9419e-02,  ...,  1.7596e-01,\n",
      "          -1.0909e-01, -4.3631e-01],\n",
      "         [ 1.2686e-01, -2.1827e-01,  3.0885e-02,  ...,  1.9302e-01,\n",
      "          -5.9524e-01, -3.6274e-01],\n",
      "         ...,\n",
      "         [ 1.1466e-01, -4.8930e-01,  9.6999e-02,  ...,  6.4887e-01,\n",
      "          -1.6113e-01, -7.3533e-01],\n",
      "         [ 3.3413e-01, -3.5542e-01, -1.5014e-01,  ...,  4.9677e-02,\n",
      "          -3.2030e-01, -3.8917e-01],\n",
      "         [ 9.6545e-01,  4.0524e-01,  1.8833e-01,  ...,  7.4115e-01,\n",
      "          -5.1347e-01, -7.8222e-01]],\n",
      "\n",
      "        [[ 5.8868e-04, -1.1549e-01,  3.8414e-01,  ...,  5.2395e-01,\n",
      "           3.3361e-02, -7.0540e-01],\n",
      "         [ 9.1126e-01, -1.1472e-02,  2.7785e-01,  ...,  2.7156e-01,\n",
      "          -2.4732e-01, -7.0307e-01],\n",
      "         [ 4.8865e-01, -2.0130e-01, -8.0412e-02,  ...,  8.5339e-02,\n",
      "          -1.0572e-01, -3.2170e-01],\n",
      "         ...,\n",
      "         [ 8.5890e-03, -4.3309e-01, -1.0311e-01,  ...,  1.7941e-01,\n",
      "          -4.7892e-01, -2.1223e-01],\n",
      "         [-9.8291e-02, -5.6453e-01, -2.4438e-01,  ...,  7.6737e-01,\n",
      "           1.2600e-01, -6.1502e-01],\n",
      "         [ 9.9288e-01,  1.8999e-01,  2.9849e-01,  ...,  7.1997e-01,\n",
      "          -6.0879e-01, -8.9957e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.0610e-01, -1.7357e-01,  3.0787e-01,  ..., -1.4776e-01,\n",
      "           -4.9108e-01,  2.0933e-01],\n",
      "          [-6.0737e-01, -1.9768e-01,  6.7570e-02,  ...,  3.4177e-01,\n",
      "           -1.2125e-01, -5.1074e-01]],\n",
      "\n",
      "         [[ 4.9862e-01,  2.0884e-01, -1.9419e-02,  ...,  8.5536e-02,\n",
      "           -5.5973e-01, -2.3557e-01],\n",
      "          [-2.8201e-01, -2.7159e-01, -2.1716e-01,  ...,  1.7596e-01,\n",
      "           -1.0909e-01, -4.3631e-01]],\n",
      "\n",
      "         [[ 1.2686e-01, -2.1827e-01,  3.0885e-02,  ..., -3.7331e-01,\n",
      "           -3.8259e-01, -9.2268e-02],\n",
      "          [ 1.2869e-01,  5.3716e-04,  5.3777e-02,  ...,  1.9302e-01,\n",
      "           -5.9524e-01, -3.6274e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1466e-01, -4.8930e-01,  9.6999e-02,  ...,  1.4620e-03,\n",
      "           -3.5778e-01, -4.8888e-01],\n",
      "          [-3.4574e-01, -1.0811e-01,  7.0453e-03,  ...,  6.4887e-01,\n",
      "           -1.6113e-01, -7.3533e-01]],\n",
      "\n",
      "         [[ 3.3413e-01, -3.5542e-01, -1.5014e-01,  ..., -1.9763e-01,\n",
      "           -3.4854e-01, -3.3739e-01],\n",
      "          [-3.2053e-01, -1.6707e-01,  3.6272e-01,  ...,  4.9677e-02,\n",
      "           -3.2030e-01, -3.8917e-01]],\n",
      "\n",
      "         [[ 9.6545e-01,  4.0524e-01,  1.8833e-01,  ..., -2.7899e-01,\n",
      "           -4.0515e-01,  2.4006e-01],\n",
      "          [-2.7291e-01,  9.2760e-02,  3.5112e-01,  ...,  7.4115e-01,\n",
      "           -5.1347e-01, -7.8222e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8868e-04, -1.1549e-01,  3.8414e-01,  ...,  1.5773e-04,\n",
      "           -3.3894e-01,  1.3736e-01],\n",
      "          [-4.7341e-01, -2.5481e-01,  1.3361e-01,  ...,  5.2395e-01,\n",
      "            3.3361e-02, -7.0540e-01]],\n",
      "\n",
      "         [[ 9.1126e-01, -1.1472e-02,  2.7785e-01,  ..., -3.6770e-01,\n",
      "           -5.0454e-01, -4.5131e-01],\n",
      "          [-2.9977e-01, -2.2201e-01, -5.8759e-02,  ...,  2.7156e-01,\n",
      "           -2.4732e-01, -7.0307e-01]],\n",
      "\n",
      "         [[ 4.8865e-01, -2.0130e-01, -8.0412e-02,  ...,  1.2142e-01,\n",
      "           -4.4835e-01,  3.2741e-01],\n",
      "          [ 2.6455e-01,  2.0719e-01,  3.7127e-01,  ...,  8.5339e-02,\n",
      "           -1.0572e-01, -3.2170e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5890e-03, -4.3309e-01, -1.0311e-01,  ...,  6.0050e-01,\n",
      "           -1.9716e-01,  1.0039e-01],\n",
      "          [-3.9862e-02,  7.6022e-02,  9.9074e-02,  ...,  1.7941e-01,\n",
      "           -4.7892e-01, -2.1223e-01]],\n",
      "\n",
      "         [[-9.8291e-02, -5.6453e-01, -2.4438e-01,  ..., -3.6561e-03,\n",
      "           -4.8575e-02, -8.4040e-02],\n",
      "          [-2.0884e-01, -8.3713e-03,  1.6382e-01,  ...,  7.6737e-01,\n",
      "            1.2600e-01, -6.1502e-01]],\n",
      "\n",
      "         [[ 9.9288e-01,  1.8999e-01,  2.9849e-01,  ..., -4.3783e-01,\n",
      "           -5.0589e-01,  5.9995e-02],\n",
      "          [-3.3925e-01, -6.1297e-02,  4.7231e-01,  ...,  7.1997e-01,\n",
      "           -6.0879e-01, -8.9957e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0009,  0.0866, -0.4306,  ..., -0.1056, -0.3497,  0.1784],\n",
      "         [ 0.1529, -0.0089,  0.1452,  ...,  0.0165, -0.0017,  0.2832],\n",
      "         [ 0.1871,  0.4420, -0.6755,  ...,  0.5915, -0.1514,  0.4901],\n",
      "         ...,\n",
      "         [ 0.1105,  0.4069, -0.6281,  ...,  0.1340,  0.0181,  0.2291],\n",
      "         [ 0.2158, -0.0306, -0.2840,  ...,  0.2495,  0.2597,  0.1051],\n",
      "         [-0.1075, -0.0825, -0.0988,  ..., -0.0238, -0.3346,  0.0628]],\n",
      "\n",
      "        [[ 0.1832,  0.2245, -0.1511,  ..., -0.1255, -0.2306,  0.1574],\n",
      "         [ 0.0403,  0.0630, -0.1605,  ..., -0.2735, -0.2708,  0.2477],\n",
      "         [ 0.8136,  0.3017, -0.3153,  ...,  0.4297,  0.2772,  0.8344],\n",
      "         ...,\n",
      "         [ 0.4948,  0.4900, -0.1977,  ..., -0.1647,  0.1929, -0.0738],\n",
      "         [ 0.1398,  0.1980, -0.3067,  ...,  0.0397,  0.0444,  0.1003],\n",
      "         [-0.0082, -0.1042, -0.0722,  ..., -0.2261, -0.2457,  0.3882]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0009,  0.0866, -0.4306,  ..., -0.1056, -0.3497,  0.1784],\n",
      "         [ 0.1529, -0.0089,  0.1452,  ...,  0.0165, -0.0017,  0.2832],\n",
      "         [ 0.1871,  0.4420, -0.6755,  ...,  0.5915, -0.1514,  0.4901],\n",
      "         ...,\n",
      "         [ 0.1105,  0.4069, -0.6281,  ...,  0.1340,  0.0181,  0.2291],\n",
      "         [ 0.2158, -0.0306, -0.2840,  ...,  0.2495,  0.2597,  0.1051],\n",
      "         [-0.1075, -0.0825, -0.0988,  ..., -0.0238, -0.3346,  0.0628]],\n",
      "\n",
      "        [[ 0.1832,  0.2245, -0.1511,  ..., -0.1255, -0.2306,  0.1574],\n",
      "         [ 0.0403,  0.0630, -0.1605,  ..., -0.2735, -0.2708,  0.2477],\n",
      "         [ 0.8136,  0.3017, -0.3153,  ...,  0.4297,  0.2772,  0.8344],\n",
      "         ...,\n",
      "         [ 0.4948,  0.4900, -0.1977,  ..., -0.1647,  0.1929, -0.0738],\n",
      "         [ 0.1398,  0.1980, -0.3067,  ...,  0.0397,  0.0444,  0.1003],\n",
      "         [-0.0082, -0.1042, -0.0722,  ..., -0.2261, -0.2457,  0.3882]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0009,  0.0866, -0.4306,  ...,  0.2099, -0.1464, -0.1842],\n",
      "          [-0.1891,  0.2168,  0.1994,  ..., -0.1056, -0.3497,  0.1784]],\n",
      "\n",
      "         [[ 0.1529, -0.0089,  0.1452,  ...,  0.2715, -0.0016,  0.1982],\n",
      "          [-0.1359,  0.1112, -0.1382,  ...,  0.0165, -0.0017,  0.2832]],\n",
      "\n",
      "         [[ 0.1871,  0.4420, -0.6755,  ...,  0.9016, -0.0895,  0.0381],\n",
      "          [ 0.1976, -0.3499, -0.6962,  ...,  0.5915, -0.1514,  0.4901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1105,  0.4069, -0.6281,  ...,  0.1991, -0.4330,  0.3347],\n",
      "          [-0.3316, -0.2801, -0.0468,  ...,  0.1340,  0.0181,  0.2291]],\n",
      "\n",
      "         [[ 0.2158, -0.0306, -0.2840,  ...,  0.6179, -0.3198,  0.4211],\n",
      "          [ 0.0348, -0.2969, -0.2725,  ...,  0.2495,  0.2597,  0.1051]],\n",
      "\n",
      "         [[-0.1075, -0.0825, -0.0988,  ..., -0.1312,  0.4255,  0.3883],\n",
      "          [ 0.2211, -0.2332, -0.4863,  ..., -0.0238, -0.3346,  0.0628]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1832,  0.2245, -0.1511,  ...,  0.3122, -0.1713, -0.0653],\n",
      "          [-0.4079,  0.2757,  0.0269,  ..., -0.1255, -0.2306,  0.1574]],\n",
      "\n",
      "         [[ 0.0403,  0.0630, -0.1605,  ..., -0.1346,  0.1401,  0.0702],\n",
      "          [-0.1702,  0.0264,  0.0635,  ..., -0.2735, -0.2708,  0.2477]],\n",
      "\n",
      "         [[ 0.8136,  0.3017, -0.3153,  ...,  0.9120, -0.1908,  0.1329],\n",
      "          [ 0.0055, -0.6270, -0.5004,  ...,  0.4297,  0.2772,  0.8344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4948,  0.4900, -0.1977,  ..., -0.0641, -0.3407,  0.2330],\n",
      "          [ 0.0784, -0.3615, -0.1340,  ..., -0.1647,  0.1929, -0.0738]],\n",
      "\n",
      "         [[ 0.1398,  0.1980, -0.3067,  ...,  0.5116, -0.0282, -0.0509],\n",
      "          [ 0.2829, -0.1532,  0.0334,  ...,  0.0397,  0.0444,  0.1003]],\n",
      "\n",
      "         [[-0.0082, -0.1042, -0.0722,  ...,  0.1758,  0.1859,  0.4010],\n",
      "          [ 0.2736, -0.2864, -0.7160,  ..., -0.2261, -0.2457,  0.3882]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-2.0470, -1.4929, -0.7190,  ..., -1.9550,  1.3075,  1.2716],\n",
      "         [-1.0268, -0.4161, -0.1037,  ..., -1.1703,  0.3448,  0.9067],\n",
      "         [-1.0112, -0.8070, -0.3635,  ..., -0.8648,  0.5934,  1.0257],\n",
      "         ...,\n",
      "         [-1.3827, -0.6430, -0.0459,  ..., -0.8000,  0.4262,  0.7503],\n",
      "         [-1.2412, -0.2957, -0.3669,  ..., -1.2976,  0.3742,  0.5920],\n",
      "         [-0.7311, -0.4311, -0.2305,  ..., -0.9919,  0.1695,  0.6762]],\n",
      "\n",
      "        [[-1.9275, -1.4816, -0.7048,  ..., -1.8260,  1.1241,  1.3495],\n",
      "         [-0.9754, -0.3124, -0.0529,  ..., -1.3833,  0.6153,  0.9630],\n",
      "         [-0.4584, -0.8911, -0.5087,  ..., -0.4356,  0.3015,  1.4386],\n",
      "         ...,\n",
      "         [-1.1160, -0.4559, -0.1266,  ..., -0.5485, -0.2007,  0.6237],\n",
      "         [-1.3851, -0.3748, -0.3186,  ..., -1.0353,  0.5888,  0.4520],\n",
      "         [-0.6577, -0.3672, -0.0829,  ..., -0.9403,  0.4244,  0.5932]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-2.0470, -1.4929, -0.7190,  ..., -1.9550,  1.3075,  1.2716],\n",
      "         [-1.0268, -0.4161, -0.1037,  ..., -1.1703,  0.3448,  0.9067],\n",
      "         [-1.0112, -0.8070, -0.3635,  ..., -0.8648,  0.5934,  1.0257],\n",
      "         ...,\n",
      "         [-1.3827, -0.6430, -0.0459,  ..., -0.8000,  0.4262,  0.7503],\n",
      "         [-1.2412, -0.2957, -0.3669,  ..., -1.2976,  0.3742,  0.5920],\n",
      "         [-0.7311, -0.4311, -0.2305,  ..., -0.9919,  0.1695,  0.6762]],\n",
      "\n",
      "        [[-1.9275, -1.4816, -0.7048,  ..., -1.8260,  1.1241,  1.3495],\n",
      "         [-0.9754, -0.3124, -0.0529,  ..., -1.3833,  0.6153,  0.9630],\n",
      "         [-0.4584, -0.8911, -0.5087,  ..., -0.4356,  0.3015,  1.4386],\n",
      "         ...,\n",
      "         [-1.1160, -0.4559, -0.1266,  ..., -0.5485, -0.2007,  0.6237],\n",
      "         [-1.3851, -0.3748, -0.3186,  ..., -1.0353,  0.5888,  0.4520],\n",
      "         [-0.6577, -0.3672, -0.0829,  ..., -0.9403,  0.4244,  0.5932]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-2.0470, -1.4929, -0.7190,  ...,  1.5545,  1.5600,  0.9203],\n",
      "          [ 0.7912,  0.1268, -0.9139,  ..., -1.9550,  1.3075,  1.2716]],\n",
      "\n",
      "         [[-1.0268, -0.4161, -0.1037,  ...,  0.3689,  0.6707,  0.5509],\n",
      "          [ 0.3097, -0.1576, -0.3086,  ..., -1.1703,  0.3448,  0.9067]],\n",
      "\n",
      "         [[-1.0112, -0.8070, -0.3635,  ...,  0.7681,  0.7027,  0.3762],\n",
      "          [ 0.3597,  0.1658, -0.5091,  ..., -0.8648,  0.5934,  1.0257]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3827, -0.6430, -0.0459,  ...,  0.1561,  0.8318,  0.2403],\n",
      "          [-0.0030, -0.0346, -0.2901,  ..., -0.8000,  0.4262,  0.7503]],\n",
      "\n",
      "         [[-1.2412, -0.2957, -0.3669,  ...,  0.2213,  0.6296, -0.1825],\n",
      "          [ 0.6160,  0.4531, -0.3321,  ..., -1.2976,  0.3742,  0.5920]],\n",
      "\n",
      "         [[-0.7311, -0.4311, -0.2305,  ...,  0.4441,  0.4671,  0.2377],\n",
      "          [ 0.2987,  0.1047, -0.6328,  ..., -0.9919,  0.1695,  0.6762]]],\n",
      "\n",
      "\n",
      "        [[[-1.9275, -1.4816, -0.7048,  ...,  1.4585,  1.5608,  0.8066],\n",
      "          [ 0.9866,  0.0867, -0.8499,  ..., -1.8260,  1.1241,  1.3495]],\n",
      "\n",
      "         [[-0.9754, -0.3124, -0.0529,  ...,  0.0772,  0.8578,  0.8202],\n",
      "          [ 0.4141,  0.6570, -0.8071,  ..., -1.3833,  0.6153,  0.9630]],\n",
      "\n",
      "         [[-0.4584, -0.8911, -0.5087,  ...,  0.1324,  0.8161,  0.0678],\n",
      "          [ 0.4007, -0.0132, -0.5647,  ..., -0.4356,  0.3015,  1.4386]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1160, -0.4559, -0.1266,  ...,  0.2124,  0.7013,  0.2122],\n",
      "          [ 0.2499, -0.1795, -0.1273,  ..., -0.5485, -0.2007,  0.6237]],\n",
      "\n",
      "         [[-1.3851, -0.3748, -0.3186,  ...,  0.1106,  0.1657, -0.0476],\n",
      "          [ 0.4896,  0.5863, -0.4330,  ..., -1.0353,  0.5888,  0.4520]],\n",
      "\n",
      "         [[-0.6577, -0.3672, -0.0829,  ...,  0.4274,  0.6386,  0.4968],\n",
      "          [ 0.6508,  0.2886, -0.7860,  ..., -0.9403,  0.4244,  0.5932]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.0610e-01, -1.7357e-01,  3.0787e-01,  ..., -1.4776e-01,\n",
      "           -4.9108e-01,  2.0933e-01],\n",
      "          [ 4.9862e-01,  2.0884e-01, -1.9419e-02,  ...,  8.5536e-02,\n",
      "           -5.5973e-01, -2.3557e-01],\n",
      "          [ 1.2686e-01, -2.1827e-01,  3.0885e-02,  ..., -3.7331e-01,\n",
      "           -3.8259e-01, -9.2268e-02],\n",
      "          ...,\n",
      "          [ 1.1466e-01, -4.8930e-01,  9.6999e-02,  ...,  1.4620e-03,\n",
      "           -3.5778e-01, -4.8888e-01],\n",
      "          [ 3.3413e-01, -3.5542e-01, -1.5014e-01,  ..., -1.9763e-01,\n",
      "           -3.4854e-01, -3.3739e-01],\n",
      "          [ 9.6545e-01,  4.0524e-01,  1.8833e-01,  ..., -2.7899e-01,\n",
      "           -4.0515e-01,  2.4006e-01]],\n",
      "\n",
      "         [[-6.0737e-01, -1.9768e-01,  6.7570e-02,  ...,  3.4177e-01,\n",
      "           -1.2125e-01, -5.1074e-01],\n",
      "          [-2.8201e-01, -2.7159e-01, -2.1716e-01,  ...,  1.7596e-01,\n",
      "           -1.0909e-01, -4.3631e-01],\n",
      "          [ 1.2869e-01,  5.3716e-04,  5.3777e-02,  ...,  1.9302e-01,\n",
      "           -5.9524e-01, -3.6274e-01],\n",
      "          ...,\n",
      "          [-3.4574e-01, -1.0811e-01,  7.0453e-03,  ...,  6.4887e-01,\n",
      "           -1.6113e-01, -7.3533e-01],\n",
      "          [-3.2053e-01, -1.6707e-01,  3.6272e-01,  ...,  4.9677e-02,\n",
      "           -3.2030e-01, -3.8917e-01],\n",
      "          [-2.7291e-01,  9.2760e-02,  3.5112e-01,  ...,  7.4115e-01,\n",
      "           -5.1347e-01, -7.8222e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8868e-04, -1.1549e-01,  3.8414e-01,  ...,  1.5773e-04,\n",
      "           -3.3894e-01,  1.3736e-01],\n",
      "          [ 9.1126e-01, -1.1472e-02,  2.7785e-01,  ..., -3.6770e-01,\n",
      "           -5.0454e-01, -4.5131e-01],\n",
      "          [ 4.8865e-01, -2.0130e-01, -8.0412e-02,  ...,  1.2142e-01,\n",
      "           -4.4835e-01,  3.2741e-01],\n",
      "          ...,\n",
      "          [ 8.5890e-03, -4.3309e-01, -1.0311e-01,  ...,  6.0050e-01,\n",
      "           -1.9716e-01,  1.0039e-01],\n",
      "          [-9.8291e-02, -5.6453e-01, -2.4438e-01,  ..., -3.6561e-03,\n",
      "           -4.8575e-02, -8.4040e-02],\n",
      "          [ 9.9288e-01,  1.8999e-01,  2.9849e-01,  ..., -4.3783e-01,\n",
      "           -5.0589e-01,  5.9995e-02]],\n",
      "\n",
      "         [[-4.7341e-01, -2.5481e-01,  1.3361e-01,  ...,  5.2395e-01,\n",
      "            3.3361e-02, -7.0540e-01],\n",
      "          [-2.9977e-01, -2.2201e-01, -5.8759e-02,  ...,  2.7156e-01,\n",
      "           -2.4732e-01, -7.0307e-01],\n",
      "          [ 2.6455e-01,  2.0719e-01,  3.7127e-01,  ...,  8.5339e-02,\n",
      "           -1.0572e-01, -3.2170e-01],\n",
      "          ...,\n",
      "          [-3.9862e-02,  7.6022e-02,  9.9074e-02,  ...,  1.7941e-01,\n",
      "           -4.7892e-01, -2.1223e-01],\n",
      "          [-2.0884e-01, -8.3713e-03,  1.6382e-01,  ...,  7.6737e-01,\n",
      "            1.2600e-01, -6.1502e-01],\n",
      "          [-3.3925e-01, -6.1297e-02,  4.7231e-01,  ...,  7.1997e-01,\n",
      "           -6.0879e-01, -8.9957e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.0121,  0.6587, -0.1414,  ...,  0.1895, -0.0211,  0.0668],\n",
      "          [ 0.0427,  0.4220, -0.2754,  ...,  0.3203, -0.0919,  0.1629],\n",
      "          [ 0.0482,  0.4402, -0.2800,  ...,  0.3246, -0.0947,  0.1665],\n",
      "          ...,\n",
      "          [ 0.0650,  0.3604, -0.3279,  ...,  0.3378, -0.1118,  0.2004],\n",
      "          [ 0.0510,  0.3792, -0.3214,  ...,  0.3104, -0.1074,  0.1846],\n",
      "          [ 0.0451,  0.0788, -0.1911,  ...,  0.1632, -0.0980,  0.1797]],\n",
      "\n",
      "         [[ 0.0024, -0.2911, -0.4485,  ...,  0.3261, -0.0750,  0.3461],\n",
      "          [ 0.0023, -0.2598, -0.3720,  ...,  0.2833, -0.0754,  0.3264],\n",
      "          [-0.0121, -0.2497, -0.3608,  ...,  0.2821, -0.0686,  0.3262],\n",
      "          ...,\n",
      "          [ 0.0235, -0.2629, -0.3551,  ...,  0.2607, -0.0436,  0.2954],\n",
      "          [-0.0085, -0.2292, -0.3215,  ...,  0.2630, -0.0709,  0.3199],\n",
      "          [ 0.0442, -0.2376, -0.3246,  ...,  0.2529, -0.0821,  0.2762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0577,  0.0976, -0.1767,  ..., -0.0558,  0.1552,  0.1880],\n",
      "          [ 0.0646,  0.1726, -0.2775,  ...,  0.0660,  0.0362,  0.1609],\n",
      "          [ 0.0888,  0.1774, -0.2871,  ...,  0.0993,  0.0176,  0.1590],\n",
      "          ...,\n",
      "          [ 0.1715,  0.1021, -0.1654,  ..., -0.0017,  0.0125,  0.1479],\n",
      "          [ 0.0947,  0.1881, -0.2803,  ...,  0.1170,  0.0021,  0.1685],\n",
      "          [-0.0224,  0.0961, -0.2547,  ...,  0.1091,  0.0760,  0.1219]],\n",
      "\n",
      "         [[ 0.3062,  0.0375, -0.4032,  ..., -0.3135, -0.0403, -0.2208],\n",
      "          [ 0.2337,  0.0439, -0.3070,  ..., -0.1884, -0.0615, -0.1019],\n",
      "          [ 0.2487, -0.0837, -0.2776,  ..., -0.1321, -0.0054, -0.0603],\n",
      "          ...,\n",
      "          [ 0.1460, -0.0019, -0.2574,  ..., -0.1256, -0.0532, -0.0108],\n",
      "          [ 0.2215, -0.0947, -0.3002,  ..., -0.1432,  0.0069, -0.0464],\n",
      "          [ 0.0844, -0.0670, -0.1089,  ...,  0.0713,  0.0040,  0.0424]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.0121,  0.6587, -0.1414,  ...,  0.1895, -0.0211,  0.0668],\n",
      "          [ 0.0024, -0.2911, -0.4485,  ...,  0.3261, -0.0750,  0.3461]],\n",
      "\n",
      "         [[ 0.0427,  0.4220, -0.2754,  ...,  0.3203, -0.0919,  0.1629],\n",
      "          [ 0.0023, -0.2598, -0.3720,  ...,  0.2833, -0.0754,  0.3264]],\n",
      "\n",
      "         [[ 0.0482,  0.4402, -0.2800,  ...,  0.3246, -0.0947,  0.1665],\n",
      "          [-0.0121, -0.2497, -0.3608,  ...,  0.2821, -0.0686,  0.3262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0650,  0.3604, -0.3279,  ...,  0.3378, -0.1118,  0.2004],\n",
      "          [ 0.0235, -0.2629, -0.3551,  ...,  0.2607, -0.0436,  0.2954]],\n",
      "\n",
      "         [[ 0.0510,  0.3792, -0.3214,  ...,  0.3104, -0.1074,  0.1846],\n",
      "          [-0.0085, -0.2292, -0.3215,  ...,  0.2630, -0.0709,  0.3199]],\n",
      "\n",
      "         [[ 0.0451,  0.0788, -0.1911,  ...,  0.1632, -0.0980,  0.1797],\n",
      "          [ 0.0442, -0.2376, -0.3246,  ...,  0.2529, -0.0821,  0.2762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0577,  0.0976, -0.1767,  ..., -0.0558,  0.1552,  0.1880],\n",
      "          [ 0.3062,  0.0375, -0.4032,  ..., -0.3135, -0.0403, -0.2208]],\n",
      "\n",
      "         [[ 0.0646,  0.1726, -0.2775,  ...,  0.0660,  0.0362,  0.1609],\n",
      "          [ 0.2337,  0.0439, -0.3070,  ..., -0.1884, -0.0615, -0.1019]],\n",
      "\n",
      "         [[ 0.0888,  0.1774, -0.2871,  ...,  0.0993,  0.0176,  0.1590],\n",
      "          [ 0.2487, -0.0837, -0.2776,  ..., -0.1321, -0.0054, -0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1715,  0.1021, -0.1654,  ..., -0.0017,  0.0125,  0.1479],\n",
      "          [ 0.1460, -0.0019, -0.2574,  ..., -0.1256, -0.0532, -0.0108]],\n",
      "\n",
      "         [[ 0.0947,  0.1881, -0.2803,  ...,  0.1170,  0.0021,  0.1685],\n",
      "          [ 0.2215, -0.0947, -0.3002,  ..., -0.1432,  0.0069, -0.0464]],\n",
      "\n",
      "         [[-0.0224,  0.0961, -0.2547,  ...,  0.1091,  0.0760,  0.1219],\n",
      "          [ 0.0844, -0.0670, -0.1089,  ...,  0.0713,  0.0040,  0.0424]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.0121,  0.6587, -0.1414,  ...,  0.1895, -0.0211,  0.0668],\n",
      "          [ 0.0024, -0.2911, -0.4485,  ...,  0.3261, -0.0750,  0.3461]],\n",
      "\n",
      "         [[ 0.0427,  0.4220, -0.2754,  ...,  0.3203, -0.0919,  0.1629],\n",
      "          [ 0.0023, -0.2598, -0.3720,  ...,  0.2833, -0.0754,  0.3264]],\n",
      "\n",
      "         [[ 0.0482,  0.4402, -0.2800,  ...,  0.3246, -0.0947,  0.1665],\n",
      "          [-0.0121, -0.2497, -0.3608,  ...,  0.2821, -0.0686,  0.3262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0650,  0.3604, -0.3279,  ...,  0.3378, -0.1118,  0.2004],\n",
      "          [ 0.0235, -0.2629, -0.3551,  ...,  0.2607, -0.0436,  0.2954]],\n",
      "\n",
      "         [[ 0.0510,  0.3792, -0.3214,  ...,  0.3104, -0.1074,  0.1846],\n",
      "          [-0.0085, -0.2292, -0.3215,  ...,  0.2630, -0.0709,  0.3199]],\n",
      "\n",
      "         [[ 0.0451,  0.0788, -0.1911,  ...,  0.1632, -0.0980,  0.1797],\n",
      "          [ 0.0442, -0.2376, -0.3246,  ...,  0.2529, -0.0821,  0.2762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0577,  0.0976, -0.1767,  ..., -0.0558,  0.1552,  0.1880],\n",
      "          [ 0.3062,  0.0375, -0.4032,  ..., -0.3135, -0.0403, -0.2208]],\n",
      "\n",
      "         [[ 0.0646,  0.1726, -0.2775,  ...,  0.0660,  0.0362,  0.1609],\n",
      "          [ 0.2337,  0.0439, -0.3070,  ..., -0.1884, -0.0615, -0.1019]],\n",
      "\n",
      "         [[ 0.0888,  0.1774, -0.2871,  ...,  0.0993,  0.0176,  0.1590],\n",
      "          [ 0.2487, -0.0837, -0.2776,  ..., -0.1321, -0.0054, -0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1715,  0.1021, -0.1654,  ..., -0.0017,  0.0125,  0.1479],\n",
      "          [ 0.1460, -0.0019, -0.2574,  ..., -0.1256, -0.0532, -0.0108]],\n",
      "\n",
      "         [[ 0.0947,  0.1881, -0.2803,  ...,  0.1170,  0.0021,  0.1685],\n",
      "          [ 0.2215, -0.0947, -0.3002,  ..., -0.1432,  0.0069, -0.0464]],\n",
      "\n",
      "         [[-0.0224,  0.0961, -0.2547,  ...,  0.1091,  0.0760,  0.1219],\n",
      "          [ 0.0844, -0.0670, -0.1089,  ...,  0.0713,  0.0040,  0.0424]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-0.0121,  0.6587, -0.1414,  ...,  0.1895, -0.0211,  0.0668],\n",
      "          [ 0.0024, -0.2911, -0.4485,  ...,  0.3261, -0.0750,  0.3461]],\n",
      "\n",
      "         [[ 0.0427,  0.4220, -0.2754,  ...,  0.3203, -0.0919,  0.1629],\n",
      "          [ 0.0023, -0.2598, -0.3720,  ...,  0.2833, -0.0754,  0.3264]],\n",
      "\n",
      "         [[ 0.0482,  0.4402, -0.2800,  ...,  0.3246, -0.0947,  0.1665],\n",
      "          [-0.0121, -0.2497, -0.3608,  ...,  0.2821, -0.0686,  0.3262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0650,  0.3604, -0.3279,  ...,  0.3378, -0.1118,  0.2004],\n",
      "          [ 0.0235, -0.2629, -0.3551,  ...,  0.2607, -0.0436,  0.2954]],\n",
      "\n",
      "         [[ 0.0510,  0.3792, -0.3214,  ...,  0.3104, -0.1074,  0.1846],\n",
      "          [-0.0085, -0.2292, -0.3215,  ...,  0.2630, -0.0709,  0.3199]],\n",
      "\n",
      "         [[ 0.0451,  0.0788, -0.1911,  ...,  0.1632, -0.0980,  0.1797],\n",
      "          [ 0.0442, -0.2376, -0.3246,  ...,  0.2529, -0.0821,  0.2762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0577,  0.0976, -0.1767,  ..., -0.0558,  0.1552,  0.1880],\n",
      "          [ 0.3062,  0.0375, -0.4032,  ..., -0.3135, -0.0403, -0.2208]],\n",
      "\n",
      "         [[ 0.0646,  0.1726, -0.2775,  ...,  0.0660,  0.0362,  0.1609],\n",
      "          [ 0.2337,  0.0439, -0.3070,  ..., -0.1884, -0.0615, -0.1019]],\n",
      "\n",
      "         [[ 0.0888,  0.1774, -0.2871,  ...,  0.0993,  0.0176,  0.1590],\n",
      "          [ 0.2487, -0.0837, -0.2776,  ..., -0.1321, -0.0054, -0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1715,  0.1021, -0.1654,  ..., -0.0017,  0.0125,  0.1479],\n",
      "          [ 0.1460, -0.0019, -0.2574,  ..., -0.1256, -0.0532, -0.0108]],\n",
      "\n",
      "         [[ 0.0947,  0.1881, -0.2803,  ...,  0.1170,  0.0021,  0.1685],\n",
      "          [ 0.2215, -0.0947, -0.3002,  ..., -0.1432,  0.0069, -0.0464]],\n",
      "\n",
      "         [[-0.0224,  0.0961, -0.2547,  ...,  0.1091,  0.0760,  0.1219],\n",
      "          [ 0.0844, -0.0670, -0.1089,  ...,  0.0713,  0.0040,  0.0424]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.7674, -0.7525, -0.7991,  ...,  0.0281, -0.9028, -0.2864],\n",
      "         [-0.3771, -0.5239, -0.3707,  ...,  0.0266, -0.8615, -0.1183],\n",
      "         [-0.2313,  0.0076, -0.3799,  ...,  0.3214, -0.5224, -0.1273],\n",
      "         ...,\n",
      "         [-0.2571, -0.5985, -0.2913,  ...,  0.3405, -0.4415, -0.1249],\n",
      "         [-0.3859, -0.1819, -0.2923,  ..., -0.3063, -0.7411,  0.1740],\n",
      "         [-0.4995,  0.2714,  0.4094,  ...,  0.0814, -0.9173,  0.2603]],\n",
      "\n",
      "        [[-0.5790, -0.4828, -0.2453,  ..., -0.1172, -0.6581, -0.2416],\n",
      "         [-0.7508, -0.6206, -0.3220,  ...,  0.0585, -0.4389, -0.2414],\n",
      "         [-0.5634,  0.2343, -0.4859,  ..., -0.0805, -0.2437, -0.0632],\n",
      "         ...,\n",
      "         [-0.4411, -0.0601, -0.1538,  ..., -0.1744, -0.5948,  0.3113],\n",
      "         [-0.2343, -0.1596, -0.4021,  ...,  0.1106, -0.2673, -0.2855],\n",
      "         [-0.4811,  0.3029,  0.4734,  ...,  0.1060, -0.7120,  0.2196]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7674, -0.7525, -0.7991,  ...,  0.0281, -0.9028, -0.2864],\n",
      "         [-0.3771, -0.5239, -0.3707,  ...,  0.0266, -0.8615, -0.1183],\n",
      "         [-0.2313,  0.0076, -0.3799,  ...,  0.3214, -0.5224, -0.1273],\n",
      "         ...,\n",
      "         [-0.2571, -0.5985, -0.2913,  ...,  0.3405, -0.4415, -0.1249],\n",
      "         [-0.3859, -0.1819, -0.2923,  ..., -0.3063, -0.7411,  0.1740],\n",
      "         [-0.4995,  0.2714,  0.4094,  ...,  0.0814, -0.9173,  0.2603]],\n",
      "\n",
      "        [[-0.5790, -0.4828, -0.2453,  ..., -0.1172, -0.6581, -0.2416],\n",
      "         [-0.7508, -0.6206, -0.3220,  ...,  0.0585, -0.4389, -0.2414],\n",
      "         [-0.5634,  0.2343, -0.4859,  ..., -0.0805, -0.2437, -0.0632],\n",
      "         ...,\n",
      "         [-0.4411, -0.0601, -0.1538,  ..., -0.1744, -0.5948,  0.3113],\n",
      "         [-0.2343, -0.1596, -0.4021,  ...,  0.1106, -0.2673, -0.2855],\n",
      "         [-0.4811,  0.3029,  0.4734,  ...,  0.1060, -0.7120,  0.2196]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.7674, -0.7525, -0.7991,  ..., -0.2791, -0.5393,  0.4828],\n",
      "          [ 0.8234, -0.2278, -0.1515,  ...,  0.0281, -0.9028, -0.2864]],\n",
      "\n",
      "         [[-0.3771, -0.5239, -0.3707,  ..., -0.4412, -0.1697,  0.3558],\n",
      "          [ 0.5239, -0.2241, -0.1131,  ...,  0.0266, -0.8615, -0.1183]],\n",
      "\n",
      "         [[-0.2313,  0.0076, -0.3799,  ..., -0.3509, -0.4691, -0.1917],\n",
      "          [ 0.3314,  0.1032, -0.3117,  ...,  0.3214, -0.5224, -0.1273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2571, -0.5985, -0.2913,  ..., -0.2929,  0.0491,  0.8802],\n",
      "          [ 0.4385,  0.0377, -0.1311,  ...,  0.3405, -0.4415, -0.1249]],\n",
      "\n",
      "         [[-0.3859, -0.1819, -0.2923,  ..., -0.2647,  0.0116,  0.4627],\n",
      "          [ 0.1069, -0.2183,  0.0299,  ..., -0.3063, -0.7411,  0.1740]],\n",
      "\n",
      "         [[-0.4995,  0.2714,  0.4094,  ..., -0.1135, -0.2362,  0.3252],\n",
      "          [ 0.2718, -0.0229, -0.6594,  ...,  0.0814, -0.9173,  0.2603]]],\n",
      "\n",
      "\n",
      "        [[[-0.5790, -0.4828, -0.2453,  ..., -0.3011, -0.2457,  0.3033],\n",
      "          [ 0.6065, -0.2532, -0.2046,  ..., -0.1172, -0.6581, -0.2416]],\n",
      "\n",
      "         [[-0.7508, -0.6206, -0.3220,  ..., -0.6217, -0.1208,  0.1939],\n",
      "          [ 0.6974,  0.1391, -0.2911,  ...,  0.0585, -0.4389, -0.2414]],\n",
      "\n",
      "         [[-0.5634,  0.2343, -0.4859,  ..., -0.0520, -0.1545, -0.1053],\n",
      "          [ 0.6529,  0.0280, -0.4395,  ..., -0.0805, -0.2437, -0.0632]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4411, -0.0601, -0.1538,  ..., -0.1459, -0.0339,  0.3289],\n",
      "          [ 0.3497,  0.0142, -0.1872,  ..., -0.1744, -0.5948,  0.3113]],\n",
      "\n",
      "         [[-0.2343, -0.1596, -0.4021,  ..., -0.3851,  0.0904, -0.0051],\n",
      "          [-0.1379,  0.0013,  0.0619,  ...,  0.1106, -0.2673, -0.2855]],\n",
      "\n",
      "         [[-0.4811,  0.3029,  0.4734,  ..., -0.0899,  0.0767,  0.2585],\n",
      "          [ 0.3261,  0.0181, -0.3658,  ...,  0.1060, -0.7120,  0.2196]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2767,  0.1302,  0.0298,  ...,  0.0399, -0.1190,  0.1973],\n",
      "         [-0.4283,  0.1715, -0.2619,  ...,  0.0173,  0.5456,  0.3737],\n",
      "         [-0.7147,  0.6787,  0.3701,  ..., -0.0375, -0.0619,  0.3252],\n",
      "         ...,\n",
      "         [-0.3910,  0.0854,  0.3361,  ...,  0.4390,  0.0566,  0.2640],\n",
      "         [-0.7269,  0.6332,  0.4740,  ...,  0.1655,  0.1364,  0.4440],\n",
      "         [ 0.1720,  0.2368,  0.1424,  ..., -0.5385, -0.3114, -0.3543]],\n",
      "\n",
      "        [[ 0.6382, -0.5245, -0.7702,  ..., -0.7651, -0.1808, -0.5141],\n",
      "         [ 0.8519, -0.5555, -0.6353,  ..., -0.3201,  0.1561, -0.2138],\n",
      "         [ 0.0574,  0.6207,  0.4624,  ..., -0.0857, -0.1432,  0.1423],\n",
      "         ...,\n",
      "         [ 0.4143, -0.5105, -0.1034,  ..., -0.8187,  0.1755, -0.4637],\n",
      "         [ 0.3631, -0.3718, -0.3695,  ..., -0.1932, -0.0944, -0.4297],\n",
      "         [ 0.6828, -0.2428,  0.0240,  ..., -0.7128, -0.2215, -0.6501]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2767,  0.1302,  0.0298,  ...,  0.0399, -0.1190,  0.1973],\n",
      "         [-0.4283,  0.1715, -0.2619,  ...,  0.0173,  0.5456,  0.3737],\n",
      "         [-0.7147,  0.6787,  0.3701,  ..., -0.0375, -0.0619,  0.3252],\n",
      "         ...,\n",
      "         [-0.3910,  0.0854,  0.3361,  ...,  0.4390,  0.0566,  0.2640],\n",
      "         [-0.7269,  0.6332,  0.4740,  ...,  0.1655,  0.1364,  0.4440],\n",
      "         [ 0.1720,  0.2368,  0.1424,  ..., -0.5385, -0.3114, -0.3543]],\n",
      "\n",
      "        [[ 0.6382, -0.5245, -0.7702,  ..., -0.7651, -0.1808, -0.5141],\n",
      "         [ 0.8519, -0.5555, -0.6353,  ..., -0.3201,  0.1561, -0.2138],\n",
      "         [ 0.0574,  0.6207,  0.4624,  ..., -0.0857, -0.1432,  0.1423],\n",
      "         ...,\n",
      "         [ 0.4143, -0.5105, -0.1034,  ..., -0.8187,  0.1755, -0.4637],\n",
      "         [ 0.3631, -0.3718, -0.3695,  ..., -0.1932, -0.0944, -0.4297],\n",
      "         [ 0.6828, -0.2428,  0.0240,  ..., -0.7128, -0.2215, -0.6501]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.2767,  0.1302,  0.0298,  ...,  0.0132, -0.0847,  0.5452],\n",
      "          [ 0.4703,  0.2592, -0.5280,  ...,  0.0399, -0.1190,  0.1973]],\n",
      "\n",
      "         [[-0.4283,  0.1715, -0.2619,  ..., -0.6202, -0.3912,  0.2236],\n",
      "          [ 0.2669,  0.3319, -0.5046,  ...,  0.0173,  0.5456,  0.3737]],\n",
      "\n",
      "         [[-0.7147,  0.6787,  0.3701,  ..., -0.0409, -0.7050,  1.0213],\n",
      "          [ 0.9410,  0.1591, -0.0671,  ..., -0.0375, -0.0619,  0.3252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3910,  0.0854,  0.3361,  ...,  0.0433, -0.0282,  0.0355],\n",
      "          [ 0.5649,  0.3720,  0.1695,  ...,  0.4390,  0.0566,  0.2640]],\n",
      "\n",
      "         [[-0.7269,  0.6332,  0.4740,  ..., -0.5724, -0.5036,  0.4242],\n",
      "          [ 0.5621,  0.9846, -0.2033,  ...,  0.1655,  0.1364,  0.4440]],\n",
      "\n",
      "         [[ 0.1720,  0.2368,  0.1424,  ..., -0.0934, -0.1159, -0.0390],\n",
      "          [ 0.5355,  0.3912, -0.0325,  ..., -0.5385, -0.3114, -0.3543]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6382, -0.5245, -0.7702,  ...,  0.2850,  0.5082,  0.0951],\n",
      "          [-0.2554, -0.5874, -0.0710,  ..., -0.7651, -0.1808, -0.5141]],\n",
      "\n",
      "         [[ 0.8519, -0.5555, -0.6353,  ...,  0.4673,  0.4198, -0.3413],\n",
      "          [-0.2974, -0.2715,  0.0745,  ..., -0.3201,  0.1561, -0.2138]],\n",
      "\n",
      "         [[ 0.0574,  0.6207,  0.4624,  ...,  0.0248, -0.2510,  0.3057],\n",
      "          [ 0.4697,  0.6698,  0.2064,  ..., -0.0857, -0.1432,  0.1423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4143, -0.5105, -0.1034,  ...,  0.5528,  0.3531, -0.5668],\n",
      "          [-0.2652, -0.2682,  0.2983,  ..., -0.8187,  0.1755, -0.4637]],\n",
      "\n",
      "         [[ 0.3631, -0.3718, -0.3695,  ..., -0.2368,  0.4987, -0.0713],\n",
      "          [ 0.1748, -0.2521, -0.2383,  ..., -0.1932, -0.0944, -0.4297]],\n",
      "\n",
      "         [[ 0.6828, -0.2428,  0.0240,  ...,  0.1391,  0.0979, -0.2702],\n",
      "          [ 0.0276,  0.0062,  0.1758,  ..., -0.7128, -0.2215, -0.6501]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1589e+00,  9.8523e-01,  7.8424e-01,  ..., -2.5626e-01,\n",
      "           4.3574e-01,  7.4141e-01],\n",
      "         [ 5.9324e-01,  3.8298e-01,  7.2367e-01,  ..., -4.8477e-02,\n",
      "           3.8187e-01,  6.7004e-01],\n",
      "         [ 6.4045e-01,  3.3070e-01,  2.6487e-01,  ..., -1.1077e-01,\n",
      "           4.7523e-01,  8.5126e-01],\n",
      "         ...,\n",
      "         [ 5.9685e-01,  1.3287e-01,  1.1208e-01,  ...,  1.4161e-01,\n",
      "          -1.6613e-01,  6.5642e-01],\n",
      "         [ 5.5575e-01, -8.5068e-04,  4.0310e-01,  ...,  2.3830e-02,\n",
      "           1.2963e-01,  5.5058e-01],\n",
      "         [ 1.4251e-01,  3.6032e-01,  3.0392e-01,  ...,  4.2464e-01,\n",
      "           2.1012e-01,  3.9417e-01]],\n",
      "\n",
      "        [[ 7.5411e-01,  8.6194e-01,  7.2668e-01,  ..., -1.3753e-01,\n",
      "           5.6444e-01,  6.4809e-01],\n",
      "         [ 3.5342e-01,  7.1302e-01,  4.6993e-01,  ...,  3.0158e-01,\n",
      "           4.9968e-01,  4.8983e-01],\n",
      "         [ 4.9125e-01,  2.0400e-01,  1.0960e-01,  ...,  4.8062e-03,\n",
      "           4.0026e-01,  9.1455e-01],\n",
      "         ...,\n",
      "         [ 5.0226e-01,  1.1644e-01,  1.2475e-01,  ...,  2.9190e-01,\n",
      "           2.7256e-01,  6.3866e-01],\n",
      "         [ 5.2669e-01,  5.8445e-01,  5.3178e-02,  ...,  4.1644e-01,\n",
      "           1.7178e-01,  4.9921e-01],\n",
      "         [ 5.5875e-02,  1.4534e-01,  3.5067e-01,  ...,  4.3738e-01,\n",
      "           4.9411e-01,  1.3566e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1589e+00,  9.8523e-01,  7.8424e-01,  ..., -2.5626e-01,\n",
      "           4.3574e-01,  7.4141e-01],\n",
      "         [ 5.9324e-01,  3.8298e-01,  7.2367e-01,  ..., -4.8477e-02,\n",
      "           3.8187e-01,  6.7004e-01],\n",
      "         [ 6.4045e-01,  3.3070e-01,  2.6487e-01,  ..., -1.1077e-01,\n",
      "           4.7523e-01,  8.5126e-01],\n",
      "         ...,\n",
      "         [ 5.9685e-01,  1.3287e-01,  1.1208e-01,  ...,  1.4161e-01,\n",
      "          -1.6613e-01,  6.5642e-01],\n",
      "         [ 5.5575e-01, -8.5068e-04,  4.0310e-01,  ...,  2.3830e-02,\n",
      "           1.2963e-01,  5.5058e-01],\n",
      "         [ 1.4251e-01,  3.6032e-01,  3.0392e-01,  ...,  4.2464e-01,\n",
      "           2.1012e-01,  3.9417e-01]],\n",
      "\n",
      "        [[ 7.5411e-01,  8.6194e-01,  7.2668e-01,  ..., -1.3753e-01,\n",
      "           5.6444e-01,  6.4809e-01],\n",
      "         [ 3.5342e-01,  7.1302e-01,  4.6993e-01,  ...,  3.0158e-01,\n",
      "           4.9968e-01,  4.8983e-01],\n",
      "         [ 4.9125e-01,  2.0400e-01,  1.0960e-01,  ...,  4.8062e-03,\n",
      "           4.0026e-01,  9.1455e-01],\n",
      "         ...,\n",
      "         [ 5.0226e-01,  1.1644e-01,  1.2475e-01,  ...,  2.9190e-01,\n",
      "           2.7256e-01,  6.3866e-01],\n",
      "         [ 5.2669e-01,  5.8445e-01,  5.3178e-02,  ...,  4.1644e-01,\n",
      "           1.7178e-01,  4.9921e-01],\n",
      "         [ 5.5875e-02,  1.4534e-01,  3.5067e-01,  ...,  4.3738e-01,\n",
      "           4.9411e-01,  1.3566e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.1589e+00,  9.8523e-01,  7.8424e-01,  ...,  1.5129e-01,\n",
      "            2.3052e-01, -1.4096e+00],\n",
      "          [-1.0604e+00, -8.4150e-01, -5.0639e-01,  ..., -2.5626e-01,\n",
      "            4.3574e-01,  7.4141e-01]],\n",
      "\n",
      "         [[ 5.9324e-01,  3.8298e-01,  7.2367e-01,  ...,  9.4640e-02,\n",
      "           -4.0518e-01,  1.3976e-02],\n",
      "          [-4.1372e-01,  8.3550e-02, -1.6337e-01,  ..., -4.8477e-02,\n",
      "            3.8187e-01,  6.7004e-01]],\n",
      "\n",
      "         [[ 6.4045e-01,  3.3070e-01,  2.6487e-01,  ..., -1.2764e-01,\n",
      "           -1.4032e-01, -9.4319e-01],\n",
      "          [-7.9937e-01,  5.6475e-01, -3.9170e-01,  ..., -1.1077e-01,\n",
      "            4.7523e-01,  8.5126e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.9685e-01,  1.3287e-01,  1.1208e-01,  ..., -8.1288e-03,\n",
      "           -5.0540e-01, -5.7927e-01],\n",
      "          [-2.2883e-01,  3.5269e-01,  9.3007e-02,  ...,  1.4161e-01,\n",
      "           -1.6613e-01,  6.5642e-01]],\n",
      "\n",
      "         [[ 5.5575e-01, -8.5068e-04,  4.0310e-01,  ...,  5.2306e-01,\n",
      "            2.7016e-01, -1.5816e-03],\n",
      "          [-4.7455e-01,  2.2552e-01, -2.9158e-01,  ...,  2.3830e-02,\n",
      "            1.2963e-01,  5.5058e-01]],\n",
      "\n",
      "         [[ 1.4251e-01,  3.6032e-01,  3.0392e-01,  ...,  6.5952e-01,\n",
      "            2.0602e-01,  1.8872e-02],\n",
      "          [-9.1745e-02,  3.5013e-01,  1.4201e-01,  ...,  4.2464e-01,\n",
      "            2.1012e-01,  3.9417e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5411e-01,  8.6194e-01,  7.2668e-01,  ...,  9.6796e-02,\n",
      "            3.2744e-01, -1.4614e+00],\n",
      "          [-6.2703e-01, -7.6386e-01, -3.6365e-01,  ..., -1.3753e-01,\n",
      "            5.6444e-01,  6.4809e-01]],\n",
      "\n",
      "         [[ 3.5342e-01,  7.1302e-01,  4.6993e-01,  ..., -1.4923e-01,\n",
      "           -1.1653e-01, -8.0269e-01],\n",
      "          [ 1.7570e-01, -2.4871e-01,  9.1092e-02,  ...,  3.0158e-01,\n",
      "            4.9968e-01,  4.8983e-01]],\n",
      "\n",
      "         [[ 4.9125e-01,  2.0400e-01,  1.0960e-01,  ..., -1.6360e-01,\n",
      "            8.1012e-02, -4.4303e-01],\n",
      "          [-3.0199e-01,  2.9763e-01,  4.1092e-01,  ...,  4.8062e-03,\n",
      "            4.0026e-01,  9.1455e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.0226e-01,  1.1644e-01,  1.2475e-01,  ...,  3.6339e-02,\n",
      "           -7.0611e-02, -9.2365e-01],\n",
      "          [ 4.5708e-01,  1.7251e-01,  4.4878e-02,  ...,  2.9190e-01,\n",
      "            2.7256e-01,  6.3866e-01]],\n",
      "\n",
      "         [[ 5.2669e-01,  5.8445e-01,  5.3178e-02,  ...,  6.2237e-01,\n",
      "           -1.1815e-01, -2.1064e-01],\n",
      "          [-2.6606e-01,  2.3316e-01, -5.3452e-01,  ...,  4.1644e-01,\n",
      "            1.7178e-01,  4.9921e-01]],\n",
      "\n",
      "         [[ 5.5875e-02,  1.4534e-01,  3.5067e-01,  ...,  6.8474e-01,\n",
      "            1.0521e-01, -1.2152e-01],\n",
      "          [-6.5364e-02, -3.0898e-02,  5.9831e-02,  ...,  4.3738e-01,\n",
      "            4.9411e-01,  1.3566e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.7674, -0.7525, -0.7991,  ..., -0.2791, -0.5393,  0.4828],\n",
      "          [-0.3771, -0.5239, -0.3707,  ..., -0.4412, -0.1697,  0.3558],\n",
      "          [-0.2313,  0.0076, -0.3799,  ..., -0.3509, -0.4691, -0.1917],\n",
      "          ...,\n",
      "          [-0.2571, -0.5985, -0.2913,  ..., -0.2929,  0.0491,  0.8802],\n",
      "          [-0.3859, -0.1819, -0.2923,  ..., -0.2647,  0.0116,  0.4627],\n",
      "          [-0.4995,  0.2714,  0.4094,  ..., -0.1135, -0.2362,  0.3252]],\n",
      "\n",
      "         [[ 0.8234, -0.2278, -0.1515,  ...,  0.0281, -0.9028, -0.2864],\n",
      "          [ 0.5239, -0.2241, -0.1131,  ...,  0.0266, -0.8615, -0.1183],\n",
      "          [ 0.3314,  0.1032, -0.3117,  ...,  0.3214, -0.5224, -0.1273],\n",
      "          ...,\n",
      "          [ 0.4385,  0.0377, -0.1311,  ...,  0.3405, -0.4415, -0.1249],\n",
      "          [ 0.1069, -0.2183,  0.0299,  ..., -0.3063, -0.7411,  0.1740],\n",
      "          [ 0.2718, -0.0229, -0.6594,  ...,  0.0814, -0.9173,  0.2603]]],\n",
      "\n",
      "\n",
      "        [[[-0.5790, -0.4828, -0.2453,  ..., -0.3011, -0.2457,  0.3033],\n",
      "          [-0.7508, -0.6206, -0.3220,  ..., -0.6217, -0.1208,  0.1939],\n",
      "          [-0.5634,  0.2343, -0.4859,  ..., -0.0520, -0.1545, -0.1053],\n",
      "          ...,\n",
      "          [-0.4411, -0.0601, -0.1538,  ..., -0.1459, -0.0339,  0.3289],\n",
      "          [-0.2343, -0.1596, -0.4021,  ..., -0.3851,  0.0904, -0.0051],\n",
      "          [-0.4811,  0.3029,  0.4734,  ..., -0.0899,  0.0767,  0.2585]],\n",
      "\n",
      "         [[ 0.6065, -0.2532, -0.2046,  ..., -0.1172, -0.6581, -0.2416],\n",
      "          [ 0.6974,  0.1391, -0.2911,  ...,  0.0585, -0.4389, -0.2414],\n",
      "          [ 0.6529,  0.0280, -0.4395,  ..., -0.0805, -0.2437, -0.0632],\n",
      "          ...,\n",
      "          [ 0.3497,  0.0142, -0.1872,  ..., -0.1744, -0.5948,  0.3113],\n",
      "          [-0.1379,  0.0013,  0.0619,  ...,  0.1106, -0.2673, -0.2855],\n",
      "          [ 0.3261,  0.0181, -0.3658,  ...,  0.1060, -0.7120,  0.2196]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.6491,  0.6771,  0.3190,  ..., -0.2270, -0.3543,  0.7354],\n",
      "          [-0.5625,  0.5291,  0.2938,  ..., -0.2386, -0.2977,  0.5482],\n",
      "          [-0.4414,  0.4182,  0.2251,  ..., -0.2341, -0.1671,  0.3732],\n",
      "          ...,\n",
      "          [-0.3327,  0.3489,  0.2437,  ..., -0.0771, -0.1336,  0.3715],\n",
      "          [-0.4352,  0.3961,  0.2279,  ..., -0.2371, -0.1662,  0.3521],\n",
      "          [-0.5267,  0.4820,  0.2970,  ..., -0.2491, -0.2647,  0.4575]],\n",
      "\n",
      "         [[ 0.4204,  0.5651, -0.1276,  ...,  0.0930, -0.1909,  0.5019],\n",
      "          [ 0.5492,  0.5196, -0.1425,  ...,  0.0576, -0.0829,  0.3413],\n",
      "          [ 0.5269,  0.5307, -0.1321,  ...,  0.0707, -0.1170,  0.3882],\n",
      "          ...,\n",
      "          [ 0.5519,  0.5215, -0.1530,  ...,  0.0467, -0.0745,  0.3238],\n",
      "          [ 0.5388,  0.5191, -0.1438,  ...,  0.0621, -0.0854,  0.3451],\n",
      "          [ 0.5040,  0.4331, -0.1334,  ...,  0.0610, -0.1015,  0.2951]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3659, -0.1278, -0.0996,  ...,  0.3225,  0.2713, -0.1866],\n",
      "          [ 0.2302, -0.0047, -0.0668,  ...,  0.2082,  0.1338, -0.0727],\n",
      "          [ 0.3753, -0.1866, -0.1613,  ...,  0.3031,  0.2753, -0.2015],\n",
      "          ...,\n",
      "          [ 0.4455, -0.2150, -0.1408,  ...,  0.3399,  0.2878, -0.2088],\n",
      "          [ 0.4249, -0.2566, -0.1894,  ...,  0.3445,  0.2751, -0.1702],\n",
      "          [ 0.2605, -0.0855, -0.1192,  ...,  0.1556,  0.1513, -0.1444]],\n",
      "\n",
      "         [[-0.0604, -0.0666,  0.2987,  ..., -0.5293,  0.0058, -0.2452],\n",
      "          [-0.0973, -0.1505,  0.2062,  ..., -0.5777, -0.0228, -0.3413],\n",
      "          [-0.0940, -0.1374,  0.2478,  ..., -0.5847, -0.0278, -0.3295],\n",
      "          ...,\n",
      "          [-0.1021, -0.1511,  0.2182,  ..., -0.5851, -0.0204, -0.3410],\n",
      "          [-0.1091, -0.1250,  0.2144,  ..., -0.5493, -0.0103, -0.2955],\n",
      "          [ 0.0051, -0.0722,  0.0279,  ..., -0.3142, -0.0584, -0.2163]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.6491,  0.6771,  0.3190,  ..., -0.2270, -0.3543,  0.7354],\n",
      "          [ 0.4204,  0.5651, -0.1276,  ...,  0.0930, -0.1909,  0.5019]],\n",
      "\n",
      "         [[-0.5625,  0.5291,  0.2938,  ..., -0.2386, -0.2977,  0.5482],\n",
      "          [ 0.5492,  0.5196, -0.1425,  ...,  0.0576, -0.0829,  0.3413]],\n",
      "\n",
      "         [[-0.4414,  0.4182,  0.2251,  ..., -0.2341, -0.1671,  0.3732],\n",
      "          [ 0.5269,  0.5307, -0.1321,  ...,  0.0707, -0.1170,  0.3882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3327,  0.3489,  0.2437,  ..., -0.0771, -0.1336,  0.3715],\n",
      "          [ 0.5519,  0.5215, -0.1530,  ...,  0.0467, -0.0745,  0.3238]],\n",
      "\n",
      "         [[-0.4352,  0.3961,  0.2279,  ..., -0.2371, -0.1662,  0.3521],\n",
      "          [ 0.5388,  0.5191, -0.1438,  ...,  0.0621, -0.0854,  0.3451]],\n",
      "\n",
      "         [[-0.5267,  0.4820,  0.2970,  ..., -0.2491, -0.2647,  0.4575],\n",
      "          [ 0.5040,  0.4331, -0.1334,  ...,  0.0610, -0.1015,  0.2951]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3659, -0.1278, -0.0996,  ...,  0.3225,  0.2713, -0.1866],\n",
      "          [-0.0604, -0.0666,  0.2987,  ..., -0.5293,  0.0058, -0.2452]],\n",
      "\n",
      "         [[ 0.2302, -0.0047, -0.0668,  ...,  0.2082,  0.1338, -0.0727],\n",
      "          [-0.0973, -0.1505,  0.2062,  ..., -0.5777, -0.0228, -0.3413]],\n",
      "\n",
      "         [[ 0.3753, -0.1866, -0.1613,  ...,  0.3031,  0.2753, -0.2015],\n",
      "          [-0.0940, -0.1374,  0.2478,  ..., -0.5847, -0.0278, -0.3295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4455, -0.2150, -0.1408,  ...,  0.3399,  0.2878, -0.2088],\n",
      "          [-0.1021, -0.1511,  0.2182,  ..., -0.5851, -0.0204, -0.3410]],\n",
      "\n",
      "         [[ 0.4249, -0.2566, -0.1894,  ...,  0.3445,  0.2751, -0.1702],\n",
      "          [-0.1091, -0.1250,  0.2144,  ..., -0.5493, -0.0103, -0.2955]],\n",
      "\n",
      "         [[ 0.2605, -0.0855, -0.1192,  ...,  0.1556,  0.1513, -0.1444],\n",
      "          [ 0.0051, -0.0722,  0.0279,  ..., -0.3142, -0.0584, -0.2163]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.6491,  0.6771,  0.3190,  ..., -0.2270, -0.3543,  0.7354],\n",
      "          [ 0.4204,  0.5651, -0.1276,  ...,  0.0930, -0.1909,  0.5019]],\n",
      "\n",
      "         [[-0.5625,  0.5291,  0.2938,  ..., -0.2386, -0.2977,  0.5482],\n",
      "          [ 0.5492,  0.5196, -0.1425,  ...,  0.0576, -0.0829,  0.3413]],\n",
      "\n",
      "         [[-0.4414,  0.4182,  0.2251,  ..., -0.2341, -0.1671,  0.3732],\n",
      "          [ 0.5269,  0.5307, -0.1321,  ...,  0.0707, -0.1170,  0.3882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3327,  0.3489,  0.2437,  ..., -0.0771, -0.1336,  0.3715],\n",
      "          [ 0.5519,  0.5215, -0.1530,  ...,  0.0467, -0.0745,  0.3238]],\n",
      "\n",
      "         [[-0.4352,  0.3961,  0.2279,  ..., -0.2371, -0.1662,  0.3521],\n",
      "          [ 0.5388,  0.5191, -0.1438,  ...,  0.0621, -0.0854,  0.3451]],\n",
      "\n",
      "         [[-0.5267,  0.4820,  0.2970,  ..., -0.2491, -0.2647,  0.4575],\n",
      "          [ 0.5040,  0.4331, -0.1334,  ...,  0.0610, -0.1015,  0.2951]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3659, -0.1278, -0.0996,  ...,  0.3225,  0.2713, -0.1866],\n",
      "          [-0.0604, -0.0666,  0.2987,  ..., -0.5293,  0.0058, -0.2452]],\n",
      "\n",
      "         [[ 0.2302, -0.0047, -0.0668,  ...,  0.2082,  0.1338, -0.0727],\n",
      "          [-0.0973, -0.1505,  0.2062,  ..., -0.5777, -0.0228, -0.3413]],\n",
      "\n",
      "         [[ 0.3753, -0.1866, -0.1613,  ...,  0.3031,  0.2753, -0.2015],\n",
      "          [-0.0940, -0.1374,  0.2478,  ..., -0.5847, -0.0278, -0.3295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4455, -0.2150, -0.1408,  ...,  0.3399,  0.2878, -0.2088],\n",
      "          [-0.1021, -0.1511,  0.2182,  ..., -0.5851, -0.0204, -0.3410]],\n",
      "\n",
      "         [[ 0.4249, -0.2566, -0.1894,  ...,  0.3445,  0.2751, -0.1702],\n",
      "          [-0.1091, -0.1250,  0.2144,  ..., -0.5493, -0.0103, -0.2955]],\n",
      "\n",
      "         [[ 0.2605, -0.0855, -0.1192,  ...,  0.1556,  0.1513, -0.1444],\n",
      "          [ 0.0051, -0.0722,  0.0279,  ..., -0.3142, -0.0584, -0.2163]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-0.6491,  0.6771,  0.3190,  ..., -0.2270, -0.3543,  0.7354],\n",
      "          [ 0.4204,  0.5651, -0.1276,  ...,  0.0930, -0.1909,  0.5019]],\n",
      "\n",
      "         [[-0.5625,  0.5291,  0.2938,  ..., -0.2386, -0.2977,  0.5482],\n",
      "          [ 0.5492,  0.5196, -0.1425,  ...,  0.0576, -0.0829,  0.3413]],\n",
      "\n",
      "         [[-0.4414,  0.4182,  0.2251,  ..., -0.2341, -0.1671,  0.3732],\n",
      "          [ 0.5269,  0.5307, -0.1321,  ...,  0.0707, -0.1170,  0.3882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3327,  0.3489,  0.2437,  ..., -0.0771, -0.1336,  0.3715],\n",
      "          [ 0.5519,  0.5215, -0.1530,  ...,  0.0467, -0.0745,  0.3238]],\n",
      "\n",
      "         [[-0.4352,  0.3961,  0.2279,  ..., -0.2371, -0.1662,  0.3521],\n",
      "          [ 0.5388,  0.5191, -0.1438,  ...,  0.0621, -0.0854,  0.3451]],\n",
      "\n",
      "         [[-0.5267,  0.4820,  0.2970,  ..., -0.2491, -0.2647,  0.4575],\n",
      "          [ 0.5040,  0.4331, -0.1334,  ...,  0.0610, -0.1015,  0.2951]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3659, -0.1278, -0.0996,  ...,  0.3225,  0.2713, -0.1866],\n",
      "          [-0.0604, -0.0666,  0.2987,  ..., -0.5293,  0.0058, -0.2452]],\n",
      "\n",
      "         [[ 0.2302, -0.0047, -0.0668,  ...,  0.2082,  0.1338, -0.0727],\n",
      "          [-0.0973, -0.1505,  0.2062,  ..., -0.5777, -0.0228, -0.3413]],\n",
      "\n",
      "         [[ 0.3753, -0.1866, -0.1613,  ...,  0.3031,  0.2753, -0.2015],\n",
      "          [-0.0940, -0.1374,  0.2478,  ..., -0.5847, -0.0278, -0.3295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4455, -0.2150, -0.1408,  ...,  0.3399,  0.2878, -0.2088],\n",
      "          [-0.1021, -0.1511,  0.2182,  ..., -0.5851, -0.0204, -0.3410]],\n",
      "\n",
      "         [[ 0.4249, -0.2566, -0.1894,  ...,  0.3445,  0.2751, -0.1702],\n",
      "          [-0.1091, -0.1250,  0.2144,  ..., -0.5493, -0.0103, -0.2955]],\n",
      "\n",
      "         [[ 0.2605, -0.0855, -0.1192,  ...,  0.1556,  0.1513, -0.1444],\n",
      "          [ 0.0051, -0.0722,  0.0279,  ..., -0.3142, -0.0584, -0.2163]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.7023,  2.1484],\n",
      "        [ 1.1715, -1.1871]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:48:58,529] Trial 10 finished with value: 0.79944 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 0 with value: 0.822.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "import torch\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4],\n",
    "    \"num_heads\": [2, 4],\n",
    "    \"hidden_size\": [128, 192],\n",
    "    \"intermediate_size\": [512, 768],\n",
    "    \"linear_layer_type\": [\"linear\", \"identity\"],  # 用字符串代替类名\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        # chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # # 将选中的值设置到 config 中\n",
    "        # print(f\"Param is {param}\")\n",
    "        # print(f\"Choose from 0 to {len(search_space[param]) - 1}\")\n",
    "        # print(f\"Idx is {chosen_idx}\")\n",
    "        # setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            # new_layer_cls = trial.suggest_categorical(\n",
    "            #     f\"{name}_type\",\n",
    "            #     search_space[\"linear_layer_choices\"],\n",
    "            # )\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 确定运行设备\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial).to(device)  # 将模型移动到 GPU\n",
    "\n",
    "    # Train a few epoches\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Compression\n",
    "    mg = MaseGraph(model.to(\"cpu\"),\n",
    "                   hf_input_names=[\n",
    "                        \"input_ids\",\n",
    "                        \"attention_mask\",\n",
    "                        \"labels\",\n",
    "                        \"token_type_ids\",\n",
    "                    ],)  # 确保 MaseGraph 处理前，模型在 CPU\n",
    "    pipe = CompressionPipeline()\n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": 8,\n",
    "                \"data_in_frac_width\": 4,\n",
    "                # weight\n",
    "                \"weight_width\": 8,\n",
    "                \"weight_frac_width\": 4,\n",
    "                # bias\n",
    "                \"bias_width\": 8,\n",
    "                \"bias_frac_width\": 4,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    pruning_config = {\n",
    "        \"weight\": {\n",
    "            \"sparsity\": 0.5,\n",
    "            \"method\": \"l1-norm\",\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"sparsity\": 0.5,\n",
    "            \"method\": \"l1-norm\",\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "    }\n",
    "    mg, _ = pipe(\n",
    "        mg,\n",
    "        pass_args={\n",
    "            \"quantize_transform_pass\": quantization_config,\n",
    "            \"prune_transform_pass\": pruning_config,\n",
    "        },\n",
    "    )\n",
    "    print(\"Model forward signature after compression:\", mg.model.forward.__annotations__)\n",
    "    \n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "    \n",
    "    # 获取当前 trial 结果\n",
    "    trainer.model = mg.model.to(device)\n",
    "    eval_results = trainer.evaluate()\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params,  # 记录所有超参数\n",
    "        \"compression\": True,\n",
    "        \"post_training\": False  # 这里标记未进行 post-training\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_com_no_post_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = TPESampler()\n",
    "n_trial = 32\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 30,\n",
    ")\n",
    "\n",
    "# 获取所有 trial 的准确率\n",
    "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# 计算累积最大准确率\n",
    "best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"GridSampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Grid Search Performance on BERT-tiny NAS\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Compression-Aware (With Post-Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:10:39,072] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.468100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.5142, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.8708]],\n",
      "\n",
      "         [[ 0.0000, -1.2378, -0.3820,  ...,  1.8911,  0.2042,  0.0000],\n",
      "          [-0.7583,  1.7336, -1.6338,  ...,  1.3147,  0.1479, -0.1311]],\n",
      "\n",
      "         [[-0.5542, -1.6353, -0.8493,  ...,  0.4129,  0.0000,  1.2651],\n",
      "          [-1.6724,  1.8016,  0.3337,  ..., -1.3131, -0.2066, -0.9545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6473, -1.7265,  0.5110,  ...,  1.0513, -0.3618,  0.2664],\n",
      "          [-0.5310,  1.1344,  1.5927,  ..., -0.0000,  0.1880, -1.0035]],\n",
      "\n",
      "         [[-2.1043, -2.3178, -0.5587,  ..., -0.1116,  0.9014, -0.8523],\n",
      "          [-0.9924,  1.1434, -0.5074,  ..., -0.0000,  0.8241,  0.4166]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "\n",
      "\n",
      "        [[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.0000, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.0000]],\n",
      "\n",
      "         [[-0.2015, -1.2604, -0.3696,  ...,  0.9278,  0.2083, -0.1261],\n",
      "          [-0.7519,  1.3533, -0.4670,  ...,  1.4167, -0.5986,  0.9434]],\n",
      "\n",
      "         [[-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.5548, -0.1530],\n",
      "          [-1.6941,  1.3256, -0.7286,  ..., -0.0000,  0.0000,  0.4345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3457, -1.5894,  1.8381,  ..., -1.5641, -0.0879,  0.2038],\n",
      "          [-2.6151,  1.4501,  0.0000,  ..., -0.0693,  0.1228, -0.7267]],\n",
      "\n",
      "         [[-1.0331, -1.4421, -0.7243,  ..., -0.5862, -0.5176, -0.1379],\n",
      "          [-2.4003,  0.8456,  0.3098,  ..., -1.2680, -1.1897,  1.3111]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.5142, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.8708]],\n",
      "\n",
      "         [[ 0.0000, -1.2378, -0.3820,  ...,  1.8911,  0.2042,  0.0000],\n",
      "          [-0.7583,  1.7336, -1.6338,  ...,  1.3147,  0.1479, -0.1311]],\n",
      "\n",
      "         [[-0.5542, -1.6353, -0.8493,  ...,  0.4129,  0.0000,  1.2651],\n",
      "          [-1.6724,  1.8016,  0.3337,  ..., -1.3131, -0.2066, -0.9545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6473, -1.7265,  0.5110,  ...,  1.0513, -0.3618,  0.2664],\n",
      "          [-0.5310,  1.1344,  1.5927,  ..., -0.0000,  0.1880, -1.0035]],\n",
      "\n",
      "         [[-2.1043, -2.3178, -0.5587,  ..., -0.1116,  0.9014, -0.8523],\n",
      "          [-0.9924,  1.1434, -0.5074,  ..., -0.0000,  0.8241,  0.4166]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "\n",
      "\n",
      "        [[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.0000, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.0000]],\n",
      "\n",
      "         [[-0.2015, -1.2604, -0.3696,  ...,  0.9278,  0.2083, -0.1261],\n",
      "          [-0.7519,  1.3533, -0.4670,  ...,  1.4167, -0.5986,  0.9434]],\n",
      "\n",
      "         [[-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.5548, -0.1530],\n",
      "          [-1.6941,  1.3256, -0.7286,  ..., -0.0000,  0.0000,  0.4345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3457, -1.5894,  1.8381,  ..., -1.5641, -0.0879,  0.2038],\n",
      "          [-2.6151,  1.4501,  0.0000,  ..., -0.0693,  0.1228, -0.7267]],\n",
      "\n",
      "         [[-1.0331, -1.4421, -0.7243,  ..., -0.5862, -0.5176, -0.1379],\n",
      "          [-2.4003,  0.8456,  0.3098,  ..., -1.2680, -1.1897,  1.3111]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.8708],\n",
      "         [ 0.0000, -1.2378, -0.3820,  ...,  1.3147,  0.1479, -0.1311],\n",
      "         [-0.5542, -1.6353, -0.8493,  ..., -1.3131, -0.2066, -0.9545],\n",
      "         ...,\n",
      "         [-0.6473, -1.7265,  0.5110,  ..., -0.0000,  0.1880, -1.0035],\n",
      "         [-2.1043, -2.3178, -0.5587,  ..., -0.0000,  0.8241,  0.4166],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]],\n",
      "\n",
      "        [[-1.5034, -0.2309, -0.2839,  ..., -0.6738,  0.9601, -0.0000],\n",
      "         [-0.2015, -1.2604, -0.3696,  ...,  1.4167, -0.5986,  0.9434],\n",
      "         [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.0000,  0.4345],\n",
      "         ...,\n",
      "         [-0.3457, -1.5894,  1.8381,  ..., -0.0693,  0.1228, -0.7267],\n",
      "         [-1.0331, -1.4421, -0.7243,  ..., -1.2680, -1.1897,  1.3111],\n",
      "         [ 0.5272, -0.0809,  0.3218,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.5142, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.8708]],\n",
      "\n",
      "         [[ 0.0000, -1.2378, -0.3820,  ...,  1.8911,  0.2042,  0.0000],\n",
      "          [-0.7583,  1.7336, -1.6338,  ...,  1.3147,  0.1479, -0.1311]],\n",
      "\n",
      "         [[-0.5542, -1.6353, -0.8493,  ...,  0.4129,  0.0000,  1.2651],\n",
      "          [-1.6724,  1.8016,  0.3337,  ..., -1.3131, -0.2066, -0.9545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6473, -1.7265,  0.5110,  ...,  1.0513, -0.3618,  0.2664],\n",
      "          [-0.5310,  1.1344,  1.5927,  ..., -0.0000,  0.1880, -1.0035]],\n",
      "\n",
      "         [[-2.1043, -2.3178, -0.5587,  ..., -0.1116,  0.9014, -0.8523],\n",
      "          [-0.9924,  1.1434, -0.5074,  ..., -0.0000,  0.8241,  0.4166]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "\n",
      "\n",
      "        [[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.0000, -0.7517],\n",
      "          [-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.0000]],\n",
      "\n",
      "         [[-0.2015, -1.2604, -0.3696,  ...,  0.9278,  0.2083, -0.1261],\n",
      "          [-0.7519,  1.3533, -0.4670,  ...,  1.4167, -0.5986,  0.9434]],\n",
      "\n",
      "         [[-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.5548, -0.1530],\n",
      "          [-1.6941,  1.3256, -0.7286,  ..., -0.0000,  0.0000,  0.4345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3457, -1.5894,  1.8381,  ..., -1.5641, -0.0879,  0.2038],\n",
      "          [-2.6151,  1.4501,  0.0000,  ..., -0.0693,  0.1228, -0.7267]],\n",
      "\n",
      "         [[-1.0331, -1.4421, -0.7243,  ..., -0.5862, -0.5176, -0.1379],\n",
      "          [-2.4003,  0.8456,  0.3098,  ..., -1.2680, -1.1897,  1.3111]],\n",
      "\n",
      "         [[ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.5142, -0.7517],\n",
      "          [ 0.0000, -1.2378, -0.3820,  ...,  1.8911,  0.2042,  0.0000],\n",
      "          [-0.5542, -1.6353, -0.8493,  ...,  0.4129,  0.0000,  1.2651],\n",
      "          ...,\n",
      "          [-0.6473, -1.7265,  0.5110,  ...,  1.0513, -0.3618,  0.2664],\n",
      "          [-2.1043, -2.3178, -0.5587,  ..., -0.1116,  0.9014, -0.8523],\n",
      "          [ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257]],\n",
      "\n",
      "         [[-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.8708],\n",
      "          [-0.7583,  1.7336, -1.6338,  ...,  1.3147,  0.1479, -0.1311],\n",
      "          [-1.6724,  1.8016,  0.3337,  ..., -1.3131, -0.2066, -0.9545],\n",
      "          ...,\n",
      "          [-0.5310,  1.1344,  1.5927,  ..., -0.0000,  0.1880, -1.0035],\n",
      "          [-0.9924,  1.1434, -0.5074,  ..., -0.0000,  0.8241,  0.4166],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]],\n",
      "\n",
      "\n",
      "        [[[-1.5034, -0.2309, -0.2839,  ..., -1.3859,  0.0000, -0.7517],\n",
      "          [-0.2015, -1.2604, -0.3696,  ...,  0.9278,  0.2083, -0.1261],\n",
      "          [-2.2967, -0.0000, -0.6270,  ..., -0.0000,  0.5548, -0.1530],\n",
      "          ...,\n",
      "          [-0.3457, -1.5894,  1.8381,  ..., -1.5641, -0.0879,  0.2038],\n",
      "          [-1.0331, -1.4421, -0.7243,  ..., -0.5862, -0.5176, -0.1379],\n",
      "          [ 0.5272, -0.0809,  0.3218,  ...,  0.6994,  0.8925, -1.4257]],\n",
      "\n",
      "         [[-1.5393,  1.2878,  0.4941,  ..., -0.6738,  0.9601, -0.0000],\n",
      "          [-0.7519,  1.3533, -0.4670,  ...,  1.4167, -0.5986,  0.9434],\n",
      "          [-1.6941,  1.3256, -0.7286,  ..., -0.0000,  0.0000,  0.4345],\n",
      "          ...,\n",
      "          [-2.6151,  1.4501,  0.0000,  ..., -0.0693,  0.1228, -0.7267],\n",
      "          [-2.4003,  0.8456,  0.3098,  ..., -1.2680, -1.1897,  1.3111],\n",
      "          [-1.0373, -0.0435, -2.0985,  ..., -0.0528, -0.3332,  0.4685]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.6665e+00, -2.6017e-01, -3.1646e-01,  ..., -1.5327e+00,\n",
      "            5.6925e-01, -8.2890e-01],\n",
      "          [-3.3103e-02, -1.3408e+00, -4.0038e-01,  ...,  2.0251e+00,\n",
      "            2.1868e-01, -1.4963e-02],\n",
      "          [-6.1983e-01, -1.8102e+00, -9.4055e-01,  ...,  4.5201e-01,\n",
      "            2.1090e-03,  1.3962e+00],\n",
      "          ...,\n",
      "          [-7.2490e-01, -1.8933e+00,  5.5855e-01,  ...,  1.1516e+00,\n",
      "           -3.9208e-01,  2.8585e-01],\n",
      "          [-2.3109e+00, -2.5449e+00, -6.1105e-01,  ..., -1.1881e-01,\n",
      "            9.8388e-01, -9.2923e-01],\n",
      "          [ 5.6680e-01, -8.9690e-02,  3.5625e-01,  ...,  7.7444e-01,\n",
      "            9.8118e-01, -1.5668e+00]],\n",
      "\n",
      "         [[-1.5119e+00,  1.5928e+00, -1.0745e-02,  ..., -7.9047e-01,\n",
      "            1.0353e+00, -2.6437e-02],\n",
      "          [-8.4358e-01,  1.9254e+00, -1.8113e+00,  ...,  1.4555e+00,\n",
      "            1.6607e-01, -1.4349e-01],\n",
      "          [-1.8214e+00,  1.9793e+00,  3.3242e-01,  ..., -1.4115e+00,\n",
      "           -1.7499e-01, -9.7710e-01],\n",
      "          ...,\n",
      "          [-5.9365e-01,  1.2650e+00,  1.7505e+00,  ..., -3.1674e-03,\n",
      "            2.1190e-01, -1.1014e+00],\n",
      "          [-1.1021e+00,  1.2776e+00, -5.6195e-01,  ..., -5.9144e-03,\n",
      "            9.1257e-01,  4.6223e-01],\n",
      "          [-1.1524e+00, -4.0033e-02, -2.3193e+00,  ..., -6.0380e-02,\n",
      "           -3.6303e-01,  5.2026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5598e-03, -2.0729e-03, -1.9469e-03,  ...,  1.1063e-03,\n",
      "            1.5379e-03, -4.0213e-04],\n",
      "          [-2.3196e-01, -1.3904e+00, -4.0908e-01,  ...,  1.0181e+00,\n",
      "            2.3098e-01, -1.4396e-01],\n",
      "          [-2.5043e+00, -1.6690e-02, -6.7978e-01,  ..., -4.2143e-02,\n",
      "            5.9309e-01, -1.9092e-01],\n",
      "          ...,\n",
      "          [-4.7619e-01, -1.5688e+00,  1.7817e+00,  ..., -1.5759e+00,\n",
      "           -5.3301e-02,  1.4739e-01],\n",
      "          [-1.1702e+00, -1.5306e+00, -7.7755e-01,  ..., -6.6003e-01,\n",
      "           -5.3314e-01, -1.7813e-01],\n",
      "          [ 5.4208e-01, -1.0869e-01,  3.3746e-01,  ...,  7.6548e-01,\n",
      "            9.6997e-01, -1.5429e+00]],\n",
      "\n",
      "         [[-1.3910e+00,  1.1220e+00,  2.8142e-01,  ..., -5.2747e-01,\n",
      "            7.3664e-01,  4.1011e-02],\n",
      "          [-8.7320e-01,  1.4610e+00, -5.0836e-01,  ...,  1.4607e+00,\n",
      "           -6.3988e-01,  1.0185e+00],\n",
      "          [-1.8769e+00,  1.4578e+00, -7.9287e-01,  ...,  7.9635e-03,\n",
      "           -6.9677e-04,  4.7388e-01],\n",
      "          ...,\n",
      "          [-4.4764e-03,  2.7338e-03, -2.4538e-03,  ...,  3.9665e-04,\n",
      "           -9.5919e-05,  8.1543e-04],\n",
      "          [-2.6562e+00,  9.3793e-01,  3.3861e-01,  ..., -1.3971e+00,\n",
      "           -1.3118e+00,  1.4457e+00],\n",
      "          [-1.1585e+00, -3.8083e-02, -2.3004e+00,  ..., -6.5469e-02,\n",
      "           -3.7108e-01,  5.2550e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-1.6665e+00, -2.6017e-01, -3.1646e-01,  ..., -1.5327e+00,\n",
      "            5.6925e-01, -8.2890e-01],\n",
      "          [-1.5119e+00,  1.5928e+00, -1.0745e-02,  ..., -7.9047e-01,\n",
      "            1.0353e+00, -2.6437e-02]],\n",
      "\n",
      "         [[-3.3103e-02, -1.3408e+00, -4.0038e-01,  ...,  2.0251e+00,\n",
      "            2.1868e-01, -1.4963e-02],\n",
      "          [-8.4358e-01,  1.9254e+00, -1.8113e+00,  ...,  1.4555e+00,\n",
      "            1.6607e-01, -1.4349e-01]],\n",
      "\n",
      "         [[-6.1983e-01, -1.8102e+00, -9.4055e-01,  ...,  4.5201e-01,\n",
      "            2.1090e-03,  1.3962e+00],\n",
      "          [-1.8214e+00,  1.9793e+00,  3.3242e-01,  ..., -1.4115e+00,\n",
      "           -1.7499e-01, -9.7710e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2490e-01, -1.8933e+00,  5.5855e-01,  ...,  1.1516e+00,\n",
      "           -3.9208e-01,  2.8585e-01],\n",
      "          [-5.9365e-01,  1.2650e+00,  1.7505e+00,  ..., -3.1674e-03,\n",
      "            2.1190e-01, -1.1014e+00]],\n",
      "\n",
      "         [[-2.3109e+00, -2.5449e+00, -6.1105e-01,  ..., -1.1881e-01,\n",
      "            9.8388e-01, -9.2923e-01],\n",
      "          [-1.1021e+00,  1.2776e+00, -5.6195e-01,  ..., -5.9144e-03,\n",
      "            9.1257e-01,  4.6223e-01]],\n",
      "\n",
      "         [[ 5.6680e-01, -8.9690e-02,  3.5625e-01,  ...,  7.7444e-01,\n",
      "            9.8118e-01, -1.5668e+00],\n",
      "          [-1.1524e+00, -4.0033e-02, -2.3193e+00,  ..., -6.0380e-02,\n",
      "           -3.6303e-01,  5.2026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5598e-03, -2.0729e-03, -1.9469e-03,  ...,  1.1063e-03,\n",
      "            1.5379e-03, -4.0213e-04],\n",
      "          [-1.3910e+00,  1.1220e+00,  2.8142e-01,  ..., -5.2747e-01,\n",
      "            7.3664e-01,  4.1011e-02]],\n",
      "\n",
      "         [[-2.3196e-01, -1.3904e+00, -4.0908e-01,  ...,  1.0181e+00,\n",
      "            2.3098e-01, -1.4396e-01],\n",
      "          [-8.7320e-01,  1.4610e+00, -5.0836e-01,  ...,  1.4607e+00,\n",
      "           -6.3988e-01,  1.0185e+00]],\n",
      "\n",
      "         [[-2.5043e+00, -1.6690e-02, -6.7978e-01,  ..., -4.2143e-02,\n",
      "            5.9309e-01, -1.9092e-01],\n",
      "          [-1.8769e+00,  1.4578e+00, -7.9287e-01,  ...,  7.9635e-03,\n",
      "           -6.9677e-04,  4.7388e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7619e-01, -1.5688e+00,  1.7817e+00,  ..., -1.5759e+00,\n",
      "           -5.3301e-02,  1.4739e-01],\n",
      "          [-4.4764e-03,  2.7338e-03, -2.4538e-03,  ...,  3.9665e-04,\n",
      "           -9.5919e-05,  8.1543e-04]],\n",
      "\n",
      "         [[-1.1702e+00, -1.5306e+00, -7.7755e-01,  ..., -6.6003e-01,\n",
      "           -5.3314e-01, -1.7813e-01],\n",
      "          [-2.6562e+00,  9.3793e-01,  3.3861e-01,  ..., -1.3971e+00,\n",
      "           -1.3118e+00,  1.4457e+00]],\n",
      "\n",
      "         [[ 5.4208e-01, -1.0869e-01,  3.3746e-01,  ...,  7.6548e-01,\n",
      "            9.6997e-01, -1.5429e+00],\n",
      "          [-1.1585e+00, -3.8083e-02, -2.3004e+00,  ..., -6.5469e-02,\n",
      "           -3.7108e-01,  5.2550e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.6665e+00, -2.6017e-01, -3.1646e-01,  ..., -1.5327e+00,\n",
      "            5.6925e-01, -8.2890e-01],\n",
      "          [-1.5119e+00,  1.5928e+00, -1.0745e-02,  ..., -7.9047e-01,\n",
      "            1.0353e+00, -2.6437e-02]],\n",
      "\n",
      "         [[-3.3103e-02, -1.3408e+00, -4.0038e-01,  ...,  2.0251e+00,\n",
      "            2.1868e-01, -1.4963e-02],\n",
      "          [-8.4358e-01,  1.9254e+00, -1.8113e+00,  ...,  1.4555e+00,\n",
      "            1.6607e-01, -1.4349e-01]],\n",
      "\n",
      "         [[-6.1983e-01, -1.8102e+00, -9.4055e-01,  ...,  4.5201e-01,\n",
      "            2.1090e-03,  1.3962e+00],\n",
      "          [-1.8214e+00,  1.9793e+00,  3.3242e-01,  ..., -1.4115e+00,\n",
      "           -1.7499e-01, -9.7710e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2490e-01, -1.8933e+00,  5.5855e-01,  ...,  1.1516e+00,\n",
      "           -3.9208e-01,  2.8585e-01],\n",
      "          [-5.9365e-01,  1.2650e+00,  1.7505e+00,  ..., -3.1674e-03,\n",
      "            2.1190e-01, -1.1014e+00]],\n",
      "\n",
      "         [[-2.3109e+00, -2.5449e+00, -6.1105e-01,  ..., -1.1881e-01,\n",
      "            9.8388e-01, -9.2923e-01],\n",
      "          [-1.1021e+00,  1.2776e+00, -5.6195e-01,  ..., -5.9144e-03,\n",
      "            9.1257e-01,  4.6223e-01]],\n",
      "\n",
      "         [[ 5.6680e-01, -8.9690e-02,  3.5625e-01,  ...,  7.7444e-01,\n",
      "            9.8118e-01, -1.5668e+00],\n",
      "          [-1.1524e+00, -4.0033e-02, -2.3193e+00,  ..., -6.0380e-02,\n",
      "           -3.6303e-01,  5.2026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5598e-03, -2.0729e-03, -1.9469e-03,  ...,  1.1063e-03,\n",
      "            1.5379e-03, -4.0213e-04],\n",
      "          [-1.3910e+00,  1.1220e+00,  2.8142e-01,  ..., -5.2747e-01,\n",
      "            7.3664e-01,  4.1011e-02]],\n",
      "\n",
      "         [[-2.3196e-01, -1.3904e+00, -4.0908e-01,  ...,  1.0181e+00,\n",
      "            2.3098e-01, -1.4396e-01],\n",
      "          [-8.7320e-01,  1.4610e+00, -5.0836e-01,  ...,  1.4607e+00,\n",
      "           -6.3988e-01,  1.0185e+00]],\n",
      "\n",
      "         [[-2.5043e+00, -1.6690e-02, -6.7978e-01,  ..., -4.2143e-02,\n",
      "            5.9309e-01, -1.9092e-01],\n",
      "          [-1.8769e+00,  1.4578e+00, -7.9287e-01,  ...,  7.9635e-03,\n",
      "           -6.9677e-04,  4.7388e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7619e-01, -1.5688e+00,  1.7817e+00,  ..., -1.5759e+00,\n",
      "           -5.3301e-02,  1.4739e-01],\n",
      "          [-4.4764e-03,  2.7338e-03, -2.4538e-03,  ...,  3.9665e-04,\n",
      "           -9.5919e-05,  8.1543e-04]],\n",
      "\n",
      "         [[-1.1702e+00, -1.5306e+00, -7.7755e-01,  ..., -6.6003e-01,\n",
      "           -5.3314e-01, -1.7813e-01],\n",
      "          [-2.6562e+00,  9.3793e-01,  3.3861e-01,  ..., -1.3971e+00,\n",
      "           -1.3118e+00,  1.4457e+00]],\n",
      "\n",
      "         [[ 5.4208e-01, -1.0869e-01,  3.3746e-01,  ...,  7.6548e-01,\n",
      "            9.6997e-01, -1.5429e+00],\n",
      "          [-1.1585e+00, -3.8083e-02, -2.3004e+00,  ..., -6.5469e-02,\n",
      "           -3.7108e-01,  5.2550e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-1.6665e+00, -2.6017e-01, -3.1646e-01,  ..., -1.5327e+00,\n",
      "            5.6925e-01, -8.2890e-01],\n",
      "          [-1.5119e+00,  1.5928e+00, -1.0745e-02,  ..., -7.9047e-01,\n",
      "            1.0353e+00, -2.6437e-02]],\n",
      "\n",
      "         [[-3.3103e-02, -1.3408e+00, -4.0038e-01,  ...,  2.0251e+00,\n",
      "            2.1868e-01, -1.4963e-02],\n",
      "          [-8.4358e-01,  1.9254e+00, -1.8113e+00,  ...,  1.4555e+00,\n",
      "            1.6607e-01, -1.4349e-01]],\n",
      "\n",
      "         [[-6.1983e-01, -1.8102e+00, -9.4055e-01,  ...,  4.5201e-01,\n",
      "            2.1090e-03,  1.3962e+00],\n",
      "          [-1.8214e+00,  1.9793e+00,  3.3242e-01,  ..., -1.4115e+00,\n",
      "           -1.7499e-01, -9.7710e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2490e-01, -1.8933e+00,  5.5855e-01,  ...,  1.1516e+00,\n",
      "           -3.9208e-01,  2.8585e-01],\n",
      "          [-5.9365e-01,  1.2650e+00,  1.7505e+00,  ..., -3.1674e-03,\n",
      "            2.1190e-01, -1.1014e+00]],\n",
      "\n",
      "         [[-2.3109e+00, -2.5449e+00, -6.1105e-01,  ..., -1.1881e-01,\n",
      "            9.8388e-01, -9.2923e-01],\n",
      "          [-1.1021e+00,  1.2776e+00, -5.6195e-01,  ..., -5.9144e-03,\n",
      "            9.1257e-01,  4.6223e-01]],\n",
      "\n",
      "         [[ 5.6680e-01, -8.9690e-02,  3.5625e-01,  ...,  7.7444e-01,\n",
      "            9.8118e-01, -1.5668e+00],\n",
      "          [-1.1524e+00, -4.0033e-02, -2.3193e+00,  ..., -6.0380e-02,\n",
      "           -3.6303e-01,  5.2026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5598e-03, -2.0729e-03, -1.9469e-03,  ...,  1.1063e-03,\n",
      "            1.5379e-03, -4.0213e-04],\n",
      "          [-1.3910e+00,  1.1220e+00,  2.8142e-01,  ..., -5.2747e-01,\n",
      "            7.3664e-01,  4.1011e-02]],\n",
      "\n",
      "         [[-2.3196e-01, -1.3904e+00, -4.0908e-01,  ...,  1.0181e+00,\n",
      "            2.3098e-01, -1.4396e-01],\n",
      "          [-8.7320e-01,  1.4610e+00, -5.0836e-01,  ...,  1.4607e+00,\n",
      "           -6.3988e-01,  1.0185e+00]],\n",
      "\n",
      "         [[-2.5043e+00, -1.6690e-02, -6.7978e-01,  ..., -4.2143e-02,\n",
      "            5.9309e-01, -1.9092e-01],\n",
      "          [-1.8769e+00,  1.4578e+00, -7.9287e-01,  ...,  7.9635e-03,\n",
      "           -6.9677e-04,  4.7388e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7619e-01, -1.5688e+00,  1.7817e+00,  ..., -1.5759e+00,\n",
      "           -5.3301e-02,  1.4739e-01],\n",
      "          [-4.4764e-03,  2.7338e-03, -2.4538e-03,  ...,  3.9665e-04,\n",
      "           -9.5919e-05,  8.1543e-04]],\n",
      "\n",
      "         [[-1.1702e+00, -1.5306e+00, -7.7755e-01,  ..., -6.6003e-01,\n",
      "           -5.3314e-01, -1.7813e-01],\n",
      "          [-2.6562e+00,  9.3793e-01,  3.3861e-01,  ..., -1.3971e+00,\n",
      "           -1.3118e+00,  1.4457e+00]],\n",
      "\n",
      "         [[ 5.4208e-01, -1.0869e-01,  3.3746e-01,  ...,  7.6548e-01,\n",
      "            9.6997e-01, -1.5429e+00],\n",
      "          [-1.1585e+00, -3.8083e-02, -2.3004e+00,  ..., -6.5469e-02,\n",
      "           -3.7108e-01,  5.2550e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.5907, -0.1680, -0.4077,  ..., -0.4810,  0.4890, -0.6489],\n",
      "          [-1.6543,  1.8011,  0.1920,  ..., -0.5432,  1.5907, -0.6919]],\n",
      "\n",
      "         [[-0.1623, -1.1254, -0.5329,  ...,  1.6476,  0.2513,  0.0867],\n",
      "          [-0.7177,  1.6887, -1.7772,  ...,  1.3268,  0.1985, -0.1206]],\n",
      "\n",
      "         [[-0.6565, -1.5798, -0.8171,  ...,  0.1130,  0.0329,  1.1185],\n",
      "          [-1.6064,  0.8875,  0.2524,  ..., -1.0247,  0.0224, -0.9422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8284, -1.7507,  0.3802,  ...,  0.6740, -0.4596,  0.2396],\n",
      "          [-0.5628,  1.1174,  1.3329,  ...,  0.3700,  0.0799, -0.4780]],\n",
      "\n",
      "         [[-2.0382, -2.1485, -0.6672,  ..., -0.1842,  0.7620, -0.8380],\n",
      "          [-0.9990,  1.1684, -0.6735,  ...,  0.2178,  1.0101,  0.3236]],\n",
      "\n",
      "         [[ 0.5102,  0.0704,  0.1589,  ...,  0.4989,  0.8889, -1.4062],\n",
      "          [-0.8267, -0.0234, -2.2304,  ...,  0.3087, -0.2142,  0.5914]]],\n",
      "\n",
      "\n",
      "        [[[-1.1147, -0.1223, -0.2752,  ..., -0.7656, -0.0028, -0.3391],\n",
      "          [-2.3552,  2.3611,  0.6000,  ..., -0.7497,  1.9726, -0.2450]],\n",
      "\n",
      "         [[-0.3068, -1.2922, -0.4610,  ...,  0.7372,  0.2589, -0.2213],\n",
      "          [-0.7666,  1.2904, -0.4699,  ...,  1.5091, -0.4252,  0.7811]],\n",
      "\n",
      "         [[-1.0953, -0.0506, -0.8500,  ..., -0.5121,  0.5434, -0.3532],\n",
      "          [-1.4651,  0.9545, -1.2043,  ...,  0.5299, -0.0541,  0.5561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6396, -2.0242,  2.2974,  ..., -1.9630, -0.0231,  0.1921],\n",
      "          [-1.5456,  0.8891, -0.1070,  ...,  0.2791,  0.1707, -0.5462]],\n",
      "\n",
      "         [[-1.0446, -1.2971, -0.8897,  ..., -0.5773, -0.5486, -0.1337],\n",
      "          [-2.4234,  1.0462,  0.3458,  ..., -1.1134, -0.2556,  1.2196]],\n",
      "\n",
      "         [[ 0.4095,  0.0178,  0.2958,  ...,  0.6534,  0.9018, -1.5401],\n",
      "          [-0.8836, -0.1276, -2.3327,  ...,  0.2856, -0.2562,  0.6158]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.5907, -0.1680, -0.4077,  ..., -0.4810,  0.4890, -0.6489],\n",
      "          [-1.6543,  1.8011,  0.1920,  ..., -0.5432,  1.5907, -0.6919]],\n",
      "\n",
      "         [[-0.1623, -1.1254, -0.5329,  ...,  1.6476,  0.2513,  0.0867],\n",
      "          [-0.7177,  1.6887, -1.7772,  ...,  1.3268,  0.1985, -0.1206]],\n",
      "\n",
      "         [[-0.6565, -1.5798, -0.8171,  ...,  0.1130,  0.0329,  1.1185],\n",
      "          [-1.6064,  0.8875,  0.2524,  ..., -1.0247,  0.0224, -0.9422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8284, -1.7507,  0.3802,  ...,  0.6740, -0.4596,  0.2396],\n",
      "          [-0.5628,  1.1174,  1.3329,  ...,  0.3700,  0.0799, -0.4780]],\n",
      "\n",
      "         [[-2.0382, -2.1485, -0.6672,  ..., -0.1842,  0.7620, -0.8380],\n",
      "          [-0.9990,  1.1684, -0.6735,  ...,  0.2178,  1.0101,  0.3236]],\n",
      "\n",
      "         [[ 0.5102,  0.0704,  0.1589,  ...,  0.4989,  0.8889, -1.4062],\n",
      "          [-0.8267, -0.0234, -2.2304,  ...,  0.3087, -0.2142,  0.5914]]],\n",
      "\n",
      "\n",
      "        [[[-1.1147, -0.1223, -0.2752,  ..., -0.7656, -0.0028, -0.3391],\n",
      "          [-2.3552,  2.3611,  0.6000,  ..., -0.7497,  1.9726, -0.2450]],\n",
      "\n",
      "         [[-0.3068, -1.2922, -0.4610,  ...,  0.7372,  0.2589, -0.2213],\n",
      "          [-0.7666,  1.2904, -0.4699,  ...,  1.5091, -0.4252,  0.7811]],\n",
      "\n",
      "         [[-1.0953, -0.0506, -0.8500,  ..., -0.5121,  0.5434, -0.3532],\n",
      "          [-1.4651,  0.9545, -1.2043,  ...,  0.5299, -0.0541,  0.5561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6396, -2.0242,  2.2974,  ..., -1.9630, -0.0231,  0.1921],\n",
      "          [-1.5456,  0.8891, -0.1070,  ...,  0.2791,  0.1707, -0.5462]],\n",
      "\n",
      "         [[-1.0446, -1.2971, -0.8897,  ..., -0.5773, -0.5486, -0.1337],\n",
      "          [-2.4234,  1.0462,  0.3458,  ..., -1.1134, -0.2556,  1.2196]],\n",
      "\n",
      "         [[ 0.4095,  0.0178,  0.2958,  ...,  0.6534,  0.9018, -1.5401],\n",
      "          [-0.8836, -0.1276, -2.3327,  ...,  0.2856, -0.2562,  0.6158]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.5907, -0.1680, -0.4077,  ..., -0.5432,  1.5907, -0.6919],\n",
      "         [-0.1623, -1.1254, -0.5329,  ...,  1.3268,  0.1985, -0.1206],\n",
      "         [-0.6565, -1.5798, -0.8171,  ..., -1.0247,  0.0224, -0.9422],\n",
      "         ...,\n",
      "         [-0.8284, -1.7507,  0.3802,  ...,  0.3700,  0.0799, -0.4780],\n",
      "         [-2.0382, -2.1485, -0.6672,  ...,  0.2178,  1.0101,  0.3236],\n",
      "         [ 0.5102,  0.0704,  0.1589,  ...,  0.3087, -0.2142,  0.5914]],\n",
      "\n",
      "        [[-1.1147, -0.1223, -0.2752,  ..., -0.7497,  1.9726, -0.2450],\n",
      "         [-0.3068, -1.2922, -0.4610,  ...,  1.5091, -0.4252,  0.7811],\n",
      "         [-1.0953, -0.0506, -0.8500,  ...,  0.5299, -0.0541,  0.5561],\n",
      "         ...,\n",
      "         [-0.6396, -2.0242,  2.2974,  ...,  0.2791,  0.1707, -0.5462],\n",
      "         [-1.0446, -1.2971, -0.8897,  ..., -1.1134, -0.2556,  1.2196],\n",
      "         [ 0.4095,  0.0178,  0.2958,  ...,  0.2856, -0.2562,  0.6158]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.5907, -0.1680, -0.4077,  ..., -0.4810,  0.4890, -0.6489],\n",
      "          [-1.6543,  1.8011,  0.1920,  ..., -0.5432,  1.5907, -0.6919]],\n",
      "\n",
      "         [[-0.1623, -1.1254, -0.5329,  ...,  1.6476,  0.2513,  0.0867],\n",
      "          [-0.7177,  1.6887, -1.7772,  ...,  1.3268,  0.1985, -0.1206]],\n",
      "\n",
      "         [[-0.6565, -1.5798, -0.8171,  ...,  0.1130,  0.0329,  1.1185],\n",
      "          [-1.6064,  0.8875,  0.2524,  ..., -1.0247,  0.0224, -0.9422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8284, -1.7507,  0.3802,  ...,  0.6740, -0.4596,  0.2396],\n",
      "          [-0.5628,  1.1174,  1.3329,  ...,  0.3700,  0.0799, -0.4780]],\n",
      "\n",
      "         [[-2.0382, -2.1485, -0.6672,  ..., -0.1842,  0.7620, -0.8380],\n",
      "          [-0.9990,  1.1684, -0.6735,  ...,  0.2178,  1.0101,  0.3236]],\n",
      "\n",
      "         [[ 0.5102,  0.0704,  0.1589,  ...,  0.4989,  0.8889, -1.4062],\n",
      "          [-0.8267, -0.0234, -2.2304,  ...,  0.3087, -0.2142,  0.5914]]],\n",
      "\n",
      "\n",
      "        [[[-1.1147, -0.1223, -0.2752,  ..., -0.7656, -0.0028, -0.3391],\n",
      "          [-2.3552,  2.3611,  0.6000,  ..., -0.7497,  1.9726, -0.2450]],\n",
      "\n",
      "         [[-0.3068, -1.2922, -0.4610,  ...,  0.7372,  0.2589, -0.2213],\n",
      "          [-0.7666,  1.2904, -0.4699,  ...,  1.5091, -0.4252,  0.7811]],\n",
      "\n",
      "         [[-1.0953, -0.0506, -0.8500,  ..., -0.5121,  0.5434, -0.3532],\n",
      "          [-1.4651,  0.9545, -1.2043,  ...,  0.5299, -0.0541,  0.5561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6396, -2.0242,  2.2974,  ..., -1.9630, -0.0231,  0.1921],\n",
      "          [-1.5456,  0.8891, -0.1070,  ...,  0.2791,  0.1707, -0.5462]],\n",
      "\n",
      "         [[-1.0446, -1.2971, -0.8897,  ..., -0.5773, -0.5486, -0.1337],\n",
      "          [-2.4234,  1.0462,  0.3458,  ..., -1.1134, -0.2556,  1.2196]],\n",
      "\n",
      "         [[ 0.4095,  0.0178,  0.2958,  ...,  0.6534,  0.9018, -1.5401],\n",
      "          [-0.8836, -0.1276, -2.3327,  ...,  0.2856, -0.2562,  0.6158]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.5907, -0.1680, -0.4077,  ..., -0.4810,  0.4890, -0.6489],\n",
      "          [-0.1623, -1.1254, -0.5329,  ...,  1.6476,  0.2513,  0.0867],\n",
      "          [-0.6565, -1.5798, -0.8171,  ...,  0.1130,  0.0329,  1.1185],\n",
      "          ...,\n",
      "          [-0.8284, -1.7507,  0.3802,  ...,  0.6740, -0.4596,  0.2396],\n",
      "          [-2.0382, -2.1485, -0.6672,  ..., -0.1842,  0.7620, -0.8380],\n",
      "          [ 0.5102,  0.0704,  0.1589,  ...,  0.4989,  0.8889, -1.4062]],\n",
      "\n",
      "         [[-1.6543,  1.8011,  0.1920,  ..., -0.5432,  1.5907, -0.6919],\n",
      "          [-0.7177,  1.6887, -1.7772,  ...,  1.3268,  0.1985, -0.1206],\n",
      "          [-1.6064,  0.8875,  0.2524,  ..., -1.0247,  0.0224, -0.9422],\n",
      "          ...,\n",
      "          [-0.5628,  1.1174,  1.3329,  ...,  0.3700,  0.0799, -0.4780],\n",
      "          [-0.9990,  1.1684, -0.6735,  ...,  0.2178,  1.0101,  0.3236],\n",
      "          [-0.8267, -0.0234, -2.2304,  ...,  0.3087, -0.2142,  0.5914]]],\n",
      "\n",
      "\n",
      "        [[[-1.1147, -0.1223, -0.2752,  ..., -0.7656, -0.0028, -0.3391],\n",
      "          [-0.3068, -1.2922, -0.4610,  ...,  0.7372,  0.2589, -0.2213],\n",
      "          [-1.0953, -0.0506, -0.8500,  ..., -0.5121,  0.5434, -0.3532],\n",
      "          ...,\n",
      "          [-0.6396, -2.0242,  2.2974,  ..., -1.9630, -0.0231,  0.1921],\n",
      "          [-1.0446, -1.2971, -0.8897,  ..., -0.5773, -0.5486, -0.1337],\n",
      "          [ 0.4095,  0.0178,  0.2958,  ...,  0.6534,  0.9018, -1.5401]],\n",
      "\n",
      "         [[-2.3552,  2.3611,  0.6000,  ..., -0.7497,  1.9726, -0.2450],\n",
      "          [-0.7666,  1.2904, -0.4699,  ...,  1.5091, -0.4252,  0.7811],\n",
      "          [-1.4651,  0.9545, -1.2043,  ...,  0.5299, -0.0541,  0.5561],\n",
      "          ...,\n",
      "          [-1.5456,  0.8891, -0.1070,  ...,  0.2791,  0.1707, -0.5462],\n",
      "          [-2.4234,  1.0462,  0.3458,  ..., -1.1134, -0.2556,  1.2196],\n",
      "          [-0.8836, -0.1276, -2.3327,  ...,  0.2856, -0.2562,  0.6158]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.7412e+00, -2.2188e-01, -4.5892e-01,  ..., -5.1149e-01,\n",
      "            5.3045e-01, -6.7756e-01],\n",
      "          [-2.4019e-01, -1.2274e+00, -5.6408e-01,  ...,  1.7389e+00,\n",
      "            2.7721e-01,  7.0749e-02],\n",
      "          [-1.3823e-02, -2.8309e-03, -3.3979e-03,  ..., -1.7185e-03,\n",
      "            4.0842e-03, -5.0960e-03],\n",
      "          ...,\n",
      "          [-9.0574e-01, -1.8936e+00,  4.0094e-01,  ...,  7.2551e-01,\n",
      "           -4.8948e-01,  2.5721e-01],\n",
      "          [-2.2304e+00, -2.3465e+00, -7.2513e-01,  ..., -1.9082e-01,\n",
      "            8.2774e-01, -9.1292e-01],\n",
      "          [ 5.4211e-01,  6.8784e-02,  1.7063e-01,  ...,  5.5548e-01,\n",
      "            9.7532e-01, -1.5373e+00]],\n",
      "\n",
      "         [[-1.7794e+00,  2.2063e+00, -9.0223e-01,  ..., -1.0555e+00,\n",
      "            1.8722e+00,  1.1155e+00],\n",
      "          [-8.0029e-01,  1.8764e+00, -1.9693e+00,  ...,  1.4649e+00,\n",
      "            2.2584e-01, -1.2887e-01],\n",
      "          [-1.7322e+00,  1.1324e+00,  8.8286e-02,  ..., -1.0522e+00,\n",
      "            2.3361e-01, -7.3071e-01],\n",
      "          ...,\n",
      "          [-6.4012e-01,  1.2569e+00,  1.4358e+00,  ...,  3.9292e-01,\n",
      "            1.1017e-01, -5.0544e-01],\n",
      "          [-1.1583e+00,  1.3791e+00, -7.9054e-01,  ...,  1.4131e-01,\n",
      "            1.1665e+00,  4.4566e-01],\n",
      "          [-9.2326e-01, -9.7102e-03, -2.4630e+00,  ...,  3.3565e-01,\n",
      "           -2.2330e-01,  6.5948e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2363e-01, -7.9576e-01, -4.0708e-02,  ..., -4.3508e-01,\n",
      "            1.6612e-01, -1.2783e-01],\n",
      "          [-3.3919e-01, -1.4236e+00, -5.0871e-01,  ...,  8.1465e-01,\n",
      "            2.8836e-01, -2.4663e-01],\n",
      "          [-1.1864e+00, -1.0525e-01, -8.7797e-01,  ..., -5.6586e-01,\n",
      "            5.8458e-01, -3.7770e-01],\n",
      "          ...,\n",
      "          [-7.1064e-01, -2.2475e+00,  2.5499e+00,  ..., -2.1791e+00,\n",
      "           -2.5293e-02,  2.1293e-01],\n",
      "          [-1.1303e+00, -1.3863e+00, -9.1098e-01,  ..., -6.2993e-01,\n",
      "           -5.3897e-01, -1.5368e-01],\n",
      "          [ 4.2241e-01, -1.5532e-02,  3.2564e-01,  ...,  6.9141e-01,\n",
      "            9.7751e-01, -1.6628e+00]],\n",
      "\n",
      "         [[-2.6125e+00,  2.6167e+00,  6.6496e-01,  ..., -8.3222e-01,\n",
      "            2.1840e+00, -2.6895e-01],\n",
      "          [-9.9730e-01,  1.3856e+00, -4.6822e-01,  ...,  1.4583e+00,\n",
      "           -3.2255e-01,  7.7927e-01],\n",
      "          [-1.6303e+00,  1.0465e+00, -1.2988e+00,  ...,  5.8704e-01,\n",
      "           -3.5361e-02,  6.0938e-01],\n",
      "          ...,\n",
      "          [-1.8798e+00,  1.0893e+00, -1.4915e-01,  ...,  9.7053e-02,\n",
      "            4.1539e-01, -4.7582e-02],\n",
      "          [-1.5481e-01,  1.4355e-01,  3.2059e-02,  ..., -4.3561e-02,\n",
      "            1.2227e-01, -1.5936e-02],\n",
      "          [-9.9603e-01, -1.2722e-01, -2.5526e+00,  ...,  3.1130e-01,\n",
      "           -2.7589e-01,  6.8567e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-1.7412e+00, -2.2188e-01, -4.5892e-01,  ..., -5.1149e-01,\n",
      "            5.3045e-01, -6.7756e-01],\n",
      "          [-1.7794e+00,  2.2063e+00, -9.0223e-01,  ..., -1.0555e+00,\n",
      "            1.8722e+00,  1.1155e+00]],\n",
      "\n",
      "         [[-2.4019e-01, -1.2274e+00, -5.6408e-01,  ...,  1.7389e+00,\n",
      "            2.7721e-01,  7.0749e-02],\n",
      "          [-8.0029e-01,  1.8764e+00, -1.9693e+00,  ...,  1.4649e+00,\n",
      "            2.2584e-01, -1.2887e-01]],\n",
      "\n",
      "         [[-1.3823e-02, -2.8309e-03, -3.3979e-03,  ..., -1.7185e-03,\n",
      "            4.0842e-03, -5.0960e-03],\n",
      "          [-1.7322e+00,  1.1324e+00,  8.8286e-02,  ..., -1.0522e+00,\n",
      "            2.3361e-01, -7.3071e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0574e-01, -1.8936e+00,  4.0094e-01,  ...,  7.2551e-01,\n",
      "           -4.8948e-01,  2.5721e-01],\n",
      "          [-6.4012e-01,  1.2569e+00,  1.4358e+00,  ...,  3.9292e-01,\n",
      "            1.1017e-01, -5.0544e-01]],\n",
      "\n",
      "         [[-2.2304e+00, -2.3465e+00, -7.2513e-01,  ..., -1.9082e-01,\n",
      "            8.2774e-01, -9.1292e-01],\n",
      "          [-1.1583e+00,  1.3791e+00, -7.9054e-01,  ...,  1.4131e-01,\n",
      "            1.1665e+00,  4.4566e-01]],\n",
      "\n",
      "         [[ 5.4211e-01,  6.8784e-02,  1.7063e-01,  ...,  5.5548e-01,\n",
      "            9.7532e-01, -1.5373e+00],\n",
      "          [-9.2326e-01, -9.7102e-03, -2.4630e+00,  ...,  3.3565e-01,\n",
      "           -2.2330e-01,  6.5948e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2363e-01, -7.9576e-01, -4.0708e-02,  ..., -4.3508e-01,\n",
      "            1.6612e-01, -1.2783e-01],\n",
      "          [-2.6125e+00,  2.6167e+00,  6.6496e-01,  ..., -8.3222e-01,\n",
      "            2.1840e+00, -2.6895e-01]],\n",
      "\n",
      "         [[-3.3919e-01, -1.4236e+00, -5.0871e-01,  ...,  8.1465e-01,\n",
      "            2.8836e-01, -2.4663e-01],\n",
      "          [-9.9730e-01,  1.3856e+00, -4.6822e-01,  ...,  1.4583e+00,\n",
      "           -3.2255e-01,  7.7927e-01]],\n",
      "\n",
      "         [[-1.1864e+00, -1.0525e-01, -8.7797e-01,  ..., -5.6586e-01,\n",
      "            5.8458e-01, -3.7770e-01],\n",
      "          [-1.6303e+00,  1.0465e+00, -1.2988e+00,  ...,  5.8704e-01,\n",
      "           -3.5361e-02,  6.0938e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1064e-01, -2.2475e+00,  2.5499e+00,  ..., -2.1791e+00,\n",
      "           -2.5293e-02,  2.1293e-01],\n",
      "          [-1.8798e+00,  1.0893e+00, -1.4915e-01,  ...,  9.7053e-02,\n",
      "            4.1539e-01, -4.7582e-02]],\n",
      "\n",
      "         [[-1.1303e+00, -1.3863e+00, -9.1098e-01,  ..., -6.2993e-01,\n",
      "           -5.3897e-01, -1.5368e-01],\n",
      "          [-1.5481e-01,  1.4355e-01,  3.2059e-02,  ..., -4.3561e-02,\n",
      "            1.2227e-01, -1.5936e-02]],\n",
      "\n",
      "         [[ 4.2241e-01, -1.5532e-02,  3.2564e-01,  ...,  6.9141e-01,\n",
      "            9.7751e-01, -1.6628e+00],\n",
      "          [-9.9603e-01, -1.2722e-01, -2.5526e+00,  ...,  3.1130e-01,\n",
      "           -2.7589e-01,  6.8567e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.7412e+00, -2.2188e-01, -4.5892e-01,  ..., -5.1149e-01,\n",
      "            5.3045e-01, -6.7756e-01],\n",
      "          [-1.7794e+00,  2.2063e+00, -9.0223e-01,  ..., -1.0555e+00,\n",
      "            1.8722e+00,  1.1155e+00]],\n",
      "\n",
      "         [[-2.4019e-01, -1.2274e+00, -5.6408e-01,  ...,  1.7389e+00,\n",
      "            2.7721e-01,  7.0749e-02],\n",
      "          [-8.0029e-01,  1.8764e+00, -1.9693e+00,  ...,  1.4649e+00,\n",
      "            2.2584e-01, -1.2887e-01]],\n",
      "\n",
      "         [[-1.3823e-02, -2.8309e-03, -3.3979e-03,  ..., -1.7185e-03,\n",
      "            4.0842e-03, -5.0960e-03],\n",
      "          [-1.7322e+00,  1.1324e+00,  8.8286e-02,  ..., -1.0522e+00,\n",
      "            2.3361e-01, -7.3071e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0574e-01, -1.8936e+00,  4.0094e-01,  ...,  7.2551e-01,\n",
      "           -4.8948e-01,  2.5721e-01],\n",
      "          [-6.4012e-01,  1.2569e+00,  1.4358e+00,  ...,  3.9292e-01,\n",
      "            1.1017e-01, -5.0544e-01]],\n",
      "\n",
      "         [[-2.2304e+00, -2.3465e+00, -7.2513e-01,  ..., -1.9082e-01,\n",
      "            8.2774e-01, -9.1292e-01],\n",
      "          [-1.1583e+00,  1.3791e+00, -7.9054e-01,  ...,  1.4131e-01,\n",
      "            1.1665e+00,  4.4566e-01]],\n",
      "\n",
      "         [[ 5.4211e-01,  6.8784e-02,  1.7063e-01,  ...,  5.5548e-01,\n",
      "            9.7532e-01, -1.5373e+00],\n",
      "          [-9.2326e-01, -9.7102e-03, -2.4630e+00,  ...,  3.3565e-01,\n",
      "           -2.2330e-01,  6.5948e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2363e-01, -7.9576e-01, -4.0708e-02,  ..., -4.3508e-01,\n",
      "            1.6612e-01, -1.2783e-01],\n",
      "          [-2.6125e+00,  2.6167e+00,  6.6496e-01,  ..., -8.3222e-01,\n",
      "            2.1840e+00, -2.6895e-01]],\n",
      "\n",
      "         [[-3.3919e-01, -1.4236e+00, -5.0871e-01,  ...,  8.1465e-01,\n",
      "            2.8836e-01, -2.4663e-01],\n",
      "          [-9.9730e-01,  1.3856e+00, -4.6822e-01,  ...,  1.4583e+00,\n",
      "           -3.2255e-01,  7.7927e-01]],\n",
      "\n",
      "         [[-1.1864e+00, -1.0525e-01, -8.7797e-01,  ..., -5.6586e-01,\n",
      "            5.8458e-01, -3.7770e-01],\n",
      "          [-1.6303e+00,  1.0465e+00, -1.2988e+00,  ...,  5.8704e-01,\n",
      "           -3.5361e-02,  6.0938e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1064e-01, -2.2475e+00,  2.5499e+00,  ..., -2.1791e+00,\n",
      "           -2.5293e-02,  2.1293e-01],\n",
      "          [-1.8798e+00,  1.0893e+00, -1.4915e-01,  ...,  9.7053e-02,\n",
      "            4.1539e-01, -4.7582e-02]],\n",
      "\n",
      "         [[-1.1303e+00, -1.3863e+00, -9.1098e-01,  ..., -6.2993e-01,\n",
      "           -5.3897e-01, -1.5368e-01],\n",
      "          [-1.5481e-01,  1.4355e-01,  3.2059e-02,  ..., -4.3561e-02,\n",
      "            1.2227e-01, -1.5936e-02]],\n",
      "\n",
      "         [[ 4.2241e-01, -1.5532e-02,  3.2564e-01,  ...,  6.9141e-01,\n",
      "            9.7751e-01, -1.6628e+00],\n",
      "          [-9.9603e-01, -1.2722e-01, -2.5526e+00,  ...,  3.1130e-01,\n",
      "           -2.7589e-01,  6.8567e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-1.7412e+00, -2.2188e-01, -4.5892e-01,  ..., -5.1149e-01,\n",
      "            5.3045e-01, -6.7756e-01],\n",
      "          [-1.7794e+00,  2.2063e+00, -9.0223e-01,  ..., -1.0555e+00,\n",
      "            1.8722e+00,  1.1155e+00]],\n",
      "\n",
      "         [[-2.4019e-01, -1.2274e+00, -5.6408e-01,  ...,  1.7389e+00,\n",
      "            2.7721e-01,  7.0749e-02],\n",
      "          [-8.0029e-01,  1.8764e+00, -1.9693e+00,  ...,  1.4649e+00,\n",
      "            2.2584e-01, -1.2887e-01]],\n",
      "\n",
      "         [[-1.3823e-02, -2.8309e-03, -3.3979e-03,  ..., -1.7185e-03,\n",
      "            4.0842e-03, -5.0960e-03],\n",
      "          [-1.7322e+00,  1.1324e+00,  8.8286e-02,  ..., -1.0522e+00,\n",
      "            2.3361e-01, -7.3071e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0574e-01, -1.8936e+00,  4.0094e-01,  ...,  7.2551e-01,\n",
      "           -4.8948e-01,  2.5721e-01],\n",
      "          [-6.4012e-01,  1.2569e+00,  1.4358e+00,  ...,  3.9292e-01,\n",
      "            1.1017e-01, -5.0544e-01]],\n",
      "\n",
      "         [[-2.2304e+00, -2.3465e+00, -7.2513e-01,  ..., -1.9082e-01,\n",
      "            8.2774e-01, -9.1292e-01],\n",
      "          [-1.1583e+00,  1.3791e+00, -7.9054e-01,  ...,  1.4131e-01,\n",
      "            1.1665e+00,  4.4566e-01]],\n",
      "\n",
      "         [[ 5.4211e-01,  6.8784e-02,  1.7063e-01,  ...,  5.5548e-01,\n",
      "            9.7532e-01, -1.5373e+00],\n",
      "          [-9.2326e-01, -9.7102e-03, -2.4630e+00,  ...,  3.3565e-01,\n",
      "           -2.2330e-01,  6.5948e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2363e-01, -7.9576e-01, -4.0708e-02,  ..., -4.3508e-01,\n",
      "            1.6612e-01, -1.2783e-01],\n",
      "          [-2.6125e+00,  2.6167e+00,  6.6496e-01,  ..., -8.3222e-01,\n",
      "            2.1840e+00, -2.6895e-01]],\n",
      "\n",
      "         [[-3.3919e-01, -1.4236e+00, -5.0871e-01,  ...,  8.1465e-01,\n",
      "            2.8836e-01, -2.4663e-01],\n",
      "          [-9.9730e-01,  1.3856e+00, -4.6822e-01,  ...,  1.4583e+00,\n",
      "           -3.2255e-01,  7.7927e-01]],\n",
      "\n",
      "         [[-1.1864e+00, -1.0525e-01, -8.7797e-01,  ..., -5.6586e-01,\n",
      "            5.8458e-01, -3.7770e-01],\n",
      "          [-1.6303e+00,  1.0465e+00, -1.2988e+00,  ...,  5.8704e-01,\n",
      "           -3.5361e-02,  6.0938e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1064e-01, -2.2475e+00,  2.5499e+00,  ..., -2.1791e+00,\n",
      "           -2.5293e-02,  2.1293e-01],\n",
      "          [-1.8798e+00,  1.0893e+00, -1.4915e-01,  ...,  9.7053e-02,\n",
      "            4.1539e-01, -4.7582e-02]],\n",
      "\n",
      "         [[-1.1303e+00, -1.3863e+00, -9.1098e-01,  ..., -6.2993e-01,\n",
      "           -5.3897e-01, -1.5368e-01],\n",
      "          [-1.5481e-01,  1.4355e-01,  3.2059e-02,  ..., -4.3561e-02,\n",
      "            1.2227e-01, -1.5936e-02]],\n",
      "\n",
      "         [[ 4.2241e-01, -1.5532e-02,  3.2564e-01,  ...,  6.9141e-01,\n",
      "            9.7751e-01, -1.6628e+00],\n",
      "          [-9.9603e-01, -1.2722e-01, -2.5526e+00,  ...,  3.1130e-01,\n",
      "           -2.7589e-01,  6.8567e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.9491,  0.9614],\n",
      "        [-0.2534,  0.3687]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.372000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:15:12,130] Trial 0 finished with value: 0.85132 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 0 with value: 0.85132.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439]],\n",
      "\n",
      "         [[-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134]],\n",
      "\n",
      "         [[-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241]],\n",
      "\n",
      "         [[ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395]],\n",
      "\n",
      "         [[-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903]],\n",
      "\n",
      "         [[-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845]],\n",
      "\n",
      "         [[-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777]],\n",
      "\n",
      "         [[-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924]],\n",
      "\n",
      "         [[-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1097,  0.3352,  0.1320,  ..., -0.4558,  0.2816, -0.3861],\n",
      "          [ 0.6299, -0.1971, -0.0828,  ...,  0.5153,  0.2517,  0.3114]],\n",
      "\n",
      "         [[ 0.2451,  0.3272,  0.5459,  ..., -0.5961, -0.1500, -0.0091],\n",
      "          [ 0.4385, -0.2509,  0.2175,  ...,  0.0888, -0.1240, -0.1948]],\n",
      "\n",
      "         [[ 0.1174,  0.0542,  1.2880,  ..., -0.3869, -0.3164,  0.0290],\n",
      "          [ 0.3691,  0.1250,  0.6001,  ...,  0.1871, -0.0380, -0.2637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0578,  0.1673,  0.7148,  ..., -0.2909,  0.0784,  0.5932],\n",
      "          [-0.1557,  0.3884,  0.6786,  ..., -0.1742, -0.1841, -0.0850]],\n",
      "\n",
      "         [[-0.2310, -0.0498,  0.5660,  ..., -0.3753, -0.1926,  0.2839],\n",
      "          [ 0.3797,  0.3378,  0.5981,  ...,  0.3780, -0.3142,  0.0227]],\n",
      "\n",
      "         [[-0.1132,  0.7820,  0.2413,  ..., -0.3549, -0.1969, -0.2243],\n",
      "          [ 0.4579,  0.5614,  0.4319,  ..., -0.2324, -0.2835,  0.2386]]],\n",
      "\n",
      "\n",
      "        [[[-0.0249,  0.0729,  0.3798,  ..., -0.4332,  0.0879, -0.1735],\n",
      "          [ 0.7480, -0.3275,  0.0840,  ...,  0.5588,  0.1082,  0.1071]],\n",
      "\n",
      "         [[ 0.1624,  0.6910,  0.0549,  ..., -0.2231, -0.3868, -0.1378],\n",
      "          [ 0.3929,  0.0487, -0.2172,  ...,  0.6898, -0.0348, -0.1844]],\n",
      "\n",
      "         [[ 0.0534,  0.6723,  1.0488,  ..., -0.6195, -0.6362,  0.1774],\n",
      "          [-0.1893,  0.3198,  0.7010,  ..., -0.0388, -0.4799, -0.5112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3221,  0.5305,  0.1513,  ..., -0.0683,  0.0978,  0.1998],\n",
      "          [-0.0146,  0.2263,  0.4035,  ..., -0.0838, -0.0507, -0.0783]],\n",
      "\n",
      "         [[ 0.0841,  0.2953,  0.0404,  ..., -0.1090, -0.1298, -0.4898],\n",
      "          [-0.0555,  0.4344,  0.0995,  ...,  0.1993, -0.3797, -0.1231]],\n",
      "\n",
      "         [[-0.0609,  0.6004,  0.0854,  ..., -0.2216, -0.1401, -0.4198],\n",
      "          [ 0.4770,  0.4764,  0.3597,  ..., -0.2995, -0.3551,  0.5115]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4359,  0.4976,  0.7856,  ..., -0.1035,  0.0759, -0.9286],\n",
      "          [ 0.4154, -0.3708, -0.2043,  ...,  0.8688,  0.4087,  0.1808]],\n",
      "\n",
      "         [[ 0.6184,  0.1471,  0.4826,  ..., -0.2727, -0.2721, -0.8751],\n",
      "          [ 0.3181, -0.3986, -0.0962,  ...,  0.5383,  0.6920,  0.0724]],\n",
      "\n",
      "         [[ 0.3066,  0.6183,  0.9976,  ..., -0.3978, -0.8315, -0.9586],\n",
      "          [ 0.5746,  0.0106,  0.0849,  ...,  0.4502,  0.9153,  0.1494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1781,  0.5436,  0.6015,  ...,  0.2855, -0.0909, -0.0573],\n",
      "          [ 0.1812, -0.1956, -0.4495,  ...,  0.2037,  0.6062, -0.4514]],\n",
      "\n",
      "         [[ 0.0189,  0.1922,  0.9736,  ..., -0.5899, -0.1052, -0.7356],\n",
      "          [ 0.6391,  0.0943,  0.1281,  ...,  0.0068,  0.3086,  0.0524]],\n",
      "\n",
      "         [[ 0.7057,  0.4967,  0.8961,  ..., -0.4079, -0.0816, -0.5669],\n",
      "          [ 0.5701, -0.2532, -0.1098,  ..., -0.0462,  0.5168,  0.0110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5473,  0.4831,  0.9296,  ..., -0.0396,  0.2039, -0.8268],\n",
      "          [ 0.5210, -0.4034,  0.0820,  ...,  1.1262,  0.7893,  0.2112]],\n",
      "\n",
      "         [[ 0.4149,  0.4882,  0.6182,  ..., -0.7389, -0.3986, -1.1529],\n",
      "          [ 0.8270, -0.1022,  0.4655,  ...,  0.3077,  0.9332, -0.2257]],\n",
      "\n",
      "         [[ 0.2383,  0.1631,  0.7105,  ..., -0.3409, -0.6267, -0.7180],\n",
      "          [ 0.3831, -0.1700,  0.2370,  ...,  0.1373,  0.9887,  0.2066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0691,  0.4363,  0.5532,  ..., -0.2719, -0.4867, -0.2527],\n",
      "          [-0.1181, -0.2490, -0.1080,  ..., -0.0396,  0.1851,  0.0056]],\n",
      "\n",
      "         [[ 0.0041, -0.0954,  0.9141,  ..., -0.4338, -0.1194, -0.9361],\n",
      "          [ 0.6609, -0.0618,  0.2417,  ...,  0.2991,  0.0499, -0.0331]],\n",
      "\n",
      "         [[ 0.7684,  0.2905,  1.1141,  ..., -0.1525, -0.0166, -0.6429],\n",
      "          [ 0.6435, -0.1535, -0.1476,  ...,  0.2005,  0.5448,  0.0371]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          ...,\n",
      "          [-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312]],\n",
      "\n",
      "         [[ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232],\n",
      "          ...,\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          ...,\n",
      "          [-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661]],\n",
      "\n",
      "         [[ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248],\n",
      "          ...,\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          ...,\n",
      "          [ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02]],\n",
      "\n",
      "         [[ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01],\n",
      "          ...,\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          ...,\n",
      "          [ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01]],\n",
      "\n",
      "         [[ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04],\n",
      "          ...,\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503]],\n",
      "\n",
      "         [[-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290]],\n",
      "\n",
      "         [[ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504]],\n",
      "\n",
      "         [[ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803]],\n",
      "\n",
      "         [[ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880]],\n",
      "\n",
      "         [[ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323]],\n",
      "\n",
      "         [[-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118]],\n",
      "\n",
      "         [[ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903]],\n",
      "\n",
      "         [[ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3577,  0.2800,  0.2037,  ...,  0.7450, -0.0404,  0.2655],\n",
      "          [-0.3038,  0.3088,  0.0754,  ..., -0.3404, -0.0769,  0.1805]],\n",
      "\n",
      "         [[ 0.3302,  0.2980, -0.5975,  ...,  0.8791, -0.2676,  0.5354],\n",
      "          [-0.4732,  0.3882,  0.0680,  ...,  0.1315, -0.4662,  0.5441]],\n",
      "\n",
      "         [[-0.1305,  0.7490, -0.4150,  ...,  0.5727,  0.0504,  0.9374],\n",
      "          [-0.6017,  0.7172,  1.0445,  ...,  0.5816, -0.8695,  1.3832]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3618,  0.8295, -0.2509,  ...,  0.2193, -0.0977,  0.6511],\n",
      "          [-0.8069,  0.7903,  0.5787,  ...,  0.1693, -0.8995,  1.1609]],\n",
      "\n",
      "         [[-0.1225,  0.6841, -0.5403,  ...,  0.5903,  0.0312,  0.5037],\n",
      "          [-0.3409,  0.5665,  0.3616,  ...,  0.4588, -0.2345,  1.0660]],\n",
      "\n",
      "         [[ 0.2595,  0.0825, -0.5167,  ...,  0.6017,  0.1817, -0.2153],\n",
      "          [-0.4661,  0.3406, -0.0344,  ..., -0.2062, -0.3607,  0.3727]]],\n",
      "\n",
      "\n",
      "        [[[-0.2201, -0.0144, -0.0774,  ...,  0.6784,  0.1805,  0.2397],\n",
      "          [-0.0605,  0.0453,  0.0433,  ..., -0.6115,  0.3912, -0.0125]],\n",
      "\n",
      "         [[ 0.2916,  0.0691, -0.1903,  ...,  0.5339,  0.4194, -0.1268],\n",
      "          [ 0.1159, -0.0895,  0.5127,  ..., -0.5232, -0.1742,  0.2232]],\n",
      "\n",
      "         [[-0.1177,  0.4989, -0.1205,  ...,  0.4891, -0.0100,  0.7693],\n",
      "          [-0.7440,  0.4526,  0.6762,  ..., -0.0592, -0.5500,  1.0284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3551,  0.2883, -0.1202,  ...,  0.3301,  0.0095,  0.3455],\n",
      "          [-0.6709,  0.5171,  0.7415,  ..., -0.1044, -0.2623,  0.7901]],\n",
      "\n",
      "         [[-0.1133,  0.8532, -0.3496,  ...,  0.4809,  0.3595,  0.2157],\n",
      "          [-0.3178,  0.1252,  0.1106,  ..., -0.3183, -0.1870,  0.4479]],\n",
      "\n",
      "         [[ 0.3404, -0.1903, -0.4894,  ...,  0.6169,  0.2482, -0.3332],\n",
      "          [-0.2898,  0.2840, -0.0842,  ..., -0.3484, -0.1666,  0.1258]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1860,  0.9009, -0.8822,  ...,  1.9637,  0.9224,  0.6598],\n",
      "          [ 1.0493,  0.9140,  1.2219,  ...,  0.1828, -0.5775, -1.4751]],\n",
      "\n",
      "         [[-0.5167,  0.7945, -0.7358,  ...,  0.8526,  0.3657, -0.0340],\n",
      "          [ 0.2634,  0.4665,  0.7317,  ..., -0.3564, -0.5390, -0.3447]],\n",
      "\n",
      "         [[ 0.0889,  0.5623, -0.2131,  ...,  0.8001,  0.5143,  0.2583],\n",
      "          [ 0.6862,  0.4463,  0.7123,  ..., -0.1764,  0.1218, -0.5365]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627,  0.5800, -0.0221,  ...,  0.3144,  0.1900, -0.2160],\n",
      "          [ 0.1833,  0.0857,  0.2281,  ..., -0.1949,  0.1917, -0.6116]],\n",
      "\n",
      "         [[-0.0459,  0.4138, -0.5192,  ...,  0.6504,  0.2812, -0.3386],\n",
      "          [ 0.2814,  0.4916,  0.2383,  ..., -0.5586,  0.0852,  0.1100]],\n",
      "\n",
      "         [[-0.5478,  0.9642, -0.4353,  ..., -0.1015,  0.3682, -0.2034],\n",
      "          [ 0.2167,  0.7069,  0.1991,  ...,  0.0943,  0.0443, -0.1434]]],\n",
      "\n",
      "\n",
      "        [[[-1.4879,  1.1552, -0.8568,  ...,  2.1281,  0.9640,  0.8450],\n",
      "          [ 1.0153,  0.8573,  1.4165,  ...,  0.3985, -1.0406, -1.4223]],\n",
      "\n",
      "         [[-0.4464,  0.8762, -0.6166,  ...,  0.7965,  0.3356,  0.0356],\n",
      "          [ 0.3064,  0.5973,  0.3372,  ..., -0.2941,  0.2337, -0.5725]],\n",
      "\n",
      "         [[ 0.1992,  0.5762, -0.2364,  ...,  0.9029,  0.5630,  0.3178],\n",
      "          [ 0.2999,  0.5476,  0.5826,  ..., -0.6547, -0.2118, -0.7978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3352,  0.6593, -0.1402,  ...,  0.5490,  0.3094,  0.2462],\n",
      "          [-0.0537,  0.2861,  0.1601,  ...,  0.0731, -0.2744, -0.4878]],\n",
      "\n",
      "         [[-0.6884,  0.5706, -0.5514,  ...,  0.4872, -0.2086,  0.2016],\n",
      "          [ 0.3053,  0.3017,  0.3818,  ..., -0.4344,  0.1905, -0.5564]],\n",
      "\n",
      "         [[-0.5629,  0.9108, -0.4845,  ...,  0.0027,  0.2492, -0.1729],\n",
      "          [ 0.3020,  0.6107,  0.3848,  ...,  0.0507, -0.1334, -0.2815]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          ...,\n",
      "          [-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199]],\n",
      "\n",
      "         [[-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678],\n",
      "          ...,\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          ...,\n",
      "          [-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172]],\n",
      "\n",
      "         [[-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296],\n",
      "          ...,\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          ...,\n",
      "          [ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01]],\n",
      "\n",
      "         [[-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01],\n",
      "          ...,\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          ...,\n",
      "          [ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01]],\n",
      "\n",
      "         [[-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01],\n",
      "          ...,\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.5450,  1.8397],\n",
      "        [-0.6022,  0.6575]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:21:32,846] Trial 1 finished with value: 0.8588 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.8588.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439]],\n",
      "\n",
      "         [[-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134]],\n",
      "\n",
      "         [[-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241]],\n",
      "\n",
      "         [[ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395]],\n",
      "\n",
      "         [[-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903]],\n",
      "\n",
      "         [[-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845]],\n",
      "\n",
      "         [[-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777]],\n",
      "\n",
      "         [[-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924]],\n",
      "\n",
      "         [[-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1097,  0.3352,  0.1320,  ..., -0.4558,  0.2816, -0.3861],\n",
      "          [ 0.6299, -0.1971, -0.0828,  ...,  0.5153,  0.2517,  0.3114]],\n",
      "\n",
      "         [[ 0.2451,  0.3272,  0.5459,  ..., -0.5961, -0.1500, -0.0091],\n",
      "          [ 0.4385, -0.2509,  0.2175,  ...,  0.0888, -0.1240, -0.1948]],\n",
      "\n",
      "         [[ 0.1174,  0.0542,  1.2880,  ..., -0.3869, -0.3164,  0.0290],\n",
      "          [ 0.3691,  0.1250,  0.6001,  ...,  0.1871, -0.0380, -0.2637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0578,  0.1673,  0.7148,  ..., -0.2909,  0.0784,  0.5932],\n",
      "          [-0.1557,  0.3884,  0.6786,  ..., -0.1742, -0.1841, -0.0850]],\n",
      "\n",
      "         [[-0.2310, -0.0498,  0.5660,  ..., -0.3753, -0.1926,  0.2839],\n",
      "          [ 0.3797,  0.3378,  0.5981,  ...,  0.3780, -0.3142,  0.0227]],\n",
      "\n",
      "         [[-0.1132,  0.7820,  0.2413,  ..., -0.3549, -0.1969, -0.2243],\n",
      "          [ 0.4579,  0.5614,  0.4319,  ..., -0.2324, -0.2835,  0.2386]]],\n",
      "\n",
      "\n",
      "        [[[-0.0249,  0.0729,  0.3798,  ..., -0.4332,  0.0879, -0.1735],\n",
      "          [ 0.7480, -0.3275,  0.0840,  ...,  0.5588,  0.1082,  0.1071]],\n",
      "\n",
      "         [[ 0.1624,  0.6910,  0.0549,  ..., -0.2231, -0.3868, -0.1378],\n",
      "          [ 0.3929,  0.0487, -0.2172,  ...,  0.6898, -0.0348, -0.1844]],\n",
      "\n",
      "         [[ 0.0534,  0.6723,  1.0488,  ..., -0.6195, -0.6362,  0.1774],\n",
      "          [-0.1893,  0.3198,  0.7010,  ..., -0.0388, -0.4799, -0.5112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3221,  0.5305,  0.1513,  ..., -0.0683,  0.0978,  0.1998],\n",
      "          [-0.0146,  0.2263,  0.4035,  ..., -0.0838, -0.0507, -0.0783]],\n",
      "\n",
      "         [[ 0.0841,  0.2953,  0.0404,  ..., -0.1090, -0.1298, -0.4898],\n",
      "          [-0.0555,  0.4344,  0.0995,  ...,  0.1993, -0.3797, -0.1231]],\n",
      "\n",
      "         [[-0.0609,  0.6004,  0.0854,  ..., -0.2216, -0.1401, -0.4198],\n",
      "          [ 0.4770,  0.4764,  0.3597,  ..., -0.2995, -0.3551,  0.5115]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4359,  0.4976,  0.7856,  ..., -0.1035,  0.0759, -0.9286],\n",
      "          [ 0.4154, -0.3708, -0.2043,  ...,  0.8688,  0.4087,  0.1808]],\n",
      "\n",
      "         [[ 0.6184,  0.1471,  0.4826,  ..., -0.2727, -0.2721, -0.8751],\n",
      "          [ 0.3181, -0.3986, -0.0962,  ...,  0.5383,  0.6920,  0.0724]],\n",
      "\n",
      "         [[ 0.3066,  0.6183,  0.9976,  ..., -0.3978, -0.8315, -0.9586],\n",
      "          [ 0.5746,  0.0106,  0.0849,  ...,  0.4502,  0.9153,  0.1494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1781,  0.5436,  0.6015,  ...,  0.2855, -0.0909, -0.0573],\n",
      "          [ 0.1812, -0.1956, -0.4495,  ...,  0.2037,  0.6062, -0.4514]],\n",
      "\n",
      "         [[ 0.0189,  0.1922,  0.9736,  ..., -0.5899, -0.1052, -0.7356],\n",
      "          [ 0.6391,  0.0943,  0.1281,  ...,  0.0068,  0.3086,  0.0524]],\n",
      "\n",
      "         [[ 0.7057,  0.4967,  0.8961,  ..., -0.4079, -0.0816, -0.5669],\n",
      "          [ 0.5701, -0.2532, -0.1098,  ..., -0.0462,  0.5168,  0.0110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5473,  0.4831,  0.9296,  ..., -0.0396,  0.2039, -0.8268],\n",
      "          [ 0.5210, -0.4034,  0.0820,  ...,  1.1262,  0.7893,  0.2112]],\n",
      "\n",
      "         [[ 0.4149,  0.4882,  0.6182,  ..., -0.7389, -0.3986, -1.1529],\n",
      "          [ 0.8270, -0.1022,  0.4655,  ...,  0.3077,  0.9332, -0.2257]],\n",
      "\n",
      "         [[ 0.2383,  0.1631,  0.7105,  ..., -0.3409, -0.6267, -0.7180],\n",
      "          [ 0.3831, -0.1700,  0.2370,  ...,  0.1373,  0.9887,  0.2066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0691,  0.4363,  0.5532,  ..., -0.2719, -0.4867, -0.2527],\n",
      "          [-0.1181, -0.2490, -0.1080,  ..., -0.0396,  0.1851,  0.0056]],\n",
      "\n",
      "         [[ 0.0041, -0.0954,  0.9141,  ..., -0.4338, -0.1194, -0.9361],\n",
      "          [ 0.6609, -0.0618,  0.2417,  ...,  0.2991,  0.0499, -0.0331]],\n",
      "\n",
      "         [[ 0.7684,  0.2905,  1.1141,  ..., -0.1525, -0.0166, -0.6429],\n",
      "          [ 0.6435, -0.1535, -0.1476,  ...,  0.2005,  0.5448,  0.0371]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          ...,\n",
      "          [-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312]],\n",
      "\n",
      "         [[ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232],\n",
      "          ...,\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          ...,\n",
      "          [-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661]],\n",
      "\n",
      "         [[ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248],\n",
      "          ...,\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          ...,\n",
      "          [ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02]],\n",
      "\n",
      "         [[ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01],\n",
      "          ...,\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          ...,\n",
      "          [ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01]],\n",
      "\n",
      "         [[ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04],\n",
      "          ...,\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503]],\n",
      "\n",
      "         [[-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290]],\n",
      "\n",
      "         [[ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504]],\n",
      "\n",
      "         [[ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803]],\n",
      "\n",
      "         [[ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880]],\n",
      "\n",
      "         [[ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323]],\n",
      "\n",
      "         [[-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118]],\n",
      "\n",
      "         [[ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903]],\n",
      "\n",
      "         [[ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3577,  0.2800,  0.2037,  ...,  0.7450, -0.0404,  0.2655],\n",
      "          [-0.3038,  0.3088,  0.0754,  ..., -0.3404, -0.0769,  0.1805]],\n",
      "\n",
      "         [[ 0.3302,  0.2980, -0.5975,  ...,  0.8791, -0.2676,  0.5354],\n",
      "          [-0.4732,  0.3882,  0.0680,  ...,  0.1315, -0.4662,  0.5441]],\n",
      "\n",
      "         [[-0.1305,  0.7490, -0.4150,  ...,  0.5727,  0.0504,  0.9374],\n",
      "          [-0.6017,  0.7172,  1.0445,  ...,  0.5816, -0.8695,  1.3832]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3618,  0.8295, -0.2509,  ...,  0.2193, -0.0977,  0.6511],\n",
      "          [-0.8069,  0.7903,  0.5787,  ...,  0.1693, -0.8995,  1.1609]],\n",
      "\n",
      "         [[-0.1225,  0.6841, -0.5403,  ...,  0.5903,  0.0312,  0.5037],\n",
      "          [-0.3409,  0.5665,  0.3616,  ...,  0.4588, -0.2345,  1.0660]],\n",
      "\n",
      "         [[ 0.2595,  0.0825, -0.5167,  ...,  0.6017,  0.1817, -0.2153],\n",
      "          [-0.4661,  0.3406, -0.0344,  ..., -0.2062, -0.3607,  0.3727]]],\n",
      "\n",
      "\n",
      "        [[[-0.2201, -0.0144, -0.0774,  ...,  0.6784,  0.1805,  0.2397],\n",
      "          [-0.0605,  0.0453,  0.0433,  ..., -0.6115,  0.3912, -0.0125]],\n",
      "\n",
      "         [[ 0.2916,  0.0691, -0.1903,  ...,  0.5339,  0.4194, -0.1268],\n",
      "          [ 0.1159, -0.0895,  0.5127,  ..., -0.5232, -0.1742,  0.2232]],\n",
      "\n",
      "         [[-0.1177,  0.4989, -0.1205,  ...,  0.4891, -0.0100,  0.7693],\n",
      "          [-0.7440,  0.4526,  0.6762,  ..., -0.0592, -0.5500,  1.0284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3551,  0.2883, -0.1202,  ...,  0.3301,  0.0095,  0.3455],\n",
      "          [-0.6709,  0.5171,  0.7415,  ..., -0.1044, -0.2623,  0.7901]],\n",
      "\n",
      "         [[-0.1133,  0.8532, -0.3496,  ...,  0.4809,  0.3595,  0.2157],\n",
      "          [-0.3178,  0.1252,  0.1106,  ..., -0.3183, -0.1870,  0.4479]],\n",
      "\n",
      "         [[ 0.3404, -0.1903, -0.4894,  ...,  0.6169,  0.2482, -0.3332],\n",
      "          [-0.2898,  0.2840, -0.0842,  ..., -0.3484, -0.1666,  0.1258]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1860,  0.9009, -0.8822,  ...,  1.9637,  0.9224,  0.6598],\n",
      "          [ 1.0493,  0.9140,  1.2219,  ...,  0.1828, -0.5775, -1.4751]],\n",
      "\n",
      "         [[-0.5167,  0.7945, -0.7358,  ...,  0.8526,  0.3657, -0.0340],\n",
      "          [ 0.2634,  0.4665,  0.7317,  ..., -0.3564, -0.5390, -0.3447]],\n",
      "\n",
      "         [[ 0.0889,  0.5623, -0.2131,  ...,  0.8001,  0.5143,  0.2583],\n",
      "          [ 0.6862,  0.4463,  0.7123,  ..., -0.1764,  0.1218, -0.5365]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627,  0.5800, -0.0221,  ...,  0.3144,  0.1900, -0.2160],\n",
      "          [ 0.1833,  0.0857,  0.2281,  ..., -0.1949,  0.1917, -0.6116]],\n",
      "\n",
      "         [[-0.0459,  0.4138, -0.5192,  ...,  0.6504,  0.2812, -0.3386],\n",
      "          [ 0.2814,  0.4916,  0.2383,  ..., -0.5586,  0.0852,  0.1100]],\n",
      "\n",
      "         [[-0.5478,  0.9642, -0.4353,  ..., -0.1015,  0.3682, -0.2034],\n",
      "          [ 0.2167,  0.7069,  0.1991,  ...,  0.0943,  0.0443, -0.1434]]],\n",
      "\n",
      "\n",
      "        [[[-1.4879,  1.1552, -0.8568,  ...,  2.1281,  0.9640,  0.8450],\n",
      "          [ 1.0153,  0.8573,  1.4165,  ...,  0.3985, -1.0406, -1.4223]],\n",
      "\n",
      "         [[-0.4464,  0.8762, -0.6166,  ...,  0.7965,  0.3356,  0.0356],\n",
      "          [ 0.3064,  0.5973,  0.3372,  ..., -0.2941,  0.2337, -0.5725]],\n",
      "\n",
      "         [[ 0.1992,  0.5762, -0.2364,  ...,  0.9029,  0.5630,  0.3178],\n",
      "          [ 0.2999,  0.5476,  0.5826,  ..., -0.6547, -0.2118, -0.7978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3352,  0.6593, -0.1402,  ...,  0.5490,  0.3094,  0.2462],\n",
      "          [-0.0537,  0.2861,  0.1601,  ...,  0.0731, -0.2744, -0.4878]],\n",
      "\n",
      "         [[-0.6884,  0.5706, -0.5514,  ...,  0.4872, -0.2086,  0.2016],\n",
      "          [ 0.3053,  0.3017,  0.3818,  ..., -0.4344,  0.1905, -0.5564]],\n",
      "\n",
      "         [[-0.5629,  0.9108, -0.4845,  ...,  0.0027,  0.2492, -0.1729],\n",
      "          [ 0.3020,  0.6107,  0.3848,  ...,  0.0507, -0.1334, -0.2815]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          ...,\n",
      "          [-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199]],\n",
      "\n",
      "         [[-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678],\n",
      "          ...,\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          ...,\n",
      "          [-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172]],\n",
      "\n",
      "         [[-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296],\n",
      "          ...,\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          ...,\n",
      "          [ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01]],\n",
      "\n",
      "         [[-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01],\n",
      "          ...,\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          ...,\n",
      "          [ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01]],\n",
      "\n",
      "         [[-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01],\n",
      "          ...,\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.5450,  1.8397],\n",
      "        [-0.6022,  0.6575]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:27:42,521] Trial 2 finished with value: 0.8588 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 1 with value: 0.8588.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.5611, -0.0988, -0.1857,  ..., -0.1847, -0.1391, -0.2811],\n",
      "         [ 0.1864,  0.5030,  0.1541,  ..., -0.2737,  0.1871, -0.1081],\n",
      "         [ 0.1157,  0.4396,  0.0210,  ...,  0.1978,  0.1496,  0.2409],\n",
      "         ...,\n",
      "         [ 0.2946,  0.8499,  0.3485,  ..., -0.4514,  0.1483, -0.8120],\n",
      "         [ 0.3239,  0.2703,  0.1681,  ..., -0.1082,  0.2879, -0.3467],\n",
      "         [ 0.4102,  0.3332,  0.2694,  ..., -0.6403,  0.2039, -0.5229]],\n",
      "\n",
      "        [[ 0.3757, -0.0427, -0.1119,  ..., -0.1412,  0.0303, -0.3268],\n",
      "         [ 0.2903,  0.6187,  0.4534,  ..., -0.2260, -0.2169, -0.3649],\n",
      "         [ 0.2148,  0.3087, -0.2417,  ...,  0.1394,  0.3197, -0.1711],\n",
      "         ...,\n",
      "         [ 0.4803,  0.7765,  0.3536,  ..., -0.5307,  0.2307, -0.9366],\n",
      "         [-0.0493, -0.1980,  0.3237,  ..., -0.2727, -0.2422, -0.1826],\n",
      "         [ 0.3331,  0.4401,  0.1692,  ..., -0.6837,  0.0168, -0.5224]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5611, -0.0988, -0.1857,  ..., -0.1847, -0.1391, -0.2811],\n",
      "         [ 0.1864,  0.5030,  0.1541,  ..., -0.2737,  0.1871, -0.1081],\n",
      "         [ 0.1157,  0.4396,  0.0210,  ...,  0.1978,  0.1496,  0.2409],\n",
      "         ...,\n",
      "         [ 0.2946,  0.8499,  0.3485,  ..., -0.4514,  0.1483, -0.8120],\n",
      "         [ 0.3239,  0.2703,  0.1681,  ..., -0.1082,  0.2879, -0.3467],\n",
      "         [ 0.4102,  0.3332,  0.2694,  ..., -0.6403,  0.2039, -0.5229]],\n",
      "\n",
      "        [[ 0.3757, -0.0427, -0.1119,  ..., -0.1412,  0.0303, -0.3268],\n",
      "         [ 0.2903,  0.6187,  0.4534,  ..., -0.2260, -0.2169, -0.3649],\n",
      "         [ 0.2148,  0.3087, -0.2417,  ...,  0.1394,  0.3197, -0.1711],\n",
      "         ...,\n",
      "         [ 0.4803,  0.7765,  0.3536,  ..., -0.5307,  0.2307, -0.9366],\n",
      "         [-0.0493, -0.1980,  0.3237,  ..., -0.2727, -0.2422, -0.1826],\n",
      "         [ 0.3331,  0.4401,  0.1692,  ..., -0.6837,  0.0168, -0.5224]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5611, -0.0988, -0.1857,  ...,  0.3606,  0.1150,  0.5219],\n",
      "          [-0.6843,  0.4588,  0.2774,  ..., -0.1847, -0.1391, -0.2811]],\n",
      "\n",
      "         [[ 0.1864,  0.5030,  0.1541,  ...,  0.2805,  0.2848,  0.3183],\n",
      "          [-0.4132,  0.3120,  0.2685,  ..., -0.2737,  0.1871, -0.1081]],\n",
      "\n",
      "         [[ 0.1157,  0.4396,  0.0210,  ...,  0.2739, -0.2855, -0.2365],\n",
      "          [-0.1585,  0.0855, -0.0493,  ...,  0.1978,  0.1496,  0.2409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2946,  0.8499,  0.3485,  ...,  0.2760,  0.0531,  0.4844],\n",
      "          [-0.8366,  0.3443,  0.2814,  ..., -0.4514,  0.1483, -0.8120]],\n",
      "\n",
      "         [[ 0.3239,  0.2703,  0.1681,  ...,  0.1880,  0.0637, -0.0745],\n",
      "          [-0.5664,  0.4192,  0.2226,  ..., -0.1082,  0.2879, -0.3467]],\n",
      "\n",
      "         [[ 0.4102,  0.3332,  0.2694,  ...,  0.4242,  0.2277,  0.7800],\n",
      "          [-0.5744,  0.3669,  0.1790,  ..., -0.6403,  0.2039, -0.5229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3757, -0.0427, -0.1119,  ...,  0.3509,  0.1595,  0.4888],\n",
      "          [-0.6326,  0.3387,  0.2329,  ..., -0.1412,  0.0303, -0.3268]],\n",
      "\n",
      "         [[ 0.2903,  0.6187,  0.4534,  ...,  0.2541,  0.3888,  0.4550],\n",
      "          [-0.3115,  0.2469,  0.3095,  ..., -0.2260, -0.2169, -0.3649]],\n",
      "\n",
      "         [[ 0.2148,  0.3087, -0.2417,  ...,  0.1432, -0.1318, -0.2453],\n",
      "          [-0.5411, -0.0288, -0.1352,  ...,  0.1394,  0.3197, -0.1711]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4803,  0.7765,  0.3536,  ...,  0.2843,  0.1827,  0.5633],\n",
      "          [-0.5287,  0.5403,  0.0905,  ..., -0.5307,  0.2307, -0.9366]],\n",
      "\n",
      "         [[-0.0493, -0.1980,  0.3237,  ...,  0.0605,  0.0484,  0.1742],\n",
      "          [-0.3287,  0.3033,  0.2650,  ..., -0.2727, -0.2422, -0.1826]],\n",
      "\n",
      "         [[ 0.3331,  0.4401,  0.1692,  ...,  0.3952,  0.2085,  0.7248],\n",
      "          [-0.4723,  0.3575,  0.0502,  ..., -0.6837,  0.0168, -0.5224]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1172, -0.3674,  0.2128,  ..., -0.1154, -0.4502,  0.0366],\n",
      "         [-0.3467, -0.0948,  0.2230,  ..., -0.1177, -0.4130,  0.4592],\n",
      "         [-0.2471, -0.8242,  0.0453,  ..., -0.7245, -0.2291,  0.3505],\n",
      "         ...,\n",
      "         [-0.3736, -0.4914,  0.3958,  ..., -0.3381, -0.2602,  0.1818],\n",
      "         [-0.8231, -0.4289,  0.3299,  ..., -0.2438, -0.5783,  0.7880],\n",
      "         [-0.1006,  0.2890,  0.5577,  ..., -0.0131,  0.1061, -0.2785]],\n",
      "\n",
      "        [[-0.0841, -0.2086,  0.0889,  ...,  0.0671, -0.2418, -0.1131],\n",
      "         [ 0.2706,  0.4783, -0.1367,  ...,  0.3702,  0.0948, -0.2214],\n",
      "         [-0.5616, -0.7844, -0.0433,  ..., -0.7721, -0.4417,  0.8680],\n",
      "         ...,\n",
      "         [-0.2637, -0.3296,  0.2411,  ...,  0.0195, -0.0010, -0.1460],\n",
      "         [-0.1253,  0.0772, -0.3873,  ...,  0.2939,  0.0713, -0.4483],\n",
      "         [-0.2331,  0.2100,  0.5230,  ..., -0.1626,  0.2461, -0.2566]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1172, -0.3674,  0.2128,  ..., -0.1154, -0.4502,  0.0366],\n",
      "         [-0.3467, -0.0948,  0.2230,  ..., -0.1177, -0.4130,  0.4592],\n",
      "         [-0.2471, -0.8242,  0.0453,  ..., -0.7245, -0.2291,  0.3505],\n",
      "         ...,\n",
      "         [-0.3736, -0.4914,  0.3958,  ..., -0.3381, -0.2602,  0.1818],\n",
      "         [-0.8231, -0.4289,  0.3299,  ..., -0.2438, -0.5783,  0.7880],\n",
      "         [-0.1006,  0.2890,  0.5577,  ..., -0.0131,  0.1061, -0.2785]],\n",
      "\n",
      "        [[-0.0841, -0.2086,  0.0889,  ...,  0.0671, -0.2418, -0.1131],\n",
      "         [ 0.2706,  0.4783, -0.1367,  ...,  0.3702,  0.0948, -0.2214],\n",
      "         [-0.5616, -0.7844, -0.0433,  ..., -0.7721, -0.4417,  0.8680],\n",
      "         ...,\n",
      "         [-0.2637, -0.3296,  0.2411,  ...,  0.0195, -0.0010, -0.1460],\n",
      "         [-0.1253,  0.0772, -0.3873,  ...,  0.2939,  0.0713, -0.4483],\n",
      "         [-0.2331,  0.2100,  0.5230,  ..., -0.1626,  0.2461, -0.2566]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1172, -0.3674,  0.2128,  ..., -0.0705, -0.4787, -0.1140],\n",
      "          [-0.0866,  0.0335,  0.1127,  ..., -0.1154, -0.4502,  0.0366]],\n",
      "\n",
      "         [[-0.3467, -0.0948,  0.2230,  ..., -0.1975, -0.2353, -0.1073],\n",
      "          [-0.1012, -0.5156,  0.1428,  ..., -0.1177, -0.4130,  0.4592]],\n",
      "\n",
      "         [[-0.2471, -0.8242,  0.0453,  ..., -0.2466, -0.1161, -0.5785],\n",
      "          [-0.3352, -0.1990,  0.8103,  ..., -0.7245, -0.2291,  0.3505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3736, -0.4914,  0.3958,  ..., -0.4937,  0.0663, -0.2456],\n",
      "          [-0.3276, -0.0415,  0.2727,  ..., -0.3381, -0.2602,  0.1818]],\n",
      "\n",
      "         [[-0.8231, -0.4289,  0.3299,  ..., -0.2775, -0.0615, -0.5398],\n",
      "          [-0.6294, -0.6246,  0.6428,  ..., -0.2438, -0.5783,  0.7880]],\n",
      "\n",
      "         [[-0.1006,  0.2890,  0.5577,  ..., -0.4541, -0.1822, -0.0373],\n",
      "          [-0.3369, -0.2965,  0.3234,  ..., -0.0131,  0.1061, -0.2785]]],\n",
      "\n",
      "\n",
      "        [[[-0.0841, -0.2086,  0.0889,  ..., -0.0515, -0.3647, -0.2079],\n",
      "          [-0.1226,  0.0340, -0.0448,  ...,  0.0671, -0.2418, -0.1131]],\n",
      "\n",
      "         [[ 0.2706,  0.4783, -0.1367,  ...,  0.6039, -0.8674,  0.0339],\n",
      "          [ 0.3012,  0.0465, -0.6376,  ...,  0.3702,  0.0948, -0.2214]],\n",
      "\n",
      "         [[-0.5616, -0.7844, -0.0433,  ..., -0.5762,  0.2669, -0.5191],\n",
      "          [-0.5155, -0.4668,  1.0122,  ..., -0.7721, -0.4417,  0.8680]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2637, -0.3296,  0.2411,  ..., -0.1620, -0.0919,  0.1370],\n",
      "          [-0.3679, -0.1303, -0.0169,  ...,  0.0195, -0.0010, -0.1460]],\n",
      "\n",
      "         [[-0.1253,  0.0772, -0.3873,  ...,  0.2036, -0.2464, -0.4050],\n",
      "          [ 0.0766,  0.0446,  0.0562,  ...,  0.2939,  0.0713, -0.4483]],\n",
      "\n",
      "         [[-0.2331,  0.2100,  0.5230,  ..., -0.4969, -0.1463,  0.0260],\n",
      "          [-0.1897, -0.4613,  0.4050,  ..., -0.1626,  0.2461, -0.2566]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0294, -1.3271, -0.8476,  ...,  1.2851, -0.6659,  1.7551],\n",
      "         [-0.0109, -0.6754, -0.1351,  ...,  0.9289, -0.2761,  0.8410],\n",
      "         [-0.0425, -1.0132, -0.1054,  ...,  0.4581, -0.2870,  1.2626],\n",
      "         ...,\n",
      "         [-0.2061, -0.9183, -0.4529,  ...,  0.7116, -0.4610,  1.1196],\n",
      "         [-0.2996, -0.5063, -0.1124,  ...,  0.5400,  0.0220,  0.8662],\n",
      "         [-0.2303, -0.5234, -0.3009,  ...,  0.8554, -0.3888,  0.9037]],\n",
      "\n",
      "        [[-0.1991, -0.9897, -0.8054,  ...,  1.1373, -0.5771,  1.7913],\n",
      "         [-0.2004, -0.4061, -0.3497,  ...,  1.1723, -0.3229,  0.8064],\n",
      "         [-0.0888, -0.4515, -0.0622,  ...,  0.4572,  0.0439,  0.7735],\n",
      "         ...,\n",
      "         [-0.4321, -0.6558, -0.2587,  ...,  0.6020, -0.5831,  1.0063],\n",
      "         [-0.0486, -0.3626, -0.0957,  ...,  0.4915, -0.4076,  0.8955],\n",
      "         [-0.3954, -0.3549, -0.3131,  ...,  0.7160, -0.3006,  0.7902]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0294, -1.3271, -0.8476,  ...,  1.2851, -0.6659,  1.7551],\n",
      "         [-0.0109, -0.6754, -0.1351,  ...,  0.9289, -0.2761,  0.8410],\n",
      "         [-0.0425, -1.0132, -0.1054,  ...,  0.4581, -0.2870,  1.2626],\n",
      "         ...,\n",
      "         [-0.2061, -0.9183, -0.4529,  ...,  0.7116, -0.4610,  1.1196],\n",
      "         [-0.2996, -0.5063, -0.1124,  ...,  0.5400,  0.0220,  0.8662],\n",
      "         [-0.2303, -0.5234, -0.3009,  ...,  0.8554, -0.3888,  0.9037]],\n",
      "\n",
      "        [[-0.1991, -0.9897, -0.8054,  ...,  1.1373, -0.5771,  1.7913],\n",
      "         [-0.2004, -0.4061, -0.3497,  ...,  1.1723, -0.3229,  0.8064],\n",
      "         [-0.0888, -0.4515, -0.0622,  ...,  0.4572,  0.0439,  0.7735],\n",
      "         ...,\n",
      "         [-0.4321, -0.6558, -0.2587,  ...,  0.6020, -0.5831,  1.0063],\n",
      "         [-0.0486, -0.3626, -0.0957,  ...,  0.4915, -0.4076,  0.8955],\n",
      "         [-0.3954, -0.3549, -0.3131,  ...,  0.7160, -0.3006,  0.7902]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0294, -1.3271, -0.8476,  ..., -0.7008, -0.7062, -0.7716],\n",
      "          [ 0.7872, -0.1130, -0.0822,  ...,  1.2851, -0.6659,  1.7551]],\n",
      "\n",
      "         [[-0.0109, -0.6754, -0.1351,  ..., -0.4846, -0.4717, -0.9338],\n",
      "          [ 0.6779, -0.4453, -0.0979,  ...,  0.9289, -0.2761,  0.8410]],\n",
      "\n",
      "         [[-0.0425, -1.0132, -0.1054,  ..., -0.4713, -0.3790, -0.2948],\n",
      "          [ 0.6843, -0.8136,  0.2648,  ...,  0.4581, -0.2870,  1.2626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2061, -0.9183, -0.4529,  ..., -0.4437, -0.1883, -0.7041],\n",
      "          [ 0.9138, -0.7831,  0.1701,  ...,  0.7116, -0.4610,  1.1196]],\n",
      "\n",
      "         [[-0.2996, -0.5063, -0.1124,  ..., -0.4720, -0.1614, -0.6263],\n",
      "          [ 0.8724, -0.2555, -0.3422,  ...,  0.5400,  0.0220,  0.8662]],\n",
      "\n",
      "         [[-0.2303, -0.5234, -0.3009,  ..., -0.4305, -0.5509, -0.5844],\n",
      "          [ 0.8088, -0.1157, -0.0114,  ...,  0.8554, -0.3888,  0.9037]]],\n",
      "\n",
      "\n",
      "        [[[-0.1991, -0.9897, -0.8054,  ..., -0.7134, -0.9324, -0.9338],\n",
      "          [ 0.8142,  0.0336, -0.0395,  ...,  1.1373, -0.5771,  1.7913]],\n",
      "\n",
      "         [[-0.2004, -0.4061, -0.3497,  ..., -0.4586, -0.4760, -0.6312],\n",
      "          [ 0.0927, -0.2811, -0.0074,  ...,  1.1723, -0.3229,  0.8064]],\n",
      "\n",
      "         [[-0.0888, -0.4515, -0.0622,  ..., -0.4573, -0.7347, -0.5322],\n",
      "          [ 0.3897, -0.5993,  0.3861,  ...,  0.4572,  0.0439,  0.7735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4321, -0.6558, -0.2587,  ..., -0.4875, -0.5596, -0.6812],\n",
      "          [ 0.6551, -0.4892,  0.2145,  ...,  0.6020, -0.5831,  1.0063]],\n",
      "\n",
      "         [[-0.0486, -0.3626, -0.0957,  ..., -0.4773, -0.5177, -0.8163],\n",
      "          [ 0.3802, -0.3268, -0.0961,  ...,  0.4915, -0.4076,  0.8955]],\n",
      "\n",
      "         [[-0.3954, -0.3549, -0.3131,  ..., -0.4810, -0.5812, -0.5537],\n",
      "          [ 0.8391, -0.1276, -0.1199,  ...,  0.7160, -0.3006,  0.7902]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5611, -0.0988, -0.1857,  ...,  0.3606,  0.1150,  0.5219],\n",
      "          [ 0.1864,  0.5030,  0.1541,  ...,  0.2805,  0.2848,  0.3183],\n",
      "          [ 0.1157,  0.4396,  0.0210,  ...,  0.2739, -0.2855, -0.2365],\n",
      "          ...,\n",
      "          [ 0.2946,  0.8499,  0.3485,  ...,  0.2760,  0.0531,  0.4844],\n",
      "          [ 0.3239,  0.2703,  0.1681,  ...,  0.1880,  0.0637, -0.0745],\n",
      "          [ 0.4102,  0.3332,  0.2694,  ...,  0.4242,  0.2277,  0.7800]],\n",
      "\n",
      "         [[-0.6843,  0.4588,  0.2774,  ..., -0.1847, -0.1391, -0.2811],\n",
      "          [-0.4132,  0.3120,  0.2685,  ..., -0.2737,  0.1871, -0.1081],\n",
      "          [-0.1585,  0.0855, -0.0493,  ...,  0.1978,  0.1496,  0.2409],\n",
      "          ...,\n",
      "          [-0.8366,  0.3443,  0.2814,  ..., -0.4514,  0.1483, -0.8120],\n",
      "          [-0.5664,  0.4192,  0.2226,  ..., -0.1082,  0.2879, -0.3467],\n",
      "          [-0.5744,  0.3669,  0.1790,  ..., -0.6403,  0.2039, -0.5229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3757, -0.0427, -0.1119,  ...,  0.3509,  0.1595,  0.4888],\n",
      "          [ 0.2903,  0.6187,  0.4534,  ...,  0.2541,  0.3888,  0.4550],\n",
      "          [ 0.2148,  0.3087, -0.2417,  ...,  0.1432, -0.1318, -0.2453],\n",
      "          ...,\n",
      "          [ 0.4803,  0.7765,  0.3536,  ...,  0.2843,  0.1827,  0.5633],\n",
      "          [-0.0493, -0.1980,  0.3237,  ...,  0.0605,  0.0484,  0.1742],\n",
      "          [ 0.3331,  0.4401,  0.1692,  ...,  0.3952,  0.2085,  0.7248]],\n",
      "\n",
      "         [[-0.6326,  0.3387,  0.2329,  ..., -0.1412,  0.0303, -0.3268],\n",
      "          [-0.3115,  0.2469,  0.3095,  ..., -0.2260, -0.2169, -0.3649],\n",
      "          [-0.5411, -0.0288, -0.1352,  ...,  0.1394,  0.3197, -0.1711],\n",
      "          ...,\n",
      "          [-0.5287,  0.5403,  0.0905,  ..., -0.5307,  0.2307, -0.9366],\n",
      "          [-0.3287,  0.3033,  0.2650,  ..., -0.2727, -0.2422, -0.1826],\n",
      "          [-0.4723,  0.3575,  0.0502,  ..., -0.6837,  0.0168, -0.5224]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          ...,\n",
      "          [-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823]],\n",
      "\n",
      "         [[-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481],\n",
      "          ...,\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          ...,\n",
      "          [ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763]],\n",
      "\n",
      "         [[-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975],\n",
      "          ...,\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.1998, -0.0492,  0.1704,  ..., -0.0182, -0.0138,  0.0050],\n",
      "         [-0.2753, -0.1305, -0.0961,  ...,  0.0413, -0.1132, -0.1466],\n",
      "         [ 0.1170,  0.0336,  0.3790,  ..., -0.0550,  0.1022, -0.1405],\n",
      "         ...,\n",
      "         [-0.5597, -0.3598, -0.0646,  ..., -0.1400, -0.3268, -0.0950],\n",
      "         [ 0.2002, -0.1351,  0.1219,  ...,  0.1461, -0.0429, -0.2517],\n",
      "         [ 0.0065, -0.1909, -0.1553,  ..., -0.5745, -0.1885, -0.2061]],\n",
      "\n",
      "        [[ 0.0402, -0.0764,  0.3462,  ...,  0.0479, -0.3367, -0.2530],\n",
      "         [-0.1708, -0.2757, -0.0735,  ..., -0.1939, -0.2058,  0.4364],\n",
      "         [-0.2007, -0.2209, -0.1836,  ..., -0.1811, -0.4636, -0.0044],\n",
      "         ...,\n",
      "         [-0.4694, -0.2780, -0.1995,  ..., -0.1188, -0.0901, -0.2336],\n",
      "         [-0.1029, -0.0909, -0.0263,  ...,  0.1983, -0.1768, -0.4357],\n",
      "         [ 0.0498, -0.3091, -0.1398,  ..., -0.4151, -0.3447, -0.1681]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1998, -0.0492,  0.1704,  ..., -0.0182, -0.0138,  0.0050],\n",
      "         [-0.2753, -0.1305, -0.0961,  ...,  0.0413, -0.1132, -0.1466],\n",
      "         [ 0.1170,  0.0336,  0.3790,  ..., -0.0550,  0.1022, -0.1405],\n",
      "         ...,\n",
      "         [-0.5597, -0.3598, -0.0646,  ..., -0.1400, -0.3268, -0.0950],\n",
      "         [ 0.2002, -0.1351,  0.1219,  ...,  0.1461, -0.0429, -0.2517],\n",
      "         [ 0.0065, -0.1909, -0.1553,  ..., -0.5745, -0.1885, -0.2061]],\n",
      "\n",
      "        [[ 0.0402, -0.0764,  0.3462,  ...,  0.0479, -0.3367, -0.2530],\n",
      "         [-0.1708, -0.2757, -0.0735,  ..., -0.1939, -0.2058,  0.4364],\n",
      "         [-0.2007, -0.2209, -0.1836,  ..., -0.1811, -0.4636, -0.0044],\n",
      "         ...,\n",
      "         [-0.4694, -0.2780, -0.1995,  ..., -0.1188, -0.0901, -0.2336],\n",
      "         [-0.1029, -0.0909, -0.0263,  ...,  0.1983, -0.1768, -0.4357],\n",
      "         [ 0.0498, -0.3091, -0.1398,  ..., -0.4151, -0.3447, -0.1681]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1998, -0.0492,  0.1704,  ...,  0.2896,  0.2818, -0.0936],\n",
      "          [ 0.1407, -0.4252, -0.3599,  ..., -0.0182, -0.0138,  0.0050]],\n",
      "\n",
      "         [[-0.2753, -0.1305, -0.0961,  ...,  0.3364,  0.3078, -0.0219],\n",
      "          [ 0.1890, -0.4718,  0.0787,  ...,  0.0413, -0.1132, -0.1466]],\n",
      "\n",
      "         [[ 0.1170,  0.0336,  0.3790,  ..., -0.0487,  0.0223,  0.1957],\n",
      "          [ 0.1070, -0.3517, -0.0592,  ..., -0.0550,  0.1022, -0.1405]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5597, -0.3598, -0.0646,  ...,  0.5059,  0.3813, -0.4893],\n",
      "          [ 0.4687, -0.5261, -0.1589,  ..., -0.1400, -0.3268, -0.0950]],\n",
      "\n",
      "         [[ 0.2002, -0.1351,  0.1219,  ...,  0.0455,  0.4077, -0.1724],\n",
      "          [-0.2069, -0.3860, -0.0706,  ...,  0.1461, -0.0429, -0.2517]],\n",
      "\n",
      "         [[ 0.0065, -0.1909, -0.1553,  ...,  0.7116,  0.4819, -0.1424],\n",
      "          [ 0.1932, -0.3805, -0.0803,  ..., -0.5745, -0.1885, -0.2061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402, -0.0764,  0.3462,  ...,  0.2967,  0.2689, -0.0847],\n",
      "          [ 0.1255, -0.3033, -0.1726,  ...,  0.0479, -0.3367, -0.2530]],\n",
      "\n",
      "         [[-0.1708, -0.2757, -0.0735,  ...,  0.2265,  0.2773,  0.0958],\n",
      "          [ 0.5640, -0.2326,  0.4416,  ..., -0.1939, -0.2058,  0.4364]],\n",
      "\n",
      "         [[-0.2007, -0.2209, -0.1836,  ...,  0.2124,  0.4810,  0.0224],\n",
      "          [ 0.0898, -0.4393,  0.0926,  ..., -0.1811, -0.4636, -0.0044]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4694, -0.2780, -0.1995,  ...,  0.6065,  0.4522, -0.2148],\n",
      "          [ 0.2732, -0.1441, -0.1055,  ..., -0.1188, -0.0901, -0.2336]],\n",
      "\n",
      "         [[-0.1029, -0.0909, -0.0263,  ...,  0.0044,  0.4540, -0.1078],\n",
      "          [-0.1095, -0.0759,  0.0675,  ...,  0.1983, -0.1768, -0.4357]],\n",
      "\n",
      "         [[ 0.0498, -0.3091, -0.1398,  ...,  0.6637,  0.5062, -0.2416],\n",
      "          [ 0.2306, -0.3508, -0.0361,  ..., -0.4151, -0.3447, -0.1681]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  4.6112e-01,\n",
      "          -7.5638e-01,  9.8061e-01],\n",
      "         [ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  2.7140e-01,\n",
      "          -1.1380e+00,  7.4050e-01],\n",
      "         [ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  5.8941e-01,\n",
      "          -8.1991e-01,  9.2370e-01],\n",
      "         ...,\n",
      "         [ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  4.3437e-01,\n",
      "          -8.8962e-01,  7.8859e-01],\n",
      "         [ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  8.3289e-01,\n",
      "          -1.1972e+00,  1.3268e+00],\n",
      "         [ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ..., -3.2599e-02,\n",
      "          -6.5663e-01,  4.3323e-01]],\n",
      "\n",
      "        [[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.3611e-01,\n",
      "           5.5846e-01, -8.6070e-04],\n",
      "         [-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.7178e-01,\n",
      "           4.1499e-01, -4.1224e-01],\n",
      "         [ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  5.9711e-01,\n",
      "          -5.0567e-01,  6.0095e-01],\n",
      "         ...,\n",
      "         [ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.6203e-01,\n",
      "          -2.1623e-01, -7.5460e-02],\n",
      "         [ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ..., -1.4295e-01,\n",
      "           1.9976e-01,  3.7237e-01],\n",
      "         [ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ..., -2.8518e-01,\n",
      "          -2.8311e-01,  6.4090e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  4.6112e-01,\n",
      "          -7.5638e-01,  9.8061e-01],\n",
      "         [ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  2.7140e-01,\n",
      "          -1.1380e+00,  7.4050e-01],\n",
      "         [ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  5.8941e-01,\n",
      "          -8.1991e-01,  9.2370e-01],\n",
      "         ...,\n",
      "         [ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  4.3437e-01,\n",
      "          -8.8962e-01,  7.8859e-01],\n",
      "         [ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  8.3289e-01,\n",
      "          -1.1972e+00,  1.3268e+00],\n",
      "         [ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ..., -3.2599e-02,\n",
      "          -6.5663e-01,  4.3323e-01]],\n",
      "\n",
      "        [[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.3611e-01,\n",
      "           5.5846e-01, -8.6070e-04],\n",
      "         [-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.7178e-01,\n",
      "           4.1499e-01, -4.1224e-01],\n",
      "         [ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  5.9711e-01,\n",
      "          -5.0567e-01,  6.0095e-01],\n",
      "         ...,\n",
      "         [ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.6203e-01,\n",
      "          -2.1623e-01, -7.5460e-02],\n",
      "         [ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ..., -1.4295e-01,\n",
      "           1.9976e-01,  3.7237e-01],\n",
      "         [ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ..., -2.8518e-01,\n",
      "          -2.8311e-01,  6.4090e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  6.0637e-01,\n",
      "            2.9660e-01,  5.3929e-01],\n",
      "          [ 5.0486e-01, -2.7842e-02, -6.5914e-01,  ...,  4.6112e-01,\n",
      "           -7.5638e-01,  9.8061e-01]],\n",
      "\n",
      "         [[ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  7.8334e-01,\n",
      "            4.7901e-01,  2.3453e-01],\n",
      "          [ 3.5756e-01, -1.4846e-01, -2.6880e-01,  ...,  2.7140e-01,\n",
      "           -1.1380e+00,  7.4050e-01]],\n",
      "\n",
      "         [[ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  1.0635e+00,\n",
      "            4.9203e-01,  3.5024e-01],\n",
      "          [ 8.6026e-01, -4.3695e-02, -7.7887e-01,  ...,  5.8941e-01,\n",
      "           -8.1991e-01,  9.2370e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  9.2902e-01,\n",
      "            4.5886e-01,  5.3908e-01],\n",
      "          [ 5.4190e-01, -2.1326e-01, -9.7762e-01,  ...,  4.3437e-01,\n",
      "           -8.8962e-01,  7.8859e-01]],\n",
      "\n",
      "         [[ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  1.5239e+00,\n",
      "            1.1062e+00,  2.9111e-01],\n",
      "          [ 8.2067e-01,  2.3693e-01, -1.2690e+00,  ...,  8.3289e-01,\n",
      "           -1.1972e+00,  1.3268e+00]],\n",
      "\n",
      "         [[ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ...,  4.1001e-01,\n",
      "            1.2279e-01,  7.4559e-01],\n",
      "          [ 3.8943e-01,  4.4695e-01, -4.9236e-01,  ..., -3.2599e-02,\n",
      "           -6.5663e-01,  4.3323e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.5675e-01,\n",
      "           -1.6733e-02,  3.6960e-01],\n",
      "          [-3.3146e-01,  3.0133e-01,  2.8925e-01,  ..., -4.3611e-01,\n",
      "            5.5846e-01, -8.6070e-04]],\n",
      "\n",
      "         [[-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.6803e-01,\n",
      "           -8.4436e-01, -1.9562e-02],\n",
      "          [-5.9253e-01,  2.6408e-01,  9.7901e-01,  ..., -8.7178e-01,\n",
      "            4.1499e-01, -4.1224e-01]],\n",
      "\n",
      "         [[ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  7.6141e-01,\n",
      "            6.7468e-01, -3.2842e-02],\n",
      "          [ 7.0920e-01,  9.6323e-03, -7.3328e-01,  ...,  5.9711e-01,\n",
      "           -5.0567e-01,  6.0095e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.1628e-01,\n",
      "            5.6547e-02,  1.5069e-01],\n",
      "          [ 1.0911e-01,  9.9595e-02, -1.6898e-01,  ..., -2.6203e-01,\n",
      "           -2.1623e-01, -7.5460e-02]],\n",
      "\n",
      "         [[ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ...,  3.8057e-02,\n",
      "            3.6087e-02,  2.5329e-01],\n",
      "          [-1.9962e-01,  4.2818e-01,  1.8055e-01,  ..., -1.4295e-01,\n",
      "            1.9976e-01,  3.7237e-01]],\n",
      "\n",
      "         [[ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ...,  1.0197e-01,\n",
      "            1.2834e-01,  6.0884e-01],\n",
      "          [ 1.6712e-01,  4.4049e-01, -7.3379e-02,  ..., -2.8518e-01,\n",
      "           -2.8311e-01,  6.4090e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.7213,  0.6297,  0.5673,  ...,  0.3995,  1.1203, -0.0572],\n",
      "         [ 0.4206,  0.1975,  0.3131,  ...,  0.0317,  0.6958,  0.2779],\n",
      "         [ 0.2541, -0.0934,  0.0590,  ..., -0.0778,  0.4074,  0.0889],\n",
      "         ...,\n",
      "         [ 0.4621, -0.2040,  0.6867,  ..., -0.3795,  0.2415,  0.0353],\n",
      "         [ 0.5789, -0.0802,  0.2609,  ..., -0.0901,  0.6126,  0.0705],\n",
      "         [ 0.4489,  0.2019,  0.6433,  ..., -0.3271,  0.4822, -0.2029]],\n",
      "\n",
      "        [[ 0.8560,  0.9752,  0.4722,  ...,  0.7999,  1.1313,  0.0475],\n",
      "         [ 0.3273,  0.8255,  0.2869,  ...,  0.1259,  0.2765, -0.0776],\n",
      "         [ 0.0195, -0.1437,  0.2610,  ..., -0.0494,  0.1685,  0.4577],\n",
      "         ...,\n",
      "         [ 0.2552, -0.0059,  0.4817,  ..., -0.6154,  0.2123,  0.3384],\n",
      "         [ 0.5519,  0.4349,  0.0524,  ..., -0.0831,  0.4730,  0.2290],\n",
      "         [ 0.3849,  0.2771,  0.5413,  ..., -0.4655,  0.3637, -0.1254]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.7213,  0.6297,  0.5673,  ...,  0.3995,  1.1203, -0.0572],\n",
      "         [ 0.4206,  0.1975,  0.3131,  ...,  0.0317,  0.6958,  0.2779],\n",
      "         [ 0.2541, -0.0934,  0.0590,  ..., -0.0778,  0.4074,  0.0889],\n",
      "         ...,\n",
      "         [ 0.4621, -0.2040,  0.6867,  ..., -0.3795,  0.2415,  0.0353],\n",
      "         [ 0.5789, -0.0802,  0.2609,  ..., -0.0901,  0.6126,  0.0705],\n",
      "         [ 0.4489,  0.2019,  0.6433,  ..., -0.3271,  0.4822, -0.2029]],\n",
      "\n",
      "        [[ 0.8560,  0.9752,  0.4722,  ...,  0.7999,  1.1313,  0.0475],\n",
      "         [ 0.3273,  0.8255,  0.2869,  ...,  0.1259,  0.2765, -0.0776],\n",
      "         [ 0.0195, -0.1437,  0.2610,  ..., -0.0494,  0.1685,  0.4577],\n",
      "         ...,\n",
      "         [ 0.2552, -0.0059,  0.4817,  ..., -0.6154,  0.2123,  0.3384],\n",
      "         [ 0.5519,  0.4349,  0.0524,  ..., -0.0831,  0.4730,  0.2290],\n",
      "         [ 0.3849,  0.2771,  0.5413,  ..., -0.4655,  0.3637, -0.1254]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.7213,  0.6297,  0.5673,  ..., -0.2608, -0.3044,  0.8183],\n",
      "          [-0.5755,  0.3248, -0.3229,  ...,  0.3995,  1.1203, -0.0572]],\n",
      "\n",
      "         [[ 0.4206,  0.1975,  0.3131,  ..., -0.1100,  0.1019,  0.6790],\n",
      "          [-0.1955,  0.1772,  0.0610,  ...,  0.0317,  0.6958,  0.2779]],\n",
      "\n",
      "         [[ 0.2541, -0.0934,  0.0590,  ...,  0.1269,  0.2680,  0.1310],\n",
      "          [-0.3885,  0.1387,  0.0064,  ..., -0.0778,  0.4074,  0.0889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4621, -0.2040,  0.6867,  ..., -0.1656, -0.1699,  0.1978],\n",
      "          [-0.2866, -0.1075, -0.0984,  ..., -0.3795,  0.2415,  0.0353]],\n",
      "\n",
      "         [[ 0.5789, -0.0802,  0.2609,  ...,  0.0108,  0.0599,  0.3440],\n",
      "          [-0.4651,  0.1209, -0.0414,  ..., -0.0901,  0.6126,  0.0705]],\n",
      "\n",
      "         [[ 0.4489,  0.2019,  0.6433,  ..., -0.2327, -0.1523,  0.3516],\n",
      "          [-0.6129,  0.0245,  0.2220,  ..., -0.3271,  0.4822, -0.2029]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8560,  0.9752,  0.4722,  ..., -0.8492, -0.5672,  1.1538],\n",
      "          [-0.6817,  0.9302, -0.4828,  ...,  0.7999,  1.1313,  0.0475]],\n",
      "\n",
      "         [[ 0.3273,  0.8255,  0.2869,  ..., -0.2090, -0.4673,  0.6375],\n",
      "          [-0.0345,  0.0667, -0.0854,  ...,  0.1259,  0.2765, -0.0776]],\n",
      "\n",
      "         [[ 0.0195, -0.1437,  0.2610,  ..., -0.0181,  0.1530,  0.0448],\n",
      "          [-0.2625,  0.2047, -0.1007,  ..., -0.0494,  0.1685,  0.4577]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2552, -0.0059,  0.4817,  ...,  0.2947, -0.2042,  0.3148],\n",
      "          [-0.3176,  0.1558, -0.2427,  ..., -0.6154,  0.2123,  0.3384]],\n",
      "\n",
      "         [[ 0.5519,  0.4349,  0.0524,  ..., -0.2111,  0.2902,  0.2238],\n",
      "          [-0.3923,  0.3489, -0.3004,  ..., -0.0831,  0.4730,  0.2290]],\n",
      "\n",
      "         [[ 0.3849,  0.2771,  0.5413,  ..., -0.3430, -0.0552,  0.3365],\n",
      "          [-0.5326,  0.0237,  0.1370,  ..., -0.4655,  0.3637, -0.1254]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1998, -0.0492,  0.1704,  ...,  0.2896,  0.2818, -0.0936],\n",
      "          [-0.2753, -0.1305, -0.0961,  ...,  0.3364,  0.3078, -0.0219],\n",
      "          [ 0.1170,  0.0336,  0.3790,  ..., -0.0487,  0.0223,  0.1957],\n",
      "          ...,\n",
      "          [-0.5597, -0.3598, -0.0646,  ...,  0.5059,  0.3813, -0.4893],\n",
      "          [ 0.2002, -0.1351,  0.1219,  ...,  0.0455,  0.4077, -0.1724],\n",
      "          [ 0.0065, -0.1909, -0.1553,  ...,  0.7116,  0.4819, -0.1424]],\n",
      "\n",
      "         [[ 0.1407, -0.4252, -0.3599,  ..., -0.0182, -0.0138,  0.0050],\n",
      "          [ 0.1890, -0.4718,  0.0787,  ...,  0.0413, -0.1132, -0.1466],\n",
      "          [ 0.1070, -0.3517, -0.0592,  ..., -0.0550,  0.1022, -0.1405],\n",
      "          ...,\n",
      "          [ 0.4687, -0.5261, -0.1589,  ..., -0.1400, -0.3268, -0.0950],\n",
      "          [-0.2069, -0.3860, -0.0706,  ...,  0.1461, -0.0429, -0.2517],\n",
      "          [ 0.1932, -0.3805, -0.0803,  ..., -0.5745, -0.1885, -0.2061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402, -0.0764,  0.3462,  ...,  0.2967,  0.2689, -0.0847],\n",
      "          [-0.1708, -0.2757, -0.0735,  ...,  0.2265,  0.2773,  0.0958],\n",
      "          [-0.2007, -0.2209, -0.1836,  ...,  0.2124,  0.4810,  0.0224],\n",
      "          ...,\n",
      "          [-0.4694, -0.2780, -0.1995,  ...,  0.6065,  0.4522, -0.2148],\n",
      "          [-0.1029, -0.0909, -0.0263,  ...,  0.0044,  0.4540, -0.1078],\n",
      "          [ 0.0498, -0.3091, -0.1398,  ...,  0.6637,  0.5062, -0.2416]],\n",
      "\n",
      "         [[ 0.1255, -0.3033, -0.1726,  ...,  0.0479, -0.3367, -0.2530],\n",
      "          [ 0.5640, -0.2326,  0.4416,  ..., -0.1939, -0.2058,  0.4364],\n",
      "          [ 0.0898, -0.4393,  0.0926,  ..., -0.1811, -0.4636, -0.0044],\n",
      "          ...,\n",
      "          [ 0.2732, -0.1441, -0.1055,  ..., -0.1188, -0.0901, -0.2336],\n",
      "          [-0.1095, -0.0759,  0.0675,  ...,  0.1983, -0.1768, -0.4357],\n",
      "          [ 0.2306, -0.3508, -0.0361,  ..., -0.4151, -0.3447, -0.1681]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          ...,\n",
      "          [ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01]],\n",
      "\n",
      "         [[ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01],\n",
      "          ...,\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          ...,\n",
      "          [-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01]],\n",
      "\n",
      "         [[-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02],\n",
      "          ...,\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.4084,  1.8033],\n",
      "        [ 0.9294, -1.1636]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.312000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:33:40,754] Trial 3 finished with value: 0.864 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          ...,\n",
      "          [ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678],\n",
      "          ...,\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          ...,\n",
      "          [ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757],\n",
      "          ...,\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          ...,\n",
      "          [ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00]],\n",
      "\n",
      "         [[-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01],\n",
      "          ...,\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          ...,\n",
      "          [ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00]],\n",
      "\n",
      "         [[-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00],\n",
      "          ...,\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          ...,\n",
      "          [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01]],\n",
      "\n",
      "         [[-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01],\n",
      "          ...,\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          ...,\n",
      "          [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00]],\n",
      "\n",
      "         [[-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00],\n",
      "          ...,\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          ...,\n",
      "          [ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584]],\n",
      "\n",
      "         [[-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470],\n",
      "          ...,\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          ...,\n",
      "          [ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641]],\n",
      "\n",
      "         [[-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474],\n",
      "          ...,\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.9553,  0.7356],\n",
      "        [-0.0274, -0.0352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:38:06,816] Trial 4 finished with value: 0.84976 and parameters: {'num_layers': 4, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.5611, -0.0988, -0.1857,  ..., -0.1847, -0.1391, -0.2811],\n",
      "         [ 0.1864,  0.5030,  0.1541,  ..., -0.2737,  0.1871, -0.1081],\n",
      "         [ 0.1157,  0.4396,  0.0210,  ...,  0.1978,  0.1496,  0.2409],\n",
      "         ...,\n",
      "         [ 0.2946,  0.8499,  0.3485,  ..., -0.4514,  0.1483, -0.8120],\n",
      "         [ 0.3239,  0.2703,  0.1681,  ..., -0.1082,  0.2879, -0.3467],\n",
      "         [ 0.4102,  0.3332,  0.2694,  ..., -0.6403,  0.2039, -0.5229]],\n",
      "\n",
      "        [[ 0.3757, -0.0427, -0.1119,  ..., -0.1412,  0.0303, -0.3268],\n",
      "         [ 0.2903,  0.6187,  0.4534,  ..., -0.2260, -0.2169, -0.3649],\n",
      "         [ 0.2148,  0.3087, -0.2417,  ...,  0.1394,  0.3197, -0.1711],\n",
      "         ...,\n",
      "         [ 0.4803,  0.7765,  0.3536,  ..., -0.5307,  0.2307, -0.9366],\n",
      "         [-0.0493, -0.1980,  0.3237,  ..., -0.2727, -0.2422, -0.1826],\n",
      "         [ 0.3331,  0.4401,  0.1692,  ..., -0.6837,  0.0168, -0.5224]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5611, -0.0988, -0.1857,  ..., -0.1847, -0.1391, -0.2811],\n",
      "         [ 0.1864,  0.5030,  0.1541,  ..., -0.2737,  0.1871, -0.1081],\n",
      "         [ 0.1157,  0.4396,  0.0210,  ...,  0.1978,  0.1496,  0.2409],\n",
      "         ...,\n",
      "         [ 0.2946,  0.8499,  0.3485,  ..., -0.4514,  0.1483, -0.8120],\n",
      "         [ 0.3239,  0.2703,  0.1681,  ..., -0.1082,  0.2879, -0.3467],\n",
      "         [ 0.4102,  0.3332,  0.2694,  ..., -0.6403,  0.2039, -0.5229]],\n",
      "\n",
      "        [[ 0.3757, -0.0427, -0.1119,  ..., -0.1412,  0.0303, -0.3268],\n",
      "         [ 0.2903,  0.6187,  0.4534,  ..., -0.2260, -0.2169, -0.3649],\n",
      "         [ 0.2148,  0.3087, -0.2417,  ...,  0.1394,  0.3197, -0.1711],\n",
      "         ...,\n",
      "         [ 0.4803,  0.7765,  0.3536,  ..., -0.5307,  0.2307, -0.9366],\n",
      "         [-0.0493, -0.1980,  0.3237,  ..., -0.2727, -0.2422, -0.1826],\n",
      "         [ 0.3331,  0.4401,  0.1692,  ..., -0.6837,  0.0168, -0.5224]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5611, -0.0988, -0.1857,  ...,  0.3606,  0.1150,  0.5219],\n",
      "          [-0.6843,  0.4588,  0.2774,  ..., -0.1847, -0.1391, -0.2811]],\n",
      "\n",
      "         [[ 0.1864,  0.5030,  0.1541,  ...,  0.2805,  0.2848,  0.3183],\n",
      "          [-0.4132,  0.3120,  0.2685,  ..., -0.2737,  0.1871, -0.1081]],\n",
      "\n",
      "         [[ 0.1157,  0.4396,  0.0210,  ...,  0.2739, -0.2855, -0.2365],\n",
      "          [-0.1585,  0.0855, -0.0493,  ...,  0.1978,  0.1496,  0.2409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2946,  0.8499,  0.3485,  ...,  0.2760,  0.0531,  0.4844],\n",
      "          [-0.8366,  0.3443,  0.2814,  ..., -0.4514,  0.1483, -0.8120]],\n",
      "\n",
      "         [[ 0.3239,  0.2703,  0.1681,  ...,  0.1880,  0.0637, -0.0745],\n",
      "          [-0.5664,  0.4192,  0.2226,  ..., -0.1082,  0.2879, -0.3467]],\n",
      "\n",
      "         [[ 0.4102,  0.3332,  0.2694,  ...,  0.4242,  0.2277,  0.7800],\n",
      "          [-0.5744,  0.3669,  0.1790,  ..., -0.6403,  0.2039, -0.5229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3757, -0.0427, -0.1119,  ...,  0.3509,  0.1595,  0.4888],\n",
      "          [-0.6326,  0.3387,  0.2329,  ..., -0.1412,  0.0303, -0.3268]],\n",
      "\n",
      "         [[ 0.2903,  0.6187,  0.4534,  ...,  0.2541,  0.3888,  0.4550],\n",
      "          [-0.3115,  0.2469,  0.3095,  ..., -0.2260, -0.2169, -0.3649]],\n",
      "\n",
      "         [[ 0.2148,  0.3087, -0.2417,  ...,  0.1432, -0.1318, -0.2453],\n",
      "          [-0.5411, -0.0288, -0.1352,  ...,  0.1394,  0.3197, -0.1711]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4803,  0.7765,  0.3536,  ...,  0.2843,  0.1827,  0.5633],\n",
      "          [-0.5287,  0.5403,  0.0905,  ..., -0.5307,  0.2307, -0.9366]],\n",
      "\n",
      "         [[-0.0493, -0.1980,  0.3237,  ...,  0.0605,  0.0484,  0.1742],\n",
      "          [-0.3287,  0.3033,  0.2650,  ..., -0.2727, -0.2422, -0.1826]],\n",
      "\n",
      "         [[ 0.3331,  0.4401,  0.1692,  ...,  0.3952,  0.2085,  0.7248],\n",
      "          [-0.4723,  0.3575,  0.0502,  ..., -0.6837,  0.0168, -0.5224]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1172, -0.3674,  0.2128,  ..., -0.1154, -0.4502,  0.0366],\n",
      "         [-0.3467, -0.0948,  0.2230,  ..., -0.1177, -0.4130,  0.4592],\n",
      "         [-0.2471, -0.8242,  0.0453,  ..., -0.7245, -0.2291,  0.3505],\n",
      "         ...,\n",
      "         [-0.3736, -0.4914,  0.3958,  ..., -0.3381, -0.2602,  0.1818],\n",
      "         [-0.8231, -0.4289,  0.3299,  ..., -0.2438, -0.5783,  0.7880],\n",
      "         [-0.1006,  0.2890,  0.5577,  ..., -0.0131,  0.1061, -0.2785]],\n",
      "\n",
      "        [[-0.0841, -0.2086,  0.0889,  ...,  0.0671, -0.2418, -0.1131],\n",
      "         [ 0.2706,  0.4783, -0.1367,  ...,  0.3702,  0.0948, -0.2214],\n",
      "         [-0.5616, -0.7844, -0.0433,  ..., -0.7721, -0.4417,  0.8680],\n",
      "         ...,\n",
      "         [-0.2637, -0.3296,  0.2411,  ...,  0.0195, -0.0010, -0.1460],\n",
      "         [-0.1253,  0.0772, -0.3873,  ...,  0.2939,  0.0713, -0.4483],\n",
      "         [-0.2331,  0.2100,  0.5230,  ..., -0.1626,  0.2461, -0.2566]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1172, -0.3674,  0.2128,  ..., -0.1154, -0.4502,  0.0366],\n",
      "         [-0.3467, -0.0948,  0.2230,  ..., -0.1177, -0.4130,  0.4592],\n",
      "         [-0.2471, -0.8242,  0.0453,  ..., -0.7245, -0.2291,  0.3505],\n",
      "         ...,\n",
      "         [-0.3736, -0.4914,  0.3958,  ..., -0.3381, -0.2602,  0.1818],\n",
      "         [-0.8231, -0.4289,  0.3299,  ..., -0.2438, -0.5783,  0.7880],\n",
      "         [-0.1006,  0.2890,  0.5577,  ..., -0.0131,  0.1061, -0.2785]],\n",
      "\n",
      "        [[-0.0841, -0.2086,  0.0889,  ...,  0.0671, -0.2418, -0.1131],\n",
      "         [ 0.2706,  0.4783, -0.1367,  ...,  0.3702,  0.0948, -0.2214],\n",
      "         [-0.5616, -0.7844, -0.0433,  ..., -0.7721, -0.4417,  0.8680],\n",
      "         ...,\n",
      "         [-0.2637, -0.3296,  0.2411,  ...,  0.0195, -0.0010, -0.1460],\n",
      "         [-0.1253,  0.0772, -0.3873,  ...,  0.2939,  0.0713, -0.4483],\n",
      "         [-0.2331,  0.2100,  0.5230,  ..., -0.1626,  0.2461, -0.2566]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1172, -0.3674,  0.2128,  ..., -0.0705, -0.4787, -0.1140],\n",
      "          [-0.0866,  0.0335,  0.1127,  ..., -0.1154, -0.4502,  0.0366]],\n",
      "\n",
      "         [[-0.3467, -0.0948,  0.2230,  ..., -0.1975, -0.2353, -0.1073],\n",
      "          [-0.1012, -0.5156,  0.1428,  ..., -0.1177, -0.4130,  0.4592]],\n",
      "\n",
      "         [[-0.2471, -0.8242,  0.0453,  ..., -0.2466, -0.1161, -0.5785],\n",
      "          [-0.3352, -0.1990,  0.8103,  ..., -0.7245, -0.2291,  0.3505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3736, -0.4914,  0.3958,  ..., -0.4937,  0.0663, -0.2456],\n",
      "          [-0.3276, -0.0415,  0.2727,  ..., -0.3381, -0.2602,  0.1818]],\n",
      "\n",
      "         [[-0.8231, -0.4289,  0.3299,  ..., -0.2775, -0.0615, -0.5398],\n",
      "          [-0.6294, -0.6246,  0.6428,  ..., -0.2438, -0.5783,  0.7880]],\n",
      "\n",
      "         [[-0.1006,  0.2890,  0.5577,  ..., -0.4541, -0.1822, -0.0373],\n",
      "          [-0.3369, -0.2965,  0.3234,  ..., -0.0131,  0.1061, -0.2785]]],\n",
      "\n",
      "\n",
      "        [[[-0.0841, -0.2086,  0.0889,  ..., -0.0515, -0.3647, -0.2079],\n",
      "          [-0.1226,  0.0340, -0.0448,  ...,  0.0671, -0.2418, -0.1131]],\n",
      "\n",
      "         [[ 0.2706,  0.4783, -0.1367,  ...,  0.6039, -0.8674,  0.0339],\n",
      "          [ 0.3012,  0.0465, -0.6376,  ...,  0.3702,  0.0948, -0.2214]],\n",
      "\n",
      "         [[-0.5616, -0.7844, -0.0433,  ..., -0.5762,  0.2669, -0.5191],\n",
      "          [-0.5155, -0.4668,  1.0122,  ..., -0.7721, -0.4417,  0.8680]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2637, -0.3296,  0.2411,  ..., -0.1620, -0.0919,  0.1370],\n",
      "          [-0.3679, -0.1303, -0.0169,  ...,  0.0195, -0.0010, -0.1460]],\n",
      "\n",
      "         [[-0.1253,  0.0772, -0.3873,  ...,  0.2036, -0.2464, -0.4050],\n",
      "          [ 0.0766,  0.0446,  0.0562,  ...,  0.2939,  0.0713, -0.4483]],\n",
      "\n",
      "         [[-0.2331,  0.2100,  0.5230,  ..., -0.4969, -0.1463,  0.0260],\n",
      "          [-0.1897, -0.4613,  0.4050,  ..., -0.1626,  0.2461, -0.2566]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0294, -1.3271, -0.8476,  ...,  1.2851, -0.6659,  1.7551],\n",
      "         [-0.0109, -0.6754, -0.1351,  ...,  0.9289, -0.2761,  0.8410],\n",
      "         [-0.0425, -1.0132, -0.1054,  ...,  0.4581, -0.2870,  1.2626],\n",
      "         ...,\n",
      "         [-0.2061, -0.9183, -0.4529,  ...,  0.7116, -0.4610,  1.1196],\n",
      "         [-0.2996, -0.5063, -0.1124,  ...,  0.5400,  0.0220,  0.8662],\n",
      "         [-0.2303, -0.5234, -0.3009,  ...,  0.8554, -0.3888,  0.9037]],\n",
      "\n",
      "        [[-0.1991, -0.9897, -0.8054,  ...,  1.1373, -0.5771,  1.7913],\n",
      "         [-0.2004, -0.4061, -0.3497,  ...,  1.1723, -0.3229,  0.8064],\n",
      "         [-0.0888, -0.4515, -0.0622,  ...,  0.4572,  0.0439,  0.7735],\n",
      "         ...,\n",
      "         [-0.4321, -0.6558, -0.2587,  ...,  0.6020, -0.5831,  1.0063],\n",
      "         [-0.0486, -0.3626, -0.0957,  ...,  0.4915, -0.4076,  0.8955],\n",
      "         [-0.3954, -0.3549, -0.3131,  ...,  0.7160, -0.3006,  0.7902]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0294, -1.3271, -0.8476,  ...,  1.2851, -0.6659,  1.7551],\n",
      "         [-0.0109, -0.6754, -0.1351,  ...,  0.9289, -0.2761,  0.8410],\n",
      "         [-0.0425, -1.0132, -0.1054,  ...,  0.4581, -0.2870,  1.2626],\n",
      "         ...,\n",
      "         [-0.2061, -0.9183, -0.4529,  ...,  0.7116, -0.4610,  1.1196],\n",
      "         [-0.2996, -0.5063, -0.1124,  ...,  0.5400,  0.0220,  0.8662],\n",
      "         [-0.2303, -0.5234, -0.3009,  ...,  0.8554, -0.3888,  0.9037]],\n",
      "\n",
      "        [[-0.1991, -0.9897, -0.8054,  ...,  1.1373, -0.5771,  1.7913],\n",
      "         [-0.2004, -0.4061, -0.3497,  ...,  1.1723, -0.3229,  0.8064],\n",
      "         [-0.0888, -0.4515, -0.0622,  ...,  0.4572,  0.0439,  0.7735],\n",
      "         ...,\n",
      "         [-0.4321, -0.6558, -0.2587,  ...,  0.6020, -0.5831,  1.0063],\n",
      "         [-0.0486, -0.3626, -0.0957,  ...,  0.4915, -0.4076,  0.8955],\n",
      "         [-0.3954, -0.3549, -0.3131,  ...,  0.7160, -0.3006,  0.7902]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0294, -1.3271, -0.8476,  ..., -0.7008, -0.7062, -0.7716],\n",
      "          [ 0.7872, -0.1130, -0.0822,  ...,  1.2851, -0.6659,  1.7551]],\n",
      "\n",
      "         [[-0.0109, -0.6754, -0.1351,  ..., -0.4846, -0.4717, -0.9338],\n",
      "          [ 0.6779, -0.4453, -0.0979,  ...,  0.9289, -0.2761,  0.8410]],\n",
      "\n",
      "         [[-0.0425, -1.0132, -0.1054,  ..., -0.4713, -0.3790, -0.2948],\n",
      "          [ 0.6843, -0.8136,  0.2648,  ...,  0.4581, -0.2870,  1.2626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2061, -0.9183, -0.4529,  ..., -0.4437, -0.1883, -0.7041],\n",
      "          [ 0.9138, -0.7831,  0.1701,  ...,  0.7116, -0.4610,  1.1196]],\n",
      "\n",
      "         [[-0.2996, -0.5063, -0.1124,  ..., -0.4720, -0.1614, -0.6263],\n",
      "          [ 0.8724, -0.2555, -0.3422,  ...,  0.5400,  0.0220,  0.8662]],\n",
      "\n",
      "         [[-0.2303, -0.5234, -0.3009,  ..., -0.4305, -0.5509, -0.5844],\n",
      "          [ 0.8088, -0.1157, -0.0114,  ...,  0.8554, -0.3888,  0.9037]]],\n",
      "\n",
      "\n",
      "        [[[-0.1991, -0.9897, -0.8054,  ..., -0.7134, -0.9324, -0.9338],\n",
      "          [ 0.8142,  0.0336, -0.0395,  ...,  1.1373, -0.5771,  1.7913]],\n",
      "\n",
      "         [[-0.2004, -0.4061, -0.3497,  ..., -0.4586, -0.4760, -0.6312],\n",
      "          [ 0.0927, -0.2811, -0.0074,  ...,  1.1723, -0.3229,  0.8064]],\n",
      "\n",
      "         [[-0.0888, -0.4515, -0.0622,  ..., -0.4573, -0.7347, -0.5322],\n",
      "          [ 0.3897, -0.5993,  0.3861,  ...,  0.4572,  0.0439,  0.7735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4321, -0.6558, -0.2587,  ..., -0.4875, -0.5596, -0.6812],\n",
      "          [ 0.6551, -0.4892,  0.2145,  ...,  0.6020, -0.5831,  1.0063]],\n",
      "\n",
      "         [[-0.0486, -0.3626, -0.0957,  ..., -0.4773, -0.5177, -0.8163],\n",
      "          [ 0.3802, -0.3268, -0.0961,  ...,  0.4915, -0.4076,  0.8955]],\n",
      "\n",
      "         [[-0.3954, -0.3549, -0.3131,  ..., -0.4810, -0.5812, -0.5537],\n",
      "          [ 0.8391, -0.1276, -0.1199,  ...,  0.7160, -0.3006,  0.7902]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5611, -0.0988, -0.1857,  ...,  0.3606,  0.1150,  0.5219],\n",
      "          [ 0.1864,  0.5030,  0.1541,  ...,  0.2805,  0.2848,  0.3183],\n",
      "          [ 0.1157,  0.4396,  0.0210,  ...,  0.2739, -0.2855, -0.2365],\n",
      "          ...,\n",
      "          [ 0.2946,  0.8499,  0.3485,  ...,  0.2760,  0.0531,  0.4844],\n",
      "          [ 0.3239,  0.2703,  0.1681,  ...,  0.1880,  0.0637, -0.0745],\n",
      "          [ 0.4102,  0.3332,  0.2694,  ...,  0.4242,  0.2277,  0.7800]],\n",
      "\n",
      "         [[-0.6843,  0.4588,  0.2774,  ..., -0.1847, -0.1391, -0.2811],\n",
      "          [-0.4132,  0.3120,  0.2685,  ..., -0.2737,  0.1871, -0.1081],\n",
      "          [-0.1585,  0.0855, -0.0493,  ...,  0.1978,  0.1496,  0.2409],\n",
      "          ...,\n",
      "          [-0.8366,  0.3443,  0.2814,  ..., -0.4514,  0.1483, -0.8120],\n",
      "          [-0.5664,  0.4192,  0.2226,  ..., -0.1082,  0.2879, -0.3467],\n",
      "          [-0.5744,  0.3669,  0.1790,  ..., -0.6403,  0.2039, -0.5229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3757, -0.0427, -0.1119,  ...,  0.3509,  0.1595,  0.4888],\n",
      "          [ 0.2903,  0.6187,  0.4534,  ...,  0.2541,  0.3888,  0.4550],\n",
      "          [ 0.2148,  0.3087, -0.2417,  ...,  0.1432, -0.1318, -0.2453],\n",
      "          ...,\n",
      "          [ 0.4803,  0.7765,  0.3536,  ...,  0.2843,  0.1827,  0.5633],\n",
      "          [-0.0493, -0.1980,  0.3237,  ...,  0.0605,  0.0484,  0.1742],\n",
      "          [ 0.3331,  0.4401,  0.1692,  ...,  0.3952,  0.2085,  0.7248]],\n",
      "\n",
      "         [[-0.6326,  0.3387,  0.2329,  ..., -0.1412,  0.0303, -0.3268],\n",
      "          [-0.3115,  0.2469,  0.3095,  ..., -0.2260, -0.2169, -0.3649],\n",
      "          [-0.5411, -0.0288, -0.1352,  ...,  0.1394,  0.3197, -0.1711],\n",
      "          ...,\n",
      "          [-0.5287,  0.5403,  0.0905,  ..., -0.5307,  0.2307, -0.9366],\n",
      "          [-0.3287,  0.3033,  0.2650,  ..., -0.2727, -0.2422, -0.1826],\n",
      "          [-0.4723,  0.3575,  0.0502,  ..., -0.6837,  0.0168, -0.5224]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          ...,\n",
      "          [-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823]],\n",
      "\n",
      "         [[-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481],\n",
      "          ...,\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          ...,\n",
      "          [ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763]],\n",
      "\n",
      "         [[-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975],\n",
      "          ...,\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-0.2758, -0.5941,  0.2351,  ..., -0.3862,  0.0205, -0.2258],\n",
      "          [-0.3353, -0.2397,  0.6779,  ..., -0.5615, -0.3808,  0.4416]],\n",
      "\n",
      "         [[-0.2496, -0.5094,  0.2333,  ..., -0.3383, -0.0482, -0.2088],\n",
      "          [-0.2858, -0.2394,  0.5574,  ..., -0.4263, -0.3591,  0.3679]],\n",
      "\n",
      "         [[-0.3032, -0.5215,  0.2655,  ..., -0.4001, -0.0570, -0.2281],\n",
      "          [-0.2479, -0.1984,  0.4890,  ..., -0.3964, -0.3257,  0.3481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3189, -0.5707,  0.2672,  ..., -0.4202, -0.0247, -0.2531],\n",
      "          [-0.2784, -0.2354,  0.5566,  ..., -0.4292, -0.3262,  0.3669]],\n",
      "\n",
      "         [[-0.2781, -0.5317,  0.2490,  ..., -0.3956, -0.0192, -0.2304],\n",
      "          [-0.2628, -0.2093,  0.5165,  ..., -0.4196, -0.3341,  0.3648]],\n",
      "\n",
      "         [[-0.1459, -0.2167,  0.1375,  ..., -0.1718, -0.1252, -0.0823],\n",
      "          [-0.2592, -0.1913,  0.5315,  ..., -0.4015, -0.3068,  0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0308, -0.2455,  ...,  0.1058, -0.3281,  0.0762],\n",
      "          [-0.0518, -0.0820,  0.1253,  ..., -0.2093, -0.0266, -0.0607]],\n",
      "\n",
      "         [[ 0.0135, -0.0344, -0.1018,  ...,  0.0196, -0.2778, -0.0611],\n",
      "          [-0.0429, -0.0932,  0.1318,  ..., -0.1433, -0.0561, -0.0932]],\n",
      "\n",
      "         [[-0.0324, -0.0698, -0.0526,  ..., -0.0168, -0.2340, -0.1025],\n",
      "          [-0.0980, -0.1178,  0.1453,  ..., -0.1517, -0.0496, -0.0975]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0238, -0.0511, -0.0334,  ..., -0.0499, -0.1925, -0.0031],\n",
      "          [-0.0379, -0.0845,  0.1032,  ..., -0.1740, -0.0439, -0.0635]],\n",
      "\n",
      "         [[-0.0260, -0.0534, -0.0582,  ..., -0.0092, -0.2456, -0.0967],\n",
      "          [-0.0675, -0.1113,  0.1539,  ..., -0.1649, -0.0466, -0.0879]],\n",
      "\n",
      "         [[ 0.0271, -0.0065, -0.1015,  ...,  0.0299, -0.2644, -0.0763],\n",
      "          [-0.1359, -0.1529,  0.2387,  ..., -0.1934, -0.1585,  0.0201]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.1998, -0.0492,  0.1704,  ..., -0.0182, -0.0138,  0.0050],\n",
      "         [-0.2753, -0.1305, -0.0961,  ...,  0.0413, -0.1132, -0.1466],\n",
      "         [ 0.1170,  0.0336,  0.3790,  ..., -0.0550,  0.1022, -0.1405],\n",
      "         ...,\n",
      "         [-0.5597, -0.3598, -0.0646,  ..., -0.1400, -0.3268, -0.0950],\n",
      "         [ 0.2002, -0.1351,  0.1219,  ...,  0.1461, -0.0429, -0.2517],\n",
      "         [ 0.0065, -0.1909, -0.1553,  ..., -0.5745, -0.1885, -0.2061]],\n",
      "\n",
      "        [[ 0.0402, -0.0764,  0.3462,  ...,  0.0479, -0.3367, -0.2530],\n",
      "         [-0.1708, -0.2757, -0.0735,  ..., -0.1939, -0.2058,  0.4364],\n",
      "         [-0.2007, -0.2209, -0.1836,  ..., -0.1811, -0.4636, -0.0044],\n",
      "         ...,\n",
      "         [-0.4694, -0.2780, -0.1995,  ..., -0.1188, -0.0901, -0.2336],\n",
      "         [-0.1029, -0.0909, -0.0263,  ...,  0.1983, -0.1768, -0.4357],\n",
      "         [ 0.0498, -0.3091, -0.1398,  ..., -0.4151, -0.3447, -0.1681]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1998, -0.0492,  0.1704,  ..., -0.0182, -0.0138,  0.0050],\n",
      "         [-0.2753, -0.1305, -0.0961,  ...,  0.0413, -0.1132, -0.1466],\n",
      "         [ 0.1170,  0.0336,  0.3790,  ..., -0.0550,  0.1022, -0.1405],\n",
      "         ...,\n",
      "         [-0.5597, -0.3598, -0.0646,  ..., -0.1400, -0.3268, -0.0950],\n",
      "         [ 0.2002, -0.1351,  0.1219,  ...,  0.1461, -0.0429, -0.2517],\n",
      "         [ 0.0065, -0.1909, -0.1553,  ..., -0.5745, -0.1885, -0.2061]],\n",
      "\n",
      "        [[ 0.0402, -0.0764,  0.3462,  ...,  0.0479, -0.3367, -0.2530],\n",
      "         [-0.1708, -0.2757, -0.0735,  ..., -0.1939, -0.2058,  0.4364],\n",
      "         [-0.2007, -0.2209, -0.1836,  ..., -0.1811, -0.4636, -0.0044],\n",
      "         ...,\n",
      "         [-0.4694, -0.2780, -0.1995,  ..., -0.1188, -0.0901, -0.2336],\n",
      "         [-0.1029, -0.0909, -0.0263,  ...,  0.1983, -0.1768, -0.4357],\n",
      "         [ 0.0498, -0.3091, -0.1398,  ..., -0.4151, -0.3447, -0.1681]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1998, -0.0492,  0.1704,  ...,  0.2896,  0.2818, -0.0936],\n",
      "          [ 0.1407, -0.4252, -0.3599,  ..., -0.0182, -0.0138,  0.0050]],\n",
      "\n",
      "         [[-0.2753, -0.1305, -0.0961,  ...,  0.3364,  0.3078, -0.0219],\n",
      "          [ 0.1890, -0.4718,  0.0787,  ...,  0.0413, -0.1132, -0.1466]],\n",
      "\n",
      "         [[ 0.1170,  0.0336,  0.3790,  ..., -0.0487,  0.0223,  0.1957],\n",
      "          [ 0.1070, -0.3517, -0.0592,  ..., -0.0550,  0.1022, -0.1405]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5597, -0.3598, -0.0646,  ...,  0.5059,  0.3813, -0.4893],\n",
      "          [ 0.4687, -0.5261, -0.1589,  ..., -0.1400, -0.3268, -0.0950]],\n",
      "\n",
      "         [[ 0.2002, -0.1351,  0.1219,  ...,  0.0455,  0.4077, -0.1724],\n",
      "          [-0.2069, -0.3860, -0.0706,  ...,  0.1461, -0.0429, -0.2517]],\n",
      "\n",
      "         [[ 0.0065, -0.1909, -0.1553,  ...,  0.7116,  0.4819, -0.1424],\n",
      "          [ 0.1932, -0.3805, -0.0803,  ..., -0.5745, -0.1885, -0.2061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402, -0.0764,  0.3462,  ...,  0.2967,  0.2689, -0.0847],\n",
      "          [ 0.1255, -0.3033, -0.1726,  ...,  0.0479, -0.3367, -0.2530]],\n",
      "\n",
      "         [[-0.1708, -0.2757, -0.0735,  ...,  0.2265,  0.2773,  0.0958],\n",
      "          [ 0.5640, -0.2326,  0.4416,  ..., -0.1939, -0.2058,  0.4364]],\n",
      "\n",
      "         [[-0.2007, -0.2209, -0.1836,  ...,  0.2124,  0.4810,  0.0224],\n",
      "          [ 0.0898, -0.4393,  0.0926,  ..., -0.1811, -0.4636, -0.0044]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4694, -0.2780, -0.1995,  ...,  0.6065,  0.4522, -0.2148],\n",
      "          [ 0.2732, -0.1441, -0.1055,  ..., -0.1188, -0.0901, -0.2336]],\n",
      "\n",
      "         [[-0.1029, -0.0909, -0.0263,  ...,  0.0044,  0.4540, -0.1078],\n",
      "          [-0.1095, -0.0759,  0.0675,  ...,  0.1983, -0.1768, -0.4357]],\n",
      "\n",
      "         [[ 0.0498, -0.3091, -0.1398,  ...,  0.6637,  0.5062, -0.2416],\n",
      "          [ 0.2306, -0.3508, -0.0361,  ..., -0.4151, -0.3447, -0.1681]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  4.6112e-01,\n",
      "          -7.5638e-01,  9.8061e-01],\n",
      "         [ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  2.7140e-01,\n",
      "          -1.1380e+00,  7.4050e-01],\n",
      "         [ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  5.8941e-01,\n",
      "          -8.1991e-01,  9.2370e-01],\n",
      "         ...,\n",
      "         [ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  4.3437e-01,\n",
      "          -8.8962e-01,  7.8859e-01],\n",
      "         [ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  8.3289e-01,\n",
      "          -1.1972e+00,  1.3268e+00],\n",
      "         [ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ..., -3.2599e-02,\n",
      "          -6.5663e-01,  4.3323e-01]],\n",
      "\n",
      "        [[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.3611e-01,\n",
      "           5.5846e-01, -8.6070e-04],\n",
      "         [-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.7178e-01,\n",
      "           4.1499e-01, -4.1224e-01],\n",
      "         [ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  5.9711e-01,\n",
      "          -5.0567e-01,  6.0095e-01],\n",
      "         ...,\n",
      "         [ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.6203e-01,\n",
      "          -2.1623e-01, -7.5460e-02],\n",
      "         [ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ..., -1.4295e-01,\n",
      "           1.9976e-01,  3.7237e-01],\n",
      "         [ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ..., -2.8518e-01,\n",
      "          -2.8311e-01,  6.4090e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  4.6112e-01,\n",
      "          -7.5638e-01,  9.8061e-01],\n",
      "         [ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  2.7140e-01,\n",
      "          -1.1380e+00,  7.4050e-01],\n",
      "         [ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  5.8941e-01,\n",
      "          -8.1991e-01,  9.2370e-01],\n",
      "         ...,\n",
      "         [ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  4.3437e-01,\n",
      "          -8.8962e-01,  7.8859e-01],\n",
      "         [ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  8.3289e-01,\n",
      "          -1.1972e+00,  1.3268e+00],\n",
      "         [ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ..., -3.2599e-02,\n",
      "          -6.5663e-01,  4.3323e-01]],\n",
      "\n",
      "        [[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.3611e-01,\n",
      "           5.5846e-01, -8.6070e-04],\n",
      "         [-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.7178e-01,\n",
      "           4.1499e-01, -4.1224e-01],\n",
      "         [ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  5.9711e-01,\n",
      "          -5.0567e-01,  6.0095e-01],\n",
      "         ...,\n",
      "         [ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.6203e-01,\n",
      "          -2.1623e-01, -7.5460e-02],\n",
      "         [ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ..., -1.4295e-01,\n",
      "           1.9976e-01,  3.7237e-01],\n",
      "         [ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ..., -2.8518e-01,\n",
      "          -2.8311e-01,  6.4090e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 8.4935e-01, -2.8101e-01,  3.4078e-01,  ...,  6.0637e-01,\n",
      "            2.9660e-01,  5.3929e-01],\n",
      "          [ 5.0486e-01, -2.7842e-02, -6.5914e-01,  ...,  4.6112e-01,\n",
      "           -7.5638e-01,  9.8061e-01]],\n",
      "\n",
      "         [[ 7.7353e-01, -6.4134e-01,  3.8786e-01,  ...,  7.8334e-01,\n",
      "            4.7901e-01,  2.3453e-01],\n",
      "          [ 3.5756e-01, -1.4846e-01, -2.6880e-01,  ...,  2.7140e-01,\n",
      "           -1.1380e+00,  7.4050e-01]],\n",
      "\n",
      "         [[ 9.4815e-01, -4.6097e-01,  6.7650e-01,  ...,  1.0635e+00,\n",
      "            4.9203e-01,  3.5024e-01],\n",
      "          [ 8.6026e-01, -4.3695e-02, -7.7887e-01,  ...,  5.8941e-01,\n",
      "           -8.1991e-01,  9.2370e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.3835e-01, -2.5400e-01,  6.9985e-01,  ...,  9.2902e-01,\n",
      "            4.5886e-01,  5.3908e-01],\n",
      "          [ 5.4190e-01, -2.1326e-01, -9.7762e-01,  ...,  4.3437e-01,\n",
      "           -8.8962e-01,  7.8859e-01]],\n",
      "\n",
      "         [[ 1.2960e+00, -4.8375e-01,  6.1042e-01,  ...,  1.5239e+00,\n",
      "            1.1062e+00,  2.9111e-01],\n",
      "          [ 8.2067e-01,  2.3693e-01, -1.2690e+00,  ...,  8.3289e-01,\n",
      "           -1.1972e+00,  1.3268e+00]],\n",
      "\n",
      "         [[ 7.0386e-01, -4.7481e-01,  6.0250e-01,  ...,  4.1001e-01,\n",
      "            1.2279e-01,  7.4559e-01],\n",
      "          [ 3.8943e-01,  4.4695e-01, -4.9236e-01,  ..., -3.2599e-02,\n",
      "           -6.5663e-01,  4.3323e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8049e-01, -5.6058e-01, -2.9847e-01,  ..., -4.5675e-01,\n",
      "           -1.6733e-02,  3.6960e-01],\n",
      "          [-3.3146e-01,  3.0133e-01,  2.8925e-01,  ..., -4.3611e-01,\n",
      "            5.5846e-01, -8.6070e-04]],\n",
      "\n",
      "         [[-5.7705e-01,  4.9795e-02, -3.5229e-01,  ..., -8.6803e-01,\n",
      "           -8.4436e-01, -1.9562e-02],\n",
      "          [-5.9253e-01,  2.6408e-01,  9.7901e-01,  ..., -8.7178e-01,\n",
      "            4.1499e-01, -4.1224e-01]],\n",
      "\n",
      "         [[ 8.6146e-01, -4.2017e-01,  5.0561e-01,  ...,  7.6141e-01,\n",
      "            6.7468e-01, -3.2842e-02],\n",
      "          [ 7.0920e-01,  9.6323e-03, -7.3328e-01,  ...,  5.9711e-01,\n",
      "           -5.0567e-01,  6.0095e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4699e-02, -3.6731e-01,  1.2328e-03,  ..., -2.1628e-01,\n",
      "            5.6547e-02,  1.5069e-01],\n",
      "          [ 1.0911e-01,  9.9595e-02, -1.6898e-01,  ..., -2.6203e-01,\n",
      "           -2.1623e-01, -7.5460e-02]],\n",
      "\n",
      "         [[ 1.7333e-01, -5.8414e-01,  6.4227e-03,  ...,  3.8057e-02,\n",
      "            3.6087e-02,  2.5329e-01],\n",
      "          [-1.9962e-01,  4.2818e-01,  1.8055e-01,  ..., -1.4295e-01,\n",
      "            1.9976e-01,  3.7237e-01]],\n",
      "\n",
      "         [[ 2.9735e-01, -5.6831e-01,  3.6124e-01,  ...,  1.0197e-01,\n",
      "            1.2834e-01,  6.0884e-01],\n",
      "          [ 1.6712e-01,  4.4049e-01, -7.3379e-02,  ..., -2.8518e-01,\n",
      "           -2.8311e-01,  6.4090e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.7213,  0.6297,  0.5673,  ...,  0.3995,  1.1203, -0.0572],\n",
      "         [ 0.4206,  0.1975,  0.3131,  ...,  0.0317,  0.6958,  0.2779],\n",
      "         [ 0.2541, -0.0934,  0.0590,  ..., -0.0778,  0.4074,  0.0889],\n",
      "         ...,\n",
      "         [ 0.4621, -0.2040,  0.6867,  ..., -0.3795,  0.2415,  0.0353],\n",
      "         [ 0.5789, -0.0802,  0.2609,  ..., -0.0901,  0.6126,  0.0705],\n",
      "         [ 0.4489,  0.2019,  0.6433,  ..., -0.3271,  0.4822, -0.2029]],\n",
      "\n",
      "        [[ 0.8560,  0.9752,  0.4722,  ...,  0.7999,  1.1313,  0.0475],\n",
      "         [ 0.3273,  0.8255,  0.2869,  ...,  0.1259,  0.2765, -0.0776],\n",
      "         [ 0.0195, -0.1437,  0.2610,  ..., -0.0494,  0.1685,  0.4577],\n",
      "         ...,\n",
      "         [ 0.2552, -0.0059,  0.4817,  ..., -0.6154,  0.2123,  0.3384],\n",
      "         [ 0.5519,  0.4349,  0.0524,  ..., -0.0831,  0.4730,  0.2290],\n",
      "         [ 0.3849,  0.2771,  0.5413,  ..., -0.4655,  0.3637, -0.1254]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.7213,  0.6297,  0.5673,  ...,  0.3995,  1.1203, -0.0572],\n",
      "         [ 0.4206,  0.1975,  0.3131,  ...,  0.0317,  0.6958,  0.2779],\n",
      "         [ 0.2541, -0.0934,  0.0590,  ..., -0.0778,  0.4074,  0.0889],\n",
      "         ...,\n",
      "         [ 0.4621, -0.2040,  0.6867,  ..., -0.3795,  0.2415,  0.0353],\n",
      "         [ 0.5789, -0.0802,  0.2609,  ..., -0.0901,  0.6126,  0.0705],\n",
      "         [ 0.4489,  0.2019,  0.6433,  ..., -0.3271,  0.4822, -0.2029]],\n",
      "\n",
      "        [[ 0.8560,  0.9752,  0.4722,  ...,  0.7999,  1.1313,  0.0475],\n",
      "         [ 0.3273,  0.8255,  0.2869,  ...,  0.1259,  0.2765, -0.0776],\n",
      "         [ 0.0195, -0.1437,  0.2610,  ..., -0.0494,  0.1685,  0.4577],\n",
      "         ...,\n",
      "         [ 0.2552, -0.0059,  0.4817,  ..., -0.6154,  0.2123,  0.3384],\n",
      "         [ 0.5519,  0.4349,  0.0524,  ..., -0.0831,  0.4730,  0.2290],\n",
      "         [ 0.3849,  0.2771,  0.5413,  ..., -0.4655,  0.3637, -0.1254]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.7213,  0.6297,  0.5673,  ..., -0.2608, -0.3044,  0.8183],\n",
      "          [-0.5755,  0.3248, -0.3229,  ...,  0.3995,  1.1203, -0.0572]],\n",
      "\n",
      "         [[ 0.4206,  0.1975,  0.3131,  ..., -0.1100,  0.1019,  0.6790],\n",
      "          [-0.1955,  0.1772,  0.0610,  ...,  0.0317,  0.6958,  0.2779]],\n",
      "\n",
      "         [[ 0.2541, -0.0934,  0.0590,  ...,  0.1269,  0.2680,  0.1310],\n",
      "          [-0.3885,  0.1387,  0.0064,  ..., -0.0778,  0.4074,  0.0889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4621, -0.2040,  0.6867,  ..., -0.1656, -0.1699,  0.1978],\n",
      "          [-0.2866, -0.1075, -0.0984,  ..., -0.3795,  0.2415,  0.0353]],\n",
      "\n",
      "         [[ 0.5789, -0.0802,  0.2609,  ...,  0.0108,  0.0599,  0.3440],\n",
      "          [-0.4651,  0.1209, -0.0414,  ..., -0.0901,  0.6126,  0.0705]],\n",
      "\n",
      "         [[ 0.4489,  0.2019,  0.6433,  ..., -0.2327, -0.1523,  0.3516],\n",
      "          [-0.6129,  0.0245,  0.2220,  ..., -0.3271,  0.4822, -0.2029]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8560,  0.9752,  0.4722,  ..., -0.8492, -0.5672,  1.1538],\n",
      "          [-0.6817,  0.9302, -0.4828,  ...,  0.7999,  1.1313,  0.0475]],\n",
      "\n",
      "         [[ 0.3273,  0.8255,  0.2869,  ..., -0.2090, -0.4673,  0.6375],\n",
      "          [-0.0345,  0.0667, -0.0854,  ...,  0.1259,  0.2765, -0.0776]],\n",
      "\n",
      "         [[ 0.0195, -0.1437,  0.2610,  ..., -0.0181,  0.1530,  0.0448],\n",
      "          [-0.2625,  0.2047, -0.1007,  ..., -0.0494,  0.1685,  0.4577]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2552, -0.0059,  0.4817,  ...,  0.2947, -0.2042,  0.3148],\n",
      "          [-0.3176,  0.1558, -0.2427,  ..., -0.6154,  0.2123,  0.3384]],\n",
      "\n",
      "         [[ 0.5519,  0.4349,  0.0524,  ..., -0.2111,  0.2902,  0.2238],\n",
      "          [-0.3923,  0.3489, -0.3004,  ..., -0.0831,  0.4730,  0.2290]],\n",
      "\n",
      "         [[ 0.3849,  0.2771,  0.5413,  ..., -0.3430, -0.0552,  0.3365],\n",
      "          [-0.5326,  0.0237,  0.1370,  ..., -0.4655,  0.3637, -0.1254]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1998, -0.0492,  0.1704,  ...,  0.2896,  0.2818, -0.0936],\n",
      "          [-0.2753, -0.1305, -0.0961,  ...,  0.3364,  0.3078, -0.0219],\n",
      "          [ 0.1170,  0.0336,  0.3790,  ..., -0.0487,  0.0223,  0.1957],\n",
      "          ...,\n",
      "          [-0.5597, -0.3598, -0.0646,  ...,  0.5059,  0.3813, -0.4893],\n",
      "          [ 0.2002, -0.1351,  0.1219,  ...,  0.0455,  0.4077, -0.1724],\n",
      "          [ 0.0065, -0.1909, -0.1553,  ...,  0.7116,  0.4819, -0.1424]],\n",
      "\n",
      "         [[ 0.1407, -0.4252, -0.3599,  ..., -0.0182, -0.0138,  0.0050],\n",
      "          [ 0.1890, -0.4718,  0.0787,  ...,  0.0413, -0.1132, -0.1466],\n",
      "          [ 0.1070, -0.3517, -0.0592,  ..., -0.0550,  0.1022, -0.1405],\n",
      "          ...,\n",
      "          [ 0.4687, -0.5261, -0.1589,  ..., -0.1400, -0.3268, -0.0950],\n",
      "          [-0.2069, -0.3860, -0.0706,  ...,  0.1461, -0.0429, -0.2517],\n",
      "          [ 0.1932, -0.3805, -0.0803,  ..., -0.5745, -0.1885, -0.2061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402, -0.0764,  0.3462,  ...,  0.2967,  0.2689, -0.0847],\n",
      "          [-0.1708, -0.2757, -0.0735,  ...,  0.2265,  0.2773,  0.0958],\n",
      "          [-0.2007, -0.2209, -0.1836,  ...,  0.2124,  0.4810,  0.0224],\n",
      "          ...,\n",
      "          [-0.4694, -0.2780, -0.1995,  ...,  0.6065,  0.4522, -0.2148],\n",
      "          [-0.1029, -0.0909, -0.0263,  ...,  0.0044,  0.4540, -0.1078],\n",
      "          [ 0.0498, -0.3091, -0.1398,  ...,  0.6637,  0.5062, -0.2416]],\n",
      "\n",
      "         [[ 0.1255, -0.3033, -0.1726,  ...,  0.0479, -0.3367, -0.2530],\n",
      "          [ 0.5640, -0.2326,  0.4416,  ..., -0.1939, -0.2058,  0.4364],\n",
      "          [ 0.0898, -0.4393,  0.0926,  ..., -0.1811, -0.4636, -0.0044],\n",
      "          ...,\n",
      "          [ 0.2732, -0.1441, -0.1055,  ..., -0.1188, -0.0901, -0.2336],\n",
      "          [-0.1095, -0.0759,  0.0675,  ...,  0.1983, -0.1768, -0.4357],\n",
      "          [ 0.2306, -0.3508, -0.0361,  ..., -0.4151, -0.3447, -0.1681]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          ...,\n",
      "          [ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01]],\n",
      "\n",
      "         [[ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01],\n",
      "          ...,\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          ...,\n",
      "          [-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01]],\n",
      "\n",
      "         [[-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02],\n",
      "          ...,\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.8484e-01, -4.1507e-01,  5.3920e-01,  ...,  1.0372e+00,\n",
      "            5.8603e-01,  3.9364e-01],\n",
      "          [ 6.9246e-01,  2.6341e-02, -7.6674e-01,  ...,  4.9366e-01,\n",
      "           -9.5384e-01,  8.3539e-01]],\n",
      "\n",
      "         [[ 9.3824e-01, -4.0011e-01,  5.2825e-01,  ...,  9.6639e-01,\n",
      "            5.2724e-01,  4.2696e-01],\n",
      "          [ 6.7977e-01,  2.4470e-02, -7.8915e-01,  ...,  4.6113e-01,\n",
      "           -9.7266e-01,  8.4834e-01]],\n",
      "\n",
      "         [[ 7.9895e-01, -3.3044e-01,  4.3074e-01,  ...,  8.0424e-01,\n",
      "            4.5579e-01,  3.8056e-01],\n",
      "          [ 6.8021e-01,  1.9065e-02, -7.9305e-01,  ...,  4.6085e-01,\n",
      "           -9.7509e-01,  8.5245e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5202e-01, -2.4266e-01,  3.9674e-01,  ...,  6.1524e-01,\n",
      "            3.1088e-01,  3.3763e-01],\n",
      "          [ 6.7718e-01,  1.2481e-02, -7.8837e-01,  ...,  4.5616e-01,\n",
      "           -9.7376e-01,  8.4530e-01]],\n",
      "\n",
      "         [[ 7.9111e-01, -3.2786e-01,  4.2512e-01,  ...,  7.9371e-01,\n",
      "            4.4785e-01,  3.7955e-01],\n",
      "          [ 6.8195e-01,  1.4445e-02, -7.9277e-01,  ...,  4.6337e-01,\n",
      "           -9.7507e-01,  8.5189e-01]],\n",
      "\n",
      "         [[ 8.4977e-01, -3.7310e-01,  4.9610e-01,  ...,  8.9636e-01,\n",
      "            4.9216e-01,  3.7837e-01],\n",
      "          [ 5.9652e-01,  5.5681e-02, -7.0525e-01,  ...,  4.0927e-01,\n",
      "           -8.9104e-01,  7.7132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5168e-01, -4.3977e-01, -1.4186e-01,  ..., -9.0311e-02,\n",
      "           -1.9107e-01,  2.7327e-01],\n",
      "          [-3.8955e-02,  1.8041e-01,  1.2050e-01,  ..., -1.0336e-01,\n",
      "            6.4890e-02, -5.5548e-02]],\n",
      "\n",
      "         [[-8.4277e-02, -2.5887e-01, -3.5675e-02,  ..., -8.1606e-03,\n",
      "           -9.9269e-02,  1.8374e-01],\n",
      "          [-1.2410e-01,  2.9369e-01,  2.2930e-01,  ..., -2.9238e-01,\n",
      "            3.6749e-02, -5.4673e-02]],\n",
      "\n",
      "         [[ 2.5363e-02, -3.6630e-01,  7.1934e-03,  ...,  5.2284e-02,\n",
      "           -2.7165e-02,  2.2954e-01],\n",
      "          [-4.8082e-02,  2.6541e-01,  1.1084e-01,  ..., -1.9535e-01,\n",
      "           -4.2151e-02,  2.1264e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4428e-01, -3.6564e-01, -7.2301e-02,  ..., -1.3565e-01,\n",
      "           -1.2402e-01,  1.9550e-01],\n",
      "          [-9.8611e-02,  2.8698e-01,  1.9243e-01,  ..., -2.6875e-01,\n",
      "            6.4028e-04, -1.4493e-02]],\n",
      "\n",
      "         [[-1.2704e-01, -3.7050e-01, -7.4072e-02,  ..., -1.4223e-01,\n",
      "           -1.0658e-01,  2.0505e-01],\n",
      "          [-8.1284e-02,  2.3413e-01,  1.8160e-01,  ..., -2.5541e-01,\n",
      "           -6.5790e-03, -7.4586e-02]],\n",
      "\n",
      "         [[ 1.1103e-01, -3.2237e-01,  2.1050e-02,  ...,  2.6418e-02,\n",
      "            3.4833e-02,  2.0522e-01],\n",
      "          [-4.3662e-02,  2.2442e-01,  6.3684e-02,  ..., -1.4870e-01,\n",
      "           -5.1647e-02,  1.1695e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.4084,  1.8033],\n",
      "        [ 0.9294, -1.1636]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.312000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:44:00,421] Trial 5 finished with value: 0.864 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 512, 'linear_layer_type': 'linear'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          ...,\n",
      "          [ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678],\n",
      "          ...,\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          ...,\n",
      "          [ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757],\n",
      "          ...,\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          ...,\n",
      "          [ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00]],\n",
      "\n",
      "         [[-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01],\n",
      "          ...,\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          ...,\n",
      "          [ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00]],\n",
      "\n",
      "         [[-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00],\n",
      "          ...,\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          ...,\n",
      "          [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01]],\n",
      "\n",
      "         [[-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01],\n",
      "          ...,\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          ...,\n",
      "          [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00]],\n",
      "\n",
      "         [[-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00],\n",
      "          ...,\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          ...,\n",
      "          [ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584]],\n",
      "\n",
      "         [[-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470],\n",
      "          ...,\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          ...,\n",
      "          [ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641]],\n",
      "\n",
      "         [[-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474],\n",
      "          ...,\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.9553,  0.7356],\n",
      "        [-0.0274, -0.0352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:48:21,046] Trial 6 finished with value: 0.84976 and parameters: {'num_layers': 2, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 128\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.2659,  0.4272, -1.3139,  ...,  1.4461, -1.0464,  0.4877],\n",
      "          [ 0.0000,  0.3272,  1.6046,  ..., -0.0768, -0.4271, -0.0608]],\n",
      "\n",
      "         [[-0.0000,  0.5798, -0.2715,  ...,  2.3739, -1.2629, -0.4552],\n",
      "          [-0.0340, -0.9512,  0.8167,  ...,  2.3688,  0.6403, -1.8196]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1143, -0.3011, -0.0608,  ...,  1.1592, -1.4771, -0.2220],\n",
      "          [ 1.0215, -1.5798, -0.5665,  ...,  0.0000, -0.5870,  2.2435]],\n",
      "\n",
      "         [[ 0.1384, -0.1416,  1.2766,  ...,  0.1817, -0.4372,  0.7720],\n",
      "          [ 0.9171, -0.1398,  1.6818,  ..., -0.0973,  1.4750, -0.7389]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.1275, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  1.9811, -0.3992]],\n",
      "\n",
      "         [[ 0.0000, -0.2131, -0.5634,  ...,  1.4880,  0.9518,  0.0000],\n",
      "          [-0.2848,  1.1513,  0.9230,  ..., -0.0000, -0.1279, -1.2541]],\n",
      "\n",
      "         [[ 0.8617, -0.3897, -0.9880,  ...,  1.7804, -2.0196, -0.3396],\n",
      "          [-0.2326,  0.4093,  1.6599,  ...,  1.2307,  0.3701, -1.0987]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3237, -0.8681, -0.2772,  ...,  1.6197, -1.4788, -0.0787],\n",
      "          [ 0.7752, -1.6474,  0.2966,  ..., -0.7913,  0.8603,  1.3509]],\n",
      "\n",
      "         [[ 0.0614, -0.0000,  1.1898,  ...,  0.3437,  0.3921,  0.5027],\n",
      "          [-0.0156, -1.6922,  2.4115,  ...,  0.6107, -0.4553, -0.6483]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.0000, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.1296]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.2659,  0.4272, -1.3139,  ...,  1.4461, -1.0464,  0.4877],\n",
      "          [ 0.0000,  0.3272,  1.6046,  ..., -0.0768, -0.4271, -0.0608]],\n",
      "\n",
      "         [[-0.0000,  0.5798, -0.2715,  ...,  2.3739, -1.2629, -0.4552],\n",
      "          [-0.0340, -0.9512,  0.8167,  ...,  2.3688,  0.6403, -1.8196]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1143, -0.3011, -0.0608,  ...,  1.1592, -1.4771, -0.2220],\n",
      "          [ 1.0215, -1.5798, -0.5665,  ...,  0.0000, -0.5870,  2.2435]],\n",
      "\n",
      "         [[ 0.1384, -0.1416,  1.2766,  ...,  0.1817, -0.4372,  0.7720],\n",
      "          [ 0.9171, -0.1398,  1.6818,  ..., -0.0973,  1.4750, -0.7389]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.1275, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  1.9811, -0.3992]],\n",
      "\n",
      "         [[ 0.0000, -0.2131, -0.5634,  ...,  1.4880,  0.9518,  0.0000],\n",
      "          [-0.2848,  1.1513,  0.9230,  ..., -0.0000, -0.1279, -1.2541]],\n",
      "\n",
      "         [[ 0.8617, -0.3897, -0.9880,  ...,  1.7804, -2.0196, -0.3396],\n",
      "          [-0.2326,  0.4093,  1.6599,  ...,  1.2307,  0.3701, -1.0987]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3237, -0.8681, -0.2772,  ...,  1.6197, -1.4788, -0.0787],\n",
      "          [ 0.7752, -1.6474,  0.2966,  ..., -0.7913,  0.8603,  1.3509]],\n",
      "\n",
      "         [[ 0.0614, -0.0000,  1.1898,  ...,  0.3437,  0.3921,  0.5027],\n",
      "          [-0.0156, -1.6922,  2.4115,  ...,  0.6107, -0.4553, -0.6483]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.0000, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.1296]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  0.0000, -0.0000],\n",
      "         [-0.2659,  0.4272, -1.3139,  ..., -0.0768, -0.4271, -0.0608],\n",
      "         [-0.0000,  0.5798, -0.2715,  ...,  2.3688,  0.6403, -1.8196],\n",
      "         ...,\n",
      "         [ 0.1143, -0.3011, -0.0608,  ...,  0.0000, -0.5870,  2.2435],\n",
      "         [ 0.1384, -0.1416,  1.2766,  ..., -0.0973,  1.4750, -0.7389],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.0000]],\n",
      "\n",
      "        [[ 0.0975, -0.5597, -0.6027,  ..., -1.2032,  1.9811, -0.3992],\n",
      "         [ 0.0000, -0.2131, -0.5634,  ..., -0.0000, -0.1279, -1.2541],\n",
      "         [ 0.8617, -0.3897, -0.9880,  ...,  1.2307,  0.3701, -1.0987],\n",
      "         ...,\n",
      "         [ 0.3237, -0.8681, -0.2772,  ..., -0.7913,  0.8603,  1.3509],\n",
      "         [ 0.0614, -0.0000,  1.1898,  ...,  0.6107, -0.4553, -0.6483],\n",
      "         [-0.4462, -0.8496, -0.7679,  ..., -0.7456, -0.0167, -0.1296]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.2659,  0.4272, -1.3139,  ...,  1.4461, -1.0464,  0.4877],\n",
      "          [ 0.0000,  0.3272,  1.6046,  ..., -0.0768, -0.4271, -0.0608]],\n",
      "\n",
      "         [[-0.0000,  0.5798, -0.2715,  ...,  2.3739, -1.2629, -0.4552],\n",
      "          [-0.0340, -0.9512,  0.8167,  ...,  2.3688,  0.6403, -1.8196]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1143, -0.3011, -0.0608,  ...,  1.1592, -1.4771, -0.2220],\n",
      "          [ 1.0215, -1.5798, -0.5665,  ...,  0.0000, -0.5870,  2.2435]],\n",
      "\n",
      "         [[ 0.1384, -0.1416,  1.2766,  ...,  0.1817, -0.4372,  0.7720],\n",
      "          [ 0.9171, -0.1398,  1.6818,  ..., -0.0973,  1.4750, -0.7389]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.1275, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  1.9811, -0.3992]],\n",
      "\n",
      "         [[ 0.0000, -0.2131, -0.5634,  ...,  1.4880,  0.9518,  0.0000],\n",
      "          [-0.2848,  1.1513,  0.9230,  ..., -0.0000, -0.1279, -1.2541]],\n",
      "\n",
      "         [[ 0.8617, -0.3897, -0.9880,  ...,  1.7804, -2.0196, -0.3396],\n",
      "          [-0.2326,  0.4093,  1.6599,  ...,  1.2307,  0.3701, -1.0987]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3237, -0.8681, -0.2772,  ...,  1.6197, -1.4788, -0.0787],\n",
      "          [ 0.7752, -1.6474,  0.2966,  ..., -0.7913,  0.8603,  1.3509]],\n",
      "\n",
      "         [[ 0.0614, -0.0000,  1.1898,  ...,  0.3437,  0.3921,  0.5027],\n",
      "          [-0.0156, -1.6922,  2.4115,  ...,  0.6107, -0.4553, -0.6483]],\n",
      "\n",
      "         [[-0.4462, -0.8496, -0.7679,  ...,  0.0000, -0.0000,  1.2419],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.1296]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [-0.2659,  0.4272, -1.3139,  ...,  1.4461, -1.0464,  0.4877],\n",
      "          [-0.0000,  0.5798, -0.2715,  ...,  2.3739, -1.2629, -0.4552],\n",
      "          ...,\n",
      "          [ 0.1143, -0.3011, -0.0608,  ...,  1.1592, -1.4771, -0.2220],\n",
      "          [ 0.1384, -0.1416,  1.2766,  ...,  0.1817, -0.4372,  0.7720],\n",
      "          [-0.4462, -0.8496, -0.7679,  ...,  0.1275, -0.0000,  1.2419]],\n",
      "\n",
      "         [[ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.3272,  1.6046,  ..., -0.0768, -0.4271, -0.0608],\n",
      "          [-0.0340, -0.9512,  0.8167,  ...,  2.3688,  0.6403, -1.8196],\n",
      "          ...,\n",
      "          [ 1.0215, -1.5798, -0.5665,  ...,  0.0000, -0.5870,  2.2435],\n",
      "          [ 0.9171, -0.1398,  1.6818,  ..., -0.0973,  1.4750, -0.7389],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0975, -0.5597, -0.6027,  ...,  1.9719,  0.1844, -0.2584],\n",
      "          [ 0.0000, -0.2131, -0.5634,  ...,  1.4880,  0.9518,  0.0000],\n",
      "          [ 0.8617, -0.3897, -0.9880,  ...,  1.7804, -2.0196, -0.3396],\n",
      "          ...,\n",
      "          [ 0.3237, -0.8681, -0.2772,  ...,  1.6197, -1.4788, -0.0787],\n",
      "          [ 0.0614, -0.0000,  1.1898,  ...,  0.3437,  0.3921,  0.5027],\n",
      "          [-0.4462, -0.8496, -0.7679,  ...,  0.0000, -0.0000,  1.2419]],\n",
      "\n",
      "         [[ 0.5332, -0.2212, -0.4133,  ..., -1.2032,  1.9811, -0.3992],\n",
      "          [-0.2848,  1.1513,  0.9230,  ..., -0.0000, -0.1279, -1.2541],\n",
      "          [-0.2326,  0.4093,  1.6599,  ...,  1.2307,  0.3701, -1.0987],\n",
      "          ...,\n",
      "          [ 0.7752, -1.6474,  0.2966,  ..., -0.7913,  0.8603,  1.3509],\n",
      "          [-0.0156, -1.6922,  2.4115,  ...,  0.6107, -0.4553, -0.6483],\n",
      "          [-0.0905, -0.5388,  0.6735,  ..., -0.7456, -0.0167, -0.1296]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.5300e-01, -5.5849e-01, -6.2741e-01,  ...,  2.0176e+00,\n",
      "            8.5790e-02, -2.7490e-01],\n",
      "          [-2.5667e-01,  4.5920e-01, -1.4001e+00,  ...,  1.5621e+00,\n",
      "           -1.1727e+00,  5.1911e-01],\n",
      "          [ 9.1643e-02,  5.6793e-01, -2.8408e-01,  ...,  2.3561e+00,\n",
      "           -1.3744e+00, -4.3656e-01],\n",
      "          ...,\n",
      "          [ 1.4250e-01, -3.1975e-01, -7.8055e-02,  ...,  1.2710e+00,\n",
      "           -1.6280e+00, -2.3739e-01],\n",
      "          [ 1.5524e-01, -1.5757e-01,  1.4043e+00,  ...,  2.0525e-01,\n",
      "           -4.8810e-01,  8.5289e-01],\n",
      "          [-4.9116e-01, -9.3677e-01, -8.4550e-01,  ...,  1.4552e-01,\n",
      "           -1.9768e-03,  1.3681e+00]],\n",
      "\n",
      "         [[ 5.8492e-01, -1.9908e-01, -1.7857e-01,  ..., -1.1936e+00,\n",
      "            9.2833e-02,  1.6396e-02],\n",
      "          [ 9.2709e-02,  2.8813e-01,  1.7376e+00,  ..., -9.0605e-02,\n",
      "           -4.6944e-01, -6.4988e-02],\n",
      "          [-3.4178e-02, -1.0444e+00,  9.0509e-01,  ...,  2.5958e+00,\n",
      "            7.0546e-01, -1.9973e+00],\n",
      "          ...,\n",
      "          [ 1.1202e+00, -1.7346e+00, -6.0405e-01,  ..., -3.8236e-03,\n",
      "           -6.3460e-01,  2.4525e+00],\n",
      "          [ 9.4761e-01, -1.5835e-01,  1.7851e+00,  ..., -1.1996e-01,\n",
      "            1.5394e+00, -7.4525e-01],\n",
      "          [ 3.1922e-03, -5.2964e-01,  8.0828e-01,  ..., -7.5617e-01,\n",
      "            5.6506e-02,  9.9069e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1328e-02, -4.2537e-02, -4.6031e-02,  ...,  8.0345e-02,\n",
      "           -6.9414e-02, -2.1278e-02],\n",
      "          [ 6.3555e-05, -2.3775e-01, -6.2609e-01,  ...,  1.6520e+00,\n",
      "            1.0546e+00, -1.1206e-03],\n",
      "          [ 9.4306e-01, -4.3637e-01, -1.0875e+00,  ...,  1.9714e+00,\n",
      "           -2.2083e+00, -3.7195e-01],\n",
      "          ...,\n",
      "          [ 3.5664e-01, -9.5668e-01, -3.1433e-01,  ...,  1.7916e+00,\n",
      "           -1.6182e+00, -8.8813e-02],\n",
      "          [ 7.2109e-02, -1.0900e-02,  1.2969e+00,  ...,  3.8936e-01,\n",
      "            4.2256e-01,  5.5161e-01],\n",
      "          [-4.8677e-01, -9.3606e-01, -8.4310e-01,  ...,  1.1927e-02,\n",
      "           -5.0268e-03,  1.3629e+00]],\n",
      "\n",
      "         [[ 5.5162e-01, -2.2354e-01, -3.0864e-01,  ..., -1.2475e+00,\n",
      "            2.0468e+00, -3.7464e-01],\n",
      "          [-2.6839e-01,  1.1309e+00,  1.0938e+00,  ..., -2.8588e-02,\n",
      "           -1.0682e-01, -1.2429e+00],\n",
      "          [-2.2537e-01,  4.2613e-01,  1.8128e+00,  ...,  1.2870e+00,\n",
      "            4.0443e-01, -1.1661e+00],\n",
      "          ...,\n",
      "          [ 5.1625e-03, -1.3690e-03,  1.6823e-02,  ..., -1.1658e-02,\n",
      "            1.0978e-02, -1.5660e-03],\n",
      "          [-1.3538e-02, -1.7403e+00,  2.5901e+00,  ...,  6.2270e-01,\n",
      "           -4.6236e-01, -6.6525e-01],\n",
      "          [-5.9965e-02, -5.5812e-01,  7.7382e-01,  ..., -7.6325e-01,\n",
      "            1.6858e-02, -1.3379e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.5300e-01, -5.5849e-01, -6.2741e-01,  ...,  2.0176e+00,\n",
      "            8.5790e-02, -2.7490e-01],\n",
      "          [ 5.8492e-01, -1.9908e-01, -1.7857e-01,  ..., -1.1936e+00,\n",
      "            9.2833e-02,  1.6396e-02]],\n",
      "\n",
      "         [[-2.5667e-01,  4.5920e-01, -1.4001e+00,  ...,  1.5621e+00,\n",
      "           -1.1727e+00,  5.1911e-01],\n",
      "          [ 9.2709e-02,  2.8813e-01,  1.7376e+00,  ..., -9.0605e-02,\n",
      "           -4.6944e-01, -6.4988e-02]],\n",
      "\n",
      "         [[ 9.1643e-02,  5.6793e-01, -2.8408e-01,  ...,  2.3561e+00,\n",
      "           -1.3744e+00, -4.3656e-01],\n",
      "          [-3.4178e-02, -1.0444e+00,  9.0509e-01,  ...,  2.5958e+00,\n",
      "            7.0546e-01, -1.9973e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4250e-01, -3.1975e-01, -7.8055e-02,  ...,  1.2710e+00,\n",
      "           -1.6280e+00, -2.3739e-01],\n",
      "          [ 1.1202e+00, -1.7346e+00, -6.0405e-01,  ..., -3.8236e-03,\n",
      "           -6.3460e-01,  2.4525e+00]],\n",
      "\n",
      "         [[ 1.5524e-01, -1.5757e-01,  1.4043e+00,  ...,  2.0525e-01,\n",
      "           -4.8810e-01,  8.5289e-01],\n",
      "          [ 9.4761e-01, -1.5835e-01,  1.7851e+00,  ..., -1.1996e-01,\n",
      "            1.5394e+00, -7.4525e-01]],\n",
      "\n",
      "         [[-4.9116e-01, -9.3677e-01, -8.4550e-01,  ...,  1.4552e-01,\n",
      "           -1.9768e-03,  1.3681e+00],\n",
      "          [ 3.1922e-03, -5.2964e-01,  8.0828e-01,  ..., -7.5617e-01,\n",
      "            5.6506e-02,  9.9069e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1328e-02, -4.2537e-02, -4.6031e-02,  ...,  8.0345e-02,\n",
      "           -6.9414e-02, -2.1278e-02],\n",
      "          [ 5.5162e-01, -2.2354e-01, -3.0864e-01,  ..., -1.2475e+00,\n",
      "            2.0468e+00, -3.7464e-01]],\n",
      "\n",
      "         [[ 6.3555e-05, -2.3775e-01, -6.2609e-01,  ...,  1.6520e+00,\n",
      "            1.0546e+00, -1.1206e-03],\n",
      "          [-2.6839e-01,  1.1309e+00,  1.0938e+00,  ..., -2.8588e-02,\n",
      "           -1.0682e-01, -1.2429e+00]],\n",
      "\n",
      "         [[ 9.4306e-01, -4.3637e-01, -1.0875e+00,  ...,  1.9714e+00,\n",
      "           -2.2083e+00, -3.7195e-01],\n",
      "          [-2.2537e-01,  4.2613e-01,  1.8128e+00,  ...,  1.2870e+00,\n",
      "            4.0443e-01, -1.1661e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5664e-01, -9.5668e-01, -3.1433e-01,  ...,  1.7916e+00,\n",
      "           -1.6182e+00, -8.8813e-02],\n",
      "          [ 5.1625e-03, -1.3690e-03,  1.6823e-02,  ..., -1.1658e-02,\n",
      "            1.0978e-02, -1.5660e-03]],\n",
      "\n",
      "         [[ 7.2109e-02, -1.0900e-02,  1.2969e+00,  ...,  3.8936e-01,\n",
      "            4.2256e-01,  5.5161e-01],\n",
      "          [-1.3538e-02, -1.7403e+00,  2.5901e+00,  ...,  6.2270e-01,\n",
      "           -4.6236e-01, -6.6525e-01]],\n",
      "\n",
      "         [[-4.8677e-01, -9.3606e-01, -8.4310e-01,  ...,  1.1927e-02,\n",
      "           -5.0268e-03,  1.3629e+00],\n",
      "          [-5.9965e-02, -5.5812e-01,  7.7382e-01,  ..., -7.6325e-01,\n",
      "            1.6858e-02, -1.3379e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.5300e-01, -5.5849e-01, -6.2741e-01,  ...,  2.0176e+00,\n",
      "            8.5790e-02, -2.7490e-01],\n",
      "          [ 5.8492e-01, -1.9908e-01, -1.7857e-01,  ..., -1.1936e+00,\n",
      "            9.2833e-02,  1.6396e-02]],\n",
      "\n",
      "         [[-2.5667e-01,  4.5920e-01, -1.4001e+00,  ...,  1.5621e+00,\n",
      "           -1.1727e+00,  5.1911e-01],\n",
      "          [ 9.2709e-02,  2.8813e-01,  1.7376e+00,  ..., -9.0605e-02,\n",
      "           -4.6944e-01, -6.4988e-02]],\n",
      "\n",
      "         [[ 9.1643e-02,  5.6793e-01, -2.8408e-01,  ...,  2.3561e+00,\n",
      "           -1.3744e+00, -4.3656e-01],\n",
      "          [-3.4178e-02, -1.0444e+00,  9.0509e-01,  ...,  2.5958e+00,\n",
      "            7.0546e-01, -1.9973e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4250e-01, -3.1975e-01, -7.8055e-02,  ...,  1.2710e+00,\n",
      "           -1.6280e+00, -2.3739e-01],\n",
      "          [ 1.1202e+00, -1.7346e+00, -6.0405e-01,  ..., -3.8236e-03,\n",
      "           -6.3460e-01,  2.4525e+00]],\n",
      "\n",
      "         [[ 1.5524e-01, -1.5757e-01,  1.4043e+00,  ...,  2.0525e-01,\n",
      "           -4.8810e-01,  8.5289e-01],\n",
      "          [ 9.4761e-01, -1.5835e-01,  1.7851e+00,  ..., -1.1996e-01,\n",
      "            1.5394e+00, -7.4525e-01]],\n",
      "\n",
      "         [[-4.9116e-01, -9.3677e-01, -8.4550e-01,  ...,  1.4552e-01,\n",
      "           -1.9768e-03,  1.3681e+00],\n",
      "          [ 3.1922e-03, -5.2964e-01,  8.0828e-01,  ..., -7.5617e-01,\n",
      "            5.6506e-02,  9.9069e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1328e-02, -4.2537e-02, -4.6031e-02,  ...,  8.0345e-02,\n",
      "           -6.9414e-02, -2.1278e-02],\n",
      "          [ 5.5162e-01, -2.2354e-01, -3.0864e-01,  ..., -1.2475e+00,\n",
      "            2.0468e+00, -3.7464e-01]],\n",
      "\n",
      "         [[ 6.3555e-05, -2.3775e-01, -6.2609e-01,  ...,  1.6520e+00,\n",
      "            1.0546e+00, -1.1206e-03],\n",
      "          [-2.6839e-01,  1.1309e+00,  1.0938e+00,  ..., -2.8588e-02,\n",
      "           -1.0682e-01, -1.2429e+00]],\n",
      "\n",
      "         [[ 9.4306e-01, -4.3637e-01, -1.0875e+00,  ...,  1.9714e+00,\n",
      "           -2.2083e+00, -3.7195e-01],\n",
      "          [-2.2537e-01,  4.2613e-01,  1.8128e+00,  ...,  1.2870e+00,\n",
      "            4.0443e-01, -1.1661e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5664e-01, -9.5668e-01, -3.1433e-01,  ...,  1.7916e+00,\n",
      "           -1.6182e+00, -8.8813e-02],\n",
      "          [ 5.1625e-03, -1.3690e-03,  1.6823e-02,  ..., -1.1658e-02,\n",
      "            1.0978e-02, -1.5660e-03]],\n",
      "\n",
      "         [[ 7.2109e-02, -1.0900e-02,  1.2969e+00,  ...,  3.8936e-01,\n",
      "            4.2256e-01,  5.5161e-01],\n",
      "          [-1.3538e-02, -1.7403e+00,  2.5901e+00,  ...,  6.2270e-01,\n",
      "           -4.6236e-01, -6.6525e-01]],\n",
      "\n",
      "         [[-4.8677e-01, -9.3606e-01, -8.4310e-01,  ...,  1.1927e-02,\n",
      "           -5.0268e-03,  1.3629e+00],\n",
      "          [-5.9965e-02, -5.5812e-01,  7.7382e-01,  ..., -7.6325e-01,\n",
      "            1.6858e-02, -1.3379e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.5300e-01, -5.5849e-01, -6.2741e-01,  ...,  2.0176e+00,\n",
      "            8.5790e-02, -2.7490e-01],\n",
      "          [ 5.8492e-01, -1.9908e-01, -1.7857e-01,  ..., -1.1936e+00,\n",
      "            9.2833e-02,  1.6396e-02]],\n",
      "\n",
      "         [[-2.5667e-01,  4.5920e-01, -1.4001e+00,  ...,  1.5621e+00,\n",
      "           -1.1727e+00,  5.1911e-01],\n",
      "          [ 9.2709e-02,  2.8813e-01,  1.7376e+00,  ..., -9.0605e-02,\n",
      "           -4.6944e-01, -6.4988e-02]],\n",
      "\n",
      "         [[ 9.1643e-02,  5.6793e-01, -2.8408e-01,  ...,  2.3561e+00,\n",
      "           -1.3744e+00, -4.3656e-01],\n",
      "          [-3.4178e-02, -1.0444e+00,  9.0509e-01,  ...,  2.5958e+00,\n",
      "            7.0546e-01, -1.9973e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4250e-01, -3.1975e-01, -7.8055e-02,  ...,  1.2710e+00,\n",
      "           -1.6280e+00, -2.3739e-01],\n",
      "          [ 1.1202e+00, -1.7346e+00, -6.0405e-01,  ..., -3.8236e-03,\n",
      "           -6.3460e-01,  2.4525e+00]],\n",
      "\n",
      "         [[ 1.5524e-01, -1.5757e-01,  1.4043e+00,  ...,  2.0525e-01,\n",
      "           -4.8810e-01,  8.5289e-01],\n",
      "          [ 9.4761e-01, -1.5835e-01,  1.7851e+00,  ..., -1.1996e-01,\n",
      "            1.5394e+00, -7.4525e-01]],\n",
      "\n",
      "         [[-4.9116e-01, -9.3677e-01, -8.4550e-01,  ...,  1.4552e-01,\n",
      "           -1.9768e-03,  1.3681e+00],\n",
      "          [ 3.1922e-03, -5.2964e-01,  8.0828e-01,  ..., -7.5617e-01,\n",
      "            5.6506e-02,  9.9069e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1328e-02, -4.2537e-02, -4.6031e-02,  ...,  8.0345e-02,\n",
      "           -6.9414e-02, -2.1278e-02],\n",
      "          [ 5.5162e-01, -2.2354e-01, -3.0864e-01,  ..., -1.2475e+00,\n",
      "            2.0468e+00, -3.7464e-01]],\n",
      "\n",
      "         [[ 6.3555e-05, -2.3775e-01, -6.2609e-01,  ...,  1.6520e+00,\n",
      "            1.0546e+00, -1.1206e-03],\n",
      "          [-2.6839e-01,  1.1309e+00,  1.0938e+00,  ..., -2.8588e-02,\n",
      "           -1.0682e-01, -1.2429e+00]],\n",
      "\n",
      "         [[ 9.4306e-01, -4.3637e-01, -1.0875e+00,  ...,  1.9714e+00,\n",
      "           -2.2083e+00, -3.7195e-01],\n",
      "          [-2.2537e-01,  4.2613e-01,  1.8128e+00,  ...,  1.2870e+00,\n",
      "            4.0443e-01, -1.1661e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5664e-01, -9.5668e-01, -3.1433e-01,  ...,  1.7916e+00,\n",
      "           -1.6182e+00, -8.8813e-02],\n",
      "          [ 5.1625e-03, -1.3690e-03,  1.6823e-02,  ..., -1.1658e-02,\n",
      "            1.0978e-02, -1.5660e-03]],\n",
      "\n",
      "         [[ 7.2109e-02, -1.0900e-02,  1.2969e+00,  ...,  3.8936e-01,\n",
      "            4.2256e-01,  5.5161e-01],\n",
      "          [-1.3538e-02, -1.7403e+00,  2.5901e+00,  ...,  6.2270e-01,\n",
      "           -4.6236e-01, -6.6525e-01]],\n",
      "\n",
      "         [[-4.8677e-01, -9.3606e-01, -8.4310e-01,  ...,  1.1927e-02,\n",
      "           -5.0268e-03,  1.3629e+00],\n",
      "          [-5.9965e-02, -5.5812e-01,  7.7382e-01,  ..., -7.6325e-01,\n",
      "            1.6858e-02, -1.3379e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-0.1346, -0.4264, -0.1682,  ...,  2.1858,  0.3179, -0.1491],\n",
      "          [ 0.6056,  0.0283, -0.4761,  ..., -1.1191,  0.2418,  0.1149]],\n",
      "\n",
      "         [[-0.6674,  0.6579, -0.8952,  ...,  1.4040, -1.2226,  0.8365],\n",
      "          [ 0.2011,  0.2784,  1.1757,  ..., -0.1372, -0.3856, -0.0295]],\n",
      "\n",
      "         [[-0.0043,  0.6642, -0.1547,  ...,  2.3340, -1.4118, -0.3964],\n",
      "          [-0.1867, -0.9835,  0.5803,  ...,  2.4777,  0.5574, -2.0960]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2780, -0.1645,  0.2914,  ...,  1.1780, -1.5452,  0.0419],\n",
      "          [ 1.0911, -0.8123, -0.8454,  ..., -0.2260, -0.6597,  2.2384]],\n",
      "\n",
      "         [[-0.1938,  0.2032,  1.2503,  ...,  0.3646, -0.5382,  1.1138],\n",
      "          [ 0.9063, -0.2135,  1.1688,  ..., -0.2540,  1.2891, -0.7501]],\n",
      "\n",
      "         [[-0.8375, -0.5690, -0.5413,  ...,  0.1838, -0.0814,  1.5459],\n",
      "          [ 0.0322, -0.2671,  0.3814,  ..., -0.8323,  0.0646, -0.1855]]],\n",
      "\n",
      "\n",
      "        [[[-0.2506, -0.3276, -0.1428,  ...,  1.3734,  0.3058, -0.1737],\n",
      "          [ 0.7376, -0.2917, -0.6325,  ..., -1.8191,  2.7632, -0.4427]],\n",
      "\n",
      "         [[-0.0369, -0.2838, -0.5295,  ...,  1.2325,  1.2438, -0.0899],\n",
      "          [-0.3751,  1.3797,  0.9030,  ..., -0.1071, -0.1014, -0.4371]],\n",
      "\n",
      "         [[ 0.7619, -0.1375, -0.5690,  ...,  1.6912, -2.1367, -0.0247],\n",
      "          [-0.1051,  0.2280,  1.0233,  ...,  0.9064,  0.3165, -1.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0488, -0.9133, -0.0069,  ...,  1.9533, -1.7656,  0.1169],\n",
      "          [ 0.3862, -1.0427,  0.1489,  ..., -0.7387,  0.4754,  0.7453]],\n",
      "\n",
      "         [[-0.1052,  0.1955,  1.2975,  ...,  0.3110,  0.4737,  0.5642],\n",
      "          [-0.1921, -0.6492,  2.2935,  ...,  0.3799, -0.5170, -0.7641]],\n",
      "\n",
      "         [[-0.7656, -0.6674, -0.8069,  ...,  0.0705, -0.0534,  1.5292],\n",
      "          [-0.0192, -0.5032,  0.4406,  ..., -0.5114,  0.0360, -0.2097]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-0.1346, -0.4264, -0.1682,  ...,  2.1858,  0.3179, -0.1491],\n",
      "          [ 0.6056,  0.0283, -0.4761,  ..., -1.1191,  0.2418,  0.1149]],\n",
      "\n",
      "         [[-0.6674,  0.6579, -0.8952,  ...,  1.4040, -1.2226,  0.8365],\n",
      "          [ 0.2011,  0.2784,  1.1757,  ..., -0.1372, -0.3856, -0.0295]],\n",
      "\n",
      "         [[-0.0043,  0.6642, -0.1547,  ...,  2.3340, -1.4118, -0.3964],\n",
      "          [-0.1867, -0.9835,  0.5803,  ...,  2.4777,  0.5574, -2.0960]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2780, -0.1645,  0.2914,  ...,  1.1780, -1.5452,  0.0419],\n",
      "          [ 1.0911, -0.8123, -0.8454,  ..., -0.2260, -0.6597,  2.2384]],\n",
      "\n",
      "         [[-0.1938,  0.2032,  1.2503,  ...,  0.3646, -0.5382,  1.1138],\n",
      "          [ 0.9063, -0.2135,  1.1688,  ..., -0.2540,  1.2891, -0.7501]],\n",
      "\n",
      "         [[-0.8375, -0.5690, -0.5413,  ...,  0.1838, -0.0814,  1.5459],\n",
      "          [ 0.0322, -0.2671,  0.3814,  ..., -0.8323,  0.0646, -0.1855]]],\n",
      "\n",
      "\n",
      "        [[[-0.2506, -0.3276, -0.1428,  ...,  1.3734,  0.3058, -0.1737],\n",
      "          [ 0.7376, -0.2917, -0.6325,  ..., -1.8191,  2.7632, -0.4427]],\n",
      "\n",
      "         [[-0.0369, -0.2838, -0.5295,  ...,  1.2325,  1.2438, -0.0899],\n",
      "          [-0.3751,  1.3797,  0.9030,  ..., -0.1071, -0.1014, -0.4371]],\n",
      "\n",
      "         [[ 0.7619, -0.1375, -0.5690,  ...,  1.6912, -2.1367, -0.0247],\n",
      "          [-0.1051,  0.2280,  1.0233,  ...,  0.9064,  0.3165, -1.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0488, -0.9133, -0.0069,  ...,  1.9533, -1.7656,  0.1169],\n",
      "          [ 0.3862, -1.0427,  0.1489,  ..., -0.7387,  0.4754,  0.7453]],\n",
      "\n",
      "         [[-0.1052,  0.1955,  1.2975,  ...,  0.3110,  0.4737,  0.5642],\n",
      "          [-0.1921, -0.6492,  2.2935,  ...,  0.3799, -0.5170, -0.7641]],\n",
      "\n",
      "         [[-0.7656, -0.6674, -0.8069,  ...,  0.0705, -0.0534,  1.5292],\n",
      "          [-0.0192, -0.5032,  0.4406,  ..., -0.5114,  0.0360, -0.2097]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1346, -0.4264, -0.1682,  ..., -1.1191,  0.2418,  0.1149],\n",
      "         [-0.6674,  0.6579, -0.8952,  ..., -0.1372, -0.3856, -0.0295],\n",
      "         [-0.0043,  0.6642, -0.1547,  ...,  2.4777,  0.5574, -2.0960],\n",
      "         ...,\n",
      "         [-0.2780, -0.1645,  0.2914,  ..., -0.2260, -0.6597,  2.2384],\n",
      "         [-0.1938,  0.2032,  1.2503,  ..., -0.2540,  1.2891, -0.7501],\n",
      "         [-0.8375, -0.5690, -0.5413,  ..., -0.8323,  0.0646, -0.1855]],\n",
      "\n",
      "        [[-0.2506, -0.3276, -0.1428,  ..., -1.8191,  2.7632, -0.4427],\n",
      "         [-0.0369, -0.2838, -0.5295,  ..., -0.1071, -0.1014, -0.4371],\n",
      "         [ 0.7619, -0.1375, -0.5690,  ...,  0.9064,  0.3165, -1.0235],\n",
      "         ...,\n",
      "         [ 0.0488, -0.9133, -0.0069,  ..., -0.7387,  0.4754,  0.7453],\n",
      "         [-0.1052,  0.1955,  1.2975,  ...,  0.3799, -0.5170, -0.7641],\n",
      "         [-0.7656, -0.6674, -0.8069,  ..., -0.5114,  0.0360, -0.2097]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-0.1346, -0.4264, -0.1682,  ...,  2.1858,  0.3179, -0.1491],\n",
      "          [ 0.6056,  0.0283, -0.4761,  ..., -1.1191,  0.2418,  0.1149]],\n",
      "\n",
      "         [[-0.6674,  0.6579, -0.8952,  ...,  1.4040, -1.2226,  0.8365],\n",
      "          [ 0.2011,  0.2784,  1.1757,  ..., -0.1372, -0.3856, -0.0295]],\n",
      "\n",
      "         [[-0.0043,  0.6642, -0.1547,  ...,  2.3340, -1.4118, -0.3964],\n",
      "          [-0.1867, -0.9835,  0.5803,  ...,  2.4777,  0.5574, -2.0960]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2780, -0.1645,  0.2914,  ...,  1.1780, -1.5452,  0.0419],\n",
      "          [ 1.0911, -0.8123, -0.8454,  ..., -0.2260, -0.6597,  2.2384]],\n",
      "\n",
      "         [[-0.1938,  0.2032,  1.2503,  ...,  0.3646, -0.5382,  1.1138],\n",
      "          [ 0.9063, -0.2135,  1.1688,  ..., -0.2540,  1.2891, -0.7501]],\n",
      "\n",
      "         [[-0.8375, -0.5690, -0.5413,  ...,  0.1838, -0.0814,  1.5459],\n",
      "          [ 0.0322, -0.2671,  0.3814,  ..., -0.8323,  0.0646, -0.1855]]],\n",
      "\n",
      "\n",
      "        [[[-0.2506, -0.3276, -0.1428,  ...,  1.3734,  0.3058, -0.1737],\n",
      "          [ 0.7376, -0.2917, -0.6325,  ..., -1.8191,  2.7632, -0.4427]],\n",
      "\n",
      "         [[-0.0369, -0.2838, -0.5295,  ...,  1.2325,  1.2438, -0.0899],\n",
      "          [-0.3751,  1.3797,  0.9030,  ..., -0.1071, -0.1014, -0.4371]],\n",
      "\n",
      "         [[ 0.7619, -0.1375, -0.5690,  ...,  1.6912, -2.1367, -0.0247],\n",
      "          [-0.1051,  0.2280,  1.0233,  ...,  0.9064,  0.3165, -1.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0488, -0.9133, -0.0069,  ...,  1.9533, -1.7656,  0.1169],\n",
      "          [ 0.3862, -1.0427,  0.1489,  ..., -0.7387,  0.4754,  0.7453]],\n",
      "\n",
      "         [[-0.1052,  0.1955,  1.2975,  ...,  0.3110,  0.4737,  0.5642],\n",
      "          [-0.1921, -0.6492,  2.2935,  ...,  0.3799, -0.5170, -0.7641]],\n",
      "\n",
      "         [[-0.7656, -0.6674, -0.8069,  ...,  0.0705, -0.0534,  1.5292],\n",
      "          [-0.0192, -0.5032,  0.4406,  ..., -0.5114,  0.0360, -0.2097]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1346, -0.4264, -0.1682,  ...,  2.1858,  0.3179, -0.1491],\n",
      "          [-0.6674,  0.6579, -0.8952,  ...,  1.4040, -1.2226,  0.8365],\n",
      "          [-0.0043,  0.6642, -0.1547,  ...,  2.3340, -1.4118, -0.3964],\n",
      "          ...,\n",
      "          [-0.2780, -0.1645,  0.2914,  ...,  1.1780, -1.5452,  0.0419],\n",
      "          [-0.1938,  0.2032,  1.2503,  ...,  0.3646, -0.5382,  1.1138],\n",
      "          [-0.8375, -0.5690, -0.5413,  ...,  0.1838, -0.0814,  1.5459]],\n",
      "\n",
      "         [[ 0.6056,  0.0283, -0.4761,  ..., -1.1191,  0.2418,  0.1149],\n",
      "          [ 0.2011,  0.2784,  1.1757,  ..., -0.1372, -0.3856, -0.0295],\n",
      "          [-0.1867, -0.9835,  0.5803,  ...,  2.4777,  0.5574, -2.0960],\n",
      "          ...,\n",
      "          [ 1.0911, -0.8123, -0.8454,  ..., -0.2260, -0.6597,  2.2384],\n",
      "          [ 0.9063, -0.2135,  1.1688,  ..., -0.2540,  1.2891, -0.7501],\n",
      "          [ 0.0322, -0.2671,  0.3814,  ..., -0.8323,  0.0646, -0.1855]]],\n",
      "\n",
      "\n",
      "        [[[-0.2506, -0.3276, -0.1428,  ...,  1.3734,  0.3058, -0.1737],\n",
      "          [-0.0369, -0.2838, -0.5295,  ...,  1.2325,  1.2438, -0.0899],\n",
      "          [ 0.7619, -0.1375, -0.5690,  ...,  1.6912, -2.1367, -0.0247],\n",
      "          ...,\n",
      "          [ 0.0488, -0.9133, -0.0069,  ...,  1.9533, -1.7656,  0.1169],\n",
      "          [-0.1052,  0.1955,  1.2975,  ...,  0.3110,  0.4737,  0.5642],\n",
      "          [-0.7656, -0.6674, -0.8069,  ...,  0.0705, -0.0534,  1.5292]],\n",
      "\n",
      "         [[ 0.7376, -0.2917, -0.6325,  ..., -1.8191,  2.7632, -0.4427],\n",
      "          [-0.3751,  1.3797,  0.9030,  ..., -0.1071, -0.1014, -0.4371],\n",
      "          [-0.1051,  0.2280,  1.0233,  ...,  0.9064,  0.3165, -1.0235],\n",
      "          ...,\n",
      "          [ 0.3862, -1.0427,  0.1489,  ..., -0.7387,  0.4754,  0.7453],\n",
      "          [-0.1921, -0.6492,  2.2935,  ...,  0.3799, -0.5170, -0.7641],\n",
      "          [-0.0192, -0.5032,  0.4406,  ..., -0.5114,  0.0360, -0.2097]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.5357e-01, -4.6404e-01, -1.8977e-01,  ...,  2.3996e+00,\n",
      "            3.3427e-01, -1.5774e-01],\n",
      "          [-7.0503e-01,  6.8444e-01, -9.2247e-01,  ...,  1.5385e+00,\n",
      "           -1.3192e+00,  8.9675e-01],\n",
      "          [-2.8225e-02, -7.2653e-04,  1.0506e-02,  ...,  1.9865e-01,\n",
      "           -7.0867e-02,  6.9793e-02],\n",
      "          ...,\n",
      "          [-3.0201e-01, -1.8048e-01,  3.1261e-01,  ...,  1.3005e+00,\n",
      "           -1.6775e+00,  4.9653e-02],\n",
      "          [-2.1806e-01,  2.1520e-01,  1.3420e+00,  ...,  4.2550e-01,\n",
      "           -5.8931e-01,  1.2155e+00],\n",
      "          [-9.2131e-01, -6.2207e-01, -5.9195e-01,  ...,  2.0807e-01,\n",
      "           -9.8141e-02,  1.7026e+00]],\n",
      "\n",
      "         [[ 5.1119e-01, -1.3507e-01,  7.6012e-02,  ..., -8.4787e-01,\n",
      "            4.6632e-01,  9.1593e-02],\n",
      "          [ 2.9283e-01,  1.8489e-01,  1.2719e+00,  ..., -1.4683e-01,\n",
      "           -3.7779e-01, -3.5317e-02],\n",
      "          [-2.0274e-01, -1.0864e+00,  6.4622e-01,  ...,  2.7319e+00,\n",
      "            6.1515e-01, -2.3125e+00],\n",
      "          ...,\n",
      "          [ 1.1796e+00, -8.9950e-01, -8.7719e-01,  ..., -2.5366e-01,\n",
      "           -6.7408e-01,  2.3973e+00],\n",
      "          [ 8.4550e-01, -3.9714e-01,  1.2195e+00,  ..., -2.4043e-01,\n",
      "            1.3356e+00, -6.3206e-01],\n",
      "          [ 9.5729e-02, -4.5293e-01,  4.9936e-01,  ..., -7.0191e-01,\n",
      "            3.4977e-01, -1.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0679e-01, -5.5460e-01, -2.1727e-01,  ...,  1.3165e+00,\n",
      "           -6.4354e-01,  2.4076e-02],\n",
      "          [-3.9744e-02, -3.1635e-01, -5.8819e-01,  ...,  1.3679e+00,\n",
      "            1.3788e+00, -1.0049e-01],\n",
      "          [ 8.3315e-01, -1.5781e-01, -6.2568e-01,  ...,  1.8645e+00,\n",
      "           -2.3521e+00, -1.9712e-02],\n",
      "          ...,\n",
      "          [ 5.4316e-02, -1.0146e+00, -7.7665e-03,  ...,  2.1700e+00,\n",
      "           -1.9613e+00,  1.2983e-01],\n",
      "          [-1.1050e-01,  2.0559e-01,  1.4223e+00,  ...,  3.5185e-01,\n",
      "            5.1410e-01,  6.2126e-01],\n",
      "          [-8.4443e-01, -7.3861e-01, -8.9100e-01,  ...,  8.3318e-02,\n",
      "           -6.6418e-02,  1.6903e+00]],\n",
      "\n",
      "         [[ 8.1534e-01, -3.2226e-01, -6.9836e-01,  ..., -2.0128e+00,\n",
      "            3.0586e+00, -4.8975e-01],\n",
      "          [-2.7672e-01,  1.1778e+00,  1.1389e+00,  ..., -2.6415e-01,\n",
      "            2.6636e-02, -3.0459e-01],\n",
      "          [-8.7365e-02,  2.2850e-01,  1.1616e+00,  ...,  8.0538e-01,\n",
      "            3.9757e-01, -1.0053e+00],\n",
      "          ...,\n",
      "          [ 2.7254e-01, -3.7893e-01,  7.0056e-01,  ..., -7.7602e-01,\n",
      "            7.3412e-01,  2.1944e-01],\n",
      "          [-2.1484e-03,  3.3389e-02,  8.5706e-02,  ..., -3.3295e-02,\n",
      "            3.4305e-02,  1.6198e-02],\n",
      "          [-9.5987e-03, -4.7219e-01,  5.7220e-01,  ..., -5.7175e-01,\n",
      "            1.2540e-01, -2.1827e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-1.5357e-01, -4.6404e-01, -1.8977e-01,  ...,  2.3996e+00,\n",
      "            3.3427e-01, -1.5774e-01],\n",
      "          [ 5.1119e-01, -1.3507e-01,  7.6012e-02,  ..., -8.4787e-01,\n",
      "            4.6632e-01,  9.1593e-02]],\n",
      "\n",
      "         [[-7.0503e-01,  6.8444e-01, -9.2247e-01,  ...,  1.5385e+00,\n",
      "           -1.3192e+00,  8.9675e-01],\n",
      "          [ 2.9283e-01,  1.8489e-01,  1.2719e+00,  ..., -1.4683e-01,\n",
      "           -3.7779e-01, -3.5317e-02]],\n",
      "\n",
      "         [[-2.8225e-02, -7.2653e-04,  1.0506e-02,  ...,  1.9865e-01,\n",
      "           -7.0867e-02,  6.9793e-02],\n",
      "          [-2.0274e-01, -1.0864e+00,  6.4622e-01,  ...,  2.7319e+00,\n",
      "            6.1515e-01, -2.3125e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0201e-01, -1.8048e-01,  3.1261e-01,  ...,  1.3005e+00,\n",
      "           -1.6775e+00,  4.9653e-02],\n",
      "          [ 1.1796e+00, -8.9950e-01, -8.7719e-01,  ..., -2.5366e-01,\n",
      "           -6.7408e-01,  2.3973e+00]],\n",
      "\n",
      "         [[-2.1806e-01,  2.1520e-01,  1.3420e+00,  ...,  4.2550e-01,\n",
      "           -5.8931e-01,  1.2155e+00],\n",
      "          [ 8.4550e-01, -3.9714e-01,  1.2195e+00,  ..., -2.4043e-01,\n",
      "            1.3356e+00, -6.3206e-01]],\n",
      "\n",
      "         [[-9.2131e-01, -6.2207e-01, -5.9195e-01,  ...,  2.0807e-01,\n",
      "           -9.8141e-02,  1.7026e+00],\n",
      "          [ 9.5729e-02, -4.5293e-01,  4.9936e-01,  ..., -7.0191e-01,\n",
      "            3.4977e-01, -1.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0679e-01, -5.5460e-01, -2.1727e-01,  ...,  1.3165e+00,\n",
      "           -6.4354e-01,  2.4076e-02],\n",
      "          [ 8.1534e-01, -3.2226e-01, -6.9836e-01,  ..., -2.0128e+00,\n",
      "            3.0586e+00, -4.8975e-01]],\n",
      "\n",
      "         [[-3.9744e-02, -3.1635e-01, -5.8819e-01,  ...,  1.3679e+00,\n",
      "            1.3788e+00, -1.0049e-01],\n",
      "          [-2.7672e-01,  1.1778e+00,  1.1389e+00,  ..., -2.6415e-01,\n",
      "            2.6636e-02, -3.0459e-01]],\n",
      "\n",
      "         [[ 8.3315e-01, -1.5781e-01, -6.2568e-01,  ...,  1.8645e+00,\n",
      "           -2.3521e+00, -1.9712e-02],\n",
      "          [-8.7365e-02,  2.2850e-01,  1.1616e+00,  ...,  8.0538e-01,\n",
      "            3.9757e-01, -1.0053e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4316e-02, -1.0146e+00, -7.7665e-03,  ...,  2.1700e+00,\n",
      "           -1.9613e+00,  1.2983e-01],\n",
      "          [ 2.7254e-01, -3.7893e-01,  7.0056e-01,  ..., -7.7602e-01,\n",
      "            7.3412e-01,  2.1944e-01]],\n",
      "\n",
      "         [[-1.1050e-01,  2.0559e-01,  1.4223e+00,  ...,  3.5185e-01,\n",
      "            5.1410e-01,  6.2126e-01],\n",
      "          [-2.1484e-03,  3.3389e-02,  8.5706e-02,  ..., -3.3295e-02,\n",
      "            3.4305e-02,  1.6198e-02]],\n",
      "\n",
      "         [[-8.4443e-01, -7.3861e-01, -8.9100e-01,  ...,  8.3318e-02,\n",
      "           -6.6418e-02,  1.6903e+00],\n",
      "          [-9.5987e-03, -4.7219e-01,  5.7220e-01,  ..., -5.7175e-01,\n",
      "            1.2540e-01, -2.1827e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-1.5357e-01, -4.6404e-01, -1.8977e-01,  ...,  2.3996e+00,\n",
      "            3.3427e-01, -1.5774e-01],\n",
      "          [ 5.1119e-01, -1.3507e-01,  7.6012e-02,  ..., -8.4787e-01,\n",
      "            4.6632e-01,  9.1593e-02]],\n",
      "\n",
      "         [[-7.0503e-01,  6.8444e-01, -9.2247e-01,  ...,  1.5385e+00,\n",
      "           -1.3192e+00,  8.9675e-01],\n",
      "          [ 2.9283e-01,  1.8489e-01,  1.2719e+00,  ..., -1.4683e-01,\n",
      "           -3.7779e-01, -3.5317e-02]],\n",
      "\n",
      "         [[-2.8225e-02, -7.2653e-04,  1.0506e-02,  ...,  1.9865e-01,\n",
      "           -7.0867e-02,  6.9793e-02],\n",
      "          [-2.0274e-01, -1.0864e+00,  6.4622e-01,  ...,  2.7319e+00,\n",
      "            6.1515e-01, -2.3125e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0201e-01, -1.8048e-01,  3.1261e-01,  ...,  1.3005e+00,\n",
      "           -1.6775e+00,  4.9653e-02],\n",
      "          [ 1.1796e+00, -8.9950e-01, -8.7719e-01,  ..., -2.5366e-01,\n",
      "           -6.7408e-01,  2.3973e+00]],\n",
      "\n",
      "         [[-2.1806e-01,  2.1520e-01,  1.3420e+00,  ...,  4.2550e-01,\n",
      "           -5.8931e-01,  1.2155e+00],\n",
      "          [ 8.4550e-01, -3.9714e-01,  1.2195e+00,  ..., -2.4043e-01,\n",
      "            1.3356e+00, -6.3206e-01]],\n",
      "\n",
      "         [[-9.2131e-01, -6.2207e-01, -5.9195e-01,  ...,  2.0807e-01,\n",
      "           -9.8141e-02,  1.7026e+00],\n",
      "          [ 9.5729e-02, -4.5293e-01,  4.9936e-01,  ..., -7.0191e-01,\n",
      "            3.4977e-01, -1.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0679e-01, -5.5460e-01, -2.1727e-01,  ...,  1.3165e+00,\n",
      "           -6.4354e-01,  2.4076e-02],\n",
      "          [ 8.1534e-01, -3.2226e-01, -6.9836e-01,  ..., -2.0128e+00,\n",
      "            3.0586e+00, -4.8975e-01]],\n",
      "\n",
      "         [[-3.9744e-02, -3.1635e-01, -5.8819e-01,  ...,  1.3679e+00,\n",
      "            1.3788e+00, -1.0049e-01],\n",
      "          [-2.7672e-01,  1.1778e+00,  1.1389e+00,  ..., -2.6415e-01,\n",
      "            2.6636e-02, -3.0459e-01]],\n",
      "\n",
      "         [[ 8.3315e-01, -1.5781e-01, -6.2568e-01,  ...,  1.8645e+00,\n",
      "           -2.3521e+00, -1.9712e-02],\n",
      "          [-8.7365e-02,  2.2850e-01,  1.1616e+00,  ...,  8.0538e-01,\n",
      "            3.9757e-01, -1.0053e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4316e-02, -1.0146e+00, -7.7665e-03,  ...,  2.1700e+00,\n",
      "           -1.9613e+00,  1.2983e-01],\n",
      "          [ 2.7254e-01, -3.7893e-01,  7.0056e-01,  ..., -7.7602e-01,\n",
      "            7.3412e-01,  2.1944e-01]],\n",
      "\n",
      "         [[-1.1050e-01,  2.0559e-01,  1.4223e+00,  ...,  3.5185e-01,\n",
      "            5.1410e-01,  6.2126e-01],\n",
      "          [-2.1484e-03,  3.3389e-02,  8.5706e-02,  ..., -3.3295e-02,\n",
      "            3.4305e-02,  1.6198e-02]],\n",
      "\n",
      "         [[-8.4443e-01, -7.3861e-01, -8.9100e-01,  ...,  8.3318e-02,\n",
      "           -6.6418e-02,  1.6903e+00],\n",
      "          [-9.5987e-03, -4.7219e-01,  5.7220e-01,  ..., -5.7175e-01,\n",
      "            1.2540e-01, -2.1827e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-1.5357e-01, -4.6404e-01, -1.8977e-01,  ...,  2.3996e+00,\n",
      "            3.3427e-01, -1.5774e-01],\n",
      "          [ 5.1119e-01, -1.3507e-01,  7.6012e-02,  ..., -8.4787e-01,\n",
      "            4.6632e-01,  9.1593e-02]],\n",
      "\n",
      "         [[-7.0503e-01,  6.8444e-01, -9.2247e-01,  ...,  1.5385e+00,\n",
      "           -1.3192e+00,  8.9675e-01],\n",
      "          [ 2.9283e-01,  1.8489e-01,  1.2719e+00,  ..., -1.4683e-01,\n",
      "           -3.7779e-01, -3.5317e-02]],\n",
      "\n",
      "         [[-2.8225e-02, -7.2653e-04,  1.0506e-02,  ...,  1.9865e-01,\n",
      "           -7.0867e-02,  6.9793e-02],\n",
      "          [-2.0274e-01, -1.0864e+00,  6.4622e-01,  ...,  2.7319e+00,\n",
      "            6.1515e-01, -2.3125e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0201e-01, -1.8048e-01,  3.1261e-01,  ...,  1.3005e+00,\n",
      "           -1.6775e+00,  4.9653e-02],\n",
      "          [ 1.1796e+00, -8.9950e-01, -8.7719e-01,  ..., -2.5366e-01,\n",
      "           -6.7408e-01,  2.3973e+00]],\n",
      "\n",
      "         [[-2.1806e-01,  2.1520e-01,  1.3420e+00,  ...,  4.2550e-01,\n",
      "           -5.8931e-01,  1.2155e+00],\n",
      "          [ 8.4550e-01, -3.9714e-01,  1.2195e+00,  ..., -2.4043e-01,\n",
      "            1.3356e+00, -6.3206e-01]],\n",
      "\n",
      "         [[-9.2131e-01, -6.2207e-01, -5.9195e-01,  ...,  2.0807e-01,\n",
      "           -9.8141e-02,  1.7026e+00],\n",
      "          [ 9.5729e-02, -4.5293e-01,  4.9936e-01,  ..., -7.0191e-01,\n",
      "            3.4977e-01, -1.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0679e-01, -5.5460e-01, -2.1727e-01,  ...,  1.3165e+00,\n",
      "           -6.4354e-01,  2.4076e-02],\n",
      "          [ 8.1534e-01, -3.2226e-01, -6.9836e-01,  ..., -2.0128e+00,\n",
      "            3.0586e+00, -4.8975e-01]],\n",
      "\n",
      "         [[-3.9744e-02, -3.1635e-01, -5.8819e-01,  ...,  1.3679e+00,\n",
      "            1.3788e+00, -1.0049e-01],\n",
      "          [-2.7672e-01,  1.1778e+00,  1.1389e+00,  ..., -2.6415e-01,\n",
      "            2.6636e-02, -3.0459e-01]],\n",
      "\n",
      "         [[ 8.3315e-01, -1.5781e-01, -6.2568e-01,  ...,  1.8645e+00,\n",
      "           -2.3521e+00, -1.9712e-02],\n",
      "          [-8.7365e-02,  2.2850e-01,  1.1616e+00,  ...,  8.0538e-01,\n",
      "            3.9757e-01, -1.0053e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4316e-02, -1.0146e+00, -7.7665e-03,  ...,  2.1700e+00,\n",
      "           -1.9613e+00,  1.2983e-01],\n",
      "          [ 2.7254e-01, -3.7893e-01,  7.0056e-01,  ..., -7.7602e-01,\n",
      "            7.3412e-01,  2.1944e-01]],\n",
      "\n",
      "         [[-1.1050e-01,  2.0559e-01,  1.4223e+00,  ...,  3.5185e-01,\n",
      "            5.1410e-01,  6.2126e-01],\n",
      "          [-2.1484e-03,  3.3389e-02,  8.5706e-02,  ..., -3.3295e-02,\n",
      "            3.4305e-02,  1.6198e-02]],\n",
      "\n",
      "         [[-8.4443e-01, -7.3861e-01, -8.9100e-01,  ...,  8.3318e-02,\n",
      "           -6.6418e-02,  1.6903e+00],\n",
      "          [-9.5987e-03, -4.7219e-01,  5.7220e-01,  ..., -5.7175e-01,\n",
      "            1.2540e-01, -2.1827e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.6767,  0.5223],\n",
      "        [-0.3288,  0.3273]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.370300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:52:35,726] Trial 7 finished with value: 0.85708 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 128, 'intermediate_size': 768, 'linear_layer_type': 'identity'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 2\n",
      "Param is num_heads, Chosen value is 4\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.4875,  0.4459, -0.0551,  ...,  0.3572, -0.0663, -0.2439],\n",
      "         [-0.0223,  0.4908, -0.1362,  ..., -0.1566, -0.1640, -0.2134],\n",
      "         [-0.4303,  0.1901, -0.0671,  ...,  0.1423, -0.2913, -0.2232],\n",
      "         ...,\n",
      "         [-0.6588,  0.0197, -0.2441,  ..., -0.2983, -0.1500, -0.4241],\n",
      "         [ 0.3753, -0.1438,  0.0875,  ..., -0.0679, -0.4326, -0.5395],\n",
      "         [-0.3337,  0.2032, -0.3451,  ...,  0.2681, -0.6443, -0.8371]],\n",
      "\n",
      "        [[-0.7096,  0.4172, -0.2672,  ...,  0.4649, -0.2927, -0.1903],\n",
      "         [-0.5937,  0.4874, -0.4776,  ..., -0.1206, -0.2059, -0.4845],\n",
      "         [-0.3919,  0.2272,  0.3906,  ...,  0.1861, -0.4908, -0.3248],\n",
      "         ...,\n",
      "         [-0.1563,  0.0522, -0.1576,  ..., -0.0570, -0.1888, -0.3777],\n",
      "         [-0.0482,  0.5544, -0.2640,  ..., -0.0671, -0.0722, -0.4924],\n",
      "         [-0.4207,  0.3938, -0.3004,  ...,  0.2510, -0.5885, -0.5697]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439]],\n",
      "\n",
      "         [[-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134]],\n",
      "\n",
      "         [[-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241]],\n",
      "\n",
      "         [[ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395]],\n",
      "\n",
      "         [[-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903]],\n",
      "\n",
      "         [[-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845]],\n",
      "\n",
      "         [[-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777]],\n",
      "\n",
      "         [[-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924]],\n",
      "\n",
      "         [[-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1097,  0.3352,  0.1320,  ...,  0.5153,  0.2517,  0.3114],\n",
      "         [ 0.2451,  0.3272,  0.5459,  ...,  0.0888, -0.1240, -0.1948],\n",
      "         [ 0.1174,  0.0542,  1.2880,  ...,  0.1871, -0.0380, -0.2637],\n",
      "         ...,\n",
      "         [ 0.0578,  0.1673,  0.7148,  ..., -0.1742, -0.1841, -0.0850],\n",
      "         [-0.2310, -0.0498,  0.5660,  ...,  0.3780, -0.3142,  0.0227],\n",
      "         [-0.1132,  0.7820,  0.2413,  ..., -0.2324, -0.2835,  0.2386]],\n",
      "\n",
      "        [[-0.0249,  0.0729,  0.3798,  ...,  0.5588,  0.1082,  0.1071],\n",
      "         [ 0.1624,  0.6910,  0.0549,  ...,  0.6898, -0.0348, -0.1844],\n",
      "         [ 0.0534,  0.6723,  1.0488,  ..., -0.0388, -0.4799, -0.5112],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5305,  0.1513,  ..., -0.0838, -0.0507, -0.0783],\n",
      "         [ 0.0841,  0.2953,  0.0404,  ...,  0.1993, -0.3797, -0.1231],\n",
      "         [-0.0609,  0.6004,  0.0854,  ..., -0.2995, -0.3551,  0.5115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1097,  0.3352,  0.1320,  ..., -0.4558,  0.2816, -0.3861],\n",
      "          [ 0.6299, -0.1971, -0.0828,  ...,  0.5153,  0.2517,  0.3114]],\n",
      "\n",
      "         [[ 0.2451,  0.3272,  0.5459,  ..., -0.5961, -0.1500, -0.0091],\n",
      "          [ 0.4385, -0.2509,  0.2175,  ...,  0.0888, -0.1240, -0.1948]],\n",
      "\n",
      "         [[ 0.1174,  0.0542,  1.2880,  ..., -0.3869, -0.3164,  0.0290],\n",
      "          [ 0.3691,  0.1250,  0.6001,  ...,  0.1871, -0.0380, -0.2637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0578,  0.1673,  0.7148,  ..., -0.2909,  0.0784,  0.5932],\n",
      "          [-0.1557,  0.3884,  0.6786,  ..., -0.1742, -0.1841, -0.0850]],\n",
      "\n",
      "         [[-0.2310, -0.0498,  0.5660,  ..., -0.3753, -0.1926,  0.2839],\n",
      "          [ 0.3797,  0.3378,  0.5981,  ...,  0.3780, -0.3142,  0.0227]],\n",
      "\n",
      "         [[-0.1132,  0.7820,  0.2413,  ..., -0.3549, -0.1969, -0.2243],\n",
      "          [ 0.4579,  0.5614,  0.4319,  ..., -0.2324, -0.2835,  0.2386]]],\n",
      "\n",
      "\n",
      "        [[[-0.0249,  0.0729,  0.3798,  ..., -0.4332,  0.0879, -0.1735],\n",
      "          [ 0.7480, -0.3275,  0.0840,  ...,  0.5588,  0.1082,  0.1071]],\n",
      "\n",
      "         [[ 0.1624,  0.6910,  0.0549,  ..., -0.2231, -0.3868, -0.1378],\n",
      "          [ 0.3929,  0.0487, -0.2172,  ...,  0.6898, -0.0348, -0.1844]],\n",
      "\n",
      "         [[ 0.0534,  0.6723,  1.0488,  ..., -0.6195, -0.6362,  0.1774],\n",
      "          [-0.1893,  0.3198,  0.7010,  ..., -0.0388, -0.4799, -0.5112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3221,  0.5305,  0.1513,  ..., -0.0683,  0.0978,  0.1998],\n",
      "          [-0.0146,  0.2263,  0.4035,  ..., -0.0838, -0.0507, -0.0783]],\n",
      "\n",
      "         [[ 0.0841,  0.2953,  0.0404,  ..., -0.1090, -0.1298, -0.4898],\n",
      "          [-0.0555,  0.4344,  0.0995,  ...,  0.1993, -0.3797, -0.1231]],\n",
      "\n",
      "         [[-0.0609,  0.6004,  0.0854,  ..., -0.2216, -0.1401, -0.4198],\n",
      "          [ 0.4770,  0.4764,  0.3597,  ..., -0.2995, -0.3551,  0.5115]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4359,  0.4976,  0.7856,  ...,  0.8688,  0.4087,  0.1808],\n",
      "         [ 0.6184,  0.1471,  0.4826,  ...,  0.5383,  0.6920,  0.0724],\n",
      "         [ 0.3066,  0.6183,  0.9976,  ...,  0.4502,  0.9153,  0.1494],\n",
      "         ...,\n",
      "         [-0.1781,  0.5436,  0.6015,  ...,  0.2037,  0.6062, -0.4514],\n",
      "         [ 0.0189,  0.1922,  0.9736,  ...,  0.0068,  0.3086,  0.0524],\n",
      "         [ 0.7057,  0.4967,  0.8961,  ..., -0.0462,  0.5168,  0.0110]],\n",
      "\n",
      "        [[ 0.5473,  0.4831,  0.9296,  ...,  1.1262,  0.7893,  0.2112],\n",
      "         [ 0.4149,  0.4882,  0.6182,  ...,  0.3077,  0.9332, -0.2257],\n",
      "         [ 0.2383,  0.1631,  0.7105,  ...,  0.1373,  0.9887,  0.2066],\n",
      "         ...,\n",
      "         [ 0.0691,  0.4363,  0.5532,  ..., -0.0396,  0.1851,  0.0056],\n",
      "         [ 0.0041, -0.0954,  0.9141,  ...,  0.2991,  0.0499, -0.0331],\n",
      "         [ 0.7684,  0.2905,  1.1141,  ...,  0.2005,  0.5448,  0.0371]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4359,  0.4976,  0.7856,  ..., -0.1035,  0.0759, -0.9286],\n",
      "          [ 0.4154, -0.3708, -0.2043,  ...,  0.8688,  0.4087,  0.1808]],\n",
      "\n",
      "         [[ 0.6184,  0.1471,  0.4826,  ..., -0.2727, -0.2721, -0.8751],\n",
      "          [ 0.3181, -0.3986, -0.0962,  ...,  0.5383,  0.6920,  0.0724]],\n",
      "\n",
      "         [[ 0.3066,  0.6183,  0.9976,  ..., -0.3978, -0.8315, -0.9586],\n",
      "          [ 0.5746,  0.0106,  0.0849,  ...,  0.4502,  0.9153,  0.1494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1781,  0.5436,  0.6015,  ...,  0.2855, -0.0909, -0.0573],\n",
      "          [ 0.1812, -0.1956, -0.4495,  ...,  0.2037,  0.6062, -0.4514]],\n",
      "\n",
      "         [[ 0.0189,  0.1922,  0.9736,  ..., -0.5899, -0.1052, -0.7356],\n",
      "          [ 0.6391,  0.0943,  0.1281,  ...,  0.0068,  0.3086,  0.0524]],\n",
      "\n",
      "         [[ 0.7057,  0.4967,  0.8961,  ..., -0.4079, -0.0816, -0.5669],\n",
      "          [ 0.5701, -0.2532, -0.1098,  ..., -0.0462,  0.5168,  0.0110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5473,  0.4831,  0.9296,  ..., -0.0396,  0.2039, -0.8268],\n",
      "          [ 0.5210, -0.4034,  0.0820,  ...,  1.1262,  0.7893,  0.2112]],\n",
      "\n",
      "         [[ 0.4149,  0.4882,  0.6182,  ..., -0.7389, -0.3986, -1.1529],\n",
      "          [ 0.8270, -0.1022,  0.4655,  ...,  0.3077,  0.9332, -0.2257]],\n",
      "\n",
      "         [[ 0.2383,  0.1631,  0.7105,  ..., -0.3409, -0.6267, -0.7180],\n",
      "          [ 0.3831, -0.1700,  0.2370,  ...,  0.1373,  0.9887,  0.2066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0691,  0.4363,  0.5532,  ..., -0.2719, -0.4867, -0.2527],\n",
      "          [-0.1181, -0.2490, -0.1080,  ..., -0.0396,  0.1851,  0.0056]],\n",
      "\n",
      "         [[ 0.0041, -0.0954,  0.9141,  ..., -0.4338, -0.1194, -0.9361],\n",
      "          [ 0.6609, -0.0618,  0.2417,  ...,  0.2991,  0.0499, -0.0331]],\n",
      "\n",
      "         [[ 0.7684,  0.2905,  1.1141,  ..., -0.1525, -0.0166, -0.6429],\n",
      "          [ 0.6435, -0.1535, -0.1476,  ...,  0.2005,  0.5448,  0.0371]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4875,  0.4459, -0.0551,  ...,  0.0075, -0.3015,  0.6765],\n",
      "          [-0.0223,  0.4908, -0.1362,  ...,  0.3883, -0.1360, -0.0451],\n",
      "          [-0.4303,  0.1901, -0.0671,  ...,  0.1978, -0.1922,  0.4217],\n",
      "          ...,\n",
      "          [-0.6588,  0.0197, -0.2441,  ...,  0.6026, -0.2372,  0.1251],\n",
      "          [ 0.3753, -0.1438,  0.0875,  ...,  0.0814,  0.0150, -0.0299],\n",
      "          [-0.3337,  0.2032, -0.3451,  ...,  0.8785, -0.1143,  0.8312]],\n",
      "\n",
      "         [[ 0.1384, -0.3015, -0.3229,  ...,  0.3572, -0.0663, -0.2439],\n",
      "          [ 0.2033, -0.3447, -0.3382,  ..., -0.1566, -0.1640, -0.2134],\n",
      "          [-0.0517,  0.1745, -0.3019,  ...,  0.1423, -0.2913, -0.2232],\n",
      "          ...,\n",
      "          [-0.3901,  0.2223, -0.3618,  ..., -0.2983, -0.1500, -0.4241],\n",
      "          [-0.0588, -0.0749, -0.3734,  ..., -0.0679, -0.4326, -0.5395],\n",
      "          [ 0.1185,  0.0533, -0.2622,  ...,  0.2681, -0.6443, -0.8371]]],\n",
      "\n",
      "\n",
      "        [[[-0.7096,  0.4172, -0.2672,  ..., -0.1444, -0.0605,  0.7724],\n",
      "          [-0.5937,  0.4874, -0.4776,  ...,  0.3963, -0.5921,  0.5013],\n",
      "          [-0.3919,  0.2272,  0.3906,  ...,  0.2221, -0.0892,  0.2723],\n",
      "          ...,\n",
      "          [-0.1563,  0.0522, -0.1576,  ...,  0.4711,  0.3144,  0.2771],\n",
      "          [-0.0482,  0.5544, -0.2640,  ...,  0.1410, -0.2850,  0.0540],\n",
      "          [-0.4207,  0.3938, -0.3004,  ...,  0.7147, -0.1125,  0.6661]],\n",
      "\n",
      "         [[ 0.1804, -0.4650, -0.3939,  ...,  0.4649, -0.2927, -0.1903],\n",
      "          [ 0.2212,  0.2877, -0.0874,  ..., -0.1206, -0.2059, -0.4845],\n",
      "          [ 0.1899, -0.2338, -0.2569,  ...,  0.1861, -0.4908, -0.3248],\n",
      "          ...,\n",
      "          [-0.2991,  0.2621, -0.3109,  ..., -0.0570, -0.1888, -0.3777],\n",
      "          [-0.1736, -0.3106, -0.0773,  ..., -0.0671, -0.0722, -0.4924],\n",
      "          [ 0.2737, -0.0508, -0.3174,  ...,  0.2510, -0.5885, -0.5697]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          ...,\n",
      "          [ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02]],\n",
      "\n",
      "         [[ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01],\n",
      "          ...,\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          ...,\n",
      "          [ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01]],\n",
      "\n",
      "         [[ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04],\n",
      "          ...,\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 6.0358e-02,  1.1107e-01,  4.8159e-01,  ..., -3.1157e-01,\n",
      "           -1.9754e-02, -2.2881e-02],\n",
      "          [ 4.1439e-01,  3.5059e-02,  3.0588e-01,  ...,  2.0986e-01,\n",
      "           -1.1510e-01, -1.6445e-01]],\n",
      "\n",
      "         [[ 8.4419e-02,  1.9512e-01,  5.3752e-01,  ..., -4.1014e-01,\n",
      "           -2.7792e-02, -8.2083e-03],\n",
      "          [ 4.1426e-01,  5.2243e-02,  3.4086e-01,  ...,  2.1144e-01,\n",
      "           -1.2567e-01, -1.2832e-01]],\n",
      "\n",
      "         [[ 1.0728e-01,  1.8871e-01,  5.9073e-01,  ..., -4.6292e-01,\n",
      "           -5.4150e-02,  8.5955e-03],\n",
      "          [ 3.6264e-01,  3.0906e-02,  2.8620e-01,  ...,  1.9344e-01,\n",
      "           -7.9779e-02, -1.5117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3173e-02,  2.1255e-01,  5.4666e-01,  ..., -4.5233e-01,\n",
      "           -5.0012e-02, -5.3428e-03],\n",
      "          [ 3.2155e-01,  7.9310e-02,  3.5617e-01,  ...,  1.3180e-01,\n",
      "           -1.6636e-01, -1.7588e-01]],\n",
      "\n",
      "         [[ 5.3828e-02,  1.3829e-01,  4.8798e-01,  ..., -3.6540e-01,\n",
      "           -3.0127e-02,  1.2188e-02],\n",
      "          [ 3.4188e-01,  3.8014e-02,  3.0274e-01,  ...,  1.8328e-01,\n",
      "           -8.0112e-02, -1.3659e-01]],\n",
      "\n",
      "         [[ 1.3789e-02,  1.6519e-01,  3.0676e-01,  ..., -3.3956e-01,\n",
      "           -9.9192e-03, -3.9864e-02],\n",
      "          [ 3.4137e-01,  6.4858e-02,  2.6901e-01,  ...,  1.9713e-01,\n",
      "           -1.0940e-01, -1.1394e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6698e-01,  2.5272e-01,  2.5897e-01,  ..., -3.7714e-01,\n",
      "           -1.9700e-01, -8.7055e-02],\n",
      "          [ 3.5089e-01, -1.0824e-01,  1.0742e-01,  ...,  2.8212e-01,\n",
      "            1.1573e-02,  8.0631e-03]],\n",
      "\n",
      "         [[ 2.4552e-01,  2.8748e-01,  2.9111e-01,  ..., -3.8305e-01,\n",
      "           -1.8262e-01, -1.3421e-01],\n",
      "          [ 3.0885e-01, -1.2270e-02,  1.3520e-01,  ...,  2.7135e-01,\n",
      "           -9.3577e-02, -4.1874e-02]],\n",
      "\n",
      "         [[ 2.3556e-01,  3.0679e-01,  3.0486e-01,  ..., -3.7784e-01,\n",
      "           -1.9318e-01, -1.1789e-01],\n",
      "          [ 3.2152e-01, -5.9231e-03,  1.7314e-01,  ...,  2.2759e-01,\n",
      "           -4.8450e-02, -2.2622e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4544e-01,  2.7062e-01,  2.5137e-01,  ..., -3.2005e-01,\n",
      "           -1.6598e-01, -4.7536e-02],\n",
      "          [ 3.1653e-01, -5.1697e-02,  1.3379e-01,  ...,  2.4056e-01,\n",
      "           -5.3960e-02, -2.6138e-02]],\n",
      "\n",
      "         [[ 2.4480e-01,  2.9612e-01,  3.0340e-01,  ..., -3.8232e-01,\n",
      "           -1.8710e-01, -1.1762e-01],\n",
      "          [ 2.1487e-01,  4.5742e-02,  1.4572e-01,  ...,  1.9625e-01,\n",
      "           -1.0186e-01, -4.7917e-02]],\n",
      "\n",
      "         [[ 2.1585e-01,  2.6048e-01,  3.0059e-01,  ..., -3.7705e-01,\n",
      "           -2.0446e-01, -1.2876e-01],\n",
      "          [ 2.1007e-01,  3.8735e-02,  1.7947e-01,  ...,  1.8090e-01,\n",
      "           -1.0941e-01, -6.8482e-02]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4675,  0.0432,  0.2267,  ..., -0.4671, -0.1344,  0.0503],\n",
      "         [-0.1849, -0.2984,  0.3823,  ..., -0.1251, -0.0747,  0.5290],\n",
      "         [ 0.1144, -0.0877, -0.3609,  ..., -0.1711,  0.0827, -0.2678],\n",
      "         ...,\n",
      "         [-0.1988, -0.3700,  0.2952,  ..., -0.0956,  0.0716,  0.3504],\n",
      "         [ 0.0765, -0.3715, -0.2171,  ..., -0.2965, -0.0421,  0.3803],\n",
      "         [ 0.3565, -0.4331,  0.3345,  ..., -0.3455,  0.4070,  0.5583]],\n",
      "\n",
      "        [[ 0.2321, -0.2398,  0.0335,  ..., -0.4040,  0.0435,  0.0880],\n",
      "         [ 0.1638, -0.2569, -0.0012,  ..., -0.5304,  0.3140,  0.2323],\n",
      "         [-0.3201, -0.1161, -0.1842,  ..., -0.3979,  0.0681,  0.1296],\n",
      "         ...,\n",
      "         [-0.3808, -0.5644,  0.1049,  ..., -0.3607,  0.0981,  0.6118],\n",
      "         [ 0.0825, -0.0434, -0.3595,  ..., -0.3551,  0.0662,  0.4903],\n",
      "         [ 0.5017, -0.4866,  0.1862,  ..., -0.0457,  0.3553,  0.2952]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503]],\n",
      "\n",
      "         [[-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290]],\n",
      "\n",
      "         [[ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504]],\n",
      "\n",
      "         [[ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803]],\n",
      "\n",
      "         [[ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880]],\n",
      "\n",
      "         [[ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323]],\n",
      "\n",
      "         [[-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118]],\n",
      "\n",
      "         [[ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903]],\n",
      "\n",
      "         [[ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3577,  0.2800,  0.2037,  ..., -0.3404, -0.0769,  0.1805],\n",
      "         [ 0.3302,  0.2980, -0.5975,  ...,  0.1315, -0.4662,  0.5441],\n",
      "         [-0.1305,  0.7490, -0.4150,  ...,  0.5816, -0.8695,  1.3832],\n",
      "         ...,\n",
      "         [ 0.3618,  0.8295, -0.2509,  ...,  0.1693, -0.8995,  1.1609],\n",
      "         [-0.1225,  0.6841, -0.5403,  ...,  0.4588, -0.2345,  1.0660],\n",
      "         [ 0.2595,  0.0825, -0.5167,  ..., -0.2062, -0.3607,  0.3727]],\n",
      "\n",
      "        [[-0.2201, -0.0144, -0.0774,  ..., -0.6115,  0.3912, -0.0125],\n",
      "         [ 0.2916,  0.0691, -0.1903,  ..., -0.5232, -0.1742,  0.2232],\n",
      "         [-0.1177,  0.4989, -0.1205,  ..., -0.0592, -0.5500,  1.0284],\n",
      "         ...,\n",
      "         [ 0.3551,  0.2883, -0.1202,  ..., -0.1044, -0.2623,  0.7901],\n",
      "         [-0.1133,  0.8532, -0.3496,  ..., -0.3183, -0.1870,  0.4479],\n",
      "         [ 0.3404, -0.1903, -0.4894,  ..., -0.3484, -0.1666,  0.1258]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3577,  0.2800,  0.2037,  ...,  0.7450, -0.0404,  0.2655],\n",
      "          [-0.3038,  0.3088,  0.0754,  ..., -0.3404, -0.0769,  0.1805]],\n",
      "\n",
      "         [[ 0.3302,  0.2980, -0.5975,  ...,  0.8791, -0.2676,  0.5354],\n",
      "          [-0.4732,  0.3882,  0.0680,  ...,  0.1315, -0.4662,  0.5441]],\n",
      "\n",
      "         [[-0.1305,  0.7490, -0.4150,  ...,  0.5727,  0.0504,  0.9374],\n",
      "          [-0.6017,  0.7172,  1.0445,  ...,  0.5816, -0.8695,  1.3832]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3618,  0.8295, -0.2509,  ...,  0.2193, -0.0977,  0.6511],\n",
      "          [-0.8069,  0.7903,  0.5787,  ...,  0.1693, -0.8995,  1.1609]],\n",
      "\n",
      "         [[-0.1225,  0.6841, -0.5403,  ...,  0.5903,  0.0312,  0.5037],\n",
      "          [-0.3409,  0.5665,  0.3616,  ...,  0.4588, -0.2345,  1.0660]],\n",
      "\n",
      "         [[ 0.2595,  0.0825, -0.5167,  ...,  0.6017,  0.1817, -0.2153],\n",
      "          [-0.4661,  0.3406, -0.0344,  ..., -0.2062, -0.3607,  0.3727]]],\n",
      "\n",
      "\n",
      "        [[[-0.2201, -0.0144, -0.0774,  ...,  0.6784,  0.1805,  0.2397],\n",
      "          [-0.0605,  0.0453,  0.0433,  ..., -0.6115,  0.3912, -0.0125]],\n",
      "\n",
      "         [[ 0.2916,  0.0691, -0.1903,  ...,  0.5339,  0.4194, -0.1268],\n",
      "          [ 0.1159, -0.0895,  0.5127,  ..., -0.5232, -0.1742,  0.2232]],\n",
      "\n",
      "         [[-0.1177,  0.4989, -0.1205,  ...,  0.4891, -0.0100,  0.7693],\n",
      "          [-0.7440,  0.4526,  0.6762,  ..., -0.0592, -0.5500,  1.0284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3551,  0.2883, -0.1202,  ...,  0.3301,  0.0095,  0.3455],\n",
      "          [-0.6709,  0.5171,  0.7415,  ..., -0.1044, -0.2623,  0.7901]],\n",
      "\n",
      "         [[-0.1133,  0.8532, -0.3496,  ...,  0.4809,  0.3595,  0.2157],\n",
      "          [-0.3178,  0.1252,  0.1106,  ..., -0.3183, -0.1870,  0.4479]],\n",
      "\n",
      "         [[ 0.3404, -0.1903, -0.4894,  ...,  0.6169,  0.2482, -0.3332],\n",
      "          [-0.2898,  0.2840, -0.0842,  ..., -0.3484, -0.1666,  0.1258]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1860,  0.9009, -0.8822,  ...,  0.1828, -0.5775, -1.4751],\n",
      "         [-0.5167,  0.7945, -0.7358,  ..., -0.3564, -0.5390, -0.3447],\n",
      "         [ 0.0889,  0.5623, -0.2131,  ..., -0.1764,  0.1218, -0.5365],\n",
      "         ...,\n",
      "         [ 0.0627,  0.5800, -0.0221,  ..., -0.1949,  0.1917, -0.6116],\n",
      "         [-0.0459,  0.4138, -0.5192,  ..., -0.5586,  0.0852,  0.1100],\n",
      "         [-0.5478,  0.9642, -0.4353,  ...,  0.0943,  0.0443, -0.1434]],\n",
      "\n",
      "        [[-1.4879,  1.1552, -0.8568,  ...,  0.3985, -1.0406, -1.4223],\n",
      "         [-0.4464,  0.8762, -0.6166,  ..., -0.2941,  0.2337, -0.5725],\n",
      "         [ 0.1992,  0.5762, -0.2364,  ..., -0.6547, -0.2118, -0.7978],\n",
      "         ...,\n",
      "         [-0.3352,  0.6593, -0.1402,  ...,  0.0731, -0.2744, -0.4878],\n",
      "         [-0.6884,  0.5706, -0.5514,  ..., -0.4344,  0.1905, -0.5564],\n",
      "         [-0.5629,  0.9108, -0.4845,  ...,  0.0507, -0.1334, -0.2815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.1860,  0.9009, -0.8822,  ...,  1.9637,  0.9224,  0.6598],\n",
      "          [ 1.0493,  0.9140,  1.2219,  ...,  0.1828, -0.5775, -1.4751]],\n",
      "\n",
      "         [[-0.5167,  0.7945, -0.7358,  ...,  0.8526,  0.3657, -0.0340],\n",
      "          [ 0.2634,  0.4665,  0.7317,  ..., -0.3564, -0.5390, -0.3447]],\n",
      "\n",
      "         [[ 0.0889,  0.5623, -0.2131,  ...,  0.8001,  0.5143,  0.2583],\n",
      "          [ 0.6862,  0.4463,  0.7123,  ..., -0.1764,  0.1218, -0.5365]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627,  0.5800, -0.0221,  ...,  0.3144,  0.1900, -0.2160],\n",
      "          [ 0.1833,  0.0857,  0.2281,  ..., -0.1949,  0.1917, -0.6116]],\n",
      "\n",
      "         [[-0.0459,  0.4138, -0.5192,  ...,  0.6504,  0.2812, -0.3386],\n",
      "          [ 0.2814,  0.4916,  0.2383,  ..., -0.5586,  0.0852,  0.1100]],\n",
      "\n",
      "         [[-0.5478,  0.9642, -0.4353,  ..., -0.1015,  0.3682, -0.2034],\n",
      "          [ 0.2167,  0.7069,  0.1991,  ...,  0.0943,  0.0443, -0.1434]]],\n",
      "\n",
      "\n",
      "        [[[-1.4879,  1.1552, -0.8568,  ...,  2.1281,  0.9640,  0.8450],\n",
      "          [ 1.0153,  0.8573,  1.4165,  ...,  0.3985, -1.0406, -1.4223]],\n",
      "\n",
      "         [[-0.4464,  0.8762, -0.6166,  ...,  0.7965,  0.3356,  0.0356],\n",
      "          [ 0.3064,  0.5973,  0.3372,  ..., -0.2941,  0.2337, -0.5725]],\n",
      "\n",
      "         [[ 0.1992,  0.5762, -0.2364,  ...,  0.9029,  0.5630,  0.3178],\n",
      "          [ 0.2999,  0.5476,  0.5826,  ..., -0.6547, -0.2118, -0.7978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3352,  0.6593, -0.1402,  ...,  0.5490,  0.3094,  0.2462],\n",
      "          [-0.0537,  0.2861,  0.1601,  ...,  0.0731, -0.2744, -0.4878]],\n",
      "\n",
      "         [[-0.6884,  0.5706, -0.5514,  ...,  0.4872, -0.2086,  0.2016],\n",
      "          [ 0.3053,  0.3017,  0.3818,  ..., -0.4344,  0.1905, -0.5564]],\n",
      "\n",
      "         [[-0.5629,  0.9108, -0.4845,  ...,  0.0027,  0.2492, -0.1729],\n",
      "          [ 0.3020,  0.6107,  0.3848,  ...,  0.0507, -0.1334, -0.2815]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4675,  0.0432,  0.2267,  ..., -0.5583, -0.2144, -0.4410],\n",
      "          [-0.1849, -0.2984,  0.3823,  ..., -0.4946, -0.0375, -0.4337],\n",
      "          [ 0.1144, -0.0877, -0.3609,  ..., -0.3791, -0.1075, -0.4487],\n",
      "          ...,\n",
      "          [-0.1988, -0.3700,  0.2952,  ..., -0.7811, -0.6576, -0.1044],\n",
      "          [ 0.0765, -0.3715, -0.2171,  ..., -0.4826, -0.0313, -0.4550],\n",
      "          [ 0.3565, -0.4331,  0.3345,  ..., -0.7810, -0.8265, -0.3199]],\n",
      "\n",
      "         [[-0.4003, -0.2417, -0.3701,  ..., -0.4671, -0.1344,  0.0503],\n",
      "          [-0.5006, -0.2895, -0.4111,  ..., -0.1251, -0.0747,  0.5290],\n",
      "          [-0.7503, -0.3329,  0.3502,  ..., -0.1711,  0.0827, -0.2678],\n",
      "          ...,\n",
      "          [-0.3671, -0.2960, -0.3196,  ..., -0.0956,  0.0716,  0.3504],\n",
      "          [-0.5093, -0.3462, -0.5214,  ..., -0.2965, -0.0421,  0.3803],\n",
      "          [-0.6882, -0.6253, -0.8002,  ..., -0.3455,  0.4070,  0.5583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2321, -0.2398,  0.0335,  ..., -0.3351, -0.2158, -0.2967],\n",
      "          [ 0.1638, -0.2569, -0.0012,  ..., -0.4965, -0.1793, -0.4662],\n",
      "          [-0.3201, -0.1161, -0.1842,  ..., -0.5655, -0.0956, -0.4220],\n",
      "          ...,\n",
      "          [-0.3808, -0.5644,  0.1049,  ..., -0.0313, -0.3151, -0.1353],\n",
      "          [ 0.0825, -0.0434, -0.3595,  ..., -0.3784, -0.1028, -0.5065],\n",
      "          [ 0.5017, -0.4866,  0.1862,  ..., -0.5147, -0.6278, -0.2172]],\n",
      "\n",
      "         [[-0.4351, -0.2226,  0.0112,  ..., -0.4040,  0.0435,  0.0880],\n",
      "          [-0.3685, -0.3499, -0.4118,  ..., -0.5304,  0.3140,  0.2323],\n",
      "          [ 0.0207, -0.2961, -0.0090,  ..., -0.3979,  0.0681,  0.1296],\n",
      "          ...,\n",
      "          [ 0.0727, -0.5079, -0.4035,  ..., -0.3607,  0.0981,  0.6118],\n",
      "          [-0.0877, -0.0534, -0.6120,  ..., -0.3551,  0.0662,  0.4903],\n",
      "          [-0.4649, -0.2625, -0.4763,  ..., -0.0457,  0.3553,  0.2952]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          ...,\n",
      "          [ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01]],\n",
      "\n",
      "         [[-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01],\n",
      "          ...,\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          ...,\n",
      "          [ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01]],\n",
      "\n",
      "         [[-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01],\n",
      "          ...,\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 9.1406e-02,  2.9419e-01, -1.7776e-01,  ...,  6.5347e-01,\n",
      "            2.2865e-01,  4.6382e-01],\n",
      "          [-6.9614e-01,  2.8158e-01,  5.8686e-01,  ...,  2.7395e-01,\n",
      "           -3.5676e-01,  8.6241e-01]],\n",
      "\n",
      "         [[ 9.7514e-02,  4.1386e-01, -2.7980e-01,  ...,  6.7875e-01,\n",
      "            1.2100e-01,  5.1956e-01],\n",
      "          [-6.5229e-01,  3.5964e-01,  5.5781e-01,  ...,  2.1342e-01,\n",
      "           -4.4329e-01,  9.1090e-01]],\n",
      "\n",
      "         [[ 1.1205e-01,  3.1841e-01, -2.2931e-01,  ...,  6.1308e-01,\n",
      "            1.1371e-01,  4.0229e-01],\n",
      "          [-6.4568e-01,  3.6311e-01,  5.4542e-01,  ...,  2.0228e-01,\n",
      "           -4.4502e-01,  9.0586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0490e-02,  3.3783e-01, -1.7749e-01,  ...,  4.4602e-01,\n",
      "            1.0494e-01,  3.4454e-01],\n",
      "          [-6.0871e-01,  3.5860e-01,  5.1940e-01,  ...,  1.7543e-01,\n",
      "           -4.5065e-01,  8.8522e-01]],\n",
      "\n",
      "         [[ 9.6498e-02,  3.7471e-01, -2.6161e-01,  ...,  6.0540e-01,\n",
      "            5.2846e-02,  4.1370e-01],\n",
      "          [-6.1437e-01,  3.6481e-01,  5.1484e-01,  ...,  1.7959e-01,\n",
      "           -4.4581e-01,  8.8213e-01]],\n",
      "\n",
      "         [[ 1.3957e-01,  4.3258e-01, -3.4366e-01,  ...,  5.7247e-01,\n",
      "            7.6985e-02,  5.0021e-01],\n",
      "          [-5.7114e-01,  3.2098e-01,  4.0169e-01,  ...,  1.1218e-01,\n",
      "           -3.6916e-01,  7.7054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0451e-01, -7.0774e-02, -1.5944e-01,  ...,  4.5747e-01,\n",
      "            2.9840e-01,  3.0601e-01],\n",
      "          [-1.5182e-01, -3.4235e-02,  2.6270e-01,  ..., -3.6068e-01,\n",
      "            3.2249e-02,  1.9191e-01]],\n",
      "\n",
      "         [[ 1.5565e-01, -2.6881e-02, -1.0713e-01,  ...,  3.0564e-01,\n",
      "            1.9477e-01,  2.2616e-01],\n",
      "          [-3.0753e-01,  3.0743e-04,  3.2697e-01,  ..., -4.6263e-01,\n",
      "           -4.5599e-02,  3.4423e-01]],\n",
      "\n",
      "         [[ 1.7105e-01,  7.8622e-02, -1.4958e-01,  ...,  3.7695e-01,\n",
      "            2.3377e-01,  2.7185e-01],\n",
      "          [-3.0401e-01,  4.8402e-03,  2.9133e-01,  ..., -4.3545e-01,\n",
      "           -3.0171e-02,  3.2107e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7098e-02,  2.8600e-02, -1.7294e-01,  ...,  3.8200e-01,\n",
      "            2.2738e-01,  2.2766e-01],\n",
      "          [-2.7496e-01, -7.8817e-03,  3.2628e-01,  ..., -4.8852e-01,\n",
      "           -3.2923e-02,  3.1571e-01]],\n",
      "\n",
      "         [[ 1.3579e-01,  2.7378e-02, -1.8658e-01,  ...,  4.1548e-01,\n",
      "            2.6852e-01,  2.2331e-01],\n",
      "          [-2.6373e-01, -2.2761e-03,  3.3262e-01,  ..., -4.3284e-01,\n",
      "           -3.5851e-02,  3.0259e-01]],\n",
      "\n",
      "         [[ 1.0657e-01,  1.7194e-01, -1.4620e-01,  ...,  3.6528e-01,\n",
      "            1.7453e-01,  2.4265e-01],\n",
      "          [-2.7125e-01,  6.9568e-02,  1.7459e-01,  ..., -2.8850e-01,\n",
      "           -8.5086e-02,  3.0947e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[-1.5450,  1.8397],\n",
      "        [-0.6022,  0.6575]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:58:54,332] Trial 8 finished with value: 0.8588 and parameters: {'num_layers': 2, 'num_heads': 4, 'hidden_size': 192, 'intermediate_size': 768, 'linear_layer_type': 'linear'}. Best is trial 3 with value: 0.864.\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Param is num_layers, Chosen value is 4\n",
      "Param is num_heads, Chosen value is 2\n",
      "Param is hidden_size, Chosen value is 192\n",
      "Param is intermediate_size, Chosen value is 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.4106],\n",
      "         [ 0.0000,  0.7377, -1.4018,  ..., -0.0986,  0.1068,  1.4981],\n",
      "         [ 0.8399,  0.2045, -2.5034,  ...,  0.8103, -0.5601,  0.3678],\n",
      "         ...,\n",
      "         [ 1.2352,  1.4456, -1.2709,  ..., -0.0000, -1.3791,  0.4846],\n",
      "         [-1.0618,  1.2260, -0.9307,  ...,  0.0000, -0.7647,  2.0649],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]],\n",
      "\n",
      "        [[ 1.1483, -0.2449, -1.3610,  ...,  0.4858, -0.8093,  0.0000],\n",
      "         [ 1.2527,  0.4015, -0.6873,  ...,  0.0863, -0.9753,  0.9174],\n",
      "         [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -0.0000, -0.9757],\n",
      "         ...,\n",
      "         [ 1.0604,  1.2926, -1.0769,  ..., -0.7648, -1.5463, -0.0779],\n",
      "         [ 0.5784,  0.4119, -2.7959,  ..., -0.3034, -1.3607,  0.3801],\n",
      "         [-0.8574, -0.6963, -0.4221,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106]],\n",
      "\n",
      "         [[ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981]],\n",
      "\n",
      "         [[ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846]],\n",
      "\n",
      "         [[-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000]],\n",
      "\n",
      "         [[ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174]],\n",
      "\n",
      "         [[ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779]],\n",
      "\n",
      "         [[ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801]],\n",
      "\n",
      "         [[-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0383, -0.1855],\n",
      "          [ 0.0000,  0.7377, -1.4018,  ...,  0.4080, -0.0786, -0.0000],\n",
      "          [ 0.8399,  0.2045, -2.5034,  ...,  1.1603, -0.0000, -0.1285],\n",
      "          ...,\n",
      "          [ 1.2352,  1.4456, -1.2709,  ...,  2.2784, -0.8089, -1.0215],\n",
      "          [-1.0618,  1.2260, -0.9307,  ..., -0.2763, -1.4567,  0.8585],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.4106],\n",
      "          [-0.1642,  0.0384,  3.2738,  ..., -0.0986,  0.1068,  1.4981],\n",
      "          [-1.1987,  0.7092, -0.1511,  ...,  0.8103, -0.5601,  0.3678],\n",
      "          ...,\n",
      "          [ 0.3875, -0.5304,  2.1294,  ..., -0.0000, -1.3791,  0.4846],\n",
      "          [-1.3070, -0.6793,  1.7414,  ...,  0.0000, -0.7647,  2.0649],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1483, -0.2449, -1.3610,  ...,  1.3690, -0.0000, -0.1855],\n",
      "          [ 1.2527,  0.4015, -0.6873,  ..., -1.6156, -0.1163, -0.0775],\n",
      "          [ 0.2712,  0.0000, -1.4539,  ...,  0.0000, -1.4508, -0.8446],\n",
      "          ...,\n",
      "          [ 1.0604,  1.2926, -1.0769,  ...,  0.8447, -0.4162, -0.0206],\n",
      "          [ 0.5784,  0.4119, -2.7959,  ...,  0.2904, -1.4395,  0.0987],\n",
      "          [-0.8574, -0.6963, -0.4221,  ...,  0.3768, -0.7669, -1.1507]],\n",
      "\n",
      "         [[-0.7061, -1.7082,  1.5664,  ...,  0.4858, -0.8093,  0.0000],\n",
      "          [-0.1955,  1.7530,  1.6303,  ...,  0.0863, -0.9753,  0.9174],\n",
      "          [-1.1079, -0.4478,  2.1195,  ...,  0.0000, -0.0000, -0.9757],\n",
      "          ...,\n",
      "          [-0.8958,  0.2829,  0.0000,  ..., -0.7648, -1.5463, -0.0779],\n",
      "          [-1.9118, -0.7762,  1.8136,  ..., -0.3034, -1.3607,  0.3801],\n",
      "          [-0.7153,  0.4054,  1.0366,  ..., -0.5625,  0.2429,  0.8486]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          ...,\n",
      "          [ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00]],\n",
      "\n",
      "         [[-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01],\n",
      "          ...,\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          ...,\n",
      "          [ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00]],\n",
      "\n",
      "         [[-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00],\n",
      "          ...,\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.2705e+00, -2.7084e-01, -1.5067e+00,  ...,  1.5159e+00,\n",
      "           -4.3334e-02, -2.0663e-01],\n",
      "          [-5.9969e-01, -1.5334e+00,  1.5444e+00,  ...,  4.4638e-01,\n",
      "           -9.1600e-01,  4.6141e-01]],\n",
      "\n",
      "         [[ 6.9964e-03,  8.1193e-01, -1.5508e+00,  ...,  4.6026e-01,\n",
      "           -9.2408e-02, -5.3907e-03],\n",
      "          [-1.8271e-01,  4.0684e-02,  3.6299e+00,  ..., -1.0881e-01,\n",
      "            1.1548e-01,  1.6611e+00]],\n",
      "\n",
      "         [[ 9.2551e-01,  2.3239e-01, -2.7085e+00,  ...,  1.2946e+00,\n",
      "           -2.0768e-02, -1.6408e-01],\n",
      "          [-1.3286e+00,  7.8303e-01, -1.6252e-01,  ...,  8.9792e-01,\n",
      "           -6.2314e-01,  4.0972e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3660e+00,  1.5562e+00, -1.4047e+00,  ...,  2.5013e+00,\n",
      "           -8.7700e-01, -1.1167e+00],\n",
      "          [ 4.0521e-01, -5.8180e-01,  2.3007e+00,  ...,  1.5648e-02,\n",
      "           -1.5026e+00,  5.3219e-01]],\n",
      "\n",
      "         [[-1.1677e+00,  1.3563e+00, -1.0345e+00,  ..., -2.9728e-01,\n",
      "           -1.6105e+00,  9.4557e-01],\n",
      "          [-1.4394e+00, -7.4696e-01,  1.9250e+00,  ...,  3.4075e-03,\n",
      "           -8.4551e-01,  2.2735e+00]],\n",
      "\n",
      "         [[-9.3388e-01, -7.6272e-01, -4.7620e-01,  ...,  4.2909e-01,\n",
      "           -8.4695e-01, -1.2708e+00],\n",
      "          [-7.9015e-01,  4.4318e-01,  1.1479e+00,  ..., -6.1910e-01,\n",
      "            2.6210e-01,  9.3707e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7854e-03,  2.5919e-03, -6.2258e-03,  ..., -1.6089e-03,\n",
      "           -2.1339e-03, -2.3979e-03],\n",
      "          [-6.7684e-01, -1.5885e+00,  1.4340e+00,  ...,  4.2289e-01,\n",
      "           -8.3962e-01, -3.1111e-03]],\n",
      "\n",
      "         [[ 1.3894e+00,  4.4233e-01, -7.6785e-01,  ..., -1.7744e+00,\n",
      "           -1.2962e-01, -8.7697e-02],\n",
      "          [-2.2182e-01,  1.9072e+00,  1.7954e+00,  ...,  9.5097e-02,\n",
      "           -1.0765e+00,  1.0050e+00]],\n",
      "\n",
      "         [[ 3.0418e-01,  2.8656e-03, -1.6123e+00,  ...,  1.0773e-02,\n",
      "           -1.5944e+00, -9.3062e-01],\n",
      "          [-1.2351e+00, -5.0019e-01,  2.3412e+00,  ..., -1.0418e-03,\n",
      "           -2.3013e-02, -1.0598e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1488e+00,  1.3258e+00, -1.1898e+00,  ...,  9.4083e-01,\n",
      "           -4.3847e-01, -4.3008e-02],\n",
      "          [-6.0692e-03, -9.6471e-03,  1.1575e-02,  ...,  3.6290e-03,\n",
      "           -1.0248e-02, -3.6492e-04]],\n",
      "\n",
      "         [[ 6.4192e-01,  4.5287e-01, -3.0809e+00,  ...,  3.2839e-01,\n",
      "           -1.5847e+00,  1.0136e-01],\n",
      "          [-2.0858e+00, -8.4454e-01,  1.9824e+00,  ..., -3.2570e-01,\n",
      "           -1.4961e+00,  4.0616e-01]],\n",
      "\n",
      "         [[-9.4140e-01, -7.6853e-01, -4.7348e-01,  ...,  4.2036e-01,\n",
      "           -8.4778e-01, -1.2721e+00],\n",
      "          [-7.7369e-01,  4.0879e-01,  1.1240e+00,  ..., -5.9652e-01,\n",
      "            2.4059e-01,  9.0505e-01]]]], grad_fn=<CloneBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.4921e-01,\n",
      "          -8.4813e-01,  1.3354e-01],\n",
      "         [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ..., -8.0228e-02,\n",
      "          -1.7036e-01,  1.3803e+00],\n",
      "         [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  7.7553e-01,\n",
      "          -6.1885e-01,  2.2161e-01],\n",
      "         ...,\n",
      "         [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  1.2577e-02,\n",
      "          -6.2308e-01,  1.6907e-01],\n",
      "         [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ...,  8.0065e-02,\n",
      "          -7.8435e-01,  1.7273e+00],\n",
      "         [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ..., -4.4983e-01,\n",
      "           2.4408e-01,  8.5303e-01]],\n",
      "\n",
      "        [[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  7.6608e-01,\n",
      "          -1.1740e+00, -2.0165e-01],\n",
      "         [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ...,  2.7860e-01,\n",
      "          -1.0081e+00,  4.7268e-01],\n",
      "         [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ..., -1.1049e-01,\n",
      "          -2.8774e-02, -1.1584e+00],\n",
      "         ...,\n",
      "         [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ..., -5.2852e-01,\n",
      "          -9.4226e-01, -2.0686e-01],\n",
      "         [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ..., -1.3112e-01,\n",
      "          -6.6523e-01, -5.0559e-02],\n",
      "         [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ..., -4.3586e-01,\n",
      "           2.3241e-01,  7.7556e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01]],\n",
      "\n",
      "         [[-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00]],\n",
      "\n",
      "         [[ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01]],\n",
      "\n",
      "         [[-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00]],\n",
      "\n",
      "         [[-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01]],\n",
      "\n",
      "         [[ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01]],\n",
      "\n",
      "         [[ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01]],\n",
      "\n",
      "         [[ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02]],\n",
      "\n",
      "         [[-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.9176e-01, -7.1604e-02, -1.1730e+00,  ...,  6.3097e-01,\n",
      "            1.3823e-01, -2.9474e-01],\n",
      "          [-1.0817e-01,  5.5234e-01, -1.0511e+00,  ...,  3.6303e-01,\n",
      "            1.1507e-01, -9.5211e-03],\n",
      "          [ 6.6953e-01,  2.2223e-01, -2.3871e+00,  ...,  1.2076e+00,\n",
      "            1.4966e-01, -5.7100e-02],\n",
      "          ...,\n",
      "          [ 1.0725e+00,  1.4029e+00, -1.2045e+00,  ...,  2.2896e+00,\n",
      "           -5.8199e-01, -9.8621e-01],\n",
      "          [-1.0191e+00,  1.0386e+00, -6.8653e-01,  ..., -2.8768e-01,\n",
      "           -1.3919e+00,  8.5163e-01],\n",
      "          [-8.7969e-01, -6.2405e-01,  1.1004e-01,  ...,  4.8571e-01,\n",
      "           -7.1951e-01, -9.6409e-01]],\n",
      "\n",
      "         [[-5.3873e-01, -1.9584e+00,  1.4377e+00,  ...,  6.4921e-01,\n",
      "           -8.4813e-01,  1.3354e-01],\n",
      "          [-1.1317e-01, -2.7087e-01,  3.1971e+00,  ..., -8.0228e-02,\n",
      "           -1.7036e-01,  1.3803e+00],\n",
      "          [-1.1094e+00, -5.7659e-03, -3.3243e-02,  ...,  7.7553e-01,\n",
      "           -6.1885e-01,  2.2161e-01],\n",
      "          ...,\n",
      "          [ 3.6517e-01, -8.1146e-01,  2.0899e+00,  ...,  1.2577e-02,\n",
      "           -6.2308e-01,  1.6907e-01],\n",
      "          [-1.2752e+00, -9.6439e-01,  1.5908e+00,  ...,  8.0065e-02,\n",
      "           -7.8435e-01,  1.7273e+00],\n",
      "          [-6.5804e-01,  1.5783e-01,  1.0776e+00,  ..., -4.4983e-01,\n",
      "            2.4408e-01,  8.5303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2370e-01, -1.3216e-01, -6.2066e-01,  ...,  8.0265e-01,\n",
      "            1.4033e-01, -1.4957e-01],\n",
      "          [ 1.0807e+00,  1.8293e-01, -5.5901e-01,  ..., -1.5647e+00,\n",
      "           -6.3112e-02, -1.2302e-02],\n",
      "          [ 1.6631e-04,  2.6393e-02, -1.3407e+00,  ...,  7.8251e-02,\n",
      "           -1.2245e+00, -8.7167e-01],\n",
      "          ...,\n",
      "          [ 1.3374e+00,  1.5859e+00, -1.4173e+00,  ...,  1.0675e+00,\n",
      "           -4.1487e-01,  1.0631e-02],\n",
      "          [ 4.0174e-01,  2.6935e-01, -2.5047e+00,  ...,  3.2639e-01,\n",
      "           -1.3990e+00,  1.8264e-01],\n",
      "          [-9.2763e-01, -7.1839e-01, -2.6878e-01,  ...,  4.0190e-01,\n",
      "           -7.6938e-01, -1.0520e+00]],\n",
      "\n",
      "         [[-7.9815e-01, -2.6270e+00,  1.9793e+00,  ...,  7.6608e-01,\n",
      "           -1.1740e+00, -2.0165e-01],\n",
      "          [-3.5186e-01,  1.4112e+00,  1.5676e+00,  ...,  2.7860e-01,\n",
      "           -1.0081e+00,  4.7268e-01],\n",
      "          [-9.1028e-01, -6.1653e-01,  2.0951e+00,  ..., -1.1049e-01,\n",
      "           -2.8774e-02, -1.1584e+00],\n",
      "          ...,\n",
      "          [-5.7521e-01, -1.0624e-01,  3.9337e-02,  ..., -5.2852e-01,\n",
      "           -9.4226e-01, -2.0686e-01],\n",
      "          [-1.9481e+00, -1.1562e+00,  1.6447e+00,  ..., -1.3112e-01,\n",
      "           -6.6523e-01, -5.0559e-02],\n",
      "          [-6.8437e-01,  2.6945e-01,  1.1013e+00,  ..., -4.3586e-01,\n",
      "            2.3241e-01,  7.7556e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          ...,\n",
      "          [ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584]],\n",
      "\n",
      "         [[-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470],\n",
      "          ...,\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          ...,\n",
      "          [ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641]],\n",
      "\n",
      "         [[-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474],\n",
      "          ...,\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 1.0974, -0.0642, -1.2986,  ...,  0.7178,  0.1432, -0.3353],\n",
      "          [-0.2600, -2.1236,  0.9635,  ...,  0.6144, -1.3113,  0.0502]],\n",
      "\n",
      "         [[-0.0951,  0.6051, -1.1614,  ...,  0.4247,  0.1124, -0.0240],\n",
      "          [-0.1251, -0.3098,  3.5312,  ..., -0.0860, -0.1975,  1.5238]],\n",
      "\n",
      "         [[ 0.0554,  0.0353, -0.0686,  ...,  0.0900, -0.0196, -0.0438],\n",
      "          [-1.2210, -0.0235, -0.0266,  ...,  0.8564, -0.6943,  0.2470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1927,  1.5077, -1.3198,  ...,  2.4942, -0.6226, -1.0813],\n",
      "          [ 0.3747, -0.9618,  2.2001,  ...,  0.0469, -0.7495,  0.1841]],\n",
      "\n",
      "         [[-1.1129,  1.1454, -0.7648,  ..., -0.3073, -1.5314,  0.9331],\n",
      "          [-1.3811, -1.0681,  1.7487,  ...,  0.0966, -0.8722,  1.8723]],\n",
      "\n",
      "         [[-0.9513, -0.6711,  0.1085,  ...,  0.5474, -0.7882, -1.0584],\n",
      "          [-0.7248,  0.1609,  1.1940,  ..., -0.4915,  0.2569,  0.9399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6316,  0.4798, -1.0295,  ...,  0.4442, -0.3779, -0.2385],\n",
      "          [-0.8844, -2.9105,  2.1921,  ...,  0.8483, -1.2999, -0.2236]],\n",
      "\n",
      "         [[ 1.1949,  0.2017, -0.6200,  ..., -1.7300, -0.0709, -0.0152],\n",
      "          [-0.4101,  1.4268,  1.7122,  ...,  0.3107, -1.1168,  0.4850]],\n",
      "\n",
      "         [[ 0.0088,  0.0394, -1.4853,  ...,  0.0970, -1.3474, -0.9563],\n",
      "          [-1.0160, -0.7050,  2.3097,  ..., -0.1065, -0.0727, -1.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4856,  1.7616, -1.5746,  ...,  1.1859, -0.4611,  0.0117],\n",
      "          [-0.8513, -1.2431,  1.2021,  ...,  0.2977, -1.3144, -0.3290]],\n",
      "\n",
      "         [[ 0.4500,  0.3077, -2.7381,  ...,  0.3682, -1.5260,  0.1892],\n",
      "          [-0.1466, -0.2815,  0.2639,  ...,  0.1077, -0.2505, -0.0745]],\n",
      "\n",
      "         [[-1.0221, -0.7906, -0.3028,  ...,  0.4467, -0.8532, -1.1641],\n",
      "          [-0.7610,  0.2202,  1.2289,  ..., -0.4361,  0.1751,  0.8053]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.9553,  0.7356],\n",
      "        [-0.0274, -0.0352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "Model forward signature after compression: {'input_ids': <class 'torch.Tensor'>, 'attention_mask': <class 'torch.Tensor'>, 'token_type_ids': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:03:28,348] Trial 9 finished with value: 0.84976 and parameters: {'num_layers': 4, 'num_heads': 2, 'hidden_size': 192, 'intermediate_size': 512, 'linear_layer_type': 'identity'}. Best is trial 3 with value: 0.864.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "from chop.tools import get_trainer\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "import torch\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4],\n",
    "    \"num_heads\": [2, 4],\n",
    "    \"hidden_size\": [128, 192],\n",
    "    \"intermediate_size\": [512, 768],\n",
    "    \"linear_layer_type\": [\"linear\", \"identity\"],  # 用字符串代替类名\n",
    "}\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        # chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # # 将选中的值设置到 config 中\n",
    "        # print(f\"Param is {param}\")\n",
    "        # print(f\"Choose from 0 to {len(search_space[param]) - 1}\")\n",
    "        # print(f\"Idx is {chosen_idx}\")\n",
    "        # setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "        chosen_value = trial.suggest_categorical(param, search_space[param])\n",
    "        print(f\"Param is {param}, Chosen value is {chosen_value}\")\n",
    "        setattr(config, param, chosen_value)\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            # new_layer_cls = trial.suggest_categorical(\n",
    "            #     f\"{name}_type\",\n",
    "            #     search_space[\"linear_layer_choices\"],\n",
    "            # )\n",
    "            # 选择 nn.Linear 还是 Identity\n",
    "            linear_type = trial.suggest_categorical(\"linear_layer_type\", [\"linear\", \"identity\"])\n",
    "            if linear_type == \"linear\":\n",
    "                new_layer_cls = nn.Linear\n",
    "            else:\n",
    "                new_layer_cls = Identity\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 确定运行设备\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial).to(device)  # 将模型移动到 GPU\n",
    "\n",
    "    # Train a few epoches\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Compression\n",
    "    mg = MaseGraph(model.to(\"cpu\"),\n",
    "                   hf_input_names=[\n",
    "                        \"input_ids\",\n",
    "                        \"attention_mask\",\n",
    "                        \"labels\",\n",
    "                        \"token_type_ids\",\n",
    "                    ],)  # 确保 MaseGraph 处理前，模型在 CPU\n",
    "    pipe = CompressionPipeline()\n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": 8,\n",
    "                \"data_in_frac_width\": 4,\n",
    "                # weight\n",
    "                \"weight_width\": 8,\n",
    "                \"weight_frac_width\": 4,\n",
    "                # bias\n",
    "                \"bias_width\": 8,\n",
    "                \"bias_frac_width\": 4,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    pruning_config = {\n",
    "        \"weight\": {\n",
    "            \"sparsity\": 0.5,\n",
    "            \"method\": \"l1-norm\",\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"sparsity\": 0.5,\n",
    "            \"method\": \"l1-norm\",\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "    }\n",
    "    mg, _ = pipe(\n",
    "        mg,\n",
    "        pass_args={\n",
    "            \"quantize_transform_pass\": quantization_config,\n",
    "            \"prune_transform_pass\": pruning_config,\n",
    "        },\n",
    "    )\n",
    "    print(\"Model forward signature after compression:\", mg.model.forward.__annotations__)\n",
    "    \n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "    \n",
    "    # 继续训练\n",
    "    model = mg.model.to(device)\n",
    "\n",
    "    # **4. 继续训练压缩后的模型**\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,  # 这里不需要 .to(device)，Trainer 处理\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,  \n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # 获取当前 trial 结果\n",
    "    eval_results = trainer.evaluate()\n",
    "    accuracy = eval_results[\"eval_accuracy\"]\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # 实时保存到 JSON 文件\n",
    "    log_data = {\n",
    "        \"trial\": trial_number,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"params\": trial.params,  # 记录所有超参数\n",
    "        \"compression\": True,\n",
    "        \"post_training\": True  # 这里标记进行 post-training\n",
    "    }\n",
    "\n",
    "    # 追加写入 JSON 文件\n",
    "    with open(\"lab2_com_post_results.json\", \"a\") as f:\n",
    "        f.write(json.dumps(log_data) + \"\\n\")\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "sampler = TPESampler()\n",
    "n_trial = 10\n",
    "# 创建 study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "# 运行超参数搜索\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trial,\n",
    "    timeout=60 * 60 * 24,\n",
    ")\n",
    "\n",
    "# 获取所有 trial 的准确率\n",
    "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "accuracies = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "# 计算累积最大准确率\n",
    "best_so_far = np.maximum.accumulate(accuracies)\n",
    "\n",
    "# 绘制 \"n_trials vs. best accuracy\" 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(trial_numbers, best_so_far, marker='o', linestyle='-', label=\"GridSampler\")\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Grid Search Performance on BERT-tiny NAS\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the three JSON files\n",
    "file_paths = [\n",
    "    \"lab2_no_com_results.json\",   # Task 1: No compression\n",
    "    \"lab2_com_no_post_results.json\", # Task 2: Compression without post-training\n",
    "    \"lab2_com_post_results.json\" # Task 2: Compression with post-training\n",
    "]\n",
    "\n",
    "# Store results from each file\n",
    "task_results = {}\n",
    "\n",
    "for file_path, label in zip(file_paths, [\"No Compression\", \"Compression No Post-Training\", \"Compression With Post-Training\"]):\n",
    "    trials = []\n",
    "    accuracies = []\n",
    "\n",
    "    # Read JSONL file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())  # Load each line as JSON\n",
    "            trials.append(data[\"trial\"])\n",
    "            accuracies.append(data[\"accuracy\"])\n",
    "\n",
    "    # Sort by trial number to ensure proper order\n",
    "    sorted_trials, sorted_accuracies = zip(*sorted(zip(trials, accuracies)))\n",
    "\n",
    "    # Compute cumulative best accuracy\n",
    "    cumulative_best_acc = np.maximum.accumulate(sorted_accuracies)\n",
    "\n",
    "    # Store results\n",
    "    task_results[label] = (sorted_trials, cumulative_best_acc)\n",
    "\n",
    "# Plot the figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for label, (trials, best_acc) in task_results.items():\n",
    "    plt.plot(trials, best_acc, marker='o', linestyle='-', label=label)\n",
    "\n",
    "plt.xlabel(\"Number of Trials\")\n",
    "plt.ylabel(\"Best Accuracy Achieved\")\n",
    "plt.title(\"Comparison of NAS Performance with and without Compression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# // {\"trial\": 10, \"accuracy\": 0.79944, \"params\": {\"num_layers\": 4, \"num_heads\": 4, \"hidden_size\": 192, \"intermediate_size\": 512, \"linear_layer_type\": \"linear\"}, \"compression\": true, \"post_training\": false}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
