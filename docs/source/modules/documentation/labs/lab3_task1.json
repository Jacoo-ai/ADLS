{"trial": 0, "accuracy": 0.87312, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_weight_width": 32, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_width": 32, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.query_weight_width": 16, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 16, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_width": 16, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_bias_width": 16, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 8, "bert.encoder.layer.1.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 2, "classifier_type": "LinearInteger", "classifier_data_in_width": 32, "classifier_data_in_frac_width": 4, "classifier_weight_width": 16, "classifier_weight_frac_width": 8, "classifier_bias_width": 8, "classifier_bias_frac_width": 8}}
{"trial": 1, "accuracy": 0.87468, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 8, "bert.encoder.layer.0.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.output.dense_weight_width": 32, "bert.encoder.layer.0.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.output.dense_bias_width": 8, "bert.encoder.layer.0.output.dense_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 32, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 8, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 16, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 2, "accuracy": 0.87008, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 8, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_weight_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_bias_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 32, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 32, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_bias_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 8, "bert.encoder.layer.0.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.output.dense_weight_width": 16, "bert.encoder.layer.0.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.output.dense_bias_width": 16, "bert.encoder.layer.0.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 16, "bert.encoder.layer.1.output.dense_data_in_frac_width": 4, "bert.encoder.layer.1.output.dense_weight_width": 8, "bert.encoder.layer.1.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.output.dense_bias_width": 32, "bert.encoder.layer.1.output.dense_bias_frac_width": 8, "classifier_type": "LinearInteger", "classifier_data_in_width": 8, "classifier_data_in_frac_width": 2, "classifier_weight_width": 8, "classifier_weight_frac_width": 4, "classifier_bias_width": 32, "classifier_bias_frac_width": 2}}
{"trial": 3, "accuracy": 0.5, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 32, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.value_weight_width": 32, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.value_bias_width": 8, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 32, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 32, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_bias_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 4, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 4, "classifier_type": "LinearInteger", "classifier_data_in_width": 8, "classifier_data_in_frac_width": 4, "classifier_weight_width": 32, "classifier_weight_frac_width": 2, "classifier_bias_width": 8, "classifier_bias_frac_width": 2}}
{"trial": 4, "accuracy": 0.85992, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 8, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 8, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 8, "bert.encoder.layer.0.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.output.dense_weight_width": 32, "bert.encoder.layer.0.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.output.dense_bias_width": 32, "bert.encoder.layer.0.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 32, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 16, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_weight_width": 32, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_width": 16, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 16, "classifier_data_in_frac_width": 2, "classifier_weight_width": 16, "classifier_weight_frac_width": 4, "classifier_bias_width": 8, "classifier_bias_frac_width": 4}}
{"trial": 5, "accuracy": 0.8674, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 8, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 8, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.value_weight_width": 32, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.value_bias_width": 32, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 32, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_weight_width": 32, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_width": 32, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 8, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 32, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 16, "bert.encoder.layer.0.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.output.dense_weight_width": 8, "bert.encoder.layer.0.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.output.dense_bias_width": 16, "bert.encoder.layer.0.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 16, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 6, "accuracy": 0.87204, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 8, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.value_weight_width": 16, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.value_bias_width": 16, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 32, "bert.encoder.layer.0.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.output.dense_weight_width": 8, "bert.encoder.layer.0.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.output.dense_bias_width": 32, "bert.encoder.layer.0.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 32, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_bias_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 8, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 32, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 16, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.output.dense_bias_width": 32, "bert.encoder.layer.1.output.dense_bias_frac_width": 8, "classifier_type": "LinearInteger", "classifier_data_in_width": 16, "classifier_data_in_frac_width": 2, "classifier_weight_width": 16, "classifier_weight_frac_width": 4, "classifier_bias_width": 16, "classifier_bias_frac_width": 8}}
{"trial": 7, "accuracy": 0.85256, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 32, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.value_weight_width": 32, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.value_bias_width": 16, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 32, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_bias_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 8, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 16, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_width": 32, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 32, "bert.encoder.layer.0.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.output.dense_weight_width": 16, "bert.encoder.layer.0.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.output.dense_bias_width": 32, "bert.encoder.layer.0.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.value_bias_width": 8, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 8, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_bias_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 32, "classifier_data_in_frac_width": 2, "classifier_weight_width": 16, "classifier_weight_frac_width": 4, "classifier_bias_width": 16, "classifier_bias_frac_width": 4}}
{"trial": 0, "accuracy": 0.87376, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 32, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 16, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 8, "classifier_type": "torch.nn.Linear"}}
{"trial": 1, "accuracy": 0.87192, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 16, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.value_weight_width": 16, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.value_bias_width": 8, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_weight_width": 16, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_bias_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 16, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_weight_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_bias_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 32, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 8, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.output.dense_bias_width": 16, "bert.encoder.layer.1.output.dense_bias_frac_width": 4, "classifier_type": "LinearInteger", "classifier_data_in_width": 32, "classifier_data_in_frac_width": 2, "classifier_weight_width": 32, "classifier_weight_frac_width": 8, "classifier_bias_width": 16, "classifier_bias_frac_width": 2}}
{"trial": 2, "accuracy": 0.87216, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 16, "bert.encoder.layer.0.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.output.dense_weight_width": 8, "bert.encoder.layer.0.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.output.dense_bias_width": 8, "bert.encoder.layer.0.output.dense_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 32, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 8, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 8, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_weight_width": 16, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_bias_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 16, "classifier_data_in_frac_width": 2, "classifier_weight_width": 16, "classifier_weight_frac_width": 4, "classifier_bias_width": 16, "classifier_bias_frac_width": 8}}
{"trial": 3, "accuracy": 0.87388, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 4, "accuracy": 0.87312, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 8, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_weight_width": 32, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_width": 32, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 32, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_width": 16, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.value_weight_width": 8, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 32, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 8, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_weight_width": 32, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_bias_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 32, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_bias_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 32, "bert.encoder.layer.1.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.output.dense_bias_width": 32, "bert.encoder.layer.1.output.dense_bias_frac_width": 8, "classifier_type": "torch.nn.Linear"}}
{"trial": 5, "accuracy": 0.86776, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_width": 32, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_bias_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 16, "bert.encoder.layer.0.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.output.dense_weight_width": 16, "bert.encoder.layer.0.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.output.dense_bias_width": 32, "bert.encoder.layer.0.output.dense_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.value_weight_width": 32, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 32, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 32, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_bias_width": 16, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.output.dense_bias_width": 16, "bert.encoder.layer.1.output.dense_bias_frac_width": 4, "classifier_type": "torch.nn.Linear"}}
{"trial": 6, "accuracy": 0.86336, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 8, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 32, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 32, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.value_weight_width": 8, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.value_bias_width": 8, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_weight_width": 32, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_width": 16, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 16, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 8, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_width": 16, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 8, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 8, "bert.encoder.layer.1.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 2, "classifier_type": "torch.nn.Linear"}}
{"trial": 7, "accuracy": 0.87272, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 32, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 32, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_width": 16, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_bias_width": 32, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 32, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_weight_width": 8, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_bias_width": 16, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 8, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 32, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 8, "accuracy": 0.86648, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 16, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.value_weight_width": 8, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.value_bias_width": 8, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 8, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 8, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_bias_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 8, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.value_bias_width": 32, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 8, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 16, "bert.encoder.layer.1.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.output.dense_weight_width": 32, "bert.encoder.layer.1.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.output.dense_bias_width": 16, "bert.encoder.layer.1.output.dense_bias_frac_width": 4, "classifier_type": "LinearInteger", "classifier_data_in_width": 16, "classifier_data_in_frac_width": 4, "classifier_weight_width": 16, "classifier_weight_frac_width": 8, "classifier_bias_width": 32, "classifier_bias_frac_width": 2}}
{"trial": 9, "accuracy": 0.87088, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 16, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_weight_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_bias_width": 32, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 32, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_weight_width": 16, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_width": 16, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 32, "bert.encoder.layer.1.output.dense_data_in_frac_width": 4, "bert.encoder.layer.1.output.dense_weight_width": 32, "bert.encoder.layer.1.output.dense_weight_frac_width": 4, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 2, "classifier_type": "torch.nn.Linear"}}
{"trial": 10, "accuracy": 0.85124, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 8, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.value_weight_width": 32, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.value_bias_width": 32, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 8, "bert.encoder.layer.0.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.output.dense_weight_width": 32, "bert.encoder.layer.0.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.output.dense_bias_width": 16, "bert.encoder.layer.0.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 8, "classifier_data_in_frac_width": 8, "classifier_weight_width": 8, "classifier_weight_frac_width": 2, "classifier_bias_width": 8, "classifier_bias_frac_width": 4}}
{"trial": 11, "accuracy": 0.87304, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 16, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 16, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 12, "accuracy": 0.873, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 32, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_bias_width": 16, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 13, "accuracy": 0.87024, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 8, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 8, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 8, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.1.intermediate.dense_weight_width": 8, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 2, "bert.encoder.layer.1.intermediate.dense_bias_width": 32, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 14, "accuracy": 0.86632, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 8, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 32, "bert.encoder.layer.0.output.dense_data_in_frac_width": 4, "bert.encoder.layer.0.output.dense_weight_width": 8, "bert.encoder.layer.0.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.output.dense_bias_width": 16, "bert.encoder.layer.0.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 8, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 32, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "LinearInteger", "bert.encoder.layer.1.output.dense_data_in_width": 32, "bert.encoder.layer.1.output.dense_data_in_frac_width": 8, "bert.encoder.layer.1.output.dense_weight_width": 16, "bert.encoder.layer.1.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.output.dense_bias_width": 8, "bert.encoder.layer.1.output.dense_bias_frac_width": 8, "classifier_type": "torch.nn.Linear"}}
{"trial": 15, "accuracy": 0.87276, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 2, "bert.encoder.layer.0.attention.self.key_weight_width": 16, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.query_weight_width": 16, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.1.intermediate.dense_data_in_width": 16, "bert.encoder.layer.1.intermediate.dense_data_in_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_weight_width": 32, "bert.encoder.layer.1.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_width": 8, "bert.encoder.layer.1.intermediate.dense_bias_frac_width": 8, "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 16, "accuracy": 0.87404, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 8, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 17, "accuracy": 0.86576, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 8, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.key_bias_width": 16, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 4, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 8, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 18, "accuracy": 0.83364, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 8, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.value_weight_width": 16, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.value_bias_width": 16, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 16, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_weight_width": 32, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 4, "bert.encoder.layer.0.intermediate.dense_bias_width": 32, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 2, "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 8, "bert.encoder.layer.0.output.dense_data_in_frac_width": 2, "bert.encoder.layer.0.output.dense_weight_width": 32, "bert.encoder.layer.0.output.dense_weight_frac_width": 8, "bert.encoder.layer.0.output.dense_bias_width": 8, "bert.encoder.layer.0.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 32, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 8, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 32, "classifier_data_in_frac_width": 4, "classifier_weight_width": 32, "classifier_weight_frac_width": 2, "classifier_bias_width": 8, "classifier_bias_frac_width": 8}}
{"trial": 19, "accuracy": 0.86, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 16, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 2, "bert.encoder.layer.0.attention.self.key_bias_width": 32, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 8, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 8, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 16, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.value_weight_width": 8, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 20, "accuracy": 0.87408, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 21, "accuracy": 0.87408, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 22, "accuracy": 0.87408, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 23, "accuracy": 0.87408, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 24, "accuracy": 0.87312, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 8, "bert.encoder.layer.0.attention.self.key_weight_width": 32, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 4, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 4, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 25, "accuracy": 0.87416, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 26, "accuracy": 0.87, "params": {"bert.encoder.layer.0.attention.self.key_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.self.value_type": "LinearInteger", "bert.encoder.layer.0.attention.self.value_data_in_width": 32, "bert.encoder.layer.0.attention.self.value_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.value_weight_width": 32, "bert.encoder.layer.0.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.0.attention.self.value_bias_width": 32, "bert.encoder.layer.0.attention.self.value_bias_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.0.attention.output.dense_data_in_width": 8, "bert.encoder.layer.0.attention.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.attention.output.dense_weight_width": 16, "bert.encoder.layer.0.attention.output.dense_weight_frac_width": 4, "bert.encoder.layer.0.attention.output.dense_bias_width": 16, "bert.encoder.layer.0.attention.output.dense_bias_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_type": "LinearInteger", "bert.encoder.layer.0.intermediate.dense_data_in_width": 8, "bert.encoder.layer.0.intermediate.dense_data_in_frac_width": 2, "bert.encoder.layer.0.intermediate.dense_weight_width": 16, "bert.encoder.layer.0.intermediate.dense_weight_frac_width": 8, "bert.encoder.layer.0.intermediate.dense_bias_width": 16, "bert.encoder.layer.0.intermediate.dense_bias_frac_width": 4, "bert.encoder.layer.0.output.dense_type": "LinearInteger", "bert.encoder.layer.0.output.dense_data_in_width": 32, "bert.encoder.layer.0.output.dense_data_in_frac_width": 8, "bert.encoder.layer.0.output.dense_weight_width": 16, "bert.encoder.layer.0.output.dense_weight_frac_width": 2, "bert.encoder.layer.0.output.dense_bias_width": 32, "bert.encoder.layer.0.output.dense_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 8, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "LinearInteger", "bert.encoder.layer.1.attention.output.dense_data_in_width": 16, "bert.encoder.layer.1.attention.output.dense_data_in_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_weight_width": 16, "bert.encoder.layer.1.attention.output.dense_weight_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_bias_width": 32, "bert.encoder.layer.1.attention.output.dense_bias_frac_width": 8, "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "LinearInteger", "classifier_data_in_width": 8, "classifier_data_in_frac_width": 8, "classifier_weight_width": 8, "classifier_weight_frac_width": 4, "classifier_bias_width": 32, "classifier_bias_frac_width": 4}}
{"trial": 27, "accuracy": 0.87416, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 28, "accuracy": 0.873, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 16, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 16, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 4, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
{"trial": 29, "accuracy": 0.87416, "params": {"bert.encoder.layer.0.attention.self.key_type": "LinearInteger", "bert.encoder.layer.0.attention.self.key_data_in_width": 32, "bert.encoder.layer.0.attention.self.key_data_in_frac_width": 4, "bert.encoder.layer.0.attention.self.key_weight_width": 8, "bert.encoder.layer.0.attention.self.key_weight_frac_width": 8, "bert.encoder.layer.0.attention.self.key_bias_width": 8, "bert.encoder.layer.0.attention.self.key_bias_frac_width": 2, "bert.encoder.layer.0.attention.self.value_type": "torch.nn.Linear", "bert.encoder.layer.0.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.0.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.attention.self.query_type": "LinearInteger", "bert.encoder.layer.1.attention.self.query_data_in_width": 16, "bert.encoder.layer.1.attention.self.query_data_in_frac_width": 8, "bert.encoder.layer.1.attention.self.query_weight_width": 32, "bert.encoder.layer.1.attention.self.query_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.query_bias_width": 8, "bert.encoder.layer.1.attention.self.query_bias_frac_width": 2, "bert.encoder.layer.1.attention.self.value_type": "LinearInteger", "bert.encoder.layer.1.attention.self.value_data_in_width": 32, "bert.encoder.layer.1.attention.self.value_data_in_frac_width": 2, "bert.encoder.layer.1.attention.self.value_weight_width": 16, "bert.encoder.layer.1.attention.self.value_weight_frac_width": 2, "bert.encoder.layer.1.attention.self.value_bias_width": 16, "bert.encoder.layer.1.attention.self.value_bias_frac_width": 2, "bert.encoder.layer.1.attention.output.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.intermediate.dense_type": "torch.nn.Linear", "bert.encoder.layer.1.output.dense_type": "torch.nn.Linear", "classifier_type": "torch.nn.Linear"}}
