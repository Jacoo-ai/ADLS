{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads, inspired by the [NAS-BERT paper](https://arxiv.org/abs/2105.14444)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\": [\n",
    "        nn.Linear,\n",
    "        Identity,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_int` and `trial.suggest_categorical` functions to trigger the chosen sampler to choose parameter choices and layer types. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    \"\"\"\n",
    "    通过 Optuna 超参数搜索构建 Transformer 模型，并动态调整其结构。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从预训练模型的 checkpoint 加载配置\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # 更新 config 中的超参数\n",
    "    for param in [\n",
    "        \"num_layers\",        # Transformer 层数\n",
    "        \"num_heads\",         # 注意力头数\n",
    "        \"hidden_size\",       # 隐藏层大小\n",
    "        \"intermediate_size\", # 前馈网络（FFN）层的隐藏维度\n",
    "    ]:\n",
    "        # 通过 Optuna 选择该超参数在 search_space 中的索引\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        # 将选中的值设置到 config 中\n",
    "        setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "    # 根据修改后的 config 创建 Transformer 模型（用于序列分类）\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    # 遍历模型的所有子模块\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        # 如果该层是 nn.Linear 且输入维度等于输出维度，则可能进行修改\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            # 通过 Optuna 选择该层是使用 nn.Linear 还是 Identity\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue  # 选择继续使用 nn.Linear，不做修改\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()  # 将 nn.Linear 替换为 Identity（恒等映射，无计算）\n",
    "                deepsetattr(trial_model, name, new_layer)  # 递归修改模型结构\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")  # 遇到未知层时报错\n",
    "\n",
    "    return trial_model  # 返回最终构造的 Transformer 模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-06 14:35:36,033] A new study created in memory with name: bert-tiny-nas-study\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/root/local/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-06 14:35:42,366] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.392900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-06 14:38:47,968] Trial 0 finished with value: 0.84484 and parameters: {'num_layers': 2, 'num_heads': 3, 'hidden_size': 2, 'intermediate_size': 0, 'bert.encoder.layer.0.attention.self.query_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.pooler.dense_type': <class 'torch.nn.modules.linear.Linear'>}. Best is trial 0 with value: 0.84484.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the model associated with the best trial as follows, and export to be used in future tutorials. In Tutorial 6, we'll see how to run mixed-precision quantization search on top of the model we've just found through NAS to further find the optimal quantization mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(\"tutorial_5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Optimized Model with CompressionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the CompressionPipeline in Mase to run uniform quantization and pruning over the searched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/srcPkgs/miniconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[[ 0.3533, -0.7125, -0.2936,  ..., -0.0965, -0.0561,  0.0839],\n",
      "         [-0.3761, -0.5114, -0.4083,  ..., -0.1438,  0.4106, -0.0654],\n",
      "         [ 0.1664, -0.0443,  0.5090,  ..., -0.5230,  0.1457, -0.2493],\n",
      "         ...,\n",
      "         [ 0.5795, -0.5903, -0.2588,  ...,  0.0802,  0.2268,  0.2108],\n",
      "         [ 0.4601, -0.3286, -0.2527,  ..., -0.2187, -0.1692,  0.0169],\n",
      "         [ 0.3610, -0.5572, -0.0688,  ...,  0.5571,  0.6747,  0.0167]],\n",
      "\n",
      "        [[ 0.3533, -0.7125, -0.2936,  ..., -0.0965, -0.0561,  0.0839],\n",
      "         [ 0.2655, -0.2662, -0.6684,  ..., -0.0689,  0.3616,  0.0375],\n",
      "         [-0.0585,  0.0489,  0.1223,  ..., -0.4615, -0.0279, -0.0485],\n",
      "         ...,\n",
      "         [ 0.2152, -0.5312,  0.1593,  ..., -0.0257,  0.6394,  0.1267],\n",
      "         [ 0.3753, -0.3662, -0.0035,  ..., -0.2552,  0.1232,  0.0782],\n",
      "         [ 0.3610, -0.5572, -0.0688,  ...,  0.5571,  0.6747,  0.0167]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3533, -0.7125, -0.2936,  ..., -0.0965, -0.0561,  0.0839],\n",
      "         [-0.3761, -0.5114, -0.4083,  ..., -0.1438,  0.4106, -0.0654],\n",
      "         [ 0.1664, -0.0443,  0.5090,  ..., -0.5230,  0.1457, -0.2493],\n",
      "         ...,\n",
      "         [ 0.5795, -0.5903, -0.2588,  ...,  0.0802,  0.2268,  0.2108],\n",
      "         [ 0.4601, -0.3286, -0.2527,  ..., -0.2187, -0.1692,  0.0169],\n",
      "         [ 0.3610, -0.5572, -0.0688,  ...,  0.5571,  0.6747,  0.0167]],\n",
      "\n",
      "        [[ 0.3533, -0.7125, -0.2936,  ..., -0.0965, -0.0561,  0.0839],\n",
      "         [ 0.2655, -0.2662, -0.6684,  ..., -0.0689,  0.3616,  0.0375],\n",
      "         [-0.0585,  0.0489,  0.1223,  ..., -0.4615, -0.0279, -0.0485],\n",
      "         ...,\n",
      "         [ 0.2152, -0.5312,  0.1593,  ..., -0.0257,  0.6394,  0.1267],\n",
      "         [ 0.3753, -0.3662, -0.0035,  ..., -0.2552,  0.1232,  0.0782],\n",
      "         [ 0.3610, -0.5572, -0.0688,  ...,  0.5571,  0.6747,  0.0167]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3533, -0.7125, -0.2936,  ...,  0.1391, -0.2633, -0.2660],\n",
      "          [-0.1282, -1.1413, -0.2037,  ..., -0.0965, -0.0561,  0.0839]],\n",
      "\n",
      "         [[-0.3761, -0.5114, -0.4083,  ...,  0.4260,  0.0705, -0.4672],\n",
      "          [ 0.3452, -0.6740, -0.0290,  ..., -0.1438,  0.4106, -0.0654]],\n",
      "\n",
      "         [[ 0.1664, -0.0443,  0.5090,  ..., -0.0619, -0.3124, -0.0753],\n",
      "          [ 0.1786, -0.0410, -0.1042,  ..., -0.5230,  0.1457, -0.2493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5795, -0.5903, -0.2588,  ...,  0.2735, -0.4342, -0.5946],\n",
      "          [ 0.2380, -0.5839, -0.4388,  ...,  0.0802,  0.2268,  0.2108]],\n",
      "\n",
      "         [[ 0.4601, -0.3286, -0.2527,  ..., -0.1668, -0.3029, -0.0874],\n",
      "          [ 0.2591, -0.3303, -0.6174,  ..., -0.2187, -0.1692,  0.0169]],\n",
      "\n",
      "         [[ 0.3610, -0.5572, -0.0688,  ...,  0.7096, -0.7926, -0.4864],\n",
      "          [ 0.2387, -0.5595,  0.2693,  ...,  0.5571,  0.6747,  0.0167]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3533, -0.7125, -0.2936,  ...,  0.1391, -0.2633, -0.2660],\n",
      "          [-0.1282, -1.1413, -0.2037,  ..., -0.0965, -0.0561,  0.0839]],\n",
      "\n",
      "         [[ 0.2655, -0.2662, -0.6684,  ...,  0.2147, -0.3954, -0.6933],\n",
      "          [ 0.3735, -0.6554, -0.1014,  ..., -0.0689,  0.3616,  0.0375]],\n",
      "\n",
      "         [[-0.0585,  0.0489,  0.1223,  ..., -0.3020, -0.2528, -0.4591],\n",
      "          [-0.1423, -0.2963,  0.0412,  ..., -0.4615, -0.0279, -0.0485]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2152, -0.5312,  0.1593,  ...,  0.2165, -0.2937, -0.2888],\n",
      "          [-0.1247, -0.1960, -0.1274,  ..., -0.0257,  0.6394,  0.1267]],\n",
      "\n",
      "         [[ 0.3753, -0.3662, -0.0035,  ..., -0.5136, -0.3249, -0.1652],\n",
      "          [-0.1472, -0.0622, -0.4436,  ..., -0.2552,  0.1232,  0.0782]],\n",
      "\n",
      "         [[ 0.3610, -0.5572, -0.0688,  ...,  0.7096, -0.7926, -0.4864],\n",
      "          [ 0.2387, -0.5595,  0.2693,  ...,  0.5571,  0.6747,  0.0167]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0182, -0.1092, -0.1198,  ...,  0.2523, -0.3455, -0.1810],\n",
      "         [-0.3540, -0.4631, -0.2097,  ...,  0.3154, -0.6058, -0.2535],\n",
      "         [-0.0706, -0.2185,  0.1203,  ...,  0.1930,  0.0934,  0.5882],\n",
      "         ...,\n",
      "         [ 0.2086,  0.1155, -0.0879,  ...,  0.3322,  0.0789,  0.0197],\n",
      "         [-0.3213, -0.6233, -0.8138,  ...,  0.0566, -0.4999,  0.1528],\n",
      "         [-0.2554,  0.3295, -0.0554,  ...,  0.5264, -0.4819, -0.3741]],\n",
      "\n",
      "        [[ 0.0182, -0.1092, -0.1198,  ...,  0.2523, -0.3455, -0.1810],\n",
      "         [-0.2261,  0.0827,  0.3377,  ...,  0.2837, -0.5094,  0.0476],\n",
      "         [-0.4804, -0.6919, -0.4588,  ...,  0.8299, -0.4011,  0.6732],\n",
      "         ...,\n",
      "         [-0.2816,  0.2298, -0.4340,  ...,  0.1174,  0.1217,  0.1021],\n",
      "         [ 0.3457, -0.2002, -0.7394,  ..., -0.2652, -0.3345,  0.1194],\n",
      "         [-0.2554,  0.3295, -0.0554,  ...,  0.5264, -0.4819, -0.3741]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0182, -0.1092, -0.1198,  ...,  0.2523, -0.3455, -0.1810],\n",
      "         [-0.3540, -0.4631, -0.2097,  ...,  0.3154, -0.6058, -0.2535],\n",
      "         [-0.0706, -0.2185,  0.1203,  ...,  0.1930,  0.0934,  0.5882],\n",
      "         ...,\n",
      "         [ 0.2086,  0.1155, -0.0879,  ...,  0.3322,  0.0789,  0.0197],\n",
      "         [-0.3213, -0.6233, -0.8138,  ...,  0.0566, -0.4999,  0.1528],\n",
      "         [-0.2554,  0.3295, -0.0554,  ...,  0.5264, -0.4819, -0.3741]],\n",
      "\n",
      "        [[ 0.0182, -0.1092, -0.1198,  ...,  0.2523, -0.3455, -0.1810],\n",
      "         [-0.2261,  0.0827,  0.3377,  ...,  0.2837, -0.5094,  0.0476],\n",
      "         [-0.4804, -0.6919, -0.4588,  ...,  0.8299, -0.4011,  0.6732],\n",
      "         ...,\n",
      "         [-0.2816,  0.2298, -0.4340,  ...,  0.1174,  0.1217,  0.1021],\n",
      "         [ 0.3457, -0.2002, -0.7394,  ..., -0.2652, -0.3345,  0.1194],\n",
      "         [-0.2554,  0.3295, -0.0554,  ...,  0.5264, -0.4819, -0.3741]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0182, -0.1092, -0.1198,  ...,  0.5220,  0.3199,  0.6532],\n",
      "          [ 0.1127, -0.0128,  0.0509,  ...,  0.2523, -0.3455, -0.1810]],\n",
      "\n",
      "         [[-0.3540, -0.4631, -0.2097,  ...,  0.1652,  0.7206,  0.0729],\n",
      "          [-0.1545,  0.1767, -0.2556,  ...,  0.3154, -0.6058, -0.2535]],\n",
      "\n",
      "         [[-0.0706, -0.2185,  0.1203,  ...,  0.2171, -0.0108,  0.1283],\n",
      "          [ 0.0683, -0.2647,  0.3336,  ...,  0.1930,  0.0934,  0.5882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2086,  0.1155, -0.0879,  ..., -0.3677, -0.0358,  0.0875],\n",
      "          [ 0.1711,  0.1508, -0.0749,  ...,  0.3322,  0.0789,  0.0197]],\n",
      "\n",
      "         [[-0.3213, -0.6233, -0.8138,  ...,  0.0327,  0.7592, -0.4205],\n",
      "          [ 0.1785,  0.1725,  0.2841,  ...,  0.0566, -0.4999,  0.1528]],\n",
      "\n",
      "         [[-0.2554,  0.3295, -0.0554,  ...,  0.0708,  0.2548, -0.0373],\n",
      "          [-0.2511,  0.0964,  0.2789,  ...,  0.5264, -0.4819, -0.3741]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0182, -0.1092, -0.1198,  ...,  0.5220,  0.3199,  0.6532],\n",
      "          [ 0.1127, -0.0128,  0.0509,  ...,  0.2523, -0.3455, -0.1810]],\n",
      "\n",
      "         [[-0.2261,  0.0827,  0.3377,  ...,  0.2111,  0.1897,  0.1190],\n",
      "          [ 0.1081,  0.2088, -0.0649,  ...,  0.2837, -0.5094,  0.0476]],\n",
      "\n",
      "         [[-0.4804, -0.6919, -0.4588,  ..., -0.2826,  0.3911, -0.2021],\n",
      "          [-0.0453, -0.0360,  0.4610,  ...,  0.8299, -0.4011,  0.6732]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2816,  0.2298, -0.4340,  ..., -0.3350, -0.0730,  0.1943],\n",
      "          [ 0.0360,  0.1199,  0.2535,  ...,  0.1174,  0.1217,  0.1021]],\n",
      "\n",
      "         [[ 0.3457, -0.2002, -0.7394,  ...,  0.0758,  0.2086, -0.2608],\n",
      "          [ 0.0486,  0.0784,  0.1717,  ..., -0.2652, -0.3345,  0.1194]],\n",
      "\n",
      "         [[-0.2554,  0.3295, -0.0554,  ...,  0.0708,  0.2548, -0.0373],\n",
      "          [-0.2511,  0.0964,  0.2789,  ...,  0.5264, -0.4819, -0.3741]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.0776,  0.4473,  2.4282,  ..., -1.4162, -0.9757, -0.8782],\n",
      "         [-0.5477, -0.8344,  1.3852,  ...,  0.2000,  0.3280,  0.7139],\n",
      "         [-1.7209,  0.7007,  1.0438,  ..., -0.1261, -1.2993, -1.4026],\n",
      "         ...,\n",
      "         [-1.1153, -0.6247,  1.1983,  ..., -0.4083, -0.7177, -0.3430],\n",
      "         [-1.2725,  0.1297,  1.6177,  ...,  0.4095, -1.4503, -1.4781],\n",
      "         [-1.1180, -0.2631,  1.7461,  ..., -1.0452,  1.0680, -0.6712]],\n",
      "\n",
      "        [[-1.0776,  0.4473,  2.4282,  ..., -1.4162, -0.9757, -0.8782],\n",
      "         [ 1.1267, -0.2009,  1.1361,  ..., -0.3605,  0.0760, -0.1993],\n",
      "         [-1.1537,  0.4381,  1.1303,  ..., -0.8754, -0.5316, -1.6814],\n",
      "         ...,\n",
      "         [-2.0760, -0.8556,  1.8600,  ..., -1.0954,  0.6967, -0.7161],\n",
      "         [ 1.1363,  1.4759,  0.3284,  ...,  0.2883, -2.2125, -0.8439],\n",
      "         [-1.1180, -0.2631,  1.7461,  ..., -1.0452,  1.0680, -0.6712]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.0776,  0.4473,  2.4282,  ..., -1.4162, -0.9757, -0.8782],\n",
      "         [-0.5477, -0.8344,  1.3852,  ...,  0.2000,  0.3280,  0.7139],\n",
      "         [-1.7209,  0.7007,  1.0438,  ..., -0.1261, -1.2993, -1.4026],\n",
      "         ...,\n",
      "         [-1.1153, -0.6247,  1.1983,  ..., -0.4083, -0.7177, -0.3430],\n",
      "         [-1.2725,  0.1297,  1.6177,  ...,  0.4095, -1.4503, -1.4781],\n",
      "         [-1.1180, -0.2631,  1.7461,  ..., -1.0452,  1.0680, -0.6712]],\n",
      "\n",
      "        [[-1.0776,  0.4473,  2.4282,  ..., -1.4162, -0.9757, -0.8782],\n",
      "         [ 1.1267, -0.2009,  1.1361,  ..., -0.3605,  0.0760, -0.1993],\n",
      "         [-1.1537,  0.4381,  1.1303,  ..., -0.8754, -0.5316, -1.6814],\n",
      "         ...,\n",
      "         [-2.0760, -0.8556,  1.8600,  ..., -1.0954,  0.6967, -0.7161],\n",
      "         [ 1.1363,  1.4759,  0.3284,  ...,  0.2883, -2.2125, -0.8439],\n",
      "         [-1.1180, -0.2631,  1.7461,  ..., -1.0452,  1.0680, -0.6712]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.0776,  0.4473,  2.4282,  ..., -1.1662,  0.4116,  1.7578],\n",
      "          [-0.6026, -0.0028, -0.3876,  ..., -1.4162, -0.9757, -0.8782]],\n",
      "\n",
      "         [[-0.5477, -0.8344,  1.3852,  ..., -0.3676, -1.7451,  2.6973],\n",
      "          [-1.4590,  1.5647, -0.4634,  ...,  0.2000,  0.3280,  0.7139]],\n",
      "\n",
      "         [[-1.7209,  0.7007,  1.0438,  ..., -1.4185, -1.2585,  2.5771],\n",
      "          [-0.8132, -0.4844,  1.5891,  ..., -0.1261, -1.2993, -1.4026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1153, -0.6247,  1.1983,  ..., -0.4577, -0.9479, -0.1407],\n",
      "          [ 1.2628,  0.5016, -0.4915,  ..., -0.4083, -0.7177, -0.3430]],\n",
      "\n",
      "         [[-1.2725,  0.1297,  1.6177,  ..., -0.2759,  0.6288,  1.0011],\n",
      "          [-1.9120, -0.7831,  0.2011,  ...,  0.4095, -1.4503, -1.4781]],\n",
      "\n",
      "         [[-1.1180, -0.2631,  1.7461,  ..., -0.9908, -0.5953,  0.5580],\n",
      "          [ 1.3537, -0.8916,  1.5323,  ..., -1.0452,  1.0680, -0.6712]]],\n",
      "\n",
      "\n",
      "        [[[-1.0776,  0.4473,  2.4282,  ..., -1.1662,  0.4116,  1.7578],\n",
      "          [-0.6026, -0.0028, -0.3876,  ..., -1.4162, -0.9757, -0.8782]],\n",
      "\n",
      "         [[ 1.1267, -0.2009,  1.1361,  ...,  0.5492, -0.4803,  1.3446],\n",
      "          [ 0.4690,  0.7168, -0.7781,  ..., -0.3605,  0.0760, -0.1993]],\n",
      "\n",
      "         [[-1.1537,  0.4381,  1.1303,  ..., -0.9165, -1.0075,  0.3806],\n",
      "          [-0.1620, -0.5513,  1.7264,  ..., -0.8754, -0.5316, -1.6814]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0760, -0.8556,  1.8600,  ..., -0.1956, -0.3821, -0.5901],\n",
      "          [ 0.0767,  0.8896,  0.5590,  ..., -1.0954,  0.6967, -0.7161]],\n",
      "\n",
      "         [[ 1.1363,  1.4759,  0.3284,  ..., -0.1590, -0.4838,  0.6315],\n",
      "          [-1.6161, -0.9391,  0.1755,  ...,  0.2883, -2.2125, -0.8439]],\n",
      "\n",
      "         [[-1.1180, -0.2631,  1.7461,  ..., -0.9908, -0.5953,  0.5580],\n",
      "          [ 1.3537, -0.8916,  1.5323,  ..., -1.0452,  1.0680, -0.6712]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3533, -0.7125, -0.2936,  ...,  0.1391, -0.2633, -0.2660],\n",
      "          [-0.3761, -0.5114, -0.4083,  ...,  0.4260,  0.0705, -0.4672],\n",
      "          [ 0.1664, -0.0443,  0.5090,  ..., -0.0619, -0.3124, -0.0753],\n",
      "          ...,\n",
      "          [ 0.5795, -0.5903, -0.2588,  ...,  0.2735, -0.4342, -0.5946],\n",
      "          [ 0.4601, -0.3286, -0.2527,  ..., -0.1668, -0.3029, -0.0874],\n",
      "          [ 0.3610, -0.5572, -0.0688,  ...,  0.7096, -0.7926, -0.4864]],\n",
      "\n",
      "         [[-0.1282, -1.1413, -0.2037,  ..., -0.0965, -0.0561,  0.0839],\n",
      "          [ 0.3452, -0.6740, -0.0290,  ..., -0.1438,  0.4106, -0.0654],\n",
      "          [ 0.1786, -0.0410, -0.1042,  ..., -0.5230,  0.1457, -0.2493],\n",
      "          ...,\n",
      "          [ 0.2380, -0.5839, -0.4388,  ...,  0.0802,  0.2268,  0.2108],\n",
      "          [ 0.2591, -0.3303, -0.6174,  ..., -0.2187, -0.1692,  0.0169],\n",
      "          [ 0.2387, -0.5595,  0.2693,  ...,  0.5571,  0.6747,  0.0167]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3533, -0.7125, -0.2936,  ...,  0.1391, -0.2633, -0.2660],\n",
      "          [ 0.2655, -0.2662, -0.6684,  ...,  0.2147, -0.3954, -0.6933],\n",
      "          [-0.0585,  0.0489,  0.1223,  ..., -0.3020, -0.2528, -0.4591],\n",
      "          ...,\n",
      "          [ 0.2152, -0.5312,  0.1593,  ...,  0.2165, -0.2937, -0.2888],\n",
      "          [ 0.3753, -0.3662, -0.0035,  ..., -0.5136, -0.3249, -0.1652],\n",
      "          [ 0.3610, -0.5572, -0.0688,  ...,  0.7096, -0.7926, -0.4864]],\n",
      "\n",
      "         [[-0.1282, -1.1413, -0.2037,  ..., -0.0965, -0.0561,  0.0839],\n",
      "          [ 0.3735, -0.6554, -0.1014,  ..., -0.0689,  0.3616,  0.0375],\n",
      "          [-0.1423, -0.2963,  0.0412,  ..., -0.4615, -0.0279, -0.0485],\n",
      "          ...,\n",
      "          [-0.1247, -0.1960, -0.1274,  ..., -0.0257,  0.6394,  0.1267],\n",
      "          [-0.1472, -0.0622, -0.4436,  ..., -0.2552,  0.1232,  0.0782],\n",
      "          [ 0.2387, -0.5595,  0.2693,  ...,  0.5571,  0.6747,  0.0167]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.3272, -0.1530, -0.1599,  ...,  0.2651,  0.2076,  0.1773],\n",
      "          [-0.2705, -0.1608, -0.2070,  ...,  0.1451,  0.2416,  0.1173],\n",
      "          [-0.2421, -0.1471, -0.1787,  ...,  0.1588,  0.2057,  0.1261],\n",
      "          ...,\n",
      "          [-0.2325, -0.1677, -0.1930,  ...,  0.1554,  0.2347,  0.1154],\n",
      "          [-0.2421, -0.1531, -0.1414,  ...,  0.2325,  0.1987,  0.1884],\n",
      "          [-0.2547, -0.1335, -0.1418,  ...,  0.2425,  0.2127,  0.2054]],\n",
      "\n",
      "         [[-0.0750, -0.0692,  0.2101,  ...,  0.3214, -0.1431,  0.1596],\n",
      "          [-0.0573, -0.0060,  0.1653,  ...,  0.3456, -0.1627,  0.0116],\n",
      "          [-0.0562, -0.0256,  0.1852,  ...,  0.3253, -0.1668,  0.0855],\n",
      "          ...,\n",
      "          [-0.0466, -0.0192,  0.1981,  ...,  0.3219, -0.2054,  0.0967],\n",
      "          [-0.0249,  0.0044,  0.1936,  ...,  0.3584, -0.2077,  0.0666],\n",
      "          [-0.0457,  0.0089,  0.1580,  ...,  0.3650, -0.2043,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.2645,  0.3022, -0.0584,  ...,  0.1897,  0.0778,  0.4975],\n",
      "          [-0.2053,  0.0540, -0.1802,  ...,  0.0574,  0.1320,  0.1997],\n",
      "          [-0.2140,  0.0687, -0.1829,  ...,  0.0701,  0.1321,  0.2415],\n",
      "          ...,\n",
      "          [-0.2218,  0.1353, -0.1414,  ...,  0.1105,  0.1225,  0.3165],\n",
      "          [-0.2082,  0.0515, -0.1846,  ...,  0.0708,  0.1435,  0.2334],\n",
      "          [-0.2049,  0.0703, -0.1618,  ...,  0.1075,  0.1599,  0.2673]],\n",
      "\n",
      "         [[-0.2551, -0.1687,  0.3586,  ...,  0.1267,  0.0176, -0.3391],\n",
      "          [-0.1317, -0.0753,  0.2798,  ...,  0.2379, -0.0804, -0.1233],\n",
      "          [-0.0890, -0.0331,  0.2633,  ...,  0.2662, -0.1305, -0.0460],\n",
      "          ...,\n",
      "          [-0.1609, -0.0945,  0.2934,  ...,  0.2097, -0.0510, -0.1843],\n",
      "          [-0.1251, -0.0699,  0.2738,  ...,  0.1841, -0.0797, -0.1548],\n",
      "          [-0.0774, -0.0539,  0.2411,  ...,  0.2762, -0.1484, -0.1197]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.3272, -0.1530, -0.1599,  ...,  0.2651,  0.2076,  0.1773],\n",
      "          [-0.0750, -0.0692,  0.2101,  ...,  0.3214, -0.1431,  0.1596]],\n",
      "\n",
      "         [[-0.2705, -0.1608, -0.2070,  ...,  0.1451,  0.2416,  0.1173],\n",
      "          [-0.0573, -0.0060,  0.1653,  ...,  0.3456, -0.1627,  0.0116]],\n",
      "\n",
      "         [[-0.2421, -0.1471, -0.1787,  ...,  0.1588,  0.2057,  0.1261],\n",
      "          [-0.0562, -0.0256,  0.1852,  ...,  0.3253, -0.1668,  0.0855]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2325, -0.1677, -0.1930,  ...,  0.1554,  0.2347,  0.1154],\n",
      "          [-0.0466, -0.0192,  0.1981,  ...,  0.3219, -0.2054,  0.0967]],\n",
      "\n",
      "         [[-0.2421, -0.1531, -0.1414,  ...,  0.2325,  0.1987,  0.1884],\n",
      "          [-0.0249,  0.0044,  0.1936,  ...,  0.3584, -0.2077,  0.0666]],\n",
      "\n",
      "         [[-0.2547, -0.1335, -0.1418,  ...,  0.2425,  0.2127,  0.2054],\n",
      "          [-0.0457,  0.0089,  0.1580,  ...,  0.3650, -0.2043,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.2645,  0.3022, -0.0584,  ...,  0.1897,  0.0778,  0.4975],\n",
      "          [-0.2551, -0.1687,  0.3586,  ...,  0.1267,  0.0176, -0.3391]],\n",
      "\n",
      "         [[-0.2053,  0.0540, -0.1802,  ...,  0.0574,  0.1320,  0.1997],\n",
      "          [-0.1317, -0.0753,  0.2798,  ...,  0.2379, -0.0804, -0.1233]],\n",
      "\n",
      "         [[-0.2140,  0.0687, -0.1829,  ...,  0.0701,  0.1321,  0.2415],\n",
      "          [-0.0890, -0.0331,  0.2633,  ...,  0.2662, -0.1305, -0.0460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2218,  0.1353, -0.1414,  ...,  0.1105,  0.1225,  0.3165],\n",
      "          [-0.1609, -0.0945,  0.2934,  ...,  0.2097, -0.0510, -0.1843]],\n",
      "\n",
      "         [[-0.2082,  0.0515, -0.1846,  ...,  0.0708,  0.1435,  0.2334],\n",
      "          [-0.1251, -0.0699,  0.2738,  ...,  0.1841, -0.0797, -0.1548]],\n",
      "\n",
      "         [[-0.2049,  0.0703, -0.1618,  ...,  0.1075,  0.1599,  0.2673],\n",
      "          [-0.0774, -0.0539,  0.2411,  ...,  0.2762, -0.1484, -0.1197]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[-0.3272, -0.1530, -0.1599,  ...,  0.2651,  0.2076,  0.1773],\n",
      "          [-0.0750, -0.0692,  0.2101,  ...,  0.3214, -0.1431,  0.1596]],\n",
      "\n",
      "         [[-0.2705, -0.1608, -0.2070,  ...,  0.1451,  0.2416,  0.1173],\n",
      "          [-0.0573, -0.0060,  0.1653,  ...,  0.3456, -0.1627,  0.0116]],\n",
      "\n",
      "         [[-0.2421, -0.1471, -0.1787,  ...,  0.1588,  0.2057,  0.1261],\n",
      "          [-0.0562, -0.0256,  0.1852,  ...,  0.3253, -0.1668,  0.0855]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2325, -0.1677, -0.1930,  ...,  0.1554,  0.2347,  0.1154],\n",
      "          [-0.0466, -0.0192,  0.1981,  ...,  0.3219, -0.2054,  0.0967]],\n",
      "\n",
      "         [[-0.2421, -0.1531, -0.1414,  ...,  0.2325,  0.1987,  0.1884],\n",
      "          [-0.0249,  0.0044,  0.1936,  ...,  0.3584, -0.2077,  0.0666]],\n",
      "\n",
      "         [[-0.2547, -0.1335, -0.1418,  ...,  0.2425,  0.2127,  0.2054],\n",
      "          [-0.0457,  0.0089,  0.1580,  ...,  0.3650, -0.2043,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.2645,  0.3022, -0.0584,  ...,  0.1897,  0.0778,  0.4975],\n",
      "          [-0.2551, -0.1687,  0.3586,  ...,  0.1267,  0.0176, -0.3391]],\n",
      "\n",
      "         [[-0.2053,  0.0540, -0.1802,  ...,  0.0574,  0.1320,  0.1997],\n",
      "          [-0.1317, -0.0753,  0.2798,  ...,  0.2379, -0.0804, -0.1233]],\n",
      "\n",
      "         [[-0.2140,  0.0687, -0.1829,  ...,  0.0701,  0.1321,  0.2415],\n",
      "          [-0.0890, -0.0331,  0.2633,  ...,  0.2662, -0.1305, -0.0460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2218,  0.1353, -0.1414,  ...,  0.1105,  0.1225,  0.3165],\n",
      "          [-0.1609, -0.0945,  0.2934,  ...,  0.2097, -0.0510, -0.1843]],\n",
      "\n",
      "         [[-0.2082,  0.0515, -0.1846,  ...,  0.0708,  0.1435,  0.2334],\n",
      "          [-0.1251, -0.0699,  0.2738,  ...,  0.1841, -0.0797, -0.1548]],\n",
      "\n",
      "         [[-0.2049,  0.0703, -0.1618,  ...,  0.1075,  0.1599,  0.2673],\n",
      "          [-0.0774, -0.0539,  0.2411,  ...,  0.2762, -0.1484, -0.1197]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[-0.3272, -0.1530, -0.1599,  ...,  0.2651,  0.2076,  0.1773],\n",
      "          [-0.0750, -0.0692,  0.2101,  ...,  0.3214, -0.1431,  0.1596]],\n",
      "\n",
      "         [[-0.2705, -0.1608, -0.2070,  ...,  0.1451,  0.2416,  0.1173],\n",
      "          [-0.0573, -0.0060,  0.1653,  ...,  0.3456, -0.1627,  0.0116]],\n",
      "\n",
      "         [[-0.2421, -0.1471, -0.1787,  ...,  0.1588,  0.2057,  0.1261],\n",
      "          [-0.0562, -0.0256,  0.1852,  ...,  0.3253, -0.1668,  0.0855]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2325, -0.1677, -0.1930,  ...,  0.1554,  0.2347,  0.1154],\n",
      "          [-0.0466, -0.0192,  0.1981,  ...,  0.3219, -0.2054,  0.0967]],\n",
      "\n",
      "         [[-0.2421, -0.1531, -0.1414,  ...,  0.2325,  0.1987,  0.1884],\n",
      "          [-0.0249,  0.0044,  0.1936,  ...,  0.3584, -0.2077,  0.0666]],\n",
      "\n",
      "         [[-0.2547, -0.1335, -0.1418,  ...,  0.2425,  0.2127,  0.2054],\n",
      "          [-0.0457,  0.0089,  0.1580,  ...,  0.3650, -0.2043,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.2645,  0.3022, -0.0584,  ...,  0.1897,  0.0778,  0.4975],\n",
      "          [-0.2551, -0.1687,  0.3586,  ...,  0.1267,  0.0176, -0.3391]],\n",
      "\n",
      "         [[-0.2053,  0.0540, -0.1802,  ...,  0.0574,  0.1320,  0.1997],\n",
      "          [-0.1317, -0.0753,  0.2798,  ...,  0.2379, -0.0804, -0.1233]],\n",
      "\n",
      "         [[-0.2140,  0.0687, -0.1829,  ...,  0.0701,  0.1321,  0.2415],\n",
      "          [-0.0890, -0.0331,  0.2633,  ...,  0.2662, -0.1305, -0.0460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2218,  0.1353, -0.1414,  ...,  0.1105,  0.1225,  0.3165],\n",
      "          [-0.1609, -0.0945,  0.2934,  ...,  0.2097, -0.0510, -0.1843]],\n",
      "\n",
      "         [[-0.2082,  0.0515, -0.1846,  ...,  0.0708,  0.1435,  0.2334],\n",
      "          [-0.1251, -0.0699,  0.2738,  ...,  0.1841, -0.0797, -0.1548]],\n",
      "\n",
      "         [[-0.2049,  0.0703, -0.1618,  ...,  0.1075,  0.1599,  0.2673],\n",
      "          [-0.0774, -0.0539,  0.2411,  ...,  0.2762, -0.1484, -0.1197]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[-1.4877,  0.4988,  2.1992,  ..., -1.6222, -1.0183, -0.4523],\n",
      "         [-1.1188, -0.6156,  1.1739,  ...,  0.1816,  0.0455,  0.5271],\n",
      "         [-2.1873,  1.0384,  0.7801,  ..., -0.2232, -1.5434, -1.1357],\n",
      "         ...,\n",
      "         [-1.5135, -0.3187,  0.8507,  ..., -0.4525, -1.0843, -0.3422],\n",
      "         [-1.6774,  0.6049,  1.3526,  ...,  0.2237, -1.7575, -1.2215],\n",
      "         [-1.4895,  0.1380,  1.3273,  ..., -1.0315,  0.8214, -0.6498]],\n",
      "\n",
      "        [[-0.9018, -0.0703,  2.2380,  ..., -1.5865, -0.5730, -0.2607],\n",
      "         [ 0.9501, -0.2371,  1.0469,  ..., -0.2545,  0.0579, -0.0557],\n",
      "         [-1.5207,  0.8043,  0.8255,  ..., -0.9019, -0.9349, -1.4754],\n",
      "         ...,\n",
      "         [-2.1884, -0.8663,  1.7437,  ..., -1.1736,  0.6743, -0.4881],\n",
      "         [ 0.9299,  1.4515,  0.4317,  ...,  0.3515, -2.1863, -0.7543],\n",
      "         [-1.3819, -0.0342,  1.3969,  ..., -1.0263,  0.9674, -0.6115]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.4877,  0.4988,  2.1992,  ..., -1.6222, -1.0183, -0.4523],\n",
      "         [-1.1188, -0.6156,  1.1739,  ...,  0.1816,  0.0455,  0.5271],\n",
      "         [-2.1873,  1.0384,  0.7801,  ..., -0.2232, -1.5434, -1.1357],\n",
      "         ...,\n",
      "         [-1.5135, -0.3187,  0.8507,  ..., -0.4525, -1.0843, -0.3422],\n",
      "         [-1.6774,  0.6049,  1.3526,  ...,  0.2237, -1.7575, -1.2215],\n",
      "         [-1.4895,  0.1380,  1.3273,  ..., -1.0315,  0.8214, -0.6498]],\n",
      "\n",
      "        [[-0.9018, -0.0703,  2.2380,  ..., -1.5865, -0.5730, -0.2607],\n",
      "         [ 0.9501, -0.2371,  1.0469,  ..., -0.2545,  0.0579, -0.0557],\n",
      "         [-1.5207,  0.8043,  0.8255,  ..., -0.9019, -0.9349, -1.4754],\n",
      "         ...,\n",
      "         [-2.1884, -0.8663,  1.7437,  ..., -1.1736,  0.6743, -0.4881],\n",
      "         [ 0.9299,  1.4515,  0.4317,  ...,  0.3515, -2.1863, -0.7543],\n",
      "         [-1.3819, -0.0342,  1.3969,  ..., -1.0263,  0.9674, -0.6115]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.4877,  0.4988,  2.1992,  ..., -1.6019, -0.1046,  1.8342],\n",
      "          [-0.3099, -0.2777, -0.6361,  ..., -1.6222, -1.0183, -0.4523]],\n",
      "\n",
      "         [[-1.1188, -0.6156,  1.1739,  ..., -0.9660, -2.2224,  2.2836],\n",
      "          [-1.1048,  0.9644, -0.5885,  ...,  0.1816,  0.0455,  0.5271]],\n",
      "\n",
      "         [[-2.1873,  1.0384,  0.7801,  ..., -2.0395, -1.6681,  2.3397],\n",
      "          [-0.4387, -0.8647,  1.2265,  ..., -0.2232, -1.5434, -1.1357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5135, -0.3187,  0.8507,  ..., -1.0260, -1.2588, -0.4401],\n",
      "          [ 1.6651, -0.0558, -0.7722,  ..., -0.4525, -1.0843, -0.3422]],\n",
      "\n",
      "         [[-1.6774,  0.6049,  1.3526,  ..., -0.8618,  0.0588,  0.5200],\n",
      "          [-1.4619, -1.3755, -0.2210,  ...,  0.2237, -1.7575, -1.2215]],\n",
      "\n",
      "         [[-1.4895,  0.1380,  1.3273,  ..., -1.4741, -0.9354,  0.2827],\n",
      "          [ 1.6019, -1.2818,  1.0809,  ..., -1.0315,  0.8214, -0.6498]]],\n",
      "\n",
      "\n",
      "        [[[-0.9018, -0.0703,  2.2380,  ..., -0.9836,  0.4048,  1.9550],\n",
      "          [-0.6697,  0.1353, -0.4749,  ..., -1.5865, -0.5730, -0.2607]],\n",
      "\n",
      "         [[ 0.9501, -0.2371,  1.0469,  ...,  0.3616, -0.7696,  1.1974],\n",
      "          [ 0.6790,  0.3595, -0.9682,  ..., -0.2545,  0.0579, -0.0557]],\n",
      "\n",
      "         [[-1.5207,  0.8043,  0.8255,  ..., -1.5164, -1.3078,  0.1021],\n",
      "          [ 0.3056, -0.8526,  1.2040,  ..., -0.9019, -0.9349, -1.4754]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1884, -0.8663,  1.7437,  ..., -0.2811, -0.4510, -0.7807],\n",
      "          [ 0.1576,  0.6775,  0.2144,  ..., -1.1736,  0.6743, -0.4881]],\n",
      "\n",
      "         [[ 0.9299,  1.4515,  0.4317,  ..., -0.2550, -0.7566,  0.4500],\n",
      "          [-1.4364, -1.2703, -0.1876,  ...,  0.3515, -2.1863, -0.7543]],\n",
      "\n",
      "         [[-1.3819, -0.0342,  1.3969,  ..., -1.3500, -0.7975,  0.3290],\n",
      "          [ 1.5441, -1.2018,  1.1645,  ..., -1.0263,  0.9674, -0.6115]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1913, -0.0474, -0.6128,  ...,  0.6048, -0.3627,  0.2646],\n",
      "         [ 0.6042, -0.3629, -0.5750,  ...,  0.9000, -0.2053,  0.3246],\n",
      "         [ 0.1913, -1.0668, -0.8212,  ...,  0.4344,  0.0274,  0.2206],\n",
      "         ...,\n",
      "         [ 0.4161, -0.8020, -0.6164,  ...,  0.9235,  0.0809,  0.2145],\n",
      "         [ 0.4839, -0.9625, -0.4311,  ...,  0.9060, -0.0963,  0.4204],\n",
      "         [ 0.4701, -0.5738, -0.9621,  ...,  0.8600, -0.5366,  0.3106]],\n",
      "\n",
      "        [[-0.7680,  0.5097, -0.1427,  ..., -0.0414, -0.1951,  0.1429],\n",
      "         [ 0.1675,  0.1128, -0.3046,  ...,  0.5792,  0.1306,  0.0592],\n",
      "         [ 0.8465, -1.4248, -1.1062,  ...,  0.9168, -0.0053,  0.1718],\n",
      "         ...,\n",
      "         [ 0.5180, -0.0721, -0.3571,  ...,  0.2142, -0.0263, -0.0485],\n",
      "         [ 0.3953, -0.1860, -0.2220,  ...,  0.2153,  0.3464,  0.2042],\n",
      "         [ 0.3000, -0.4192, -0.8425,  ...,  0.6901, -0.5091,  0.2869]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1913, -0.0474, -0.6128,  ...,  0.6048, -0.3627,  0.2646],\n",
      "         [ 0.6042, -0.3629, -0.5750,  ...,  0.9000, -0.2053,  0.3246],\n",
      "         [ 0.1913, -1.0668, -0.8212,  ...,  0.4344,  0.0274,  0.2206],\n",
      "         ...,\n",
      "         [ 0.4161, -0.8020, -0.6164,  ...,  0.9235,  0.0809,  0.2145],\n",
      "         [ 0.4839, -0.9625, -0.4311,  ...,  0.9060, -0.0963,  0.4204],\n",
      "         [ 0.4701, -0.5738, -0.9621,  ...,  0.8600, -0.5366,  0.3106]],\n",
      "\n",
      "        [[-0.7680,  0.5097, -0.1427,  ..., -0.0414, -0.1951,  0.1429],\n",
      "         [ 0.1675,  0.1128, -0.3046,  ...,  0.5792,  0.1306,  0.0592],\n",
      "         [ 0.8465, -1.4248, -1.1062,  ...,  0.9168, -0.0053,  0.1718],\n",
      "         ...,\n",
      "         [ 0.5180, -0.0721, -0.3571,  ...,  0.2142, -0.0263, -0.0485],\n",
      "         [ 0.3953, -0.1860, -0.2220,  ...,  0.2153,  0.3464,  0.2042],\n",
      "         [ 0.3000, -0.4192, -0.8425,  ...,  0.6901, -0.5091,  0.2869]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1913, -0.0474, -0.6128,  ..., -0.5783,  0.5845,  0.0783],\n",
      "          [-0.1991,  0.4250, -0.5390,  ...,  0.6048, -0.3627,  0.2646]],\n",
      "\n",
      "         [[ 0.6042, -0.3629, -0.5750,  ..., -1.5108,  0.6597,  0.6087],\n",
      "          [-0.4578,  0.3842, -0.3769,  ...,  0.9000, -0.2053,  0.3246]],\n",
      "\n",
      "         [[ 0.1913, -1.0668, -0.8212,  ..., -0.6070,  0.4938,  0.1743],\n",
      "          [-0.4461,  0.5708, -0.9084,  ...,  0.4344,  0.0274,  0.2206]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4161, -0.8020, -0.6164,  ..., -0.8476,  0.4567,  0.0468],\n",
      "          [-0.4939,  0.4868, -0.5701,  ...,  0.9235,  0.0809,  0.2145]],\n",
      "\n",
      "         [[ 0.4839, -0.9625, -0.4311,  ..., -0.9265,  0.2466,  0.8604],\n",
      "          [-0.8981,  1.0392, -0.5792,  ...,  0.9060, -0.0963,  0.4204]],\n",
      "\n",
      "         [[ 0.4701, -0.5738, -0.9621,  ..., -1.3351,  0.7740,  0.5850],\n",
      "          [-0.5063,  0.2449, -0.4536,  ...,  0.8600, -0.5366,  0.3106]]],\n",
      "\n",
      "\n",
      "        [[[-0.7680,  0.5097, -0.1427,  ...,  0.2164,  0.2067, -0.4272],\n",
      "          [ 0.2853, -0.2175, -0.0699,  ..., -0.0414, -0.1951,  0.1429]],\n",
      "\n",
      "         [[ 0.1675,  0.1128, -0.3046,  ..., -0.4378,  0.1376,  0.0077],\n",
      "          [-0.2203, -0.2284, -0.1345,  ...,  0.5792,  0.1306,  0.0592]],\n",
      "\n",
      "         [[ 0.8465, -1.4248, -1.1062,  ..., -1.3710,  0.9190,  0.8643],\n",
      "          [-0.9146,  1.0082, -0.8462,  ...,  0.9168, -0.0053,  0.1718]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5180, -0.0721, -0.3571,  ..., -0.1900,  0.1329, -0.5749],\n",
      "          [-0.3046,  0.0223, -0.2186,  ...,  0.2142, -0.0263, -0.0485]],\n",
      "\n",
      "         [[ 0.3953, -0.1860, -0.2220,  ..., -0.2058, -0.1838,  0.5917],\n",
      "          [-0.4727,  0.9623, -0.3405,  ...,  0.2153,  0.3464,  0.2042]],\n",
      "\n",
      "         [[ 0.3000, -0.4192, -0.8425,  ..., -1.1249,  0.6729,  0.4411],\n",
      "          [-0.3792,  0.0534, -0.3244,  ...,  0.6901, -0.5091,  0.2869]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.0571,  0.5931, -0.2572,  ...,  0.1986,  0.3636,  1.3000],\n",
      "         [ 0.4599, -0.0789, -0.2603,  ...,  0.1686,  0.3435,  0.3380],\n",
      "         [ 0.5682,  0.2366,  0.1448,  ...,  0.0722,  0.4574,  0.2727],\n",
      "         ...,\n",
      "         [ 0.4137, -0.0430, -0.0400,  ...,  0.0981,  0.2273,  0.6582],\n",
      "         [ 0.4548, -0.1009, -0.0280,  ...,  0.2862,  0.1080,  0.1923],\n",
      "         [ 0.4685,  0.0301,  0.1054,  ...,  0.4275,  0.1924,  0.3990]],\n",
      "\n",
      "        [[ 1.1342,  0.6289, -0.2926,  ...,  0.0539,  0.1662,  1.2286],\n",
      "         [ 0.4932,  0.3845, -0.1957,  ...,  0.3382,  0.2353,  0.6131],\n",
      "         [ 0.0780,  0.1425,  0.0978,  ...,  0.3713,  0.3336,  0.1833],\n",
      "         ...,\n",
      "         [ 1.0305,  0.3554,  0.0409,  ...,  0.4984, -0.2080,  0.3600],\n",
      "         [ 0.2229,  0.0044,  0.2295,  ...,  0.1935, -0.0302,  0.3736],\n",
      "         [ 0.5077,  0.0370,  0.0920,  ...,  0.4008,  0.1429,  0.3934]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.0571,  0.5931, -0.2572,  ...,  0.1986,  0.3636,  1.3000],\n",
      "         [ 0.4599, -0.0789, -0.2603,  ...,  0.1686,  0.3435,  0.3380],\n",
      "         [ 0.5682,  0.2366,  0.1448,  ...,  0.0722,  0.4574,  0.2727],\n",
      "         ...,\n",
      "         [ 0.4137, -0.0430, -0.0400,  ...,  0.0981,  0.2273,  0.6582],\n",
      "         [ 0.4548, -0.1009, -0.0280,  ...,  0.2862,  0.1080,  0.1923],\n",
      "         [ 0.4685,  0.0301,  0.1054,  ...,  0.4275,  0.1924,  0.3990]],\n",
      "\n",
      "        [[ 1.1342,  0.6289, -0.2926,  ...,  0.0539,  0.1662,  1.2286],\n",
      "         [ 0.4932,  0.3845, -0.1957,  ...,  0.3382,  0.2353,  0.6131],\n",
      "         [ 0.0780,  0.1425,  0.0978,  ...,  0.3713,  0.3336,  0.1833],\n",
      "         ...,\n",
      "         [ 1.0305,  0.3554,  0.0409,  ...,  0.4984, -0.2080,  0.3600],\n",
      "         [ 0.2229,  0.0044,  0.2295,  ...,  0.1935, -0.0302,  0.3736],\n",
      "         [ 0.5077,  0.0370,  0.0920,  ...,  0.4008,  0.1429,  0.3934]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.0571,  0.5931, -0.2572,  ...,  1.0129,  0.1262,  0.1723],\n",
      "          [-0.3626,  0.5330, -0.2538,  ...,  0.1986,  0.3636,  1.3000]],\n",
      "\n",
      "         [[ 0.4599, -0.0789, -0.2603,  ...,  0.3149,  0.1113,  0.0782],\n",
      "          [-0.2577,  0.0932, -0.2331,  ...,  0.1686,  0.3435,  0.3380]],\n",
      "\n",
      "         [[ 0.5682,  0.2366,  0.1448,  ...,  0.3550, -0.2631,  0.3002],\n",
      "          [-0.0086,  0.3777,  0.0195,  ...,  0.0722,  0.4574,  0.2727]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4137, -0.0430, -0.0400,  ...,  0.0252, -0.2881,  0.0648],\n",
      "          [ 0.0738, -0.0737,  0.1452,  ...,  0.0981,  0.2273,  0.6582]],\n",
      "\n",
      "         [[ 0.4548, -0.1009, -0.0280,  ...,  0.1367,  0.3401, -0.2455],\n",
      "          [-0.5351,  0.4127,  0.5441,  ...,  0.2862,  0.1080,  0.1923]],\n",
      "\n",
      "         [[ 0.4685,  0.0301,  0.1054,  ...,  0.0438, -0.2440,  0.0617],\n",
      "          [-0.2351,  0.1657,  0.0516,  ...,  0.4275,  0.1924,  0.3990]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1342,  0.6289, -0.2926,  ...,  0.8864,  0.1492,  0.2012],\n",
      "          [-0.4975,  0.5959, -0.3489,  ...,  0.0539,  0.1662,  1.2286]],\n",
      "\n",
      "         [[ 0.4932,  0.3845, -0.1957,  ...,  0.1162, -0.1284,  0.0616],\n",
      "          [-0.3034,  0.7425, -0.1887,  ...,  0.3382,  0.2353,  0.6131]],\n",
      "\n",
      "         [[ 0.0780,  0.1425,  0.0978,  ...,  0.6253, -0.1459, -0.1031],\n",
      "          [ 0.2846,  0.3423,  0.2520,  ...,  0.3713,  0.3336,  0.1833]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0305,  0.3554,  0.0409,  ..., -0.1583, -0.1038,  0.0575],\n",
      "          [ 0.2226,  0.4461, -0.0104,  ...,  0.4984, -0.2080,  0.3600]],\n",
      "\n",
      "         [[ 0.2229,  0.0044,  0.2295,  ...,  0.3111, -0.2538, -0.5686],\n",
      "          [-0.3232,  0.3956, -0.2011,  ...,  0.1935, -0.0302,  0.3736]],\n",
      "\n",
      "         [[ 0.5077,  0.0370,  0.0920,  ...,  0.0058, -0.2509,  0.0783],\n",
      "          [-0.2908,  0.1851,  0.0270,  ...,  0.4008,  0.1429,  0.3934]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.4877,  0.4988,  2.1992,  ..., -1.6019, -0.1046,  1.8342],\n",
      "          [-1.1188, -0.6156,  1.1739,  ..., -0.9660, -2.2224,  2.2836],\n",
      "          [-2.1873,  1.0384,  0.7801,  ..., -2.0395, -1.6681,  2.3397],\n",
      "          ...,\n",
      "          [-1.5135, -0.3187,  0.8507,  ..., -1.0260, -1.2588, -0.4401],\n",
      "          [-1.6774,  0.6049,  1.3526,  ..., -0.8618,  0.0588,  0.5200],\n",
      "          [-1.4895,  0.1380,  1.3273,  ..., -1.4741, -0.9354,  0.2827]],\n",
      "\n",
      "         [[-0.3099, -0.2777, -0.6361,  ..., -1.6222, -1.0183, -0.4523],\n",
      "          [-1.1048,  0.9644, -0.5885,  ...,  0.1816,  0.0455,  0.5271],\n",
      "          [-0.4387, -0.8647,  1.2265,  ..., -0.2232, -1.5434, -1.1357],\n",
      "          ...,\n",
      "          [ 1.6651, -0.0558, -0.7722,  ..., -0.4525, -1.0843, -0.3422],\n",
      "          [-1.4619, -1.3755, -0.2210,  ...,  0.2237, -1.7575, -1.2215],\n",
      "          [ 1.6019, -1.2818,  1.0809,  ..., -1.0315,  0.8214, -0.6498]]],\n",
      "\n",
      "\n",
      "        [[[-0.9018, -0.0703,  2.2380,  ..., -0.9836,  0.4048,  1.9550],\n",
      "          [ 0.9501, -0.2371,  1.0469,  ...,  0.3616, -0.7696,  1.1974],\n",
      "          [-1.5207,  0.8043,  0.8255,  ..., -1.5164, -1.3078,  0.1021],\n",
      "          ...,\n",
      "          [-2.1884, -0.8663,  1.7437,  ..., -0.2811, -0.4510, -0.7807],\n",
      "          [ 0.9299,  1.4515,  0.4317,  ..., -0.2550, -0.7566,  0.4500],\n",
      "          [-1.3819, -0.0342,  1.3969,  ..., -1.3500, -0.7975,  0.3290]],\n",
      "\n",
      "         [[-0.6697,  0.1353, -0.4749,  ..., -1.5865, -0.5730, -0.2607],\n",
      "          [ 0.6790,  0.3595, -0.9682,  ..., -0.2545,  0.0579, -0.0557],\n",
      "          [ 0.3056, -0.8526,  1.2040,  ..., -0.9019, -0.9349, -1.4754],\n",
      "          ...,\n",
      "          [ 0.1576,  0.6775,  0.2144,  ..., -1.1736,  0.6743, -0.4881],\n",
      "          [-1.4364, -1.2703, -0.1876,  ...,  0.3515, -2.1863, -0.7543],\n",
      "          [ 1.5441, -1.2018,  1.1645,  ..., -1.0263,  0.9674, -0.6115]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1731, -0.4780, -0.4390,  ..., -0.6405,  0.4397,  0.2598],\n",
      "          [ 0.2751, -0.5831, -0.5868,  ..., -0.8300,  0.5166,  0.3538],\n",
      "          [ 0.2058, -0.5247, -0.4943,  ..., -0.6990,  0.4526,  0.2659],\n",
      "          ...,\n",
      "          [ 0.2438, -0.5523, -0.5423,  ..., -0.7721,  0.4898,  0.3238],\n",
      "          [ 0.2556, -0.5524, -0.5554,  ..., -0.8067,  0.4865,  0.3458],\n",
      "          [ 0.2801, -0.5491, -0.5827,  ..., -0.8442,  0.5363,  0.3273]],\n",
      "\n",
      "         [[-0.7609,  0.5197, -0.7625,  ...,  0.7866, -0.3663,  0.2004],\n",
      "          [-0.5879,  0.4459, -0.5956,  ...,  0.6947, -0.2836,  0.1561],\n",
      "          [-0.5253,  0.4686, -0.5802,  ...,  0.6613, -0.2574,  0.1317],\n",
      "          ...,\n",
      "          [-0.5498,  0.4554, -0.5668,  ...,  0.6678, -0.2523,  0.1353],\n",
      "          [-0.5790,  0.4650, -0.6076,  ...,  0.6679, -0.2582,  0.1549],\n",
      "          [-0.5070,  0.4475, -0.5977,  ...,  0.6195, -0.2478,  0.1338]]],\n",
      "\n",
      "\n",
      "        [[[-0.1571,  0.1763, -0.0042,  ..., -0.0422,  0.0956, -0.1761],\n",
      "          [ 0.1200, -0.1971, -0.3653,  ..., -0.4020,  0.3104,  0.1074],\n",
      "          [-0.0828,  0.0768, -0.1326,  ..., -0.1573,  0.1712, -0.1263],\n",
      "          ...,\n",
      "          [ 0.0260, -0.0622, -0.2562,  ..., -0.2745,  0.2217,  0.0083],\n",
      "          [ 0.0274, -0.0522, -0.2502,  ..., -0.2718,  0.2169, -0.0011],\n",
      "          [ 0.0342, -0.0573, -0.2644,  ..., -0.2858,  0.2452, -0.0394]],\n",
      "\n",
      "         [[ 0.0257, -0.0254, -0.1816,  ..., -0.0344, -0.0847, -0.0101],\n",
      "          [-0.1564,  0.0546, -0.2280,  ...,  0.1425, -0.1229,  0.0583],\n",
      "          [ 0.0093, -0.0803, -0.1397,  ..., -0.0178, -0.0981,  0.0052],\n",
      "          ...,\n",
      "          [-0.0376, -0.0081, -0.1748,  ...,  0.0101, -0.0892,  0.0139],\n",
      "          [-0.0791,  0.0220, -0.1769,  ...,  0.0367, -0.0747,  0.0238],\n",
      "          [-0.0935,  0.0401, -0.2048,  ...,  0.0780, -0.1076,  0.0473]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[ 0.1731, -0.4780, -0.4390,  ..., -0.6405,  0.4397,  0.2598],\n",
      "          [-0.7609,  0.5197, -0.7625,  ...,  0.7866, -0.3663,  0.2004]],\n",
      "\n",
      "         [[ 0.2751, -0.5831, -0.5868,  ..., -0.8300,  0.5166,  0.3538],\n",
      "          [-0.5879,  0.4459, -0.5956,  ...,  0.6947, -0.2836,  0.1561]],\n",
      "\n",
      "         [[ 0.2058, -0.5247, -0.4943,  ..., -0.6990,  0.4526,  0.2659],\n",
      "          [-0.5253,  0.4686, -0.5802,  ...,  0.6613, -0.2574,  0.1317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2438, -0.5523, -0.5423,  ..., -0.7721,  0.4898,  0.3238],\n",
      "          [-0.5498,  0.4554, -0.5668,  ...,  0.6678, -0.2523,  0.1353]],\n",
      "\n",
      "         [[ 0.2556, -0.5524, -0.5554,  ..., -0.8067,  0.4865,  0.3458],\n",
      "          [-0.5790,  0.4650, -0.6076,  ...,  0.6679, -0.2582,  0.1549]],\n",
      "\n",
      "         [[ 0.2801, -0.5491, -0.5827,  ..., -0.8442,  0.5363,  0.3273],\n",
      "          [-0.5070,  0.4475, -0.5977,  ...,  0.6195, -0.2478,  0.1338]]],\n",
      "\n",
      "\n",
      "        [[[-0.1571,  0.1763, -0.0042,  ..., -0.0422,  0.0956, -0.1761],\n",
      "          [ 0.0257, -0.0254, -0.1816,  ..., -0.0344, -0.0847, -0.0101]],\n",
      "\n",
      "         [[ 0.1200, -0.1971, -0.3653,  ..., -0.4020,  0.3104,  0.1074],\n",
      "          [-0.1564,  0.0546, -0.2280,  ...,  0.1425, -0.1229,  0.0583]],\n",
      "\n",
      "         [[-0.0828,  0.0768, -0.1326,  ..., -0.1573,  0.1712, -0.1263],\n",
      "          [ 0.0093, -0.0803, -0.1397,  ..., -0.0178, -0.0981,  0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0260, -0.0622, -0.2562,  ..., -0.2745,  0.2217,  0.0083],\n",
      "          [-0.0376, -0.0081, -0.1748,  ...,  0.0101, -0.0892,  0.0139]],\n",
      "\n",
      "         [[ 0.0274, -0.0522, -0.2502,  ..., -0.2718,  0.2169, -0.0011],\n",
      "          [-0.0791,  0.0220, -0.1769,  ...,  0.0367, -0.0747,  0.0238]],\n",
      "\n",
      "         [[ 0.0342, -0.0573, -0.2644,  ..., -0.2858,  0.2452, -0.0394],\n",
      "          [-0.0935,  0.0401, -0.2048,  ...,  0.0780, -0.1076,  0.0473]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[ 0.1731, -0.4780, -0.4390,  ..., -0.6405,  0.4397,  0.2598],\n",
      "          [-0.7609,  0.5197, -0.7625,  ...,  0.7866, -0.3663,  0.2004]],\n",
      "\n",
      "         [[ 0.2751, -0.5831, -0.5868,  ..., -0.8300,  0.5166,  0.3538],\n",
      "          [-0.5879,  0.4459, -0.5956,  ...,  0.6947, -0.2836,  0.1561]],\n",
      "\n",
      "         [[ 0.2058, -0.5247, -0.4943,  ..., -0.6990,  0.4526,  0.2659],\n",
      "          [-0.5253,  0.4686, -0.5802,  ...,  0.6613, -0.2574,  0.1317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2438, -0.5523, -0.5423,  ..., -0.7721,  0.4898,  0.3238],\n",
      "          [-0.5498,  0.4554, -0.5668,  ...,  0.6678, -0.2523,  0.1353]],\n",
      "\n",
      "         [[ 0.2556, -0.5524, -0.5554,  ..., -0.8067,  0.4865,  0.3458],\n",
      "          [-0.5790,  0.4650, -0.6076,  ...,  0.6679, -0.2582,  0.1549]],\n",
      "\n",
      "         [[ 0.2801, -0.5491, -0.5827,  ..., -0.8442,  0.5363,  0.3273],\n",
      "          [-0.5070,  0.4475, -0.5977,  ...,  0.6195, -0.2478,  0.1338]]],\n",
      "\n",
      "\n",
      "        [[[-0.1571,  0.1763, -0.0042,  ..., -0.0422,  0.0956, -0.1761],\n",
      "          [ 0.0257, -0.0254, -0.1816,  ..., -0.0344, -0.0847, -0.0101]],\n",
      "\n",
      "         [[ 0.1200, -0.1971, -0.3653,  ..., -0.4020,  0.3104,  0.1074],\n",
      "          [-0.1564,  0.0546, -0.2280,  ...,  0.1425, -0.1229,  0.0583]],\n",
      "\n",
      "         [[-0.0828,  0.0768, -0.1326,  ..., -0.1573,  0.1712, -0.1263],\n",
      "          [ 0.0093, -0.0803, -0.1397,  ..., -0.0178, -0.0981,  0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0260, -0.0622, -0.2562,  ..., -0.2745,  0.2217,  0.0083],\n",
      "          [-0.0376, -0.0081, -0.1748,  ...,  0.0101, -0.0892,  0.0139]],\n",
      "\n",
      "         [[ 0.0274, -0.0522, -0.2502,  ..., -0.2718,  0.2169, -0.0011],\n",
      "          [-0.0791,  0.0220, -0.1769,  ...,  0.0367, -0.0747,  0.0238]],\n",
      "\n",
      "         [[ 0.0342, -0.0573, -0.2644,  ..., -0.2858,  0.2452, -0.0394],\n",
      "          [-0.0935,  0.0401, -0.2048,  ...,  0.0780, -0.1076,  0.0473]]]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[[[ 0.1731, -0.4780, -0.4390,  ..., -0.6405,  0.4397,  0.2598],\n",
      "          [-0.7609,  0.5197, -0.7625,  ...,  0.7866, -0.3663,  0.2004]],\n",
      "\n",
      "         [[ 0.2751, -0.5831, -0.5868,  ..., -0.8300,  0.5166,  0.3538],\n",
      "          [-0.5879,  0.4459, -0.5956,  ...,  0.6947, -0.2836,  0.1561]],\n",
      "\n",
      "         [[ 0.2058, -0.5247, -0.4943,  ..., -0.6990,  0.4526,  0.2659],\n",
      "          [-0.5253,  0.4686, -0.5802,  ...,  0.6613, -0.2574,  0.1317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2438, -0.5523, -0.5423,  ..., -0.7721,  0.4898,  0.3238],\n",
      "          [-0.5498,  0.4554, -0.5668,  ...,  0.6678, -0.2523,  0.1353]],\n",
      "\n",
      "         [[ 0.2556, -0.5524, -0.5554,  ..., -0.8067,  0.4865,  0.3458],\n",
      "          [-0.5790,  0.4650, -0.6076,  ...,  0.6679, -0.2582,  0.1549]],\n",
      "\n",
      "         [[ 0.2801, -0.5491, -0.5827,  ..., -0.8442,  0.5363,  0.3273],\n",
      "          [-0.5070,  0.4475, -0.5977,  ...,  0.6195, -0.2478,  0.1338]]],\n",
      "\n",
      "\n",
      "        [[[-0.1571,  0.1763, -0.0042,  ..., -0.0422,  0.0956, -0.1761],\n",
      "          [ 0.0257, -0.0254, -0.1816,  ..., -0.0344, -0.0847, -0.0101]],\n",
      "\n",
      "         [[ 0.1200, -0.1971, -0.3653,  ..., -0.4020,  0.3104,  0.1074],\n",
      "          [-0.1564,  0.0546, -0.2280,  ...,  0.1425, -0.1229,  0.0583]],\n",
      "\n",
      "         [[-0.0828,  0.0768, -0.1326,  ..., -0.1573,  0.1712, -0.1263],\n",
      "          [ 0.0093, -0.0803, -0.1397,  ..., -0.0178, -0.0981,  0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0260, -0.0622, -0.2562,  ..., -0.2745,  0.2217,  0.0083],\n",
      "          [-0.0376, -0.0081, -0.1748,  ...,  0.0101, -0.0892,  0.0139]],\n",
      "\n",
      "         [[ 0.0274, -0.0522, -0.2502,  ..., -0.2718,  0.2169, -0.0011],\n",
      "          [-0.0791,  0.0220, -0.1769,  ...,  0.0367, -0.0747,  0.0238]],\n",
      "\n",
      "         [[ 0.0342, -0.0573, -0.2644,  ..., -0.2858,  0.2452, -0.0394],\n",
      "          [-0.0935,  0.0401, -0.2048,  ...,  0.0780, -0.1076,  0.0473]]]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the MaseGraph for the compressed checkpoint to be used in future tutorials for hardware generation and distributed deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to tutorial_5_nas_compressed.pt, tutorial_5_nas_compressed.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to tutorial_5_nas_compressed.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to tutorial_5_nas_compressed.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg.export(\"tutorial_5_nas_compressed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
