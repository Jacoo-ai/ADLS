{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT Quantization Tutorial\n",
    "\n",
    "This notebook is designed to show the features of the TensorRT passes integrated into MASE as part of the MASERT framework. The following demonstrations were run on a NVIDIA RTX A2000 GPU with a Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz CPU.\n",
    "\n",
    "## Section 1. Show Configuration\n",
    "Firstly, we will show you how to do a int8 quantization of a simple model, `jsc-toy`, and compare the quantized model to the original model using the `Machop API`. The quantization process is split into the following stages, each using their own individual pass, and are explained in depth at each subsection:\n",
    "\n",
    "1. [Fake quantization](#section-11-fake-quantization): `tensorrt_fake_quantize_transform_pass`\n",
    "2. [Calibration](#section-12-calibration): `tensorrt_calibrate_transform_pass`\n",
    "3. [Quantized Aware Training](#section-13-quantized-aware-training-qat): `tensorrt_fine_tune_transform_pass`\n",
    "4. [Quantization](#section-14-tensorrt-quantization): `tensorrt_engine_interface_pass`\n",
    "5. [Analysis](#section-15-performance-analysis): `tensorrt_analysis_pass`\n",
    "\n",
    "We start by loading in the required libraries and passes required for the notebook as well as ensuring the correct path is set for machop to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"src\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_fine_tune_transform_pass,\n",
    "    tensorrt_engine_interface_pass,\n",
    "    runtime_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dependency (the dependent package \"cuda\" refers to \"cuda-python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExtension: All dependencies for TensorRT pass are available.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chop.tools.check_dependency import check_deps_tensorRT_pass\n",
    "check_deps_tensorRT_pass(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the toml file used for quantization. To view the configuration, click [here](../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}\n",
      "{'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "# Path to your TOML file\n",
    "RES_TOML_PATH = 'resnet18_INT8_quant.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(RES_TOML_PATH, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt' section and its children\n",
    "tensorrt_config = pass_args.get('passes', {}).get('tensorrt', {})\n",
    "print(tensorrt_config)\n",
    "# Extract the 'passes.runtime_analysis' section and its children\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('tensorrt', {}).get('runtime_analysis', {})\n",
    "print(runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `MaseGraph` by loading in a model and training it using the toml configuration model arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n"
     ]
    }
   ],
   "source": [
    "from chop.dataset import MaseDataModule\n",
    "from chop.models import get_model_info\n",
    "from chop.models import get_model\n",
    "from chop.tools.get_input import InputGenerator\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['dataset'] = pass_args['dataset']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    # task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0311 00:15:51.512130 140276942296128 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File | Manual Override |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                 |           cls            |\n",
      "| load_name               |           None           |              |                 |           None           |\n",
      "| load_type               |            mz            |              |                 |            mz            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                 |            64            |\n",
      "| to_debug                |          False           |              |                 |          False           |\n",
      "| log_level               |           info           |              |                 |           info           |\n",
      "| report_to               |       tensorboard        |              |                 |       tensorboard        |\n",
      "| seed                    |            0             |              |                 |            0             |\n",
      "| quant_config            |           None           |              |                 |           None           |\n",
      "| training_optimizer      |           adam           |              |                 |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                 |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                 |          0.001           |\n",
      "| weight_decay            |            0             |              |                 |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                 |            10            |\n",
      "| max_steps               |            -1            |              |                 |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                 |            1             |\n",
      "| log_every_n_steps       |            50            |              |                 |            50            |\n",
      "| num_workers             |            20            |              |                 |            20            |\n",
      "| num_devices             |            1             |              |                 |            1             |\n",
      "| num_nodes               |            1             |              |                 |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                 |           gpu            |\n",
      "| strategy                |           auto           |              |                 |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                 |          False           |\n",
      "| github_ci               |          False           |              |                 |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                 |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                 |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                 |           100            |\n",
      "| is_pretrained           |          False           |              |                 |          False           |\n",
      "| max_token_len           |           512            |              |                 |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                 | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                 |         e_output         |\n",
      "| project                 |           None           |              |                 |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                 |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                 |         cifar10          |\n",
      "| t_max                   |            20            |              |                 |            20            |\n",
      "| eta_min                 |          1e-06           |              |                 |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-11\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTraining model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m##### WEIGHT DECAY ##### 0\u001b[0m\n",
      "I0311 00:15:51.711618 140276942296128 rank_zero.py:63] Using 16bit Automatic Mixed Precision (AMP)\n",
      "I0311 00:15:51.718478 140276942296128 rank_zero.py:63] GPU available: True (cuda), used: True\n",
      "I0311 00:15:51.718928 140276942296128 rank_zero.py:63] TPU available: False, using: 0 TPU cores\n",
      "I0311 00:15:51.718978 140276942296128 rank_zero.py:63] HPU available: False, using: 0 HPUs\n",
      "I0311 00:15:54.418565 140276942296128 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0311 00:15:54.708575 140276942296128 model_summary.py:104] \n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | ResNet             | 11.2 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_train | MulticlassAccuracy | 0      | train\n",
      "3 | loss_val  | MeanMetric         | 0      | train\n",
      "4 | loss_test | MeanMetric         | 0      | train\n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0:  53%|▌| 411/782 [00:11<00:10, 35.12it/s, v_num=0, train_acc_step=0.234]I0311 00:16:07.596064 140276942296128 rank_zero.py:63] \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 ./ch train --config /workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model done!\n",
      "dummy in done\n",
      "_ done\n",
      "init_metadata_analysis_pass done\n",
      "add_common_metadata_analysis_pass done\n",
      "add_software_metadata_analysis_pass done\n",
      "metadata_value_type_cast_transform_pass done\n",
      "using safe deepcopy\n",
      "deep copy done\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "\n",
    "# Load model directly\n",
    "# from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "# processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "# model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "model = load_model(load_name=RES_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "print(\"load model done!\")\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "print(\"dummy in done\")\n",
    "dummy_in_converted = {\"pixel_values\": dummy_in[\"x\"]}\n",
    "\n",
    "_ = model(**dummy_in_converted)\n",
    "\n",
    "print(\"_ done\")\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "print(\"init_metadata_analysis_pass done\")\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "print(\"add_common_metadata_analysis_pass done\")\n",
    "\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "print(\"add_software_metadata_analysis_pass done\")\n",
    "\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
    "print(\"metadata_value_type_cast_transform_pass done\")\n",
    "\n",
    "# Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "print(\"deep copy done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorrt config: {'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}\n",
      "runtime_analysis config: {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}\n",
      "Loading HuggingFace model and processor ...\n",
      "HuggingFace model loaded.\n",
      "Dummy input obtained.\n",
      "Model forward pass succeeded.\n",
      "Tracing model into MaseGraph ...\n",
      "init_metadata_analysis_pass done.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown module: resnet.encoder.stages.0.layers.0.layer.2.activation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 109\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_metadata_analysis_pass done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# 添加通用的元数据（使用转换后的 dummy_in）\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m \u001b[43madd_common_metadata_analysis_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy_in\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_in_converted\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_common_metadata_analysis_pass done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# 添加软件相关的元数据\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/ADLS_Proj/src/chop/passes/graph/analysis/add_metadata/add_common_metadata.py:499\u001b[0m, in \u001b[0;36madd_common_metadata_analysis_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy_in must be provided for add_common_metadata_analysis_pass.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    498\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(graph\u001b[38;5;241m.\u001b[39mfx_graph)\n\u001b[0;32m--> 499\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_iterator_for_mase_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_iterator_for_metadata(graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpass_args)\n\u001b[1;32m    501\u001b[0m graph \u001b[38;5;241m=\u001b[39m _add_graph_metadata(graph)\n",
      "File \u001b[0;32m/workspace/ADLS_Proj/src/chop/passes/graph/analysis/add_metadata/add_common_metadata.py:133\u001b[0m, in \u001b[0;36mgraph_iterator_for_mase_ops\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mase_op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown module: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m node\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mase_type\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase_op\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mase_op\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown module: resnet.encoder.stages.0.layers.0.layer.2.activation"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import toml\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "# 导入 MASE 相关工具与 passes\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator, get_dummy_input, get_cf_args\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "\n",
    "# 导入数据和模型工具\n",
    "from chop.dataset import MaseDataModule\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "# 从 transformers 导入 HuggingFace 模型及预处理器\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "# 读取 TOML 配置文件\n",
    "RES_TOML_PATH = 'resnet18_INT8_quant.toml'\n",
    "with open(RES_TOML_PATH, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# 从配置中提取各个部分\n",
    "tensorrt_config = pass_args.get('passes', {}).get('tensorrt', {})\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('tensorrt', {}).get('runtime_analysis', {})\n",
    "\n",
    "print(\"tensorrt config:\", tensorrt_config)\n",
    "print(\"runtime_analysis config:\", runtime_analysis_config)\n",
    "\n",
    "# 基础设定\n",
    "model_name = pass_args['model']      # 此处应为 \"resnet18\"\n",
    "dataset_name = pass_args['dataset']   # 例如 \"cifar10\"\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "# 初始化数据模块\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# 将额外信息加入到配置中\n",
    "configs = [tensorrt_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['dataset'] = dataset_name\n",
    "    config['batch_size'] = batch_size\n",
    "    config['model'] = model_name\n",
    "    config['data_module'] = data_module\n",
    "    # 如果配置中 accelerator 为 gpu，则转换为 cuda\n",
    "    config['accelerator'] = 'cuda' if accelerator == 'gpu' else accelerator\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "# 获取模型信息（例如该模型是否是视觉任务）\n",
    "model_info = get_model_info(model_name)\n",
    "\n",
    "# 使用 HuggingFace 下载预训练模型和对应的预处理器\n",
    "print(\"Loading HuggingFace model and processor ...\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "print(\"HuggingFace model loaded.\")\n",
    "\n",
    "# 使用 InputGenerator 获取一个 dummy 输入\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=pass_args['task'],  # 例如 \"cls\"\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "dummy_in = next(iter(input_generator))\n",
    "print(\"Dummy input obtained.\")\n",
    "\n",
    "# 假设 input_generator 返回的字典中键名为 \"x\"（可以根据实际情况修改）\n",
    "# 将其转换为模型所需的键 \"pixel_values\"\n",
    "dummy_in_converted = {\"pixel_values\": dummy_in[\"x\"]}\n",
    "# 检查模型前向能否正常工作\n",
    "_ = model(**dummy_in_converted)\n",
    "print(\"Model forward pass succeeded.\")\n",
    "\n",
    "# 构造用于 FX 跟踪的 concrete args，确保只包含 pixel_values\n",
    "cf_args = {\"pixel_values\": dummy_in_converted[\"pixel_values\"]}\n",
    "\n",
    "# 创建 MaseGraph 对象\n",
    "print(\"Tracing model into MaseGraph ...\")\n",
    "mg = MaseGraph(model=model, cf_args=cf_args, hf_input_names=[\"pixel_values\"])\n",
    "\n",
    "# 初始化节点元数据\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "print(\"init_metadata_analysis_pass done.\")\n",
    "\n",
    "# 添加通用的元数据（使用转换后的 dummy_in）\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in_converted})\n",
    "print(\"add_common_metadata_analysis_pass done.\")\n",
    "\n",
    "# 添加软件相关的元数据\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "print(\"add_software_metadata_analysis_pass done.\")\n",
    "\n",
    "# 将节点中包含 tensor 的值转换为 numpy（以便后续处理）\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
    "print(\"metadata_value_type_cast_transform_pass done.\")\n",
    "\n",
    "# 备份一份原始图\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "print(\"MaseGraph deep copy done.\")\n",
    "\n",
    "# 此时 mg 对象即为你从 HuggingFace 下载的模型转换而成的 MaseGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HuggingFace model and processor ...\n",
      "HuggingFace model loaded.\n",
      "Tracing model into MaseGraph ...\n",
      "init_metadata_analysis_pass done.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown module: resnet.encoder.stages.0.layers.0.layer.2.activation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 添加通用的元数据（利用 dummy 输入自动解析各节点参数信息）\u001b[39;00m\n\u001b[1;32m     63\u001b[0m dummy_in \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)}\n\u001b[0;32m---> 64\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m \u001b[43madd_common_metadata_analysis_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy_in\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_in\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_common_metadata_analysis_pass done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 添加软件相关的元数据\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/ADLS_Proj/src/chop/passes/graph/analysis/add_metadata/add_common_metadata.py:499\u001b[0m, in \u001b[0;36madd_common_metadata_analysis_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy_in must be provided for add_common_metadata_analysis_pass.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    498\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(graph\u001b[38;5;241m.\u001b[39mfx_graph)\n\u001b[0;32m--> 499\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_iterator_for_mase_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_iterator_for_metadata(graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpass_args)\n\u001b[1;32m    501\u001b[0m graph \u001b[38;5;241m=\u001b[39m _add_graph_metadata(graph)\n",
      "File \u001b[0;32m/workspace/ADLS_Proj/src/chop/passes/graph/analysis/add_metadata/add_common_metadata.py:133\u001b[0m, in \u001b[0;36mgraph_iterator_for_mase_ops\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mase_op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown module: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m node\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mase_type\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmase_op\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mase_op\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown module: resnet.encoder.stages.0.layers.0.layer.2.activation"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import toml\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "# 导入 MASE 相关工具与 passes\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator, get_dummy_input, get_cf_args\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "\n",
    "# 导入数据和模型工具\n",
    "from chop.dataset import MaseDataModule\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "# 从 transformers 导入 HuggingFace 模型及预处理器\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "# 对于 ResNet 模型，我们使用 CIFAR-10 数据集作为例子\n",
    "checkpoint = \"\"              # 图像模型直接从 HuggingFace加载，不需要指定预训练检查点路径\n",
    "tokenizer_checkpoint = \"\"    # 图像模型不需要分词器\n",
    "dataset_name = \"cifar10\"     # 使用 CIFAR-10 数据集\n",
    "\n",
    "# 初始化数据模块（这里假设 MaseDataModule 已实现对图像数据集的加载）\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    model_name=\"resnet18\",  # 模型名称为 resnet18\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# 使用 HuggingFace 下载预训练模型及对应的图像预处理器\n",
    "print(\"Loading HuggingFace model and processor ...\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "print(\"HuggingFace model loaded.\")\n",
    "\n",
    "# 设置模型的配置参数，表明这是一个图像分类问题\n",
    "model.config.problem_type = \"image_classification\"\n",
    "\n",
    "# 创建 MaseGraph 对象，对于图像模型，输入名称为 \"pixel_values\"\n",
    "print(\"Tracing model into MaseGraph ...\")\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\"pixel_values\"],\n",
    ")\n",
    "\n",
    "# 初始化节点元数据\n",
    "mg, _ = init_metadata_analysis_pass(mg)\n",
    "print(\"init_metadata_analysis_pass done.\")\n",
    "\n",
    "# 添加通用的元数据（利用 dummy 输入自动解析各节点参数信息）\n",
    "dummy_in = {\"pixel_values\": torch.randn(1, 3, 224, 224)}\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "print(\"add_common_metadata_analysis_pass done.\")\n",
    "\n",
    "# 添加软件相关的元数据\n",
    "mg, _ = add_software_metadata_analysis_pass(mg)\n",
    "print(\"add_software_metadata_analysis_pass done.\")\n",
    "\n",
    "# 将节点中包含 tensor 的值转换为 numpy（以便后续处理）\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
    "print(\"metadata_value_type_cast_transform_pass done.\")\n",
    "\n",
    "# 备份一份原始图，用于后续对比或恢复\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "print(\"MaseGraph deep copy done.\")\n",
    "\n",
    "# 此时 mg 对象即为你从 HuggingFace 下载的 ResNet 模型转换而成的 MaseGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_metadata_analysis_pass done.\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[-0.0113, -0.1129],\n",
      "        [ 0.0329, -0.0667]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "add_common_metadata_analysis_pass done.\n",
      "using safe deepcopy\n",
      "MaseGraph deep copy done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import toml\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "# 导入 MASE 相关工具与 passes\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator, get_dummy_input, get_cf_args\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "\n",
    "# 导入数据和模型工具\n",
    "from chop.dataset import MaseDataModule\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "# 从 transformers 导入 HuggingFace 模型及预处理器\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "import chop.passes as passes\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "# 加载 IMDb 数据集，并获取对应的分词器\n",
    "checkpoint = \"prajjwal1/bert-tiny\"  # 预训练模型的检查点\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"  # 分词器的检查点\n",
    "dataset_name = \"imdb\"  # 数据集名称\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "# 加载预训练的 BERT 模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"  # 设置问题类型为单标签分类\n",
    "\n",
    "# 初始化 MaseGraph（模型量化和优化工具）\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\"input_ids\", \"attention_mask\", \"labels\"],  # 指定输入张量名称\n",
    ")\n",
    "\n",
    "# 初始化节点元数据\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "print(\"init_metadata_analysis_pass done.\")\n",
    "\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)\n",
    "print(\"add_common_metadata_analysis_pass done.\")\n",
    "\n",
    "# 备份一份原始图，用于后续对比或恢复\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "print(\"MaseGraph deep copy done.\")\n",
    "\n",
    "# 此时 mg 对象即为你从 HuggingFace 下载的 ResNet 模型转换而成的 MaseGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 17:55:34.734239 140152862438464 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+---------------------+---------------------+--------------------------+\n",
      "| Name                    |         Default          |    Config. File     |   Manual Override   |        Effective         |\n",
      "+-------------------------+--------------------------+---------------------+---------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls         |                     |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           | \u001b[38;5;8mprajjwal1/bert-tiny\u001b[0m | prajjwal1/bert-tiny |   prajjwal1/bert-tiny    |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |         \u001b[38;5;8mhf\u001b[0m          |         hf          |            hf            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |         32          |                     |            32            |\n",
      "| to_debug                |          False           |                     |                     |          False           |\n",
      "| log_level               |           info           |                     |                     |           info           |\n",
      "| report_to               |       tensorboard        |                     |                     |       tensorboard        |\n",
      "| seed                    |            0             |                     |                     |            0             |\n",
      "| quant_config            |           None           |                     |                     |           None           |\n",
      "| training_optimizer      |           adam           |                     |                     |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                     |                     |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001        |                     |          0.001           |\n",
      "| weight_decay            |            0             |                     |                     |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |         10          |                     |            10            |\n",
      "| max_steps               |            -1            |                     |                     |            -1            |\n",
      "| accumulate_grad_batches |            1             |                     |                     |            1             |\n",
      "| log_every_n_steps       |            50            |                     |                     |            50            |\n",
      "| num_workers             |            20            |                     |                     |            20            |\n",
      "| num_devices             |            1             |                     |                     |            1             |\n",
      "| num_nodes               |            1             |                     |                     |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu         |                     |           gpu            |\n",
      "| strategy                |           auto           |                     |                     |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                     |                     |          False           |\n",
      "| github_ci               |          False           |                     |                     |          False           |\n",
      "| disable_dataset_cache   |          False           |                     |                     |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                     |                     |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                     |                     |           100            |\n",
      "| is_pretrained           |          False           |                     |                     |          False           |\n",
      "| max_token_len           |           512            |                     |                     |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                     |                     | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                     |                     |         e_output         |\n",
      "| project                 |           None           |                     |                     |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |      bert-tiny      |                     |        bert-tiny         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |        sst2         |                     |           sst2           |\n",
      "| t_max                   |            20            |                     |                     |            20            |\n",
      "| eta_min                 |          1e-06           |                     |                     |          1e-06           |\n",
      "+-------------------------+--------------------------+---------------------+---------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'bert-tiny'...\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ADLS_Proj/docs/tutorials/proj/ch\", line 6, in <module>\n",
      "    ChopCLI().run()\n",
      "    ^^^^^^^^^\n",
      "  File \"/workspace/ADLS_Proj/src/chop/cli.py\", line 240, in __init__\n",
      "    ) = self._setup_model_and_dataset()\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/ADLS_Proj/src/chop/cli.py\", line 864, in _setup_model_and_dataset\n",
      "    model_info = models.get_model_info(self.args.model)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/ADLS_Proj/src/chop/models/__init__.py\", line 28, in get_model_info\n",
      "    return ModelFactory._model_info_dict[name]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "KeyError: 'bert-tiny'\n"
     ]
    }
   ],
   "source": [
    "BER_INT8_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/bert_INT8_quant.toml\"\n",
    "BER_CHECKPOINT_PATH = \"prajjwal1/bert-tiny\"  # 使用 HuggingFace 上的模型标识\n",
    "!python ch transform --config {BER_INT8_BY_TYPE_TOML} --load {BER_CHECKPOINT_PATH} --load-type hf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Resnet: INT8/FP16/FP32 Quantization Comparison\n",
    "\n",
    "We will now load in a new toml configuration that uses fp16 instead of int8, whilst keeping the other settings the exact same for a fair comparison. This time however, we will use chop from the terminal which runs all the passes showcased in [Section 1](#section-1---int8-quantization).\n",
    "\n",
    "Since float quantization does not require calibration, nor is it supported by `pytorch-quantization`, the model will not undergo fake quantization; for the time being this unfortunately means QAT is unavailable and only undergoes Post Training Quantization (PTQ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 15:53:53.484075 140467152626752 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+---------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |   Manual Override   |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+---------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                     |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | microsoft/resnet-50 |   microsoft/resnet-50    |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |         hf          |            hf            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                     |            64            |\n",
      "| to_debug                |          False           |              |                     |          False           |\n",
      "| log_level               |           info           |              |                     |           info           |\n",
      "| report_to               |       tensorboard        |              |                     |       tensorboard        |\n",
      "| seed                    |            0             |              |                     |            0             |\n",
      "| quant_config            |           None           |              |                     |           None           |\n",
      "| training_optimizer      |           adam           |              |                     |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                     |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                     |          0.001           |\n",
      "| weight_decay            |            0             |              |                     |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                     |            10            |\n",
      "| max_steps               |            -1            |              |                     |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                     |            1             |\n",
      "| log_every_n_steps       |            50            |              |                     |            50            |\n",
      "| num_workers             |            20            |              |                     |            20            |\n",
      "| num_devices             |            1             |              |                     |            1             |\n",
      "| num_nodes               |            1             |              |                     |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                     |           gpu            |\n",
      "| strategy                |           auto           |              |                     |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                     |          False           |\n",
      "| github_ci               |          False           |              |                     |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                     |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                     |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                     |           100            |\n",
      "| is_pretrained           |          False           |              |                     |          False           |\n",
      "| max_token_len           |           512            |              |                     |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                     | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                     |         e_output         |\n",
      "| project                 |           None           |              |                     |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                     |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                     |         cifar10          |\n",
      "| t_max                   |            20            |              |                     |            20            |\n",
      "| eta_min                 |          1e-06           |              |                     |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+---------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded HuggingFace model from microsoft/resnet-50\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded HuggingFace model from microsoft/resnet-50\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ADLS_Proj/docs/tutorials/proj/ch\", line 6, in <module>\n",
      "    ChopCLI().run()\n",
      "  File \"/workspace/ADLS_Proj/src/chop/cli.py\", line 272, in run\n",
      "    run_action_fn()\n",
      "  File \"/workspace/ADLS_Proj/src/chop/cli.py\", line 386, in _run_transform\n",
      "    transform(**transform_params)\n",
      "  File \"/workspace/ADLS_Proj/src/chop/actions/transform.py\", line 98, in transform\n",
      "    transform_graph(\n",
      "  File \"/workspace/ADLS_Proj/src/chop/actions/transform.py\", line 250, in transform_graph\n",
      "    graph = MaseGraph(model=model, cf_args=cf_args)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/ADLS_Proj/src/chop/ir/graph/mase_graph.py\", line 309, in __init__\n",
      "    self.model = trace_torch_module(\n",
      "                 ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/ADLS_Proj/src/chop/ir/graph/mase_graph.py\", line 154, in trace_torch_module\n",
      "    graph_module = hf_symbolic_trace(\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/srcPkgs/miniconda3/lib/python3.11/site-packages/transformers/utils/fx.py\", line 1483, in symbolic_trace\n",
      "    concrete_args = get_concrete_args(model, input_names)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/srcPkgs/miniconda3/lib/python3.11/site-packages/transformers/utils/fx.py\", line 1429, in get_concrete_args\n",
      "    raise ValueError(\n",
      "ValueError: The model does not have input(s) named: input_ids, expected a subset of the following: pixel_values, labels, output_hidden_states, return_dict\n"
     ]
    }
   ],
   "source": [
    "RES_INT8_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"microsoft/resnet-50\"  # 使用 HuggingFace 上的模型标识\n",
    "!python ch transform --config {RES_INT8_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 01:23:45.774668 139703610053696 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "op is placeholder\n",
      "placeholder not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is max_pool2d\n",
      "max_pool2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is adaptive_avg_pool2d\n",
      "adaptive_avg_pool2d not in QUANTIZEABLE_OP\n",
      "op is flatten\n",
      "flatten not in QUANTIZEABLE_OP\n",
      "op is linear\n",
      "node.op == call_module\n",
      "op is output\n",
      "output not in QUANTIZEABLE_OP\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type     | OP                  |   Total |   Changed |   Unchanged |\n",
      "|-------------------+---------------------+---------+-----------+-------------|\n",
      "| AdaptiveAvgPool2d | adaptive_avg_pool2d |       1 |         0 |           1 |\n",
      "| BatchNorm2d       | batch_norm2d        |      20 |         0 |          20 |\n",
      "| MaxPool2d         | max_pool2d          |       1 |         0 |           1 |\n",
      "| QuantConv2d       | conv2d              |      20 |         0 |          20 |\n",
      "| QuantLinear       | linear              |       1 |         0 |           1 |\n",
      "| ReLU              | relu                |      17 |         0 |          17 |\n",
      "| add               | add                 |       8 |         0 |           8 |\n",
      "| flatten           | flatten             |       1 |         0 |           1 |\n",
      "| output            | output              |       1 |         0 |           1 |\n",
      "| x                 | placeholder         |       1 |         0 |           1 |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.922260 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.922491 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.922657 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.922785 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.922956 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923104 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923228 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923357 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923478 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923589 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923706 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923818 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.923936 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924046 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924172 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924284 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924398 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924507 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924622 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924733 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924848 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.924958 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925071 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925192 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925306 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925416 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925532 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925656 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925778 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.925884 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926000 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926108 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926219 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926326 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926456 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926565 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926676 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926784 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.926894 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.927001 139703610053696 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.927117 139703610053696 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0315 01:23:58.927211 139703610053696 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0315 01:23:58.927518 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0315 01:23:58.927609 139703610053696 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.6224 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.927929 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1400 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.928180 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.2234 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.928388 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2111 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.928645 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.1065 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.928863 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1980 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.929070 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.8358 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.929276 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1957 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.929511 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.1359 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.929744 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1970 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.929947 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.4627 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.930136 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1583 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.930328 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.2610 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.930509 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1586 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.930694 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=5.4627 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.930871 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3493 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931056 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.5872 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931236 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931422 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.2720 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931605 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1517 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931797 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.5370 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.931978 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1277 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.932162 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.6489 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.932338 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1132 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.932523 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=4.5370 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.932701 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2536 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.932884 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.4016 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933084 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0943 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933270 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.3014 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933448 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0944 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933627 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.2608 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933794 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0710 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.933966 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.5874 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.934165 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0598 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.934376 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=5.2608 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.934560 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.1907 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.934740 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.9013 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.934911 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0552 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.935086 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.0223 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.935261 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.935403 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.6309 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:23:58.935742 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.72608   |\n",
      "|      Average Precision       |   0.71486   |\n",
      "|        Average Recall        |   0.71875   |\n",
      "|       Average F1 Score       |   0.71577   |\n",
      "|         Average Loss         |   0.81619   |\n",
      "|       Average Latency        |  34.633 ms  |\n",
      "|   Average GPU Power Usage    |  13.806 W   |\n",
      "| Inference Energy Consumption | 0.13282 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_0/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0315 01:24:06.038734 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.6384 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.039483 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1815 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.039825 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.4700 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.040095 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2904 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.040351 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.2549 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.040592 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2525 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.040854 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.1755 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.041092 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2498 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.041334 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.1552 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.041567 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2537 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.041802 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.9494 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.042031 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2041 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.042269 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.3049 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.042513 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2041 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.042753 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=7.9494 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.043049 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4401 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.043301 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.1995 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.043533 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2007 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.043810 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.3943 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.044165 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1949 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.044557 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.7997 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.044898 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1651 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.045269 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.1052 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.045599 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1593 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.045931 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=6.7997 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.046232 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3283 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.046531 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.6513 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.046845 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1263 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.047185 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.1650 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.047479 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1284 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.047739 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.4910 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.047980 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1042 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.048222 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.3105 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.048454 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0840 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.048927 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=8.4910 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.049339 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2463 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.049886 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.2235 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.050177 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0714 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.050515 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.4094 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.050834 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0719 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.051083 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.6309 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:06.051247 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.72868    |\n",
      "|      Average Precision       |   0.71952    |\n",
      "|        Average Recall        |   0.72268    |\n",
      "|       Average F1 Score       |    0.7203    |\n",
      "|         Average Loss         |   0.80705    |\n",
      "|       Average Latency        |  28.964 ms   |\n",
      "|   Average GPU Power Usage    |   10.53 W    |\n",
      "| Inference Energy Consumption | 0.084719 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_1/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0315 01:24:11.926549 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=3.0570 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.927209 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.2071 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.927555 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.8774 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.927806 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3663 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.928054 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.4204 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.928285 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2896 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.928526 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.6484 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.928769 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2951 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.929061 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.2232 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.929307 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2948 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.929539 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.5421 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.929760 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2492 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.930126 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.3595 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.930378 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2424 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.930610 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=10.5421 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.930837 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.5430 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.931249 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.8363 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.931474 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2315 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.932123 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.4469 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.932453 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2258 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.932724 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.2777 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.932990 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1993 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.933232 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.4579 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.933460 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2141 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.933697 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=9.2777 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.933957 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3806 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.934198 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.7517 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.934422 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1591 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.934650 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.7914 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.934872 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1755 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.935144 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.0269 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.935390 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1403 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.935625 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.1205 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.935845 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1098 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.936084 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=12.0269 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.936304 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2988 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.936535 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.7121 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.936811 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0875 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.937063 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.8232 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.937299 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0867 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.937504 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.6309 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:11.937657 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.72872    |\n",
      "|      Average Precision       |   0.71967    |\n",
      "|        Average Recall        |   0.72279    |\n",
      "|       Average F1 Score       |   0.72034    |\n",
      "|         Average Loss         |   0.80904    |\n",
      "|       Average Latency        |  26.359 ms   |\n",
      "|   Average GPU Power Usage    |   10.624 W   |\n",
      "| Inference Energy Consumption | 0.077789 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_2/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0315 01:24:17.712724 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=3.3180 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:17.894579 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.2056 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:18.251268 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.1045 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:18.431818 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3741 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:18.694564 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.1439 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:18.881787 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3233 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:19.219688 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.0065 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:19.399970 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2902 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:19.650830 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.9089 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:19.819225 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2955 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:20.001526 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.9078 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:20.172828 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2500 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:20.438764 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.9042 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:20.627349 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2475 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:20.827448 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=11.9078 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:21.013975 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.5176 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:21.211982 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.6229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:21.391825 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2328 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:21.612207 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.0186 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:21.784920 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2287 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:22.150280 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.7115 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:22.329423 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2018 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:22.599805 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.0589 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:22.787929 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2356 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:23.105024 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=10.7115 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:23.295989 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4561 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:23.579686 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.9177 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:23.766986 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1725 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:23.944687 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.7037 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:24.128643 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2001 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:24.316481 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=13.0893 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:24.499539 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1536 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:24.684113 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.1098 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.054862 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1161 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.232592 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=13.0893 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.412049 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3027 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.592864 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.2634 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.771907 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0888 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:25.950548 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.7587 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:26.129124 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:26.130245 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.6309 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:26.130683 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.72848   |\n",
      "|      Average Precision       |   0.71898   |\n",
      "|        Average Recall        |   0.72227   |\n",
      "|       Average F1 Score       |   0.7197    |\n",
      "|         Average Loss         |   0.80978   |\n",
      "|       Average Latency        |  33.931 ms  |\n",
      "|   Average GPU Power Usage    |  9.4373 W   |\n",
      "| Inference Energy Consumption | 0.08895 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_3/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0315 01:24:35.326884 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.1200 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:36.899141 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1926 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:39.525205 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.4599 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:41.033430 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3665 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:42.986601 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.8759 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:44.495841 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3090 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:47.389332 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.1156 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:48.954459 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2953 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:50.742857 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.5661 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:52.182403 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2965 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:53.631896 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=14.0887 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:55.090106 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2664 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:57.066362 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.4994 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:24:58.536308 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2533 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:00.002814 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=14.0887 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:01.434386 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4531 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:02.874977 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.5907 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:04.346352 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2549 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:05.848518 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.6632 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:07.320424 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:09.730585 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=13.1341 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:11.231554 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2261 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:13.152189 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.0554 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:14.590133 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2659 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:17.024239 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=13.1341 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:18.439450 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4147 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:20.490301 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.9782 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:21.951633 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1992 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:23.403716 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.3777 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:24.795568 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2278 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:26.234439 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=14.0340 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:27.662348 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1693 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:29.139847 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.4003 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:30.580707 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1449 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:32.044255 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=14.0340 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:33.526308 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3188 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:34.972633 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.4923 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:36.432395 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1031 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:37.897637 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.8677 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:39.397825 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1051 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:39.398750 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.6309 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0315 01:25:39.399023 139703610053696 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |    0.7293    |\n",
      "|      Average Precision       |   0.71953    |\n",
      "|        Average Recall        |   0.72299    |\n",
      "|       Average F1 Score       |   0.72043    |\n",
      "|         Average Loss         |   0.81129    |\n",
      "|       Average Latency        |  26.884 ms   |\n",
      "|   Average GPU Power Usage    |   10.213 W   |\n",
      "| Inference Energy Consumption | 0.076263 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_4/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning for 2 epochs...\u001b[0m\n",
      "I0315 01:25:45.103971 139703610053696 rank_zero.py:63] GPU available: True (cuda), used: True\n",
      "I0315 01:25:45.104289 139703610053696 rank_zero.py:63] TPU available: False, using: 0 TPU cores\n",
      "I0315 01:25:45.104348 139703610053696 rank_zero.py:63] HPU available: False, using: 0 HPUs\n",
      "I0315 01:25:47.751724 139703610053696 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0315 01:25:47.763391 139703610053696 model_summary.py:104] \n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | GraphModule        | 11.2 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_train | MulticlassAccuracy | 0      | train\n",
      "3 | loss_val  | MeanMetric         | 0      | train\n",
      "4 | loss_test | MeanMetric         | 0      | train\n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "114       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0: 100%|█| 782/782 [00:31<00:00, 24.52it/s, v_num=12, train_acc_step=0.688\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:04, 31.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 2/157 [00:00<00:04, 32.68it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 3/157 [00:00<00:04, 34.96it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍                 | 4/157 [00:00<00:04, 34.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 5/157 [00:00<00:04, 32.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 6/157 [00:00<00:04, 33.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                 | 7/157 [00:00<00:04, 33.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 8/157 [00:00<00:04, 32.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                 | 9/157 [00:00<00:04, 32.80it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 10/157 [00:00<00:04, 32.76it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 11/157 [00:00<00:04, 32.26it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▎               | 12/157 [00:00<00:04, 31.98it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍               | 13/157 [00:00<00:04, 31.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌               | 14/157 [00:00<00:04, 31.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▌               | 15/157 [00:00<00:04, 31.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 16/157 [00:00<00:04, 31.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 17/157 [00:00<00:04, 31.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▉               | 18/157 [00:00<00:04, 31.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 19/157 [00:00<00:04, 30.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 20/157 [00:00<00:04, 30.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎              | 21/157 [00:00<00:04, 30.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 22/157 [00:00<00:04, 31.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▍              | 23/157 [00:00<00:04, 30.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 24/157 [00:00<00:04, 30.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 25/157 [00:00<00:04, 30.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▊              | 26/157 [00:00<00:04, 30.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 27/157 [00:00<00:04, 29.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 28/157 [00:00<00:04, 29.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███▏             | 29/157 [00:00<00:04, 29.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 30/157 [00:01<00:04, 29.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▎             | 31/157 [00:01<00:04, 29.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 32/157 [00:01<00:04, 29.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 33/157 [00:01<00:04, 29.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 34/157 [00:01<00:04, 29.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▊             | 35/157 [00:01<00:04, 29.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 36/157 [00:01<00:04, 29.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 37/157 [00:01<00:04, 28.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 38/157 [00:01<00:04, 28.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▏            | 39/157 [00:01<00:04, 28.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 40/157 [00:01<00:04, 28.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 41/157 [00:01<00:04, 28.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 42/157 [00:01<00:04, 28.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▋            | 43/157 [00:01<00:03, 28.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 44/157 [00:01<00:03, 28.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▊            | 45/157 [00:01<00:03, 28.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 46/157 [00:01<00:03, 28.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 47/157 [00:01<00:03, 28.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▏           | 48/157 [00:01<00:03, 28.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 49/157 [00:01<00:03, 28.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 50/157 [00:01<00:03, 28.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▌           | 51/157 [00:01<00:03, 28.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▋           | 52/157 [00:01<00:03, 28.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▋           | 53/157 [00:01<00:03, 29.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 54/157 [00:01<00:03, 29.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 55/157 [00:01<00:03, 29.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 56/157 [00:01<00:03, 29.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████▏          | 57/157 [00:01<00:03, 29.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 58/157 [00:01<00:03, 29.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 59/157 [00:02<00:03, 29.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 60/157 [00:02<00:03, 29.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▌          | 61/157 [00:02<00:03, 29.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 62/157 [00:02<00:03, 29.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 63/157 [00:02<00:03, 29.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 64/157 [00:02<00:03, 28.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████          | 65/157 [00:02<00:03, 28.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 66/157 [00:02<00:03, 28.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 67/157 [00:02<00:03, 28.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 68/157 [00:02<00:03, 28.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 69/157 [00:02<00:03, 28.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▌         | 70/157 [00:02<00:02, 29.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▋         | 71/157 [00:02<00:02, 29.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▊         | 72/157 [00:02<00:02, 29.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▉         | 73/157 [00:02<00:02, 29.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|████████         | 74/157 [00:02<00:02, 29.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████         | 75/157 [00:02<00:02, 29.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 76/157 [00:02<00:02, 29.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████████▎        | 77/157 [00:02<00:02, 29.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████▍        | 78/157 [00:02<00:02, 29.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████▌        | 79/157 [00:02<00:02, 29.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▋        | 80/157 [00:02<00:02, 29.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 81/157 [00:02<00:02, 29.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▉        | 82/157 [00:02<00:02, 29.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▉        | 83/157 [00:02<00:02, 29.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████        | 84/157 [00:02<00:02, 29.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▏       | 85/157 [00:02<00:02, 29.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▎       | 86/157 [00:02<00:02, 29.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▍       | 87/157 [00:02<00:02, 29.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████▌       | 88/157 [00:02<00:02, 29.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▋       | 89/157 [00:03<00:02, 29.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▋       | 90/157 [00:03<00:02, 29.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▊       | 91/157 [00:03<00:02, 29.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▉       | 92/157 [00:03<00:02, 29.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|██████████       | 93/157 [00:03<00:02, 29.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▏      | 94/157 [00:03<00:02, 29.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 95/157 [00:03<00:02, 29.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▍      | 96/157 [00:03<00:02, 29.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████████▌      | 97/157 [00:03<00:02, 29.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████████▌      | 98/157 [00:03<00:02, 29.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▋      | 99/157 [00:03<00:01, 29.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▏     | 100/157 [00:03<00:01, 29.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▎     | 101/157 [00:03<00:01, 29.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▍     | 102/157 [00:03<00:01, 29.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▍     | 103/157 [00:03<00:01, 29.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▌     | 104/157 [00:03<00:01, 29.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 105/157 [00:03<00:01, 29.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▊     | 106/157 [00:03<00:01, 29.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▉     | 107/157 [00:03<00:01, 29.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 108/157 [00:03<00:01, 29.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 109/157 [00:03<00:01, 29.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 110/157 [00:03<00:01, 29.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 111/157 [00:03<00:01, 29.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▍    | 112/157 [00:03<00:01, 29.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 113/157 [00:03<00:01, 29.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▌    | 114/157 [00:03<00:01, 29.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 115/157 [00:03<00:01, 29.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 116/157 [00:03<00:01, 29.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████▉    | 117/157 [00:03<00:01, 29.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████    | 118/157 [00:04<00:01, 29.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 119/157 [00:04<00:01, 29.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 120/157 [00:04<00:01, 29.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▎   | 121/157 [00:04<00:01, 29.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▍   | 122/157 [00:04<00:01, 29.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▌   | 123/157 [00:04<00:01, 29.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▋   | 124/157 [00:04<00:01, 29.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▋   | 125/157 [00:04<00:01, 29.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▊   | 126/157 [00:04<00:01, 29.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 127/157 [00:04<00:01, 29.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████   | 128/157 [00:04<00:00, 29.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▏  | 129/157 [00:04<00:00, 29.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▏  | 130/157 [00:04<00:00, 29.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▎  | 131/157 [00:04<00:00, 29.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 132/157 [00:04<00:00, 29.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 133/157 [00:04<00:00, 29.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▋  | 134/157 [00:04<00:00, 29.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 135/157 [00:04<00:00, 29.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▊  | 136/157 [00:04<00:00, 29.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 137/157 [00:04<00:00, 29.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 138/157 [00:04<00:00, 29.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▏ | 139/157 [00:04<00:00, 29.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 140/157 [00:04<00:00, 29.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▎ | 141/157 [00:04<00:00, 29.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 142/157 [00:04<00:00, 29.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 143/157 [00:04<00:00, 29.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 144/157 [00:04<00:00, 29.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 145/157 [00:04<00:00, 29.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 146/157 [00:04<00:00, 29.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|██████████████▉ | 147/157 [00:04<00:00, 29.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████ | 148/157 [00:05<00:00, 29.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 149/157 [00:05<00:00, 29.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▎| 150/157 [00:05<00:00, 29.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▍| 151/157 [00:05<00:00, 29.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▍| 152/157 [00:05<00:00, 29.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▌| 153/157 [00:05<00:00, 29.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 154/157 [00:05<00:00, 29.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 155/157 [00:05<00:00, 29.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▉| 156/157 [00:05<00:00, 29.59it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████| 157/157 [00:05<00:00, 29.63it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 782/782 [00:37<00:00, 20.61it/s, v_num=12, train_acc_step=0.125\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:04, 34.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 2/157 [00:00<00:05, 27.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 3/157 [00:00<00:05, 28.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍                 | 4/157 [00:00<00:04, 31.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 5/157 [00:00<00:04, 32.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 6/157 [00:00<00:04, 32.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                 | 7/157 [00:00<00:04, 33.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 8/157 [00:00<00:04, 34.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                 | 9/157 [00:00<00:04, 34.76it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 10/157 [00:00<00:04, 33.92it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 11/157 [00:00<00:04, 33.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▎               | 12/157 [00:00<00:04, 33.35it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍               | 13/157 [00:00<00:04, 33.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌               | 14/157 [00:00<00:04, 33.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▌               | 15/157 [00:00<00:04, 32.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 16/157 [00:00<00:04, 32.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 17/157 [00:00<00:04, 32.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▉               | 18/157 [00:00<00:04, 32.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 19/157 [00:00<00:04, 33.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 20/157 [00:00<00:04, 33.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎              | 21/157 [00:00<00:04, 33.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 22/157 [00:00<00:04, 33.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▍              | 23/157 [00:00<00:04, 33.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 24/157 [00:00<00:03, 33.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 25/157 [00:00<00:03, 33.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▊              | 26/157 [00:00<00:03, 33.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 27/157 [00:00<00:03, 33.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 28/157 [00:00<00:03, 33.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███▏             | 29/157 [00:00<00:03, 33.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 30/157 [00:00<00:03, 33.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▎             | 31/157 [00:00<00:03, 33.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 32/157 [00:00<00:03, 33.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 33/157 [00:00<00:03, 34.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 34/157 [00:00<00:03, 34.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▊             | 35/157 [00:01<00:03, 34.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 36/157 [00:01<00:03, 33.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 37/157 [00:01<00:03, 33.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 38/157 [00:01<00:03, 34.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▏            | 39/157 [00:01<00:03, 34.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 40/157 [00:01<00:03, 33.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 41/157 [00:01<00:03, 34.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 42/157 [00:01<00:03, 34.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▋            | 43/157 [00:01<00:03, 34.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 44/157 [00:01<00:03, 34.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▊            | 45/157 [00:01<00:03, 34.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 46/157 [00:01<00:03, 34.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 47/157 [00:01<00:03, 34.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▏           | 48/157 [00:01<00:03, 34.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 49/157 [00:01<00:03, 33.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 50/157 [00:01<00:03, 33.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▌           | 51/157 [00:01<00:03, 33.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▋           | 52/157 [00:01<00:03, 33.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▋           | 53/157 [00:01<00:03, 33.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 54/157 [00:01<00:03, 33.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 55/157 [00:01<00:03, 33.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 56/157 [00:01<00:03, 33.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████▏          | 57/157 [00:01<00:02, 33.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 58/157 [00:01<00:02, 33.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 59/157 [00:01<00:02, 33.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 60/157 [00:01<00:02, 32.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▌          | 61/157 [00:01<00:02, 32.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 62/157 [00:01<00:02, 32.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 63/157 [00:01<00:02, 32.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 64/157 [00:01<00:02, 32.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████          | 65/157 [00:02<00:02, 32.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 66/157 [00:02<00:02, 32.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 67/157 [00:02<00:02, 32.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 68/157 [00:02<00:02, 32.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 69/157 [00:02<00:02, 32.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▌         | 70/157 [00:02<00:02, 32.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▋         | 71/157 [00:02<00:02, 32.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▊         | 72/157 [00:02<00:02, 31.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▉         | 73/157 [00:02<00:02, 31.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|████████         | 74/157 [00:02<00:02, 31.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████         | 75/157 [00:02<00:02, 31.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 76/157 [00:02<00:02, 31.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████████▎        | 77/157 [00:02<00:02, 31.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████▍        | 78/157 [00:02<00:02, 31.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████▌        | 79/157 [00:02<00:02, 31.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▋        | 80/157 [00:02<00:02, 31.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 81/157 [00:02<00:02, 31.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▉        | 82/157 [00:02<00:02, 31.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▉        | 83/157 [00:02<00:02, 31.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████        | 84/157 [00:02<00:02, 31.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▏       | 85/157 [00:02<00:02, 31.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▎       | 86/157 [00:02<00:02, 31.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▍       | 87/157 [00:02<00:02, 31.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████▌       | 88/157 [00:02<00:02, 31.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▋       | 89/157 [00:02<00:02, 31.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▋       | 90/157 [00:02<00:02, 31.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▊       | 91/157 [00:02<00:02, 31.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▉       | 92/157 [00:02<00:02, 30.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|██████████       | 93/157 [00:03<00:02, 30.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▏      | 94/157 [00:03<00:02, 31.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 95/157 [00:03<00:02, 30.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▍      | 96/157 [00:03<00:01, 30.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████████▌      | 97/157 [00:03<00:01, 30.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████████▌      | 98/157 [00:03<00:01, 30.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▋      | 99/157 [00:03<00:01, 30.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▏     | 100/157 [00:03<00:01, 30.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▎     | 101/157 [00:03<00:01, 30.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▍     | 102/157 [00:03<00:01, 30.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▍     | 103/157 [00:03<00:01, 30.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▌     | 104/157 [00:03<00:01, 30.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 105/157 [00:03<00:01, 30.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▊     | 106/157 [00:03<00:01, 30.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▉     | 107/157 [00:03<00:01, 30.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 108/157 [00:03<00:01, 30.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 109/157 [00:03<00:01, 30.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 110/157 [00:03<00:01, 30.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 111/157 [00:03<00:01, 30.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▍    | 112/157 [00:03<00:01, 30.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 113/157 [00:03<00:01, 30.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▌    | 114/157 [00:03<00:01, 29.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 115/157 [00:03<00:01, 29.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 116/157 [00:03<00:01, 29.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████▉    | 117/157 [00:03<00:01, 29.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████    | 118/157 [00:03<00:01, 29.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 119/157 [00:03<00:01, 30.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 120/157 [00:04<00:01, 29.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▎   | 121/157 [00:04<00:01, 29.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▍   | 122/157 [00:04<00:01, 29.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▌   | 123/157 [00:04<00:01, 29.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▋   | 124/157 [00:04<00:01, 29.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▋   | 125/157 [00:04<00:01, 29.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▊   | 126/157 [00:04<00:01, 29.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 127/157 [00:04<00:01, 29.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████   | 128/157 [00:04<00:00, 29.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▏  | 129/157 [00:04<00:00, 29.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▏  | 130/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▎  | 131/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 132/157 [00:04<00:00, 29.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 133/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▋  | 134/157 [00:04<00:00, 29.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 135/157 [00:04<00:00, 29.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▊  | 136/157 [00:04<00:00, 29.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 137/157 [00:04<00:00, 29.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 138/157 [00:04<00:00, 29.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▏ | 139/157 [00:04<00:00, 29.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 140/157 [00:04<00:00, 29.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▎ | 141/157 [00:04<00:00, 29.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 142/157 [00:04<00:00, 29.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 143/157 [00:04<00:00, 29.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 144/157 [00:04<00:00, 29.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 145/157 [00:04<00:00, 29.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 146/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|██████████████▉ | 147/157 [00:04<00:00, 29.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████ | 148/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 149/157 [00:04<00:00, 29.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▎| 150/157 [00:05<00:00, 29.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▍| 151/157 [00:05<00:00, 29.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▍| 152/157 [00:05<00:00, 29.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▌| 153/157 [00:05<00:00, 29.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 154/157 [00:05<00:00, 29.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 155/157 [00:05<00:00, 29.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▉| 156/157 [00:05<00:00, 29.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████| 157/157 [00:05<00:00, 29.89it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 782/782 [00:43<00:00, 17.95it/s, v_num=12, train_acc_step=0.125\u001b[AI0315 01:27:10.410279 139703610053696 rank_zero.py:63] `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Epoch 1: 100%|█| 782/782 [00:43<00:00, 17.84it/s, v_num=12, train_acc_step=0.125\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_1/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_2/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_3/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.73031   |\n",
      "|      Average Precision       |   0.72099   |\n",
      "|        Average Recall        |   0.72423   |\n",
      "|       Average F1 Score       |   0.7218    |\n",
      "|         Average Loss         |   0.81107   |\n",
      "|       Average Latency        |  42.757 ms  |\n",
      "|   Average GPU Power Usage    |  9.3992 W   |\n",
      "| Inference Energy Consumption | 0.11163 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_5/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/15/2025-01:30:18] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.74089    |\n",
      "|      Average Precision       |   0.74216    |\n",
      "|        Average Recall        |   0.74431    |\n",
      "|       Average F1 Score       |   0.74236    |\n",
      "|         Average Loss         |    0.7364    |\n",
      "|       Average Latency        |  4.4764 ms   |\n",
      "|   Average GPU Power Usage    |   12.884 W   |\n",
      "| Inference Energy Consumption | 0.016021 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/tensorrt/version_0/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_INT8_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_INT8_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 01:36:29.907291 139755539158080 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp16'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mprecision=fp16, skipping int8 calibration/fine-tune...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_7/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_8/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72852    |\n",
      "|      Average Precision       |   0.71886    |\n",
      "|        Average Recall        |   0.72227    |\n",
      "|       Average F1 Score       |   0.71961    |\n",
      "|         Average Loss         |   0.80975    |\n",
      "|       Average Latency        |  8.0633 ms   |\n",
      "|   Average GPU Power Usage    |   13.007 W   |\n",
      "| Inference Energy Consumption | 0.029134 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_7/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/15/2025-01:36:52] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74178    |\n",
      "|      Average Precision       |    0.7423     |\n",
      "|        Average Recall        |    0.74514    |\n",
      "|       Average F1 Score       |    0.74268    |\n",
      "|         Average Loss         |    0.73414    |\n",
      "|       Average Latency        |   1.0096 ms   |\n",
      "|   Average GPU Power Usage    |   9.6732 W    |\n",
      "| Inference Energy Consumption | 0.0027127 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/tensorrt/version_2/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP16_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_FP16_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_FP16_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 01:43:15.535419 140335826768960 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp32'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mprecision=fp32, skipping int8 calibration/fine-tune...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_13/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_14/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72852    |\n",
      "|      Average Precision       |   0.71886    |\n",
      "|        Average Recall        |   0.72227    |\n",
      "|       Average F1 Score       |   0.71961    |\n",
      "|         Average Loss         |   0.80975    |\n",
      "|       Average Latency        |  8.3068 ms   |\n",
      "|   Average GPU Power Usage    |   17.661 W   |\n",
      "| Inference Energy Consumption | 0.040752 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/15/2025-01:43:32] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74162    |\n",
      "|      Average Precision       |    0.74235    |\n",
      "|        Average Recall        |    0.74514    |\n",
      "|       Average F1 Score       |    0.7427     |\n",
      "|         Average Loss         |    0.73414    |\n",
      "|       Average Latency        |   2.706 ms    |\n",
      "|   Average GPU Power Usage    |   11.678 W    |\n",
      "| Inference Energy Consumption | 0.0087779 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/tensorrt/version_4/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP32_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_FP32_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_FP32_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `fp16` acheives a slighty higher test accuracy but a slightly lower latency (~30%) from that of int8 quantization; it is still ~2.5x faster than the unquantized model. Now lets apply quantization to a more complicated model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
