{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADLS Proj: TensorRT with MASE for Multiple Precision Inference\n",
    "\n",
    "This notebook demonstrates the integration of TensorRT passes into MASE as part of the MASERT framework.\n",
    "\n",
    "Currently, our experiments are conducted on RTX 4060 and RTX 3070 GPUs, as our request for A100 access is still pending.\n",
    "\n",
    "### Objective\n",
    "Our goal is to plot trade-off curves that analyze the relationship between different variables, including:\n",
    "- **GPU Type** (e.g., RTX 4060, RTX 3070, and A100 when available)\n",
    "- **Dataset** (e.g., CIFAR-10)\n",
    "- **Model Type** (e.g., ResNet18, ResNet50, VGG, AlexNet ...)\n",
    "- **Precision vs. Runtime Trade-off** (FP32, FP16, INT8)\n",
    "\n",
    "At this stage, we have successfully implemented inference using multiple models, such as **ResNet18 and ResNet50**, on the **CIFAR-10 dataset**. Further experiments will explore the precision-runtime trade-off across different GPU architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model for Quantization Experiments\n",
    "\n",
    "In this section, we train an original model of a target model type. The trained model will later serve as a baseline for different precision quantization experiments, including FP32, FP16, and INT8. This process helps in evaluating the trade-offs between model accuracy and runtime efficiency across different GPU architectures.\n",
    "\n",
    "#### Running the Training Script\n",
    "\n",
    "To train the model, execute the following command:\n",
    "\n",
    "```bash\n",
    "!python3 ./ch train --config /workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quantization_by_type.toml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0311 00:15:51.512130 140276942296128 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File | Manual Override |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                 |           cls            |\n",
      "| load_name               |           None           |              |                 |           None           |\n",
      "| load_type               |            mz            |              |                 |            mz            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                 |            64            |\n",
      "| to_debug                |          False           |              |                 |          False           |\n",
      "| log_level               |           info           |              |                 |           info           |\n",
      "| report_to               |       tensorboard        |              |                 |       tensorboard        |\n",
      "| seed                    |            0             |              |                 |            0             |\n",
      "| quant_config            |           None           |              |                 |           None           |\n",
      "| training_optimizer      |           adam           |              |                 |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                 |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                 |          0.001           |\n",
      "| weight_decay            |            0             |              |                 |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                 |            10            |\n",
      "| max_steps               |            -1            |              |                 |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                 |            1             |\n",
      "| log_every_n_steps       |            50            |              |                 |            50            |\n",
      "| num_workers             |            20            |              |                 |            20            |\n",
      "| num_devices             |            1             |              |                 |            1             |\n",
      "| num_nodes               |            1             |              |                 |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                 |           gpu            |\n",
      "| strategy                |           auto           |              |                 |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                 |          False           |\n",
      "| github_ci               |          False           |              |                 |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                 |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                 |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                 |           100            |\n",
      "| is_pretrained           |          False           |              |                 |          False           |\n",
      "| max_token_len           |           512            |              |                 |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                 | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                 |         e_output         |\n",
      "| project                 |           None           |              |                 |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                 |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                 |         cifar10          |\n",
      "| t_max                   |            20            |              |                 |            20            |\n",
      "| eta_min                 |          1e-06           |              |                 |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-11\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTraining model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m##### WEIGHT DECAY ##### 0\u001b[0m\n",
      "I0311 00:15:51.711618 140276942296128 rank_zero.py:63] Using 16bit Automatic Mixed Precision (AMP)\n",
      "I0311 00:15:51.718478 140276942296128 rank_zero.py:63] GPU available: True (cuda), used: True\n",
      "I0311 00:15:51.718928 140276942296128 rank_zero.py:63] TPU available: False, using: 0 TPU cores\n",
      "I0311 00:15:51.718978 140276942296128 rank_zero.py:63] HPU available: False, using: 0 HPUs\n",
      "I0311 00:15:54.418565 140276942296128 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0311 00:15:54.708575 140276942296128 model_summary.py:104] \n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | ResNet             | 11.2 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_train | MulticlassAccuracy | 0      | train\n",
      "3 | loss_val  | MeanMetric         | 0      | train\n",
      "4 | loss_test | MeanMetric         | 0      | train\n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0:  53%|â–Œ| 411/782 [00:11<00:10, 35.12it/s, v_num=0, train_acc_step=0.234]I0311 00:16:07.596064 140276942296128 rank_zero.py:63] \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 ./ch train --config /workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INT8 Quantization with TensorRT\n",
    "\n",
    "This section explains the process of **INT8 quantization** using TensorRT within the MASE framework. The key steps include **fake quantization, calibration, fine-tuning, and generating a TensorRT engine**.\n",
    "\n",
    "### Code Execution Flow\n",
    "\n",
    "1. **Apply TensorRT Passes**\n",
    "   - **Fake Quantization**: Inserts quantization simulation operations.\n",
    "   - **Summarization**: Displays which layers were quantized.\n",
    "   - **Calibration**: Uses calibration algorithms (e.g., histogram-based) to determine optimal quantization parameters.\n",
    "   - **Fine-Tuning**: Adjusts parameters to recover accuracy loss after quantization.\n",
    "\n",
    "2. **Generate the TensorRT Engine**\n",
    "   - Calls `tensorrt_engine_interface_pass` to convert the optimized graph into a **TensorRT engine**.\n",
    "\n",
    "3. **Benchmarking & Performance Analysis**\n",
    "   - Runs inference tests with warm-up and batch evaluation to measure efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0316 23:33:16.033470 139949971272768 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-16\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning minimal runtime analysis on original graph (just 1 batch) ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBefore analyzing original graph: pass_args = {'by': 'type', 'num_calibration_batches': 10, 'post_calibration_analysis': True, 'default': {'config': {'quantize': True, 'calibrators': ['percentile', 'mse', 'entropy'], 'percentiles': [99.0, 99.9, 99.99], 'precision': 'int8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': True}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}, 'task': 'cls', 'dataset': 'cifar10', 'batch_size': 64, 'model': 'resnet18', 'data_module': <chop.dataset.MaseDataModule object at 0x7f46783a6790>, 'accelerator': 'cuda', 'num_GPU_warmup_batches': 0, 'num_batches': 1, 'test': True}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.68146    |\n",
      "|      Average Precision       |   0.72305    |\n",
      "|        Average Recall        |   0.70312    |\n",
      "|       Average F1 Score       |    0.7063    |\n",
      "|         Average Loss         |   0.88661    |\n",
      "|       Average Latency        |  9.1563 ms   |\n",
      "|   Average GPU Power Usage    |   12.336 W   |\n",
      "| Inference Energy Consumption | 0.031376 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_92/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "op is placeholder\n",
      "placeholder not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is max_pool2d\n",
      "max_pool2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is conv2d\n",
      "node.op == call_module\n",
      "op is batch_norm2d\n",
      "batch_norm2d not in QUANTIZEABLE_OP\n",
      "op is add\n",
      "add not in QUANTIZEABLE_OP\n",
      "op is relu\n",
      "relu not in QUANTIZEABLE_OP\n",
      "op is adaptive_avg_pool2d\n",
      "adaptive_avg_pool2d not in QUANTIZEABLE_OP\n",
      "op is flatten\n",
      "flatten not in QUANTIZEABLE_OP\n",
      "op is linear\n",
      "node.op == call_module\n",
      "op is output\n",
      "output not in QUANTIZEABLE_OP\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type     | OP                  |   Total |   Changed |   Unchanged |\n",
      "|-------------------+---------------------+---------+-----------+-------------|\n",
      "| AdaptiveAvgPool2d | adaptive_avg_pool2d |       1 |         0 |           1 |\n",
      "| BatchNorm2d       | batch_norm2d        |      20 |         0 |          20 |\n",
      "| MaxPool2d         | max_pool2d          |       1 |         0 |           1 |\n",
      "| QuantConv2d       | conv2d              |      20 |         0 |          20 |\n",
      "| QuantLinear       | linear              |       1 |         0 |           1 |\n",
      "| ReLU              | relu                |      17 |         0 |          17 |\n",
      "| add               | add                 |       8 |         0 |           8 |\n",
      "| flatten           | flatten             |       1 |         0 |           1 |\n",
      "| output            | output              |       1 |         0 |           1 |\n",
      "| x                 | placeholder         |       1 |         0 |           1 |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.374635 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.374905 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375022 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375117 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375214 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375304 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375401 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375502 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375596 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375684 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375777 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375866 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.375959 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376046 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376138 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376226 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376351 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376449 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376544 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376631 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376723 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.376934 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377039 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377126 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377218 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377311 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377403 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377496 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377590 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377676 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377769 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377855 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.377939 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378027 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378117 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378202 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378294 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378367 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378456 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378540 139949971272768 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378637 139949971272768 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "W0316 23:33:28.378722 139949971272768 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0316 23:33:28.378963 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0316 23:33:28.379018 139949971272768 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.6224 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.379268 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1400 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.379453 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.2058 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.379612 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2111 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.379772 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.1079 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.379925 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1980 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380090 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.8223 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380250 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1957 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380419 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.1361 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380581 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1970 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380751 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.4339 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.380904 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1583 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381063 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.2583 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381209 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1586 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381362 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=5.4339 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381511 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3493 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381663 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.5862 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.381811 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382134 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.2681 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382292 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1517 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382451 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.5355 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382599 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1277 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382751 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.6591 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.382896 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1132 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.383047 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=4.5355 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.383193 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2536 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.383353 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.3890 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.383574 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0943 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.383742 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.2634 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384056 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0944 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384229 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.2509 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384377 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0710 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384526 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.5516 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384670 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0598 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384847 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=5.2509 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.384998 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.1907 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.385150 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=2.7655 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.385288 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0552 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.385429 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.8474 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.385566 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.385680 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.7439 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:28.386364 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72647    |\n",
      "|      Average Precision       |   0.71544    |\n",
      "|        Average Recall        |   0.71927    |\n",
      "|       Average F1 Score       |   0.71627    |\n",
      "|         Average Loss         |   0.81653    |\n",
      "|       Average Latency        |   28.48 ms   |\n",
      "|   Average GPU Power Usage    |   9.9762 W   |\n",
      "| Inference Energy Consumption | 0.078923 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_93/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0316 23:33:34.669170 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.6391 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.670367 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1815 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.670709 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.4239 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.670995 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2904 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.671260 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.2295 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.671504 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2525 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.671758 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.1635 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.672040 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2498 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.672278 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.1502 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.672672 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2537 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.672982 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.9474 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.673335 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2041 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.673606 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.3220 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.673857 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2041 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.674115 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=7.9474 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.674345 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4401 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.674587 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.2313 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.674825 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2007 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.675070 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=3.3806 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.675660 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1949 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.675922 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.8090 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.676162 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1651 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.676598 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.0989 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.676830 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1593 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.677070 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=6.8090 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.677295 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3283 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.677526 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.6025 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.677749 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1263 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.677980 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.5455 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.678203 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1284 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.678431 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.6085 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.678693 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1042 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.678922 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.4767 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.679169 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0840 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.679399 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=8.6085 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.679628 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2463 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.679853 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.5514 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.680091 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0714 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.680317 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.3538 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.680538 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0719 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.680737 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.7439 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:34.680893 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.72817    |\n",
      "|      Average Precision       |   0.71891    |\n",
      "|        Average Recall        |   0.72206    |\n",
      "|       Average F1 Score       |   0.71969    |\n",
      "|         Average Loss         |   0.80688    |\n",
      "|       Average Latency        |  26.695 ms   |\n",
      "|   Average GPU Power Usage    |   10.231 W   |\n",
      "| Inference Energy Consumption | 0.075864 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_94/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0316 23:33:40.369793 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=3.0904 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.370489 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.2071 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.370844 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.8670 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.371139 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3663 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.371416 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.3450 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.371681 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2896 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.371962 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.6981 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.372231 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2951 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.372495 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.1751 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.372755 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2948 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.373031 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.7036 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.373361 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2492 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.373635 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.3397 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.373938 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2424 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.374217 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=10.7036 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.374497 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.5430 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.374927 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.7919 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.375241 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2315 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.375535 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.3874 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.376043 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2258 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.376321 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.0064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.376582 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1993 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.377084 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.3984 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.377329 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2141 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.377593 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=9.0064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.377834 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3806 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.378083 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.9462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.378326 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1591 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.378573 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.2523 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.378813 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1755 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.379063 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.8157 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.379321 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1403 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.379645 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.2320 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.379895 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1098 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.380143 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=12.8157 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.380383 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.2988 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.380625 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.0683 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.380862 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0875 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.381102 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.7768 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.381345 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0867 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.381557 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.7439 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:40.381721 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.72906   |\n",
      "|      Average Precision       |  0.71952   |\n",
      "|        Average Recall        |  0.72268   |\n",
      "|       Average F1 Score       |  0.72018   |\n",
      "|         Average Loss         |  0.80881   |\n",
      "|       Average Latency        | 27.193 ms  |\n",
      "|   Average GPU Power Usage    |  10.353 W  |\n",
      "| Inference Energy Consumption | 0.0782 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_95/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0316 23:33:46.393481 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=3.3198 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:46.580791 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.2056 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:46.936910 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.9787 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:47.134923 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3741 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:47.413661 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.9539 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:47.602616 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3233 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:48.001583 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.4356 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:48.184937 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2902 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:48.371558 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.7954 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:48.561864 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2955 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:48.963184 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.3566 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:49.148711 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2500 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:49.459297 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.8587 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:49.645491 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2475 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:50.035724 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=12.3566 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:50.218654 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.5176 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:50.492040 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=7.7086 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:50.674982 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2328 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:50.896987 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=4.8137 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:51.079945 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2287 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:51.348553 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.2809 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:51.537195 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2018 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:51.816132 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.0214 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:51.993501 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2356 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:52.250335 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=10.2809 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:52.425881 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4561 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:52.690710 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.2944 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:52.871062 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1725 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:53.051720 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.0620 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:53.233784 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2001 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:53.476575 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=14.3893 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:53.663780 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1536 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:53.841041 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.2001 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.017572 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1161 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.275478 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=14.3893 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.458733 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3027 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.642318 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.5748 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.818391 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0888 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:54.992552 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.7390 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:55.179094 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.0879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:55.181164 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.7439 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:33:55.181576 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.72856    |\n",
      "|      Average Precision       |   0.71857    |\n",
      "|        Average Recall        |   0.72175    |\n",
      "|       Average F1 Score       |   0.71928    |\n",
      "|         Average Loss         |   0.80959    |\n",
      "|       Average Latency        |  29.637 ms   |\n",
      "|   Average GPU Power Usage    |   9.9135 W   |\n",
      "| Inference Energy Consumption | 0.081613 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_96/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "W0316 23:34:03.560781 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.1229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:04.966312 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mconv1._weight_quantizer                 : TensorQuantizer(8bit fake per-tensor amax=0.1926 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:07.634674 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.3725 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:09.054171 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3665 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:10.878047 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.4997 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:12.280713 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.3090 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:15.369678 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=13.1397 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:16.802258 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2953 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:18.203141 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.7466 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:19.627512 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer1.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2965 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:22.753909 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=14.0239 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:24.159440 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2664 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:26.375501 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.9187 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:27.817661 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2533 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:30.957582 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=14.0239 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:32.330909 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4531 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:34.137400 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=9.0212 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:35.560478 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2549 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:37.129853 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=5.5567 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:38.575501 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer2.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2557 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:40.396651 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=11.8660 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:41.819386 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2261 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:43.817842 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.9484 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:45.208031 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2659 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:47.035292 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=11.8660 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:48.417859 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.4147 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:50.161555 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=10.7637 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:51.559497 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1992 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:52.952321 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.6150 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:54.282879 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer3.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.2278 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:55.785040 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=14.4419 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:57.181826 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1693 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:34:58.630017 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.6902 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:00.010381 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1449 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:01.497818 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._input_quantizer  : TensorQuantizer(8bit fake per-tensor amax=14.4419 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:02.940324 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.0.downsample.0._weight_quantizer : TensorQuantizer(8bit fake per-tensor amax=0.3188 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:04.362363 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=12.0067 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:05.797974 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv1._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1031 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:07.183573 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=8.9238 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:08.614521 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlayer4.1.conv2._weight_quantizer        : TensorQuantizer(8bit fake per-tensor amax=0.1051 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:08.615902 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._input_quantizer                     : TensorQuantizer(8bit fake per-tensor amax=19.7439 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "W0316 23:35:08.616193 139949971272768 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfc._weight_quantizer                    : TensorQuantizer(8bit fake axis=0 amax=[0.0832, 0.1520](10) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.72818    |\n",
      "|      Average Precision       |   0.71889    |\n",
      "|        Average Recall        |   0.72227    |\n",
      "|       Average F1 Score       |   0.71974    |\n",
      "|         Average Loss         |   0.81131    |\n",
      "|       Average Latency        |  23.414 ms   |\n",
      "|   Average GPU Power Usage    |   13.143 W   |\n",
      "| Inference Energy Consumption | 0.085483 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_97/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning for 2 epochs...\u001b[0m\n",
      "I0316 23:35:13.945412 139949971272768 rank_zero.py:63] GPU available: True (cuda), used: True\n",
      "I0316 23:35:13.945756 139949971272768 rank_zero.py:63] TPU available: False, using: 0 TPU cores\n",
      "I0316 23:35:13.945809 139949971272768 rank_zero.py:63] HPU available: False, using: 0 HPUs\n",
      "I0316 23:35:16.615782 139949971272768 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0316 23:35:16.628233 139949971272768 model_summary.py:104] \n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | GraphModule        | 11.2 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_train | MulticlassAccuracy | 0      | train\n",
      "3 | loss_val  | MeanMetric         | 0      | train\n",
      "4 | loss_test | MeanMetric         | 0      | train\n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "114       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0: 100%|â–ˆ| 782/782 [00:28<00:00, 27.84it/s, v_num=21, train_acc_step=0.500\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:03, 44.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|â–                 | 2/157 [00:00<00:03, 41.34it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|â–Ž                 | 3/157 [00:00<00:04, 35.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|â–                 | 4/157 [00:00<00:03, 39.07it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|â–Œ                 | 5/157 [00:00<00:03, 40.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|â–‹                 | 6/157 [00:00<00:03, 42.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|â–Š                 | 7/157 [00:00<00:03, 42.88it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|â–‰                 | 8/157 [00:00<00:03, 41.70it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|â–ˆ                 | 9/157 [00:00<00:03, 41.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|â–ˆ                | 10/157 [00:00<00:03, 41.64it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|â–ˆâ–               | 11/157 [00:00<00:03, 41.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|â–ˆâ–Ž               | 12/157 [00:00<00:03, 41.84it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|â–ˆâ–               | 13/157 [00:00<00:03, 42.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|â–ˆâ–Œ               | 14/157 [00:00<00:03, 41.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|â–ˆâ–Œ               | 15/157 [00:00<00:03, 42.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|â–ˆâ–‹               | 16/157 [00:00<00:03, 42.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|â–ˆâ–Š               | 17/157 [00:00<00:03, 42.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|â–ˆâ–‰               | 18/157 [00:00<00:03, 43.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|â–ˆâ–ˆ               | 19/157 [00:00<00:03, 43.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|â–ˆâ–ˆâ–              | 20/157 [00:00<00:03, 43.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|â–ˆâ–ˆâ–Ž              | 21/157 [00:00<00:03, 43.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|â–ˆâ–ˆâ–              | 22/157 [00:00<00:03, 44.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|â–ˆâ–ˆâ–              | 23/157 [00:00<00:03, 44.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|â–ˆâ–ˆâ–Œ              | 24/157 [00:00<00:02, 44.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|â–ˆâ–ˆâ–‹              | 25/157 [00:00<00:02, 44.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|â–ˆâ–ˆâ–Š              | 26/157 [00:00<00:02, 44.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|â–ˆâ–ˆâ–‰              | 27/157 [00:00<00:02, 44.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|â–ˆâ–ˆâ–ˆ              | 28/157 [00:00<00:02, 44.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|â–ˆâ–ˆâ–ˆâ–             | 29/157 [00:00<00:02, 44.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|â–ˆâ–ˆâ–ˆâ–             | 30/157 [00:00<00:02, 44.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|â–ˆâ–ˆâ–ˆâ–Ž             | 31/157 [00:00<00:02, 45.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|â–ˆâ–ˆâ–ˆâ–             | 32/157 [00:00<00:02, 45.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|â–ˆâ–ˆâ–ˆâ–Œ             | 33/157 [00:00<00:02, 45.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–‹             | 34/157 [00:00<00:02, 45.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–Š             | 35/157 [00:00<00:02, 45.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|â–ˆâ–ˆâ–ˆâ–‰             | 36/157 [00:00<00:02, 45.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|â–ˆâ–ˆâ–ˆâ–ˆ             | 37/157 [00:00<00:02, 45.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|â–ˆâ–ˆâ–ˆâ–ˆ             | 38/157 [00:00<00:02, 45.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–            | 39/157 [00:00<00:02, 45.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 40/157 [00:00<00:02, 45.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–            | 41/157 [00:00<00:02, 45.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 42/157 [00:00<00:02, 45.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 43/157 [00:00<00:02, 45.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 44/157 [00:00<00:02, 45.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 45/157 [00:00<00:02, 45.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 46/157 [00:01<00:02, 45.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 47/157 [00:01<00:02, 45.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 48/157 [00:01<00:02, 45.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 49/157 [00:01<00:02, 44.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 50/157 [00:01<00:02, 44.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 51/157 [00:01<00:02, 44.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 52/157 [00:01<00:02, 44.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 53/157 [00:01<00:02, 44.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 54/157 [00:01<00:02, 44.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 55/157 [00:01<00:02, 44.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 56/157 [00:01<00:02, 44.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 57/157 [00:01<00:02, 44.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 58/157 [00:01<00:02, 44.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 59/157 [00:01<00:02, 44.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 60/157 [00:01<00:02, 44.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 61/157 [00:01<00:02, 44.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 62/157 [00:01<00:02, 44.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 63/157 [00:01<00:02, 44.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 64/157 [00:01<00:02, 44.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 65/157 [00:01<00:02, 44.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 66/157 [00:01<00:02, 44.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 67/157 [00:01<00:02, 44.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 68/157 [00:01<00:01, 44.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 69/157 [00:01<00:01, 44.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 70/157 [00:01<00:01, 44.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 71/157 [00:01<00:01, 44.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 72/157 [00:01<00:01, 44.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 73/157 [00:01<00:01, 44.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 74/157 [00:01<00:01, 44.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 75/157 [00:01<00:01, 44.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 76/157 [00:01<00:01, 44.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 77/157 [00:01<00:01, 44.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 78/157 [00:01<00:01, 44.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 79/157 [00:01<00:01, 44.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 80/157 [00:01<00:01, 44.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 81/157 [00:01<00:01, 44.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 82/157 [00:01<00:01, 44.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 83/157 [00:01<00:01, 43.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 84/157 [00:01<00:01, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 85/157 [00:01<00:01, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 86/157 [00:01<00:01, 43.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 87/157 [00:01<00:01, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 88/157 [00:02<00:01, 43.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 89/157 [00:02<00:01, 43.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 90/157 [00:02<00:01, 43.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 91/157 [00:02<00:01, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 92/157 [00:02<00:01, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 93/157 [00:02<00:01, 43.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 94/157 [00:02<00:01, 43.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 95/157 [00:02<00:01, 43.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 96/157 [00:02<00:01, 43.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 97/157 [00:02<00:01, 43.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 98/157 [00:02<00:01, 43.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 99/157 [00:02<00:01, 43.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 100/157 [00:02<00:01, 43.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 101/157 [00:02<00:01, 43.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 102/157 [00:02<00:01, 43.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/157 [00:02<00:01, 43.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 104/157 [00:02<00:01, 43.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 105/157 [00:02<00:01, 43.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 106/157 [00:02<00:01, 43.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 107/157 [00:02<00:01, 43.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 108/157 [00:02<00:01, 43.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 109/157 [00:02<00:01, 43.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/157 [00:02<00:01, 43.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 111/157 [00:02<00:01, 43.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 112/157 [00:02<00:01, 43.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/157 [00:02<00:01, 43.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 114/157 [00:02<00:00, 43.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/157 [00:02<00:00, 43.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/157 [00:02<00:00, 43.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/157 [00:02<00:00, 43.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118/157 [00:02<00:00, 43.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 119/157 [00:02<00:00, 43.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 120/157 [00:02<00:00, 43.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 121/157 [00:02<00:00, 43.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/157 [00:02<00:00, 43.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 123/157 [00:02<00:00, 43.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 124/157 [00:02<00:00, 43.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 125/157 [00:02<00:00, 43.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 126/157 [00:02<00:00, 43.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 127/157 [00:02<00:00, 43.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 128/157 [00:02<00:00, 43.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 129/157 [00:02<00:00, 43.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 130/157 [00:02<00:00, 43.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 131/157 [00:02<00:00, 43.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 132/157 [00:03<00:00, 43.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 133/157 [00:03<00:00, 43.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 134/157 [00:03<00:00, 44.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 135/157 [00:03<00:00, 44.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 136/157 [00:03<00:00, 44.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 137/157 [00:03<00:00, 43.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 138/157 [00:03<00:00, 44.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 139/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 140/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 141/157 [00:03<00:00, 43.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 142/157 [00:03<00:00, 43.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 143/157 [00:03<00:00, 43.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 144/157 [00:03<00:00, 43.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 145/157 [00:03<00:00, 43.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 146/157 [00:03<00:00, 43.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 147/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 148/157 [00:03<00:00, 43.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 150/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/157 [00:03<00:00, 43.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 152/157 [00:03<00:00, 43.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/157 [00:03<00:00, 43.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/157 [00:03<00:00, 43.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 155/157 [00:03<00:00, 43.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 156/157 [00:03<00:00, 43.98it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:03<00:00, 43.96it/s]\u001b[A\n",
      "Epoch 1: 100%|â–ˆ| 782/782 [00:30<00:00, 25.29it/s, v_num=21, train_acc_step=0.625\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:04, 35.86it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|â–                 | 2/157 [00:00<00:03, 39.49it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|â–Ž                 | 3/157 [00:00<00:03, 43.30it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|â–                 | 4/157 [00:00<00:03, 44.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|â–Œ                 | 5/157 [00:00<00:03, 44.60it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|â–‹                 | 6/157 [00:00<00:03, 44.48it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|â–Š                 | 7/157 [00:00<00:03, 44.42it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|â–‰                 | 8/157 [00:00<00:03, 44.54it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|â–ˆ                 | 9/157 [00:00<00:03, 44.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|â–ˆ                | 10/157 [00:00<00:03, 45.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|â–ˆâ–               | 11/157 [00:00<00:03, 44.61it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|â–ˆâ–Ž               | 12/157 [00:00<00:03, 44.69it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|â–ˆâ–               | 13/157 [00:00<00:03, 44.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|â–ˆâ–Œ               | 14/157 [00:00<00:03, 44.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|â–ˆâ–Œ               | 15/157 [00:00<00:03, 44.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|â–ˆâ–‹               | 16/157 [00:00<00:03, 44.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|â–ˆâ–Š               | 17/157 [00:00<00:03, 44.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|â–ˆâ–‰               | 18/157 [00:00<00:03, 43.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|â–ˆâ–ˆ               | 19/157 [00:00<00:03, 44.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|â–ˆâ–ˆâ–              | 20/157 [00:00<00:03, 43.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|â–ˆâ–ˆâ–Ž              | 21/157 [00:00<00:03, 43.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|â–ˆâ–ˆâ–              | 22/157 [00:00<00:03, 41.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|â–ˆâ–ˆâ–              | 23/157 [00:00<00:03, 41.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|â–ˆâ–ˆâ–Œ              | 24/157 [00:00<00:03, 41.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|â–ˆâ–ˆâ–‹              | 25/157 [00:00<00:03, 41.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|â–ˆâ–ˆâ–Š              | 26/157 [00:00<00:03, 41.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|â–ˆâ–ˆâ–‰              | 27/157 [00:00<00:03, 41.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|â–ˆâ–ˆâ–ˆ              | 28/157 [00:00<00:03, 41.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|â–ˆâ–ˆâ–ˆâ–             | 29/157 [00:00<00:03, 41.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|â–ˆâ–ˆâ–ˆâ–             | 30/157 [00:00<00:03, 41.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|â–ˆâ–ˆâ–ˆâ–Ž             | 31/157 [00:00<00:03, 41.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|â–ˆâ–ˆâ–ˆâ–             | 32/157 [00:00<00:03, 41.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|â–ˆâ–ˆâ–ˆâ–Œ             | 33/157 [00:00<00:02, 41.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–‹             | 34/157 [00:00<00:02, 41.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–Š             | 35/157 [00:00<00:02, 40.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|â–ˆâ–ˆâ–ˆâ–‰             | 36/157 [00:00<00:02, 40.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|â–ˆâ–ˆâ–ˆâ–ˆ             | 37/157 [00:00<00:02, 40.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|â–ˆâ–ˆâ–ˆâ–ˆ             | 38/157 [00:00<00:02, 40.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–            | 39/157 [00:00<00:02, 40.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 40/157 [00:00<00:02, 40.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–            | 41/157 [00:01<00:02, 40.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 42/157 [00:01<00:02, 40.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 43/157 [00:01<00:02, 40.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 44/157 [00:01<00:02, 40.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 45/157 [00:01<00:02, 40.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 46/157 [00:01<00:02, 40.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 47/157 [00:01<00:02, 40.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 48/157 [00:01<00:02, 40.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 49/157 [00:01<00:02, 39.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 50/157 [00:01<00:02, 39.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 51/157 [00:01<00:02, 39.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 52/157 [00:01<00:02, 39.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 53/157 [00:01<00:02, 39.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 54/157 [00:01<00:02, 39.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 55/157 [00:01<00:02, 39.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 56/157 [00:01<00:02, 39.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 57/157 [00:01<00:02, 39.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 58/157 [00:01<00:02, 39.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 59/157 [00:01<00:02, 39.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 60/157 [00:01<00:02, 39.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 61/157 [00:01<00:02, 39.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 62/157 [00:01<00:02, 39.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 63/157 [00:01<00:02, 39.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 64/157 [00:01<00:02, 39.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 65/157 [00:01<00:02, 39.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 66/157 [00:01<00:02, 39.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 67/157 [00:01<00:02, 39.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 68/157 [00:01<00:02, 39.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 69/157 [00:01<00:02, 39.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 70/157 [00:01<00:02, 39.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 71/157 [00:01<00:02, 39.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 72/157 [00:01<00:02, 39.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 73/157 [00:01<00:02, 39.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 74/157 [00:01<00:02, 39.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 75/157 [00:01<00:02, 39.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 76/157 [00:01<00:02, 39.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 77/157 [00:01<00:02, 39.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 78/157 [00:01<00:02, 39.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 79/157 [00:02<00:01, 39.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 80/157 [00:02<00:01, 39.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 81/157 [00:02<00:01, 39.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 82/157 [00:02<00:01, 39.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 83/157 [00:02<00:01, 39.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 84/157 [00:02<00:01, 39.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 85/157 [00:02<00:01, 39.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 86/157 [00:02<00:01, 39.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 87/157 [00:02<00:01, 39.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 88/157 [00:02<00:01, 39.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 89/157 [00:02<00:01, 39.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 90/157 [00:02<00:01, 39.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 91/157 [00:02<00:01, 39.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 92/157 [00:02<00:01, 39.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 93/157 [00:02<00:01, 39.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 94/157 [00:02<00:01, 38.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 95/157 [00:02<00:01, 38.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 96/157 [00:02<00:01, 38.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 97/157 [00:02<00:01, 38.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 98/157 [00:02<00:01, 38.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 99/157 [00:02<00:01, 38.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 100/157 [00:02<00:01, 38.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 101/157 [00:02<00:01, 38.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 102/157 [00:02<00:01, 38.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/157 [00:02<00:01, 38.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 104/157 [00:02<00:01, 38.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 105/157 [00:02<00:01, 38.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 106/157 [00:02<00:01, 38.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 107/157 [00:02<00:01, 38.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 108/157 [00:02<00:01, 38.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 109/157 [00:02<00:01, 38.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/157 [00:02<00:01, 38.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 111/157 [00:02<00:01, 38.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 112/157 [00:02<00:01, 38.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/157 [00:02<00:01, 38.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 114/157 [00:02<00:01, 38.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/157 [00:02<00:01, 38.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/157 [00:03<00:01, 38.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/157 [00:03<00:01, 38.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118/157 [00:03<00:01, 38.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 119/157 [00:03<00:00, 38.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 120/157 [00:03<00:00, 38.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 121/157 [00:03<00:00, 38.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/157 [00:03<00:00, 38.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 123/157 [00:03<00:00, 38.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 124/157 [00:03<00:00, 38.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 125/157 [00:03<00:00, 38.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 126/157 [00:03<00:00, 38.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 127/157 [00:03<00:00, 38.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 128/157 [00:03<00:00, 38.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 129/157 [00:03<00:00, 38.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 130/157 [00:03<00:00, 38.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 131/157 [00:03<00:00, 38.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 132/157 [00:03<00:00, 38.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 133/157 [00:03<00:00, 38.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 134/157 [00:03<00:00, 38.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 135/157 [00:03<00:00, 38.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 136/157 [00:03<00:00, 38.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 137/157 [00:03<00:00, 38.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 138/157 [00:03<00:00, 38.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 139/157 [00:03<00:00, 38.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 140/157 [00:03<00:00, 37.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 141/157 [00:03<00:00, 37.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 142/157 [00:03<00:00, 37.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 143/157 [00:03<00:00, 37.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 144/157 [00:03<00:00, 37.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 145/157 [00:03<00:00, 37.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 146/157 [00:03<00:00, 37.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 147/157 [00:03<00:00, 37.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 148/157 [00:03<00:00, 37.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149/157 [00:03<00:00, 37.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 150/157 [00:03<00:00, 37.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/157 [00:04<00:00, 37.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 152/157 [00:04<00:00, 37.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/157 [00:04<00:00, 37.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/157 [00:04<00:00, 37.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 155/157 [00:04<00:00, 37.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 156/157 [00:04<00:00, 37.76it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:04<00:00, 37.79it/s]\u001b[A\n",
      "Epoch 1: 100%|â–ˆ| 782/782 [00:35<00:00, 21.96it/s, v_num=21, train_acc_step=0.625\u001b[AI0316 23:36:26.460790 139949971272768 rank_zero.py:63] `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Epoch 1: 100%|â–ˆ| 782/782 [00:35<00:00, 21.73it/s, v_num=21, train_acc_step=0.625\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_26/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Failed finding int8 cache!\n",
      "Failed finding int8 cache!\n",
      "Succeed saving int8 cache!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_28/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_29/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mMeasuring final TensorRT engine with warmup=20, test=500 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/16/2025-23:44:02] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73739    |\n",
      "|      Average Precision       |    0.73949    |\n",
      "|        Average Recall        |    0.74069    |\n",
      "|       Average F1 Score       |    0.73859    |\n",
      "|         Average Loss         |    0.7431     |\n",
      "|       Average Latency        |   2.2448 ms   |\n",
      "|   Average GPU Power Usage    |   15.399 W    |\n",
      "| Inference Energy Consumption | 0.0096021 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/tensorrt/version_8/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-16/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_INT8_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_INT8_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_INT8_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP16 Conversion with TensorRT\n",
    "\n",
    "#### Overview\n",
    "This section describes the process of converting a model to **FP16 precision** using TensorRT. Unlike **INT8 quantization**, **FP16 does not require calibration, fake quantization, or fine-tuning**. The conversion process is simpler and primarily focuses on **speeding up inference while maintaining high precision**.\n",
    "\n",
    "### Code Execution Flow\n",
    "\n",
    "1. **Apply TensorRT FP16 Pass**\n",
    "   - **No Fake Quantization**: Since FP16 does not require quantization-aware training, the `quantize` option is set to `false`.\n",
    "   - **No Calibration**: Unlike INT8, FP16 does not need calibration data, so `num_calibration_batches` is set to `0`.\n",
    "   - **No Fine-Tuning**: Additional training is unnecessary in FP16 mode.\n",
    "\n",
    "2. **Generate the TensorRT Engine**\n",
    "   - Calls `tensorrt_engine_interface_pass` to convert the model to a **TensorRT FP16 engine**.\n",
    "\n",
    "3. **Benchmarking & Performance Analysis**\n",
    "   - Runs inference tests with warm-up and batch evaluation to measure efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0316 18:46:58.871801 140478726022208 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-16\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp16'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mprecision=fp16, skipping int8 calibration/fine-tune...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_14/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_15/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/2025-03-16/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning minimal runtime analysis on original graph (just 1 batch) ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBefore analyzing original graph: pass_args = {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp16'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}, 'task': 'cls', 'dataset': 'cifar10', 'batch_size': 64, 'model': 'resnet18', 'data_module': <chop.dataset.MaseDataModule object at 0x7fc1952c9c90>, 'accelerator': 'cuda', 'num_GPU_warmup_batches': 0, 'num_batches': 1, 'test': True}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.68146    |\n",
      "|      Average Precision       |   0.72305    |\n",
      "|        Average Recall        |   0.70312    |\n",
      "|       Average F1 Score       |    0.7063    |\n",
      "|         Average Loss         |   0.88661    |\n",
      "|       Average Latency        |  13.428 ms   |\n",
      "|   Average GPU Power Usage    |   8.974 W    |\n",
      "| Inference Energy Consumption | 0.033473 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/mase_graph/version_79/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mMeasuring final TensorRT engine with warmup=20, test=500 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/16/2025-18:48:06] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74016    |\n",
      "|      Average Precision       |    0.73992    |\n",
      "|        Average Recall        |    0.74276    |\n",
      "|       Average F1 Score       |    0.74024    |\n",
      "|         Average Loss         |    0.73782    |\n",
      "|       Average Latency        |   2.6209 ms   |\n",
      "|   Average GPU Power Usage    |   7.9719 W    |\n",
      "| Inference Energy Consumption | 0.0058037 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-16/tensorrt/version_5/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-16/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP16_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_FP16_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_FP16_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP32 Conversion with TensorRT\n",
    "\n",
    "The process for converting a model to **FP32 precision** using TensorRT is quite similar to the **FP16 conversion**, but with even fewer modifications. Since FP32 is the default precision for deep learning models, the main goal here is to **leverage TensorRT optimizations** without changing the numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 01:43:15.535419 140335826768960 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp32'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mprecision=fp32, skipping int8 calibration/fine-tune...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_13/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_14/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72852    |\n",
      "|      Average Precision       |   0.71886    |\n",
      "|        Average Recall        |   0.72227    |\n",
      "|       Average F1 Score       |   0.71961    |\n",
      "|         Average Loss         |   0.80975    |\n",
      "|       Average Latency        |  8.3068 ms   |\n",
      "|   Average GPU Power Usage    |   17.661 W   |\n",
      "| Inference Energy Consumption | 0.040752 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/15/2025-01:43:32] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74162    |\n",
      "|      Average Precision       |    0.74235    |\n",
      "|        Average Recall        |    0.74514    |\n",
      "|       Average F1 Score       |    0.7427     |\n",
      "|         Average Loss         |    0.73414    |\n",
      "|       Average Latency        |   2.706 ms    |\n",
      "|   Average GPU Power Usage    |   11.678 W    |\n",
      "| Inference Energy Consumption | 0.0087779 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/tensorrt/version_4/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP32_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_FP32_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {RES_FP32_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on RTX 4060 with ResNet18 and CIFAR-10\n",
    "\n",
    "The following results were obtained while running **ResNet18 on CIFAR-10** using **TensorRT** on an **RTX 4060 GPU**. \n",
    "\n",
    "#### **Accuracy Comparison**\n",
    "| Model Version   | Accuracy |\n",
    "|----------------|----------|\n",
    "| **Original (FP32)**  | **0.73**  |\n",
    "| **After Quantization**  | **0.74**  |\n",
    "\n",
    "- The slight accuracy **increase** after quantization is attributed to **QAT**.\n",
    "\n",
    "#### **Latency Reduction**\n",
    "| Precision Mode | Initial Latency | Optimized Latency |\n",
    "|---------------|----------------|------------------|\n",
    "| **FP32**      | 8.3ms            | **2.7ms**        |\n",
    "| **FP16**      | 8.1ms            | **1.0ms**        |\n",
    "| **INT8**      | **42.8ms**       | **4.5ms**        |\n",
    "\n",
    "- **FP32 to FP16** significantly reduces latency, bringing it down to **1.0ms**.\n",
    "- **INT8 inference** achieves **4.5ms latency**, but the initial unoptimized latency was **42.8ms**, è¿™å¾ˆå¥‡æ€ªï¼Œæ€€ç–‘æ˜¯fake quantizeæ“ä½œ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: Model:Resnet18 Restnet50 VGG\n",
    "\n",
    "Variable: Precision: INT8 FP16 FP32 (Original) | batch size\n",
    "\n",
    "Output: Original INT8 FP16 FP32 (Acc, Runtime)(Model, batch size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0317 17:52:22.237135 140261090690112 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |     Config. File     |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls          |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |                      | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |                      | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |                      | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |                      | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |                      |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |                      |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            | [8, 16, 32, 64, 128] |                          |   [8, 16, 32, 64, 128]   |\n",
      "| to_debug                |          False           |                      |                          |          False           |\n",
      "| log_level               |           info           |                      |                          |           info           |\n",
      "| report_to               |       tensorboard        |                      |                          |       tensorboard        |\n",
      "| seed                    |            0             |                      |                          |            0             |\n",
      "| quant_config            |           None           |                      |                          |           None           |\n",
      "| training_optimizer      |           adam           |                      |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                      |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001         |                          |          0.001           |\n",
      "| weight_decay            |            0             |                      |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |          10          |                          |            10            |\n",
      "| max_steps               |            -1            |                      |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                      |                          |            1             |\n",
      "| log_every_n_steps       |            50            |                      |                          |            50            |\n",
      "| num_workers             |            20            |                      |                          |            20            |\n",
      "| num_devices             |            1             |                      |                          |            1             |\n",
      "| num_nodes               |            1             |                      |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu          |                          |           gpu            |\n",
      "| strategy                |           auto           |                      |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                      |                          |          False           |\n",
      "| github_ci               |          False           |                      |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                      |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                      |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                      |                          |           100            |\n",
      "| is_pretrained           |          False           |                      |                          |          False           |\n",
      "| max_token_len           |           512            |                      |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                      |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                      |                          |         e_output         |\n",
      "| project                 |           None           |                      |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |       resnet18       |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |       cifar10        |                          |         cifar10          |\n",
      "| t_max                   |            20            |                      |                          |            20            |\n",
      "| eta_min                 |          1e-06           |                      |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet18 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=8 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.53327    |\n",
      "|      Average Precision       |   0.64654    |\n",
      "|        Average Recall        |   0.64912    |\n",
      "|       Average F1 Score       |   0.64651    |\n",
      "|         Average Loss         |    1.026     |\n",
      "|       Average Latency        |   5.277 ms   |\n",
      "|   Average GPU Power Usage    |   13.273 W   |\n",
      "| Inference Energy Consumption | 0.019457 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_0/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_2/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_3/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:10] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.62798    |\n",
      "|      Average Precision       |    0.72789    |\n",
      "|        Average Recall        |    0.71995    |\n",
      "|       Average F1 Score       |    0.71991    |\n",
      "|         Average Loss         |    0.80968    |\n",
      "|       Average Latency        |   1.5852 ms   |\n",
      "|   Average GPU Power Usage    |   10.324 W    |\n",
      "| Inference Energy Consumption | 0.0045462 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_45/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_4/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_5/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_6/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:31] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.6277     |\n",
      "|      Average Precision       |    0.72683    |\n",
      "|        Average Recall        |    0.71944    |\n",
      "|       Average F1 Score       |    0.71913    |\n",
      "|         Average Loss         |    0.80694    |\n",
      "|       Average Latency        |   1.4446 ms   |\n",
      "|   Average GPU Power Usage    |   12.094 W    |\n",
      "| Inference Energy Consumption | 0.0048531 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_46/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_7/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_8/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:45] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.62744    |\n",
      "|      Average Precision       |   0.72628    |\n",
      "|        Average Recall        |   0.71919    |\n",
      "|       Average F1 Score       |   0.71876    |\n",
      "|         Average Loss         |    0.807     |\n",
      "|       Average Latency        |  7.7848 ms   |\n",
      "|   Average GPU Power Usage    |   11.26 W    |\n",
      "| Inference Energy Consumption | 0.024349 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_47/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=8 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=16 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.63839    |\n",
      "|      Average Precision       |   0.69645    |\n",
      "|        Average Recall        |   0.69868    |\n",
      "|       Average F1 Score       |   0.69676    |\n",
      "|         Average Loss         |   0.88776    |\n",
      "|       Average Latency        |  13.897 ms   |\n",
      "|   Average GPU Power Usage    |   12.529 W   |\n",
      "| Inference Energy Consumption | 0.048363 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_10/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_12/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_13/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:54:39] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.67587    |\n",
      "|      Average Precision       |    0.73327    |\n",
      "|        Average Recall        |    0.73056    |\n",
      "|       Average F1 Score       |    0.7296     |\n",
      "|         Average Loss         |    0.79824    |\n",
      "|       Average Latency        |   1.7622 ms   |\n",
      "|   Average GPU Power Usage    |   10.546 W    |\n",
      "| Inference Energy Consumption | 0.0051625 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_48/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_14/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_15/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:55:02] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.67499    |\n",
      "|      Average Precision       |    0.73221    |\n",
      "|        Average Recall        |    0.72942    |\n",
      "|       Average F1 Score       |    0.72832    |\n",
      "|         Average Loss         |    0.78645    |\n",
      "|       Average Latency        |   2.0498 ms   |\n",
      "|   Average GPU Power Usage    |   10.721 W    |\n",
      "| Inference Energy Consumption | 0.0061044 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_49/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_17/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_18/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:55:17] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.67516    |\n",
      "|      Average Precision       |   0.73215    |\n",
      "|        Average Recall        |   0.72942    |\n",
      "|       Average F1 Score       |   0.72834    |\n",
      "|         Average Loss         |   0.78641    |\n",
      "|       Average Latency        |  7.5107 ms   |\n",
      "|   Average GPU Power Usage    |   11.672 W   |\n",
      "| Inference Energy Consumption | 0.024352 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_50/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=16 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=32 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.70809    |\n",
      "|      Average Precision       |   0.70874    |\n",
      "|        Average Recall        |   0.71192    |\n",
      "|       Average F1 Score       |   0.70968    |\n",
      "|         Average Loss         |    0.8365    |\n",
      "|       Average Latency        |   14.73 ms   |\n",
      "|   Average GPU Power Usage    |   13.022 W   |\n",
      "| Inference Energy Consumption | 0.053281 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_17/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_20/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_22/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_23/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:06] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.71444    |\n",
      "|      Average Precision       |   0.73637    |\n",
      "|        Average Recall        |   0.73422    |\n",
      "|       Average F1 Score       |   0.73393    |\n",
      "|         Average Loss         |    0.7834    |\n",
      "|       Average Latency        |  1.4322 ms   |\n",
      "|   Average GPU Power Usage    |   9.9136 W   |\n",
      "| Inference Energy Consumption | 0.003944 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_51/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_24/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_25/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_26/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:27] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.71709    |\n",
      "|      Average Precision       |    0.73662    |\n",
      "|        Average Recall        |    0.73453    |\n",
      "|       Average F1 Score       |    0.73408    |\n",
      "|         Average Loss         |    0.77975    |\n",
      "|       Average Latency        |   1.7785 ms   |\n",
      "|   Average GPU Power Usage    |   10.892 W    |\n",
      "| Inference Energy Consumption | 0.0053809 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_52/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_27/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_28/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_29/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.71683    |\n",
      "|      Average Precision       |   0.73654    |\n",
      "|        Average Recall        |   0.73453    |\n",
      "|       Average F1 Score       |   0.73405    |\n",
      "|         Average Loss         |   0.77977    |\n",
      "|       Average Latency        |  7.6064 ms   |\n",
      "|   Average GPU Power Usage    |   11.442 W   |\n",
      "| Inference Energy Consumption | 0.024175 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_53/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=32 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72733    |\n",
      "|      Average Precision       |   0.71774    |\n",
      "|        Average Recall        |    0.7211    |\n",
      "|       Average F1 Score       |   0.71844    |\n",
      "|         Average Loss         |   0.81241    |\n",
      "|       Average Latency        |  17.865 ms   |\n",
      "|   Average GPU Power Usage    |   12.98 W    |\n",
      "| Inference Energy Consumption | 0.064413 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_18/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_30/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_32/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_33/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:24] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73223    |\n",
      "|      Average Precision       |    0.73642    |\n",
      "|        Average Recall        |    0.73665    |\n",
      "|       Average F1 Score       |    0.73568    |\n",
      "|         Average Loss         |    0.78729    |\n",
      "|       Average Latency        |   2.3134 ms   |\n",
      "|   Average GPU Power Usage    |    8.682 W    |\n",
      "| Inference Energy Consumption | 0.0055792 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_54/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_34/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_35/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_36/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:44] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73285    |\n",
      "|      Average Precision       |    0.73597    |\n",
      "|        Average Recall        |    0.73624    |\n",
      "|       Average F1 Score       |    0.73514    |\n",
      "|         Average Loss         |    0.77958    |\n",
      "|       Average Latency        |   1.7162 ms   |\n",
      "|   Average GPU Power Usage    |   9.9179 W    |\n",
      "| Inference Energy Consumption | 0.0047282 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_55/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_37/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_38/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_39/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:58] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73263    |\n",
      "|      Average Precision       |   0.73577    |\n",
      "|        Average Recall        |   0.73603    |\n",
      "|       Average F1 Score       |   0.73491    |\n",
      "|         Average Loss         |   0.77954    |\n",
      "|       Average Latency        |  9.7836 ms   |\n",
      "|   Average GPU Power Usage    |   12.211 W   |\n",
      "| Inference Energy Consumption | 0.033186 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_56/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=128 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73052    |\n",
      "|      Average Precision       |   0.72403    |\n",
      "|        Average Recall        |   0.72725    |\n",
      "|       Average F1 Score       |   0.72451    |\n",
      "|         Average Loss         |   0.80109    |\n",
      "|       Average Latency        |  20.081 ms   |\n",
      "|   Average GPU Power Usage    |   13.491 W   |\n",
      "| Inference Energy Consumption | 0.075254 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_40/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_42/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_43/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:58:44] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73315    |\n",
      "|      Average Precision       |    0.73448    |\n",
      "|        Average Recall        |    0.73587    |\n",
      "|       Average F1 Score       |    0.73444    |\n",
      "|         Average Loss         |    0.78575    |\n",
      "|       Average Latency        |   3.4924 ms   |\n",
      "|   Average GPU Power Usage    |   7.4494 W    |\n",
      "| Inference Energy Consumption | 0.0072267 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_57/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_44/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_45/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_46/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:59:07] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73227    |\n",
      "|      Average Precision       |    0.733     |\n",
      "|        Average Recall        |   0.73491    |\n",
      "|       Average F1 Score       |   0.73308    |\n",
      "|         Average Loss         |   0.78348    |\n",
      "|       Average Latency        |  3.7376 ms   |\n",
      "|   Average GPU Power Usage    |   12.297 W   |\n",
      "| Inference Energy Consumption | 0.012767 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_58/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_47/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_48/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_49/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:59:22] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73246    |\n",
      "|      Average Precision       |    0.7332    |\n",
      "|        Average Recall        |   0.73512    |\n",
      "|       Average F1 Score       |   0.73327    |\n",
      "|         Average Loss         |   0.78351    |\n",
      "|       Average Latency        |  11.864 ms   |\n",
      "|   Average GPU Power Usage    |   11.771 W   |\n",
      "| Inference Energy Consumption | 0.038794 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_59/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=128 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MUL_PRECISION_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_Mul_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {MUL_PRECISION_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is for Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0317 18:34:02.077955 140444487648320 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |     Config. File     |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls          |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |                      | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |                      | e_output/resnet50_cls_ci | e_output/resnet50_cls_ci |\n",
      "|                         |                          |                      | far10_2025-03-15/softwar | far10_2025-03-15/softwar |\n",
      "|                         |                          |                      | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |                      |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |                      |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            | [8, 16, 32, 64, 128] |                          |   [8, 16, 32, 64, 128]   |\n",
      "| to_debug                |          False           |                      |                          |          False           |\n",
      "| log_level               |           info           |                      |                          |           info           |\n",
      "| report_to               |       tensorboard        |                      |                          |       tensorboard        |\n",
      "| seed                    |            0             |                      |                          |            0             |\n",
      "| quant_config            |           None           |                      |                          |           None           |\n",
      "| training_optimizer      |           adam           |                      |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                      |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001         |                          |          0.001           |\n",
      "| weight_decay            |            0             |                      |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |          10          |                          |            10            |\n",
      "| max_steps               |            -1            |                      |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                      |                          |            1             |\n",
      "| log_every_n_steps       |            50            |                      |                          |            50            |\n",
      "| num_workers             |            20            |                      |                          |            20            |\n",
      "| num_devices             |            1             |                      |                          |            1             |\n",
      "| num_nodes               |            1             |                      |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu          |                          |           gpu            |\n",
      "| strategy                |           auto           |                      |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                      |                          |          False           |\n",
      "| github_ci               |          False           |                      |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                      |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                      |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                      |                          |           100            |\n",
      "| is_pretrained           |          False           |                      |                          |          False           |\n",
      "| max_token_len           |           512            |                      |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                      |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                      |                          |         e_output         |\n",
      "| project                 |           None           |                      |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |       resnet50       |                          |         resnet50         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |       cifar10        |                          |         cifar10          |\n",
      "| t_max                   |            20            |                      |                          |            20            |\n",
      "| eta_min                 |          1e-06           |                      |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet50'...\u001b[0m\n",
      "self.args.model is resnet50\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet50'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet50 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=8 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.25593    |\n",
      "|      Average Precision       |   0.39695    |\n",
      "|        Average Recall        |   0.31212    |\n",
      "|       Average F1 Score       |   0.28777    |\n",
      "|         Average Loss         |    2.0529    |\n",
      "|       Average Latency        |  23.572 ms   |\n",
      "|   Average GPU Power Usage    |   13.697 W   |\n",
      "| Inference Energy Consumption | 0.089684 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_5/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_50/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_52/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_53/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:35:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.10948    |\n",
      "|      Average Precision       |   0.044274    |\n",
      "|        Average Recall        |    0.10833    |\n",
      "|       Average F1 Score       |   0.035417    |\n",
      "|         Average Loss         |    9.4165     |\n",
      "|       Average Latency        |   2.3392 ms   |\n",
      "|   Average GPU Power Usage    |   10.775 W    |\n",
      "| Inference Energy Consumption | 0.0070011 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_54/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_55/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_56/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:36:17] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.26117   |\n",
      "|      Average Precision       |   0.50246   |\n",
      "|        Average Recall        |   0.29874   |\n",
      "|       Average F1 Score       |   0.25196   |\n",
      "|         Average Loss         |     nan     |\n",
      "|       Average Latency        |  2.8038 ms  |\n",
      "|   Average GPU Power Usage    |  12.865 W   |\n",
      "| Inference Energy Consumption | 0.01002 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_57/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_58/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_59/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:36:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.26162    |\n",
      "|      Average Precision       |   0.49738    |\n",
      "|        Average Recall        |     0.3      |\n",
      "|       Average F1 Score       |   0.25325    |\n",
      "|         Average Loss         |    666.31    |\n",
      "|       Average Latency        |   8.782 ms   |\n",
      "|   Average GPU Power Usage    |   13.644 W   |\n",
      "| Inference Energy Consumption | 0.033284 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_17/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=8 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=16 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.4122    |\n",
      "|      Average Precision       |   0.45405   |\n",
      "|        Average Recall        |   0.45701   |\n",
      "|       Average F1 Score       |   0.44373   |\n",
      "|         Average Loss         |   1.5006    |\n",
      "|       Average Latency        |  28.391 ms  |\n",
      "|   Average GPU Power Usage    |  13.761 W   |\n",
      "| Inference Energy Consumption | 0.10853 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_6/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_60/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_62/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_63/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:38:19] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.43925    |\n",
      "|      Average Precision       |    0.50382    |\n",
      "|        Average Recall        |    0.49179    |\n",
      "|       Average F1 Score       |    0.4794     |\n",
      "|         Average Loss         |     1.406     |\n",
      "|       Average Latency        |   2.4084 ms   |\n",
      "|   Average GPU Power Usage    |   12.255 W    |\n",
      "| Inference Energy Consumption | 0.0081983 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_18/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_64/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_65/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_66/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:38:57] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.44637    |\n",
      "|      Average Precision       |    0.50707    |\n",
      "|        Average Recall        |    0.49773    |\n",
      "|       Average F1 Score       |    0.48445    |\n",
      "|         Average Loss         |    7.0362     |\n",
      "|       Average Latency        |   2.5438 ms   |\n",
      "|   Average GPU Power Usage    |   13.553 W    |\n",
      "| Inference Energy Consumption | 0.0095768 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_67/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_68/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_69/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:39:20] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.44607    |\n",
      "|      Average Precision       |   0.50722    |\n",
      "|        Average Recall        |   0.49773    |\n",
      "|       Average F1 Score       |   0.48443    |\n",
      "|         Average Loss         |    7.0373    |\n",
      "|       Average Latency        |  9.3761 ms   |\n",
      "|   Average GPU Power Usage    |   13.766 W   |\n",
      "| Inference Energy Consumption | 0.035854 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_20/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=16 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=32 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.47844   |\n",
      "|      Average Precision       |   0.47768   |\n",
      "|        Average Recall        |    0.485    |\n",
      "|       Average F1 Score       |   0.47723   |\n",
      "|         Average Loss         |   1.4296    |\n",
      "|       Average Latency        |  33.949 ms  |\n",
      "|   Average GPU Power Usage    |  14.182 W   |\n",
      "| Inference Energy Consumption | 0.13374 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_7/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_70/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_72/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_73/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:40:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.48954    |\n",
      "|      Average Precision       |    0.50817    |\n",
      "|        Average Recall        |    0.50855    |\n",
      "|       Average F1 Score       |    0.50345    |\n",
      "|         Average Loss         |    1.4095     |\n",
      "|       Average Latency        |   2.9664 ms   |\n",
      "|   Average GPU Power Usage    |   11.386 W    |\n",
      "| Inference Energy Consumption | 0.0093819 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_21/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_74/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_75/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_76/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:41:25] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.49638    |\n",
      "|      Average Precision       |    0.51393    |\n",
      "|        Average Recall        |    0.51741    |\n",
      "|       Average F1 Score       |    0.51166    |\n",
      "|         Average Loss         |    1.6039     |\n",
      "|       Average Latency        |   2.3347 ms   |\n",
      "|   Average GPU Power Usage    |   14.514 W    |\n",
      "| Inference Energy Consumption | 0.0094128 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_22/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_77/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_78/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_79/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:41:47] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.49683    |\n",
      "|      Average Precision       |   0.51443    |\n",
      "|        Average Recall        |   0.51781    |\n",
      "|       Average F1 Score       |   0.51211    |\n",
      "|         Average Loss         |    1.6036    |\n",
      "|       Average Latency        |  9.4764 ms   |\n",
      "|   Average GPU Power Usage    |   15.759 W   |\n",
      "| Inference Energy Consumption | 0.041484 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_23/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=32 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.5044    |\n",
      "|      Average Precision       |   0.49101   |\n",
      "|        Average Recall        |   0.50043   |\n",
      "|       Average F1 Score       |   0.49177   |\n",
      "|         Average Loss         |    1.405    |\n",
      "|       Average Latency        |  44.13 ms   |\n",
      "|   Average GPU Power Usage    |   14.94 W   |\n",
      "| Inference Energy Consumption | 0.18314 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_8/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_80/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_82/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_83/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:43:09] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.50818    |\n",
      "|      Average Precision       |    0.5066    |\n",
      "|        Average Recall        |   0.51055    |\n",
      "|       Average F1 Score       |    0.5043    |\n",
      "|         Average Loss         |    1.3873    |\n",
      "|       Average Latency        |  3.3475 ms   |\n",
      "|   Average GPU Power Usage    |    12.1 W    |\n",
      "| Inference Energy Consumption | 0.011251 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_24/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_84/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_85/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_86/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:43:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51405    |\n",
      "|      Average Precision       |   0.51082    |\n",
      "|        Average Recall        |   0.51718    |\n",
      "|       Average F1 Score       |   0.51041    |\n",
      "|         Average Loss         |    1.3992    |\n",
      "|       Average Latency        |   4.173 ms   |\n",
      "|   Average GPU Power Usage    |   11.484 W   |\n",
      "| Inference Energy Consumption | 0.013312 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_25/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_87/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_88/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_89/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:44:06] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51378    |\n",
      "|      Average Precision       |   0.51043    |\n",
      "|        Average Recall        |   0.51687    |\n",
      "|       Average F1 Score       |   0.51004    |\n",
      "|         Average Loss         |    1.3992    |\n",
      "|       Average Latency        |  14.427 ms   |\n",
      "|   Average GPU Power Usage    |   12.718 W   |\n",
      "| Inference Energy Consumption | 0.050969 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_26/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=128 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.51395   |\n",
      "|      Average Precision       |   0.50189   |\n",
      "|        Average Recall        |   0.51103   |\n",
      "|       Average F1 Score       |   0.50174   |\n",
      "|         Average Loss         |   1.3966    |\n",
      "|       Average Latency        |  41.231 ms  |\n",
      "|   Average GPU Power Usage    |  19.645 W   |\n",
      "| Inference Energy Consumption | 0.22499 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_90/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_92/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_93/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:45:26] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51183    |\n",
      "|      Average Precision       |   0.50626    |\n",
      "|        Average Recall        |    0.5137    |\n",
      "|       Average F1 Score       |   0.50516    |\n",
      "|         Average Loss         |    1.3877    |\n",
      "|       Average Latency        |  6.0985 ms   |\n",
      "|   Average GPU Power Usage    |   11.637 W   |\n",
      "| Inference Energy Consumption | 0.019713 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_27/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_94/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_95/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_96/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:46:07] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51788    |\n",
      "|      Average Precision       |   0.51125    |\n",
      "|        Average Recall        |   0.51916    |\n",
      "|       Average F1 Score       |   0.51082    |\n",
      "|         Average Loss         |    1.3853    |\n",
      "|       Average Latency        |  4.6722 ms   |\n",
      "|   Average GPU Power Usage    |   15.035 W   |\n",
      "| Inference Energy Consumption | 0.019513 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_28/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_97/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_98/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_99/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:46:31] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51791    |\n",
      "|      Average Precision       |    0.5114    |\n",
      "|        Average Recall        |   0.51926    |\n",
      "|       Average F1 Score       |   0.51092    |\n",
      "|         Average Loss         |    1.3853    |\n",
      "|       Average Latency        |  19.938 ms   |\n",
      "|   Average GPU Power Usage    |   15.005 W   |\n",
      "| Inference Energy Consumption | 0.083106 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_29/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=128 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MUL_PRECISION_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet50_Mul_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {MUL_PRECISION_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
