{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADLS Proj: TensorRT with MASE for Multiple Precision Inference\n",
    "\n",
    "This notebook demonstrates the integration of TensorRT passes into MASE as part of the MASERT framework.\n",
    "\n",
    "Currently, our experiments are conducted on RTX 4060 and RTX 3070 GPUs, as our request for A100 access is still pending.\n",
    "\n",
    "### Objective\n",
    "Our goal is to plot trade-off curves that analyze the relationship between different variables, including:\n",
    "- **GPU Type** (e.g., RTX 4060, RTX 3070, and A100 when available)\n",
    "- **Dataset** (e.g., CIFAR-10)\n",
    "- **Model Type** (e.g., ResNet18, ResNet50, VGG, AlexNet ...)\n",
    "- **Precision vs. Runtime Trade-off** (FP32, FP16, INT8)\n",
    "\n",
    "At this stage, we have successfully implemented inference using multiple models, such as **ResNet18 and ResNet50**, on the **CIFAR-10 dataset**. Further experiments will explore the precision-runtime trade-off across different GPU architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model for Quantization Experiments\n",
    "\n",
    "In this section, we train an original model of a target model type. The trained model will later serve as a baseline for different precision quantization experiments, including FP32, FP16, and INT8. This process helps in evaluating the trade-offs between model accuracy and runtime efficiency across different GPU architectures.\n",
    "\n",
    "#### Running the Training Script\n",
    "\n",
    "To train the model, execute the following command:\n",
    "\n",
    "```bash\n",
    "!python3 ./ch train --config /workspace/ADLS_Proj/docs/tutorials/tensorrt/resnet18_INT8_quantization_by_type.toml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0311 00:15:51.512130 140276942296128 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File | Manual Override |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                 |           cls            |\n",
      "| load_name               |           None           |              |                 |           None           |\n",
      "| load_type               |            mz            |              |                 |            mz            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                 |            64            |\n",
      "| to_debug                |          False           |              |                 |          False           |\n",
      "| log_level               |           info           |              |                 |           info           |\n",
      "| report_to               |       tensorboard        |              |                 |       tensorboard        |\n",
      "| seed                    |            0             |              |                 |            0             |\n",
      "| quant_config            |           None           |              |                 |           None           |\n",
      "| training_optimizer      |           adam           |              |                 |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                 |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                 |          0.001           |\n",
      "| weight_decay            |            0             |              |                 |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                 |            10            |\n",
      "| max_steps               |            -1            |              |                 |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                 |            1             |\n",
      "| log_every_n_steps       |            50            |              |                 |            50            |\n",
      "| num_workers             |            20            |              |                 |            20            |\n",
      "| num_devices             |            1             |              |                 |            1             |\n",
      "| num_nodes               |            1             |              |                 |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                 |           gpu            |\n",
      "| strategy                |           auto           |              |                 |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                 |          False           |\n",
      "| github_ci               |          False           |              |                 |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                 |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                 |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                 |           100            |\n",
      "| is_pretrained           |          False           |              |                 |          False           |\n",
      "| max_token_len           |           512            |              |                 |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                 | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                 |         e_output         |\n",
      "| project                 |           None           |              |                 |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                 |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                 |         cifar10          |\n",
      "| t_max                   |            20            |              |                 |            20            |\n",
      "| eta_min                 |          1e-06           |              |                 |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+-----------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-11\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTraining model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m##### WEIGHT DECAY ##### 0\u001b[0m\n",
      "I0311 00:15:51.711618 140276942296128 rank_zero.py:63] Using 16bit Automatic Mixed Precision (AMP)\n",
      "I0311 00:15:51.718478 140276942296128 rank_zero.py:63] GPU available: True (cuda), used: True\n",
      "I0311 00:15:51.718928 140276942296128 rank_zero.py:63] TPU available: False, using: 0 TPU cores\n",
      "I0311 00:15:51.718978 140276942296128 rank_zero.py:63] HPU available: False, using: 0 HPUs\n",
      "I0311 00:15:54.418565 140276942296128 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0311 00:15:54.708575 140276942296128 model_summary.py:104] \n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | ResNet             | 11.2 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_train | MulticlassAccuracy | 0      | train\n",
      "3 | loss_val  | MeanMetric         | 0      | train\n",
      "4 | loss_test | MeanMetric         | 0      | train\n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0:  53%|â–Œ| 411/782 [00:11<00:10, 35.12it/s, v_num=0, train_acc_step=0.234]I0311 00:16:07.596064 140276942296128 rank_zero.py:63] \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 ./ch train --config /workspace/ADLS_Proj/docs/tutorials/proj/resnet18_INT8_quant.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INT8 Quantization with TensorRT\n",
    "\n",
    "This section explains the process of **INT8 quantization** using TensorRT within the MASE framework. The key steps include **fake quantization, calibration, fine-tuning, and generating a TensorRT engine**.\n",
    "\n",
    "### Code Execution Flow\n",
    "\n",
    "1. **Apply TensorRT Passes**\n",
    "   - **Fake Quantization**: Inserts quantization simulation operations.\n",
    "   - **Summarization**: Displays which layers were quantized.\n",
    "   - **Calibration**: Uses calibration algorithms (e.g., histogram-based) to determine optimal quantization parameters.\n",
    "   - **Fine-Tuning**: Adjusts parameters to recover accuracy loss after quantization.\n",
    "\n",
    "2. **Generate the TensorRT Engine**\n",
    "   - Calls `tensorrt_engine_interface_pass` to convert the optimized graph into a **TensorRT engine**.\n",
    "\n",
    "3. **Benchmarking & Performance Analysis**\n",
    "   - Runs inference tests with warm-up and batch evaluation to measure efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0320 00:42:34.917057 139954364924992 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/doc | /workspace/ADLS_Proj/doc |\n",
      "|                         |                          |              | s/tutorials/proj/model/r | s/tutorials/proj/model/r |\n",
      "|                         |                          |              |    esnet18/best.ckpt     |    esnet18/best.ckpt     |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet18 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_0/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_2/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_3/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/20/2025-00:43:17] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.74039    |\n",
      "|      Average Precision       |    0.7425    |\n",
      "|        Average Recall        |   0.74483    |\n",
      "|       Average F1 Score       |   0.74268    |\n",
      "|         Average Loss         |   0.73716    |\n",
      "|       Average Latency        |  2.2112 ms   |\n",
      "|   Average GPU Power Usage    |   8.6206 W   |\n",
      "| Inference Energy Consumption | 0.005295 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/tensorrt/version_0/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_INT8_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_INT8_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\"\n",
    "!python ch transform --config {RES_INT8_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP16 Conversion with TensorRT\n",
    "\n",
    "#### Overview\n",
    "This section describes the process of converting a model to **FP16 precision** using TensorRT. Unlike **INT8 quantization**, **FP16 does not require calibration, fake quantization, or fine-tuning**. The conversion process is simpler and primarily focuses on **speeding up inference while maintaining high precision**.\n",
    "\n",
    "### Code Execution Flow\n",
    "\n",
    "1. **Apply TensorRT FP16 Pass**\n",
    "   - **No Fake Quantization**: Since FP16 does not require quantization-aware training, the `quantize` option is set to `false`.\n",
    "   - **No Calibration**: Unlike INT8, FP16 does not need calibration data, so `num_calibration_batches` is set to `0`.\n",
    "   - **No Fine-Tuning**: Additional training is unnecessary in FP16 mode.\n",
    "\n",
    "2. **Generate the TensorRT Engine**\n",
    "   - Calls `tensorrt_engine_interface_pass` to convert the model to a **TensorRT FP16 engine**.\n",
    "\n",
    "3. **Benchmarking & Performance Analysis**\n",
    "   - Runs inference tests with warm-up and batch evaluation to measure efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0320 00:49:48.720277 140621743559744 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/doc | /workspace/ADLS_Proj/doc |\n",
      "|                         |                          |              | s/tutorials/proj/model/r | s/tutorials/proj/model/r |\n",
      "|                         |                          |              |    esnet18/best.ckpt     |    esnet18/best.ckpt     |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet18 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_4/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_5/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/2025-03-20/version_6/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/20/2025-00:50:16] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74164    |\n",
      "|      Average Precision       |    0.74232    |\n",
      "|        Average Recall        |    0.74514    |\n",
      "|       Average F1 Score       |    0.74268    |\n",
      "|         Average Loss         |    0.73413    |\n",
      "|       Average Latency        |   2.909 ms    |\n",
      "|   Average GPU Power Usage    |   12.169 W    |\n",
      "| Inference Energy Consumption | 0.0098334 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-20/tensorrt/version_1/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-20/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP16_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_FP16_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\"\n",
    "!python ch transform --config {RES_FP16_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP32 Conversion with TensorRT\n",
    "\n",
    "The process for converting a model to **FP32 precision** using TensorRT is quite similar to the **FP16 conversion**, but with even fewer modifications. Since FP32 is the default precision for deep learning models, the main goal here is to **leverage TensorRT optimizations** without changing the numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0315 01:43:15.535419 140335826768960 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |     cls      |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |              | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |              | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |              | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |              | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |              |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |              |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |      64      |                          |            64            |\n",
      "| to_debug                |          False           |              |                          |          False           |\n",
      "| log_level               |           info           |              |                          |           info           |\n",
      "| report_to               |       tensorboard        |              |                          |       tensorboard        |\n",
      "| seed                    |            0             |              |                          |            0             |\n",
      "| quant_config            |           None           |              |                          |           None           |\n",
      "| training_optimizer      |           adam           |              |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |              |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |            0             |              |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |      10      |                          |            10            |\n",
      "| max_steps               |            -1            |              |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |              |                          |            1             |\n",
      "| log_every_n_steps       |            50            |              |                          |            50            |\n",
      "| num_workers             |            20            |              |                          |            20            |\n",
      "| num_devices             |            1             |              |                          |            1             |\n",
      "| num_nodes               |            1             |              |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |     gpu      |                          |           gpu            |\n",
      "| strategy                |           auto           |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |              |                          |          False           |\n",
      "| github_ci               |          False           |              |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |              |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |              |                          |           100            |\n",
      "| is_pretrained           |          False           |              |                          |          False           |\n",
      "| max_token_len           |           512            |              |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |              |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |              |                          |         e_output         |\n",
      "| project                 |           None           |              |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |   resnet18   |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |            20            |              |                          |            20            |\n",
      "| eta_min                 |          1e-06           |              |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "{'model': 'resnet18', 'dataset': 'cifar10', 'max_epochs': 10, 'batch_size': 64, 'learning_rate': 0.001, 'accelerator': 'gpu', 'task': 'cls', 'transform': {'style': 'graph'}, 'passes': {'tensorrt': {'by': 'type', 'num_calibration_batches': 0, 'post_calibration_analysis': False, 'default': {'config': {'quantize': False, 'precision': 'fp32'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'fine_tune': {'fine_tune': False}, 'runtime_analysis': {'num_batches': 500, 'num_GPU_warmup_batches': 5, 'test': True}}}}\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mprecision=fp32, skipping int8 calibration/fine-tune...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_13/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_14/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/2025-03-15/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72852    |\n",
      "|      Average Precision       |   0.71886    |\n",
      "|        Average Recall        |   0.72227    |\n",
      "|       Average F1 Score       |   0.71961    |\n",
      "|         Average Loss         |   0.80975    |\n",
      "|       Average Latency        |  8.3068 ms   |\n",
      "|   Average GPU Power Usage    |   17.661 W   |\n",
      "| Inference Energy Consumption | 0.040752 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/mase_graph/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/15/2025-01:43:32] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.74162    |\n",
      "|      Average Precision       |    0.74235    |\n",
      "|        Average Recall        |    0.74514    |\n",
      "|       Average F1 Score       |    0.7427     |\n",
      "|         Average Loss         |    0.73414    |\n",
      "|       Average Latency        |   2.706 ms    |\n",
      "|   Average GPU Power Usage    |   11.678 W    |\n",
      "| Inference Energy Consumption | 0.0087779 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-15/tensorrt/version_4/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-15/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RES_FP32_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_FP32_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/docs/tutorials/proj/model/resnet18/best.ckpt\"\n",
    "!python ch transform --config {RES_FP32_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Precision Multi-Batch size (Runtime-Accuracy Trade-off)\n",
    "\n",
    "input: Model:Resnet18 Restnet50 VGG\n",
    "\n",
    "Variable: Precision: INT8 FP16 FP32 (Original) | batch size\n",
    "\n",
    "Output: Original INT8 FP16 FP32 (Acc, Runtime)(Model, batch size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0317 17:52:22.237135 140261090690112 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |     Config. File     |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls          |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |                      | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |                      | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |                      | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |                      | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |                      |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |                      |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            | [8, 16, 32, 64, 128] |                          |   [8, 16, 32, 64, 128]   |\n",
      "| to_debug                |          False           |                      |                          |          False           |\n",
      "| log_level               |           info           |                      |                          |           info           |\n",
      "| report_to               |       tensorboard        |                      |                          |       tensorboard        |\n",
      "| seed                    |            0             |                      |                          |            0             |\n",
      "| quant_config            |           None           |                      |                          |           None           |\n",
      "| training_optimizer      |           adam           |                      |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                      |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001         |                          |          0.001           |\n",
      "| weight_decay            |            0             |                      |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |          10          |                          |            10            |\n",
      "| max_steps               |            -1            |                      |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                      |                          |            1             |\n",
      "| log_every_n_steps       |            50            |                      |                          |            50            |\n",
      "| num_workers             |            20            |                      |                          |            20            |\n",
      "| num_devices             |            1             |                      |                          |            1             |\n",
      "| num_nodes               |            1             |                      |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu          |                          |           gpu            |\n",
      "| strategy                |           auto           |                      |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                      |                          |          False           |\n",
      "| github_ci               |          False           |                      |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                      |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                      |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                      |                          |           100            |\n",
      "| is_pretrained           |          False           |                      |                          |          False           |\n",
      "| max_token_len           |           512            |                      |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                      |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                      |                          |         e_output         |\n",
      "| project                 |           None           |                      |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |       resnet18       |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |       cifar10        |                          |         cifar10          |\n",
      "| t_max                   |            20            |                      |                          |            20            |\n",
      "| eta_min                 |          1e-06           |                      |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet18 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=8 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.53327    |\n",
      "|      Average Precision       |   0.64654    |\n",
      "|        Average Recall        |   0.64912    |\n",
      "|       Average F1 Score       |   0.64651    |\n",
      "|         Average Loss         |    1.026     |\n",
      "|       Average Latency        |   5.277 ms   |\n",
      "|   Average GPU Power Usage    |   13.273 W   |\n",
      "| Inference Energy Consumption | 0.019457 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_0/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_2/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_3/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:10] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.62798    |\n",
      "|      Average Precision       |    0.72789    |\n",
      "|        Average Recall        |    0.71995    |\n",
      "|       Average F1 Score       |    0.71991    |\n",
      "|         Average Loss         |    0.80968    |\n",
      "|       Average Latency        |   1.5852 ms   |\n",
      "|   Average GPU Power Usage    |   10.324 W    |\n",
      "| Inference Energy Consumption | 0.0045462 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_45/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_4/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_5/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_6/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:31] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.6277     |\n",
      "|      Average Precision       |    0.72683    |\n",
      "|        Average Recall        |    0.71944    |\n",
      "|       Average F1 Score       |    0.71913    |\n",
      "|         Average Loss         |    0.80694    |\n",
      "|       Average Latency        |   1.4446 ms   |\n",
      "|   Average GPU Power Usage    |   12.094 W    |\n",
      "| Inference Energy Consumption | 0.0048531 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_46/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_7/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_8/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:53:45] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.62744    |\n",
      "|      Average Precision       |   0.72628    |\n",
      "|        Average Recall        |   0.71919    |\n",
      "|       Average F1 Score       |   0.71876    |\n",
      "|         Average Loss         |    0.807     |\n",
      "|       Average Latency        |  7.7848 ms   |\n",
      "|   Average GPU Power Usage    |   11.26 W    |\n",
      "| Inference Energy Consumption | 0.024349 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_47/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=8 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=16 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.63839    |\n",
      "|      Average Precision       |   0.69645    |\n",
      "|        Average Recall        |   0.69868    |\n",
      "|       Average F1 Score       |   0.69676    |\n",
      "|         Average Loss         |   0.88776    |\n",
      "|       Average Latency        |  13.897 ms   |\n",
      "|   Average GPU Power Usage    |   12.529 W   |\n",
      "| Inference Energy Consumption | 0.048363 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_10/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_12/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_13/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:54:39] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.67587    |\n",
      "|      Average Precision       |    0.73327    |\n",
      "|        Average Recall        |    0.73056    |\n",
      "|       Average F1 Score       |    0.7296     |\n",
      "|         Average Loss         |    0.79824    |\n",
      "|       Average Latency        |   1.7622 ms   |\n",
      "|   Average GPU Power Usage    |   10.546 W    |\n",
      "| Inference Energy Consumption | 0.0051625 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_48/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_14/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_15/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:55:02] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.67499    |\n",
      "|      Average Precision       |    0.73221    |\n",
      "|        Average Recall        |    0.72942    |\n",
      "|       Average F1 Score       |    0.72832    |\n",
      "|         Average Loss         |    0.78645    |\n",
      "|       Average Latency        |   2.0498 ms   |\n",
      "|   Average GPU Power Usage    |   10.721 W    |\n",
      "| Inference Energy Consumption | 0.0061044 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_49/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_17/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_18/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:55:17] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.67516    |\n",
      "|      Average Precision       |   0.73215    |\n",
      "|        Average Recall        |   0.72942    |\n",
      "|       Average F1 Score       |   0.72834    |\n",
      "|         Average Loss         |   0.78641    |\n",
      "|       Average Latency        |  7.5107 ms   |\n",
      "|   Average GPU Power Usage    |   11.672 W   |\n",
      "| Inference Energy Consumption | 0.024352 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_50/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=16 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=32 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.70809    |\n",
      "|      Average Precision       |   0.70874    |\n",
      "|        Average Recall        |   0.71192    |\n",
      "|       Average F1 Score       |   0.70968    |\n",
      "|         Average Loss         |    0.8365    |\n",
      "|       Average Latency        |   14.73 ms   |\n",
      "|   Average GPU Power Usage    |   13.022 W   |\n",
      "| Inference Energy Consumption | 0.053281 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_17/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_20/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_22/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_23/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:06] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.71444    |\n",
      "|      Average Precision       |   0.73637    |\n",
      "|        Average Recall        |   0.73422    |\n",
      "|       Average F1 Score       |   0.73393    |\n",
      "|         Average Loss         |    0.7834    |\n",
      "|       Average Latency        |  1.4322 ms   |\n",
      "|   Average GPU Power Usage    |   9.9136 W   |\n",
      "| Inference Energy Consumption | 0.003944 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_51/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_24/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_25/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_26/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:27] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.71709    |\n",
      "|      Average Precision       |    0.73662    |\n",
      "|        Average Recall        |    0.73453    |\n",
      "|       Average F1 Score       |    0.73408    |\n",
      "|         Average Loss         |    0.77975    |\n",
      "|       Average Latency        |   1.7785 ms   |\n",
      "|   Average GPU Power Usage    |   10.892 W    |\n",
      "| Inference Energy Consumption | 0.0053809 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_52/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_27/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_28/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_29/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:56:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.71683    |\n",
      "|      Average Precision       |   0.73654    |\n",
      "|        Average Recall        |   0.73453    |\n",
      "|       Average F1 Score       |   0.73405    |\n",
      "|         Average Loss         |   0.77977    |\n",
      "|       Average Latency        |  7.6064 ms   |\n",
      "|   Average GPU Power Usage    |   11.442 W   |\n",
      "| Inference Energy Consumption | 0.024175 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_53/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=32 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72733    |\n",
      "|      Average Precision       |   0.71774    |\n",
      "|        Average Recall        |    0.7211    |\n",
      "|       Average F1 Score       |   0.71844    |\n",
      "|         Average Loss         |   0.81241    |\n",
      "|       Average Latency        |  17.865 ms   |\n",
      "|   Average GPU Power Usage    |   12.98 W    |\n",
      "| Inference Energy Consumption | 0.064413 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_18/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_30/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_32/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_33/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:24] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73223    |\n",
      "|      Average Precision       |    0.73642    |\n",
      "|        Average Recall        |    0.73665    |\n",
      "|       Average F1 Score       |    0.73568    |\n",
      "|         Average Loss         |    0.78729    |\n",
      "|       Average Latency        |   2.3134 ms   |\n",
      "|   Average GPU Power Usage    |    8.682 W    |\n",
      "| Inference Energy Consumption | 0.0055792 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_54/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_34/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_35/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_36/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:44] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73285    |\n",
      "|      Average Precision       |    0.73597    |\n",
      "|        Average Recall        |    0.73624    |\n",
      "|       Average F1 Score       |    0.73514    |\n",
      "|         Average Loss         |    0.77958    |\n",
      "|       Average Latency        |   1.7162 ms   |\n",
      "|   Average GPU Power Usage    |   9.9179 W    |\n",
      "| Inference Energy Consumption | 0.0047282 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_55/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_37/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_38/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_39/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:57:58] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73263    |\n",
      "|      Average Precision       |   0.73577    |\n",
      "|        Average Recall        |   0.73603    |\n",
      "|       Average F1 Score       |   0.73491    |\n",
      "|         Average Loss         |   0.77954    |\n",
      "|       Average Latency        |  9.7836 ms   |\n",
      "|   Average GPU Power Usage    |   12.211 W   |\n",
      "| Inference Energy Consumption | 0.033186 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_56/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=128 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73052    |\n",
      "|      Average Precision       |   0.72403    |\n",
      "|        Average Recall        |   0.72725    |\n",
      "|       Average F1 Score       |   0.72451    |\n",
      "|         Average Loss         |   0.80109    |\n",
      "|       Average Latency        |  20.081 ms   |\n",
      "|   Average GPU Power Usage    |   13.491 W   |\n",
      "| Inference Energy Consumption | 0.075254 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/mase_graph/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_40/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_42/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_43/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:58:44] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73315    |\n",
      "|      Average Precision       |    0.73448    |\n",
      "|        Average Recall        |    0.73587    |\n",
      "|       Average F1 Score       |    0.73444    |\n",
      "|         Average Loss         |    0.78575    |\n",
      "|       Average Latency        |   3.4924 ms   |\n",
      "|   Average GPU Power Usage    |   7.4494 W    |\n",
      "| Inference Energy Consumption | 0.0072267 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_57/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_44/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_45/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_46/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:59:07] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73227    |\n",
      "|      Average Precision       |    0.733     |\n",
      "|        Average Recall        |   0.73491    |\n",
      "|       Average F1 Score       |   0.73308    |\n",
      "|         Average Loss         |   0.78348    |\n",
      "|       Average Latency        |  3.7376 ms   |\n",
      "|   Average GPU Power Usage    |   12.297 W   |\n",
      "| Inference Energy Consumption | 0.012767 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_58/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_47/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_48/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/2025-03-17/version_49/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/17/2025-17:59:22] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73246    |\n",
      "|      Average Precision       |    0.7332    |\n",
      "|        Average Recall        |   0.73512    |\n",
      "|       Average F1 Score       |   0.73327    |\n",
      "|         Average Loss         |   0.78351    |\n",
      "|       Average Latency        |  11.864 ms   |\n",
      "|   Average GPU Power Usage    |   11.771 W   |\n",
      "| Inference Energy Consumption | 0.038794 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-17/tensorrt/version_59/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=128 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-17/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MUL_PRECISION_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_Mul_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {MUL_PRECISION_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is for Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0317 18:34:02.077955 140444487648320 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |     Config. File     |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls          |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |                      | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |                      | e_output/resnet50_cls_ci | e_output/resnet50_cls_ci |\n",
      "|                         |                          |                      | far10_2025-03-15/softwar | far10_2025-03-15/softwar |\n",
      "|                         |                          |                      | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |                      |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |                      |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            | [8, 16, 32, 64, 128] |                          |   [8, 16, 32, 64, 128]   |\n",
      "| to_debug                |          False           |                      |                          |          False           |\n",
      "| log_level               |           info           |                      |                          |           info           |\n",
      "| report_to               |       tensorboard        |                      |                          |       tensorboard        |\n",
      "| seed                    |            0             |                      |                          |            0             |\n",
      "| quant_config            |           None           |                      |                          |           None           |\n",
      "| training_optimizer      |           adam           |                      |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                      |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001         |                          |          0.001           |\n",
      "| weight_decay            |            0             |                      |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |          10          |                          |            10            |\n",
      "| max_steps               |            -1            |                      |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                      |                          |            1             |\n",
      "| log_every_n_steps       |            50            |                      |                          |            50            |\n",
      "| num_workers             |            20            |                      |                          |            20            |\n",
      "| num_devices             |            1             |                      |                          |            1             |\n",
      "| num_nodes               |            1             |                      |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu          |                          |           gpu            |\n",
      "| strategy                |           auto           |                      |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                      |                          |          False           |\n",
      "| github_ci               |          False           |                      |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                      |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                      |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                      |                          |           100            |\n",
      "| is_pretrained           |          False           |                      |                          |          False           |\n",
      "| max_token_len           |           512            |                      |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                      |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                      |                          |         e_output         |\n",
      "| project                 |           None           |                      |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |       resnet50       |                          |         resnet50         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |       cifar10        |                          |         cifar10          |\n",
      "| t_max                   |            20            |                      |                          |            20            |\n",
      "| eta_min                 |          1e-06           |                      |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet50'...\u001b[0m\n",
      "self.args.model is resnet50\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet50'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet50 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=8 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.25593    |\n",
      "|      Average Precision       |   0.39695    |\n",
      "|        Average Recall        |   0.31212    |\n",
      "|       Average F1 Score       |   0.28777    |\n",
      "|         Average Loss         |    2.0529    |\n",
      "|       Average Latency        |  23.572 ms   |\n",
      "|   Average GPU Power Usage    |   13.697 W   |\n",
      "| Inference Energy Consumption | 0.089684 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_5/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_50/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_52/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_53/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:35:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.10948    |\n",
      "|      Average Precision       |   0.044274    |\n",
      "|        Average Recall        |    0.10833    |\n",
      "|       Average F1 Score       |   0.035417    |\n",
      "|         Average Loss         |    9.4165     |\n",
      "|       Average Latency        |   2.3392 ms   |\n",
      "|   Average GPU Power Usage    |   10.775 W    |\n",
      "| Inference Energy Consumption | 0.0070011 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_54/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_55/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_56/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:36:17] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.26117   |\n",
      "|      Average Precision       |   0.50246   |\n",
      "|        Average Recall        |   0.29874   |\n",
      "|       Average F1 Score       |   0.25196   |\n",
      "|         Average Loss         |     nan     |\n",
      "|       Average Latency        |  2.8038 ms  |\n",
      "|   Average GPU Power Usage    |  12.865 W   |\n",
      "| Inference Energy Consumption | 0.01002 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_57/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_58/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_59/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:36:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.26162    |\n",
      "|      Average Precision       |   0.49738    |\n",
      "|        Average Recall        |     0.3      |\n",
      "|       Average F1 Score       |   0.25325    |\n",
      "|         Average Loss         |    666.31    |\n",
      "|       Average Latency        |   8.782 ms   |\n",
      "|   Average GPU Power Usage    |   13.644 W   |\n",
      "| Inference Energy Consumption | 0.033284 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_17/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=8 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=16 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.4122    |\n",
      "|      Average Precision       |   0.45405   |\n",
      "|        Average Recall        |   0.45701   |\n",
      "|       Average F1 Score       |   0.44373   |\n",
      "|         Average Loss         |   1.5006    |\n",
      "|       Average Latency        |  28.391 ms  |\n",
      "|   Average GPU Power Usage    |  13.761 W   |\n",
      "| Inference Energy Consumption | 0.10853 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_6/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_60/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_62/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_63/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:38:19] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.43925    |\n",
      "|      Average Precision       |    0.50382    |\n",
      "|        Average Recall        |    0.49179    |\n",
      "|       Average F1 Score       |    0.4794     |\n",
      "|         Average Loss         |     1.406     |\n",
      "|       Average Latency        |   2.4084 ms   |\n",
      "|   Average GPU Power Usage    |   12.255 W    |\n",
      "| Inference Energy Consumption | 0.0081983 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_18/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_64/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_65/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_66/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:38:57] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.44637    |\n",
      "|      Average Precision       |    0.50707    |\n",
      "|        Average Recall        |    0.49773    |\n",
      "|       Average F1 Score       |    0.48445    |\n",
      "|         Average Loss         |    7.0362     |\n",
      "|       Average Latency        |   2.5438 ms   |\n",
      "|   Average GPU Power Usage    |   13.553 W    |\n",
      "| Inference Energy Consumption | 0.0095768 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_67/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_68/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_69/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:39:20] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.44607    |\n",
      "|      Average Precision       |   0.50722    |\n",
      "|        Average Recall        |   0.49773    |\n",
      "|       Average F1 Score       |   0.48443    |\n",
      "|         Average Loss         |    7.0373    |\n",
      "|       Average Latency        |  9.3761 ms   |\n",
      "|   Average GPU Power Usage    |   13.766 W   |\n",
      "| Inference Energy Consumption | 0.035854 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_20/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=16 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=32 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.47844   |\n",
      "|      Average Precision       |   0.47768   |\n",
      "|        Average Recall        |    0.485    |\n",
      "|       Average F1 Score       |   0.47723   |\n",
      "|         Average Loss         |   1.4296    |\n",
      "|       Average Latency        |  33.949 ms  |\n",
      "|   Average GPU Power Usage    |  14.182 W   |\n",
      "| Inference Energy Consumption | 0.13374 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_7/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_70/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_72/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_73/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:40:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.48954    |\n",
      "|      Average Precision       |    0.50817    |\n",
      "|        Average Recall        |    0.50855    |\n",
      "|       Average F1 Score       |    0.50345    |\n",
      "|         Average Loss         |    1.4095     |\n",
      "|       Average Latency        |   2.9664 ms   |\n",
      "|   Average GPU Power Usage    |   11.386 W    |\n",
      "| Inference Energy Consumption | 0.0093819 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_21/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_74/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_75/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_76/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:41:25] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.49638    |\n",
      "|      Average Precision       |    0.51393    |\n",
      "|        Average Recall        |    0.51741    |\n",
      "|       Average F1 Score       |    0.51166    |\n",
      "|         Average Loss         |    1.6039     |\n",
      "|       Average Latency        |   2.3347 ms   |\n",
      "|   Average GPU Power Usage    |   14.514 W    |\n",
      "| Inference Energy Consumption | 0.0094128 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_22/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_77/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_78/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_79/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:41:47] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.49683    |\n",
      "|      Average Precision       |   0.51443    |\n",
      "|        Average Recall        |   0.51781    |\n",
      "|       Average F1 Score       |   0.51211    |\n",
      "|         Average Loss         |    1.6036    |\n",
      "|       Average Latency        |  9.4764 ms   |\n",
      "|   Average GPU Power Usage    |   15.759 W   |\n",
      "| Inference Energy Consumption | 0.041484 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_23/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=32 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.5044    |\n",
      "|      Average Precision       |   0.49101   |\n",
      "|        Average Recall        |   0.50043   |\n",
      "|       Average F1 Score       |   0.49177   |\n",
      "|         Average Loss         |    1.405    |\n",
      "|       Average Latency        |  44.13 ms   |\n",
      "|   Average GPU Power Usage    |   14.94 W   |\n",
      "| Inference Energy Consumption | 0.18314 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_8/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_80/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_82/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_83/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:43:09] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.50818    |\n",
      "|      Average Precision       |    0.5066    |\n",
      "|        Average Recall        |   0.51055    |\n",
      "|       Average F1 Score       |    0.5043    |\n",
      "|         Average Loss         |    1.3873    |\n",
      "|       Average Latency        |  3.3475 ms   |\n",
      "|   Average GPU Power Usage    |    12.1 W    |\n",
      "| Inference Energy Consumption | 0.011251 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_24/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_84/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_85/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_86/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:43:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51405    |\n",
      "|      Average Precision       |   0.51082    |\n",
      "|        Average Recall        |   0.51718    |\n",
      "|       Average F1 Score       |   0.51041    |\n",
      "|         Average Loss         |    1.3992    |\n",
      "|       Average Latency        |   4.173 ms   |\n",
      "|   Average GPU Power Usage    |   11.484 W   |\n",
      "| Inference Energy Consumption | 0.013312 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_25/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_87/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_88/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_89/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:44:06] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51378    |\n",
      "|      Average Precision       |   0.51043    |\n",
      "|        Average Recall        |   0.51687    |\n",
      "|       Average F1 Score       |   0.51004    |\n",
      "|         Average Loss         |    1.3992    |\n",
      "|       Average Latency        |  14.427 ms   |\n",
      "|   Average GPU Power Usage    |   12.718 W   |\n",
      "| Inference Energy Consumption | 0.050969 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_26/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=128 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-15/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.51395   |\n",
      "|      Average Precision       |   0.50189   |\n",
      "|        Average Recall        |   0.51103   |\n",
      "|       Average F1 Score       |   0.50174   |\n",
      "|         Average Loss         |   1.3966    |\n",
      "|       Average Latency        |  41.231 ms  |\n",
      "|   Average GPU Power Usage    |  19.645 W   |\n",
      "| Inference Energy Consumption | 0.22499 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/mase_graph/version_9/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_int8 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_90/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: int8\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping existing int8 cache (read_calibration_cache -> None).\n",
      "Skipping writing int8 cache (write_calibration_cache does nothing).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_92/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_93/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:45:26] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51183    |\n",
      "|      Average Precision       |   0.50626    |\n",
      "|        Average Recall        |    0.5137    |\n",
      "|       Average F1 Score       |   0.50516    |\n",
      "|         Average Loss         |    1.3877    |\n",
      "|       Average Latency        |  6.0985 ms   |\n",
      "|   Average GPU Power Usage    |   11.637 W   |\n",
      "| Inference Energy Consumption | 0.019713 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_27/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_94/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_95/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_96/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:46:07] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51788    |\n",
      "|      Average Precision       |   0.51125    |\n",
      "|        Average Recall        |   0.51916    |\n",
      "|       Average F1 Score       |   0.51082    |\n",
      "|         Average Loss         |    1.3853    |\n",
      "|       Average Latency        |  4.6722 ms   |\n",
      "|   Average GPU Power Usage    |   15.035 W   |\n",
      "| Inference Energy Consumption | 0.019513 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_28/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp32 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_97/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp32\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_98/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/2025-03-17/version_99/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet50-trt_quantized\u001b[0m\n",
      "[03/17/2025-18:46:31] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet50-trt_quantized:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.51791    |\n",
      "|      Average Precision       |    0.5114    |\n",
      "|        Average Recall        |   0.51926    |\n",
      "|       Average F1 Score       |   0.51092    |\n",
      "|         Average Loss         |    1.3853    |\n",
      "|       Average Latency        |  19.938 ms   |\n",
      "|   Average GPU Power Usage    |   15.005 W   |\n",
      "| Inference Energy Consumption | 0.083106 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet50_cls_cifar10_2025-03-17/tensorrt/version_29/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=128 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet50_cls_cifar10_2025-03-17/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MUL_PRECISION_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet50_Mul_quant.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/docs/tutorials/proj/model/resnet50/best.ckpt\"\n",
    "!python ch transform --config {MUL_PRECISION_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srcPkgs/miniconda3/lib/python3.11/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0319 01:41:30.468708 140167305331776 seed.py:57] Seed set to 0\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |     Config. File     |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |         cls          |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           |                      | /workspace/ADLS_Proj/mas | /workspace/ADLS_Proj/mas |\n",
      "|                         |                          |                      | e_output/resnet18_cls_ci | e_output/resnet18_cls_ci |\n",
      "|                         |                          |                      | far10_2025-03-08/softwar | far10_2025-03-08/softwar |\n",
      "|                         |                          |                      | e/training_ckpts/best.ck | e/training_ckpts/best.ck |\n",
      "|                         |                          |                      |            pt            |            pt            |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |                      |            pl            |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            | [8, 16, 32, 64, 128] |                          |   [8, 16, 32, 64, 128]   |\n",
      "| to_debug                |          False           |                      |                          |          False           |\n",
      "| log_level               |           info           |                      |                          |           info           |\n",
      "| report_to               |       tensorboard        |                      |                          |       tensorboard        |\n",
      "| seed                    |            0             |                      |                          |            0             |\n",
      "| quant_config            |           None           |                      |                          |           None           |\n",
      "| training_optimizer      |           adam           |                      |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                      |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |        0.001         |                          |          0.001           |\n",
      "| weight_decay            |            0             |                      |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |          10          |                          |            10            |\n",
      "| max_steps               |            -1            |                      |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                      |                          |            1             |\n",
      "| log_every_n_steps       |            50            |                      |                          |            50            |\n",
      "| num_workers             |            20            |                      |                          |            20            |\n",
      "| num_devices             |            1             |                      |                          |            1             |\n",
      "| num_nodes               |            1             |                      |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |         gpu          |                          |           gpu            |\n",
      "| strategy                |           auto           |                      |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                      |                          |          False           |\n",
      "| github_ci               |          False           |                      |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                      |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                      |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                      |                          |           100            |\n",
      "| is_pretrained           |          False           |                      |                          |          False           |\n",
      "| max_token_len           |           512            |                      |                          |           512            |\n",
      "| project_dir             | /workspace/ADLS_Proj/mas |                      |                          | /workspace/ADLS_Proj/mas |\n",
      "|                         |         e_output         |                      |                          |         e_output         |\n",
      "| project                 |           None           |                      |                          |           None           |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |       resnet18       |                          |         resnet18         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |       cifar10        |                          |         cifar10          |\n",
      "| t_max                   |            20            |                      |                          |            20            |\n",
      "| eta_min                 |          1e-06           |                      |                          |          1e-06           |\n",
      "+-------------------------+--------------------------+----------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'resnet18'...\u001b[0m\n",
      "self.args.model is resnet18\n",
      "model_info is MaseModelInfo(name='resnet', model_source=<ModelSource.TORCHVISION: 'torchvision'>, task_type=<ModelTaskType.VISION: 'vision'>, image_classification=True, physical_data_point_classification=False, sequence_classification=False, seq2seqLM=False, causal_LM=False, is_quantized=False, is_lora=False, is_sparse=False, is_fx_traceable=True)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-19\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'resnet18'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m(transnew) Using graph style transform on resnet18 ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=8 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.53327    |\n",
      "|      Average Precision       |   0.64654    |\n",
      "|        Average Recall        |   0.64912    |\n",
      "|       Average F1 Score       |   0.64651    |\n",
      "|         Average Loss         |    1.026     |\n",
      "|       Average Latency        |  5.9115 ms   |\n",
      "|   Average GPU Power Usage    |   11.894 W   |\n",
      "| Inference Energy Consumption | 0.019531 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/mase_graph/version_21/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_50/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_51/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_52/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:42:07] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.62759    |\n",
      "|      Average Precision       |    0.72678    |\n",
      "|        Average Recall        |    0.71944    |\n",
      "|       Average F1 Score       |    0.71912    |\n",
      "|         Average Loss         |    0.80693    |\n",
      "|       Average Latency        |  0.60001 ms   |\n",
      "|   Average GPU Power Usage    |   8.7055 W    |\n",
      "| Inference Energy Consumption | 0.0014509 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_11/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> sparsity_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mUsing batch_size=8 for sparsity pass\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying 2:4 structured sparsity to PyTorch weights ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2:4 structured sparsity done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting model to ONNX for FP16 + SPARSE (batch_size=8)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX exported => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_53/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding TensorRT engine with FP16 + SPARSE_WEIGHTS (batch_size=8)\u001b[0m\n",
      "TensorRT Input Shape:  (8, 3, 32, 32)\n",
      "TensorRT Optimized Input Shape: [(8, 3, 32, 32), (8, 3, 32, 32), (8, 3, 32, 32)]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSparse + FP16 TensorRT engine built => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_54/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:42:33] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.45591    |\n",
      "|      Average Precision       |    0.6829     |\n",
      "|        Average Recall        |    0.53838    |\n",
      "|       Average F1 Score       |    0.52481    |\n",
      "|         Average Loss         |    1.3923     |\n",
      "|       Average Latency        |  0.55437 ms   |\n",
      "|   Average GPU Power Usage    |   9.3351 W    |\n",
      "| Inference Energy Consumption | 0.0014375 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_12/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=8 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=16 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.63839    |\n",
      "|      Average Precision       |   0.69645    |\n",
      "|        Average Recall        |   0.69868    |\n",
      "|       Average F1 Score       |   0.69676    |\n",
      "|         Average Loss         |   0.88776    |\n",
      "|       Average Latency        |  5.1485 ms   |\n",
      "|   Average GPU Power Usage    |   12.577 W   |\n",
      "| Inference Energy Consumption | 0.017987 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/mase_graph/version_22/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_55/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_56/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_57/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:43:02] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |     0.675     |\n",
      "|      Average Precision       |    0.7321     |\n",
      "|        Average Recall        |    0.72929    |\n",
      "|       Average F1 Score       |    0.72824    |\n",
      "|         Average Loss         |    0.78645    |\n",
      "|       Average Latency        |  0.57991 ms   |\n",
      "|   Average GPU Power Usage    |   9.9692 W    |\n",
      "| Inference Energy Consumption | 0.0016059 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_13/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> sparsity_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mUsing batch_size=16 for sparsity pass\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying 2:4 structured sparsity to PyTorch weights ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2:4 structured sparsity done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting model to ONNX for FP16 + SPARSE (batch_size=16)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX exported => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_58/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding TensorRT engine with FP16 + SPARSE_WEIGHTS (batch_size=16)\u001b[0m\n",
      "TensorRT Input Shape:  (16, 3, 32, 32)\n",
      "TensorRT Optimized Input Shape: [(16, 3, 32, 32), (16, 3, 32, 32), (16, 3, 32, 32)]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSparse + FP16 TensorRT engine built => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_59/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:43:28] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.45489    |\n",
      "|      Average Precision       |    0.67223    |\n",
      "|        Average Recall        |    0.49167    |\n",
      "|       Average F1 Score       |    0.4734     |\n",
      "|         Average Loss         |    1.4755     |\n",
      "|       Average Latency        |  0.57591 ms   |\n",
      "|   Average GPU Power Usage    |   9.7974 W    |\n",
      "| Inference Energy Consumption | 0.0015673 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_14/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=16 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=32 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.70809    |\n",
      "|      Average Precision       |   0.70874    |\n",
      "|        Average Recall        |   0.71192    |\n",
      "|       Average F1 Score       |   0.70968    |\n",
      "|         Average Loss         |    0.8365    |\n",
      "|       Average Latency        |  5.8677 ms   |\n",
      "|   Average GPU Power Usage    |   14.863 W   |\n",
      "| Inference Energy Consumption | 0.024226 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/mase_graph/version_23/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_60/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_61/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_62/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:43:54] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.71685    |\n",
      "|      Average Precision       |    0.73635    |\n",
      "|        Average Recall        |    0.73422    |\n",
      "|       Average F1 Score       |    0.7338     |\n",
      "|         Average Loss         |    0.77976    |\n",
      "|       Average Latency        |  0.57844 ms   |\n",
      "|   Average GPU Power Usage    |   10.405 W    |\n",
      "| Inference Energy Consumption | 0.0016719 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_15/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> sparsity_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mUsing batch_size=32 for sparsity pass\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying 2:4 structured sparsity to PyTorch weights ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2:4 structured sparsity done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting model to ONNX for FP16 + SPARSE (batch_size=32)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX exported => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_63/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding TensorRT engine with FP16 + SPARSE_WEIGHTS (batch_size=32)\u001b[0m\n",
      "TensorRT Input Shape:  (32, 3, 32, 32)\n",
      "TensorRT Optimized Input Shape: [(32, 3, 32, 32), (32, 3, 32, 32), (32, 3, 32, 32)]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSparse + FP16 TensorRT engine built => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_64/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:44:20] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.49246    |\n",
      "|      Average Precision       |    0.67232    |\n",
      "|        Average Recall        |    0.50204    |\n",
      "|       Average F1 Score       |    0.49103    |\n",
      "|         Average Loss         |    1.4517     |\n",
      "|       Average Latency        |  0.59578 ms   |\n",
      "|   Average GPU Power Usage    |   9.4811 W    |\n",
      "| Inference Energy Consumption | 0.0015691 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_16/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=32 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=64 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72733    |\n",
      "|      Average Precision       |   0.71774    |\n",
      "|        Average Recall        |    0.7211    |\n",
      "|       Average F1 Score       |   0.71844    |\n",
      "|         Average Loss         |   0.81241    |\n",
      "|       Average Latency        |  8.1603 ms   |\n",
      "|   Average GPU Power Usage    |   11.239 W   |\n",
      "| Inference Energy Consumption | 0.025476 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/mase_graph/version_24/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_65/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_66/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_67/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:44:45] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73282    |\n",
      "|      Average Precision       |    0.73594    |\n",
      "|        Average Recall        |    0.73624    |\n",
      "|       Average F1 Score       |    0.7351     |\n",
      "|         Average Loss         |    0.77958    |\n",
      "|       Average Latency        |  0.62346 ms   |\n",
      "|   Average GPU Power Usage    |   10.433 W    |\n",
      "| Inference Energy Consumption | 0.0018069 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_17/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> sparsity_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mUsing batch_size=64 for sparsity pass\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying 2:4 structured sparsity to PyTorch weights ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2:4 structured sparsity done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting model to ONNX for FP16 + SPARSE (batch_size=64)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX exported => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_68/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding TensorRT engine with FP16 + SPARSE_WEIGHTS (batch_size=64)\u001b[0m\n",
      "TensorRT Input Shape:  (64, 3, 32, 32)\n",
      "TensorRT Optimized Input Shape: [(64, 3, 32, 32), (64, 3, 32, 32), (64, 3, 32, 32)]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSparse + FP16 TensorRT engine built => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_69/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:45:10] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.51205    |\n",
      "|      Average Precision       |    0.66844    |\n",
      "|        Average Recall        |    0.51262    |\n",
      "|       Average F1 Score       |    0.50206    |\n",
      "|         Average Loss         |    1.4257     |\n",
      "|       Average Latency        |  0.59702 ms   |\n",
      "|   Average GPU Power Usage    |   10.694 W    |\n",
      "| Inference Energy Consumption | 0.0017735 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_18/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=64 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Start passes for batch_size=128 ===\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> runtime_analysis_ori pass ...\u001b[0m\n",
      "using safe deepcopy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73052    |\n",
      "|      Average Precision       |   0.72403    |\n",
      "|        Average Recall        |   0.72725    |\n",
      "|       Average F1 Score       |   0.72451    |\n",
      "|         Average Loss         |   0.80109    |\n",
      "|       Average Latency        |  8.6898 ms   |\n",
      "|   Average GPU Power Usage    |   9.7011 W   |\n",
      "| Inference Energy Consumption | 0.023417 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/mase_graph/version_25/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> tensorrt_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_70/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "default_precision: fp16\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_71/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_72/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:45:33] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73229    |\n",
      "|      Average Precision       |    0.73298    |\n",
      "|        Average Recall        |    0.73491    |\n",
      "|       Average F1 Score       |    0.73307    |\n",
      "|         Average Loss         |    0.7835     |\n",
      "|       Average Latency        |  0.86373 ms   |\n",
      "|   Average GPU Power Usage    |   16.514 W    |\n",
      "| Inference Energy Consumption | 0.0039621 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_19/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m>> sparsity_fp16 pass ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mUsing batch_size=128 for sparsity pass\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying 2:4 structured sparsity to PyTorch weights ...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2:4 structured sparsity done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting model to ONNX for FP16 + SPARSE (batch_size=128)\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX exported => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_73/model.onnx\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding TensorRT engine with FP16 + SPARSE_WEIGHTS (batch_size=128)\u001b[0m\n",
      "TensorRT Input Shape:  (128, 3, 32, 32)\n",
      "TensorRT Optimized Input Shape: [(128, 3, 32, 32), (128, 3, 32, 32), (128, 3, 32, 32)]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSparse + FP16 TensorRT engine built => /workspace/ADLS_Proj/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/2025-03-19/version_74/model.trt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on resnet18-trt_quantized\u001b[0m\n",
      "[03/19/2025-01:45:58] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results resnet18-trt_quantized:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.52231    |\n",
      "|      Average Precision       |    0.66708    |\n",
      "|        Average Recall        |    0.52451    |\n",
      "|       Average F1 Score       |    0.5152     |\n",
      "|         Average Loss         |    1.4068     |\n",
      "|       Average Latency        |  0.81243 ms   |\n",
      "|   Average GPU Power Usage    |   11.204 W    |\n",
      "| Inference Energy Consumption | 0.0025285 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /workspace/mase_output/tensorrt/quantization/resnet18_cls_cifar10_2025-03-19/tensorrt/version_20/model.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m=== Finished passes for batch_size=128 ===\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPlot saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-19/software/transform/multi_bs_curves.png\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCSV saved to: /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-19/software/transform/multi_bs_results.csv\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-19/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mtransform_graph complete.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "FP16_SPARSITY_BY_TYPE_TOML = \"/workspace/ADLS_Proj/docs/tutorials/proj/resnet18_FP16_spar.toml\"\n",
    "RES_CHECKPOINT_PATH = \"/workspace/ADLS_Proj/mase_output/resnet18_cls_cifar10_2025-03-08/software/training_ckpts/best.ckpt\"\n",
    "!python ch transform --config {FP16_SPARSITY_BY_TYPE_TOML} --load {RES_CHECKPOINT_PATH} --load-type pl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
